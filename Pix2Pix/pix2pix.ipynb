{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvrajsingh/miniconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "    device = 'cpu'\n",
    "    batch_size = 1\n",
    "    lr = 0.0002\n",
    "    img_size = 256\n",
    "    no_of_channels = 3\n",
    "    kernel_size = (4,4)\n",
    "    stride = 2\n",
    "    dropout = 0.5\n",
    "    padding = 1\n",
    "    lr_slope = 0.2\n",
    "    beta_1 = 0.5\n",
    "    beta_2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms for images\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    transforms.Resize(size=(ModelArgs.img_size,ModelArgs.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)  #mean = 0, std = 0.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(ModelArgs.no_of_channels, 64, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(128, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(256, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=ModelArgs.kernel_size, stride=1, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=ModelArgs.kernel_size, stride=1 ,padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connection = []\n",
    "        for layer in self.main:\n",
    "            x = layer(x)\n",
    "            if isinstance(layer, nn.LeakyReLU):\n",
    "                skip_connection.append(x)\n",
    "        return x, skip_connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.randn((ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size), device=ModelArgs.device)\n",
    "enc = enc.to(ModelArgs.device)\n",
    "x, skip_connection = enc(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "Encoder (Encoder)                        [1, 3, 256, 256]     [1, 512, 2, 2]       --                   True\n",
       "├─Sequential (main)                      --                   --                   --                   True\n",
       "│    └─Conv2d (0)                        [1, 3, 256, 256]     [1, 64, 128, 128]    3,136                True\n",
       "│    └─LeakyReLU (1)                     [1, 64, 128, 128]    [1, 64, 128, 128]    --                   --\n",
       "│    └─Conv2d (2)                        [1, 64, 128, 128]    [1, 128, 64, 64]     131,200              True\n",
       "│    └─InstanceNorm2d (3)                [1, 128, 64, 64]     [1, 128, 64, 64]     256                  True\n",
       "│    └─LeakyReLU (4)                     [1, 128, 64, 64]     [1, 128, 64, 64]     --                   --\n",
       "│    └─Conv2d (5)                        [1, 128, 64, 64]     [1, 256, 32, 32]     524,544              True\n",
       "│    └─InstanceNorm2d (6)                [1, 256, 32, 32]     [1, 256, 32, 32]     512                  True\n",
       "│    └─LeakyReLU (7)                     [1, 256, 32, 32]     [1, 256, 32, 32]     --                   --\n",
       "│    └─Conv2d (8)                        [1, 256, 32, 32]     [1, 512, 16, 16]     2,097,664            True\n",
       "│    └─InstanceNorm2d (9)                [1, 512, 16, 16]     [1, 512, 16, 16]     1,024                True\n",
       "│    └─LeakyReLU (10)                    [1, 512, 16, 16]     [1, 512, 16, 16]     --                   --\n",
       "│    └─Conv2d (11)                       [1, 512, 16, 16]     [1, 512, 8, 8]       4,194,816            True\n",
       "│    └─InstanceNorm2d (12)               [1, 512, 8, 8]       [1, 512, 8, 8]       1,024                True\n",
       "│    └─LeakyReLU (13)                    [1, 512, 8, 8]       [1, 512, 8, 8]       --                   --\n",
       "│    └─Conv2d (14)                       [1, 512, 8, 8]       [1, 512, 4, 4]       4,194,816            True\n",
       "│    └─InstanceNorm2d (15)               [1, 512, 4, 4]       [1, 512, 4, 4]       1,024                True\n",
       "│    └─LeakyReLU (16)                    [1, 512, 4, 4]       [1, 512, 4, 4]       --                   --\n",
       "│    └─Conv2d (17)                       [1, 512, 4, 4]       [1, 512, 3, 3]       4,194,816            True\n",
       "│    └─InstanceNorm2d (18)               [1, 512, 3, 3]       [1, 512, 3, 3]       1,024                True\n",
       "│    └─LeakyReLU (19)                    [1, 512, 3, 3]       [1, 512, 3, 3]       --                   --\n",
       "│    └─Conv2d (20)                       [1, 512, 3, 3]       [1, 512, 2, 2]       4,194,816            True\n",
       "│    └─InstanceNorm2d (21)               [1, 512, 2, 2]       [1, 512, 2, 2]       1,024                True\n",
       "│    └─LeakyReLU (22)                    [1, 512, 2, 2]       [1, 512, 2, 2]       --                   --\n",
       "========================================================================================================================\n",
       "Total params: 19,541,696\n",
       "Trainable params: 19,541,696\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.05\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 23.83\n",
       "Params size (MB): 78.17\n",
       "Estimated Total Size (MB): 102.78\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# images = torch.randn(64, 1, 64, 64)\n",
    "# labels = torch.randint(0, 10, (64,), dtype=torch.long)\n",
    "enc = Encoder()\n",
    "summary(model=enc,\n",
    "        input_size=(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size),\n",
    "        # input_data=(images.to(ModelArgs.device), labels.to(ModelArgs.device)),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArgs.stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArgs.kernel_size = (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            # nn.Upsample(size=(3,3)),\n",
    "            nn.ConvTranspose2d(512, 512, kernel_size=ModelArgs.kernel_size, stride=1, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512*2,affine=True),\n",
    "            nn.Dropout(p=ModelArgs.dropout),\n",
    "            nn.ReLU(),\n",
    "            # print(\"DOnE\"),\n",
    "            \n",
    "            # nn.Upsample(size=(4,4)),\n",
    "            nn.ConvTranspose2d(512*2, 512, kernel_size=ModelArgs.kernel_size, stride=1, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512*2,affine=True),\n",
    "            nn.Dropout(p=ModelArgs.dropout),\n",
    "            nn.ReLU(),\n",
    "               \n",
    "            # nn.Upsample(size=(8,8)),\n",
    "            nn.ConvTranspose2d(512*2, 512, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512*2,affine=True),\n",
    "            nn.Dropout(p=ModelArgs.dropout),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # nn.Upsample(size=(16,16)),\n",
    "            nn.ConvTranspose2d(512*2, 512, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512*2,affine=True),\n",
    "            # nn.Dropout(p=ModelArgs.dropout),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # nn.Upsample(size=(32,32)),\n",
    "            nn.ConvTranspose2d(512*2, 256, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride,padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(256*2,affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # nn.Upsample(size=(64,64)),\n",
    "            nn.ConvTranspose2d(256*2, 128, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride,padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(128*2,affine=True),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # nn.Upsample(size=(128,128)),\n",
    "            nn.ConvTranspose2d(128*2, 64, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride,padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(64*2,affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # nn.Upsample(size=(256,256)),\n",
    "            # nn.Conv2d(256*2, 128, kernel_size=ModelArgs.kernel_size, padding=ModelArgs.padding),\n",
    "            # nn.InstanceNorm2d(128,affine=True),\n",
    "            # nn.ReLU(),\n",
    "            \n",
    "            \n",
    "            nn.ConvTranspose2d(64*2, ModelArgs.no_of_channels, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, skip_connection):\n",
    "        \n",
    "        skip_connection = skip_connection[-2::-1]\n",
    "        count = 0\n",
    "        for idx, layer in enumerate(self.main):\n",
    "            \n",
    "            # print(\"Original: \", x.shape)\n",
    "            if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.ConvTranspose2d)) and count < len(skip_connection):\n",
    "                \n",
    "                # print(f\"Before applying layer{layer}\", x.shape)\n",
    "                x = layer(x)\n",
    "                # print(f\"After applying layer{layer}:\", x.shape)\n",
    "                # print(\"Skip connection:\",skip_connection[count].shape)\n",
    "                x = torch.concat([x, skip_connection[count]], dim=1)\n",
    "                # print(\"Final: \", x.shape)\n",
    "                # print(count)\n",
    "                count += 1\n",
    "            else:\n",
    "                # print(f\"Before applying layer{layer}\", x.shape)\n",
    "                x = layer(x)\n",
    "                # print(f\"After applying layer{layer}:\", x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 6.8836e-01,  3.2033e-01,  3.3346e-01,  ...,  4.5964e-02,\n",
       "            -1.0953e-01, -5.0371e-02],\n",
       "           [ 5.0429e-01, -6.7398e-02,  1.4376e-01,  ...,  2.1144e-01,\n",
       "             4.6284e-01,  9.5048e-01],\n",
       "           [-9.5324e-02,  6.7478e-01,  1.7943e-01,  ...,  3.3460e-01,\n",
       "             2.6215e-01,  2.3474e-01],\n",
       "           ...,\n",
       "           [ 5.4861e-01,  2.3438e-01,  2.9127e-01,  ..., -4.9607e-02,\n",
       "            -2.8231e-02,  3.3847e-01],\n",
       "           [ 2.1475e-01, -1.9573e-01,  3.0462e-01,  ...,  6.6461e-01,\n",
       "            -1.6278e-01, -8.4918e-02],\n",
       "           [ 3.6583e-01,  1.9185e-01,  1.4353e+00,  ..., -4.2945e-04,\n",
       "            -9.7129e-02,  3.6384e-02]],\n",
       " \n",
       "          [[-8.0441e-02,  1.1631e-01,  4.8557e-01,  ...,  5.0810e-01,\n",
       "            -8.2178e-02,  1.8448e-01],\n",
       "           [ 4.5781e-01,  7.2728e-01, -5.7750e-02,  ...,  6.5324e-01,\n",
       "            -6.5259e-02,  7.0425e-01],\n",
       "           [-1.1518e-01, -2.9324e-01, -2.3471e-02,  ...,  4.6726e-01,\n",
       "             1.2763e+00,  2.8709e-01],\n",
       "           ...,\n",
       "           [ 5.5297e-01, -1.9333e-02,  1.1683e+00,  ...,  2.2518e-01,\n",
       "            -1.0646e-01, -4.3942e-02],\n",
       "           [ 4.0892e-02,  2.4176e-01,  2.0272e-01,  ...,  9.4306e-01,\n",
       "             3.7832e-01, -6.1746e-02],\n",
       "           [ 1.0502e-01, -1.2335e-01, -3.6351e-02,  ...,  1.3735e+00,\n",
       "            -2.0193e-01, -3.0789e-02]],\n",
       " \n",
       "          [[-3.2660e-02,  7.7807e-01, -2.6939e-02,  ..., -1.7415e-01,\n",
       "             1.3917e-01, -8.5018e-03],\n",
       "           [ 4.8567e-01, -1.5629e-01,  1.3689e+00,  ...,  5.0111e-01,\n",
       "            -9.2067e-02, -9.0785e-02],\n",
       "           [-8.0621e-02,  2.4088e-01, -9.5723e-02,  ..., -3.2340e-02,\n",
       "             3.2688e-02, -1.3561e-01],\n",
       "           ...,\n",
       "           [ 1.8365e-01, -9.6001e-02, -6.3730e-02,  ...,  8.1673e-01,\n",
       "             2.9673e-01, -6.2847e-04],\n",
       "           [ 6.8348e-01, -2.1556e-01, -2.3116e-02,  ..., -3.9544e-02,\n",
       "            -9.6188e-02,  4.8810e-01],\n",
       "           [-2.8965e-02,  1.0560e+00,  5.7462e-01,  ...,  5.1644e-01,\n",
       "            -3.1509e-01, -7.7777e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.4970e-02,  4.8938e-01, -3.3799e-02,  ..., -6.9263e-02,\n",
       "             4.2710e-01, -7.0750e-02],\n",
       "           [-7.0296e-02, -3.3629e-03,  1.1006e+00,  ..., -2.7415e-02,\n",
       "            -1.3748e-02,  3.8730e-01],\n",
       "           [ 5.6111e-01, -9.5702e-03,  2.6499e-01,  ...,  1.4511e-01,\n",
       "             4.5708e-01, -1.4359e-01],\n",
       "           ...,\n",
       "           [-2.8220e-01, -1.9863e-01,  1.1235e-01,  ..., -6.5845e-02,\n",
       "             7.4249e-01,  5.4307e-01],\n",
       "           [ 2.4189e-01, -5.7312e-03,  5.0606e-01,  ...,  3.1663e-01,\n",
       "            -1.7451e-01, -2.4855e-02],\n",
       "           [-9.8211e-02, -2.0366e-01, -3.4828e-02,  ...,  7.4371e-01,\n",
       "             4.0996e-01,  3.6838e-01]],\n",
       " \n",
       "          [[-1.1833e-01, -2.2670e-01,  7.1129e-01,  ..., -2.4814e-02,\n",
       "             2.7163e-01,  7.8062e-03],\n",
       "           [ 4.6653e-01, -4.7809e-02, -6.5472e-02,  ...,  4.1169e-01,\n",
       "             9.2548e-01,  1.8380e+00],\n",
       "           [-4.2064e-02, -3.1912e-01, -2.1280e-01,  ..., -1.4358e-02,\n",
       "            -1.9544e-01, -2.8640e-02],\n",
       "           ...,\n",
       "           [-1.0982e-02,  4.4800e-01, -1.1541e-01,  ..., -1.3668e-02,\n",
       "            -3.8410e-02, -1.8603e-02],\n",
       "           [-1.0033e-01,  3.7145e-01,  2.6990e-02,  ...,  1.1026e+00,\n",
       "            -9.8594e-02, -7.0395e-02],\n",
       "           [-7.7390e-02, -1.1954e-01,  4.0627e-01,  ...,  8.7749e-02,\n",
       "             5.3037e-01, -2.5992e-02]],\n",
       " \n",
       "          [[ 3.3706e-01, -5.3223e-02,  4.5604e-01,  ...,  9.3054e-01,\n",
       "            -2.0192e-01, -8.5571e-04],\n",
       "           [ 7.8831e-01, -9.9772e-02,  1.3004e-01,  ...,  9.5061e-02,\n",
       "             3.2149e-01,  3.0710e-01],\n",
       "           [-2.1040e-01,  1.1114e-01, -2.0466e-01,  ..., -1.1668e-01,\n",
       "            -9.7226e-02,  7.5357e-01],\n",
       "           ...,\n",
       "           [ 9.2942e-01, -5.9015e-02, -1.5253e-01,  ..., -2.5188e-02,\n",
       "             1.6559e-01, -5.8352e-02],\n",
       "           [-3.0800e-02,  3.1645e-01, -1.0321e-01,  ...,  1.0657e+00,\n",
       "            -8.7340e-02, -2.2169e-01],\n",
       "           [-1.2828e-01,  4.8698e-01, -3.4797e-02,  ...,  1.4264e-01,\n",
       "             1.9913e-01, -4.0390e-02]]]], grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[[ 1.9119e-01, -1.4699e-01, -3.1243e-02,  ..., -3.5791e-01,\n",
       "             1.3174e-01,  6.6006e-03],\n",
       "           [ 1.3427e+00, -1.1270e-01, -6.5518e-02,  ...,  1.6520e-01,\n",
       "             6.6561e-01,  6.6701e-01],\n",
       "           [-1.4994e-01,  3.6770e-01, -1.0242e-01,  ..., -6.8370e-02,\n",
       "             1.7391e+00, -2.3638e-01],\n",
       "           ...,\n",
       "           [-7.3247e-02, -7.1634e-02, -7.6636e-02,  ..., -1.1385e-01,\n",
       "            -1.6094e-01,  4.4409e-01],\n",
       "           [-2.9939e-01, -1.3719e-01, -2.0187e-01,  ...,  7.2268e-01,\n",
       "             4.2420e-01, -8.0403e-02],\n",
       "           [-1.7481e-01,  3.0512e-01,  8.1054e-01,  ..., -9.3510e-02,\n",
       "             4.5594e-03, -4.4873e-02]],\n",
       " \n",
       "          [[ 7.9077e-01,  6.4459e-01,  2.1906e-03,  ...,  4.9283e-01,\n",
       "            -3.9495e-02, -3.7175e-02],\n",
       "           [-1.2625e-02,  7.1750e-01, -3.5479e-01,  ..., -9.7225e-02,\n",
       "            -1.2818e-01,  6.6095e-01],\n",
       "           [ 1.5066e+00,  3.4337e-01, -2.0957e-01,  ..., -4.3549e-01,\n",
       "             1.0064e+00, -2.0871e-01],\n",
       "           ...,\n",
       "           [ 2.7365e-01, -4.2711e-01, -1.7206e-01,  ...,  1.0874e+00,\n",
       "            -3.0659e-01, -1.6968e-01],\n",
       "           [ 1.3755e+00,  5.5367e-01, -1.1530e-02,  ..., -2.7567e-01,\n",
       "             9.8689e-01,  7.0047e-01],\n",
       "           [ 4.1498e-01,  2.0819e-01,  5.8713e-01,  ..., -2.0704e-01,\n",
       "             1.0383e+00,  2.1025e-01]],\n",
       " \n",
       "          [[-3.5616e-02, -2.4373e-01, -2.4642e-01,  ...,  4.1765e-01,\n",
       "            -4.5671e-01, -7.2474e-02],\n",
       "           [ 1.9215e+00, -2.8916e-02, -9.3182e-02,  ..., -6.0862e-02,\n",
       "            -1.0606e-01, -2.0010e-01],\n",
       "           [ 7.1498e-01, -5.5547e-02,  5.5622e-01,  ...,  8.8866e-01,\n",
       "            -2.0670e-01, -1.8503e-01],\n",
       "           ...,\n",
       "           [ 3.4434e-01,  9.2688e-02,  4.9559e-01,  ..., -2.3223e-01,\n",
       "            -4.3366e-02,  4.2810e-01],\n",
       "           [ 3.5060e-03,  4.0747e-01,  9.2459e-01,  ...,  7.9309e-01,\n",
       "            -4.0362e-02,  2.3793e-01],\n",
       "           [ 6.0740e-03,  3.8428e-01, -1.7823e-01,  ...,  2.3232e-01,\n",
       "             9.8762e-01,  7.1205e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3416e+00,  9.0051e-01,  5.6211e-01,  ...,  9.6515e-01,\n",
       "             2.8022e-01,  2.3144e-01],\n",
       "           [ 2.0359e+00, -1.1134e-01,  9.4424e-01,  ...,  6.1601e-01,\n",
       "            -1.6446e-01,  1.5838e-01],\n",
       "           [ 1.4895e+00,  5.8712e-01, -2.4349e-01,  ...,  1.0625e-01,\n",
       "             6.0135e-01, -9.4417e-02],\n",
       "           ...,\n",
       "           [-2.2476e-01, -3.9262e-01, -1.2474e-01,  ..., -2.8551e-01,\n",
       "            -3.7653e-02, -1.8787e-01],\n",
       "           [ 1.6081e+00, -2.0449e-02, -3.3519e-01,  ..., -2.4906e-01,\n",
       "            -1.6970e-01,  1.4447e+00],\n",
       "           [ 1.0270e-01, -2.9783e-02,  1.7322e+00,  ..., -4.4590e-02,\n",
       "             1.4604e+00,  6.9901e-01]],\n",
       " \n",
       "          [[ 6.6075e-02, -2.9235e-01, -2.6525e-01,  ...,  1.0621e+00,\n",
       "            -1.7711e-01, -9.5669e-02],\n",
       "           [-3.3338e-02,  5.0572e-01, -8.1497e-02,  ..., -1.5122e-01,\n",
       "            -1.1096e-01, -1.7697e-03],\n",
       "           [-2.1082e-02, -1.9693e-01, -1.9921e-01,  ..., -2.1168e-01,\n",
       "             6.9999e-01,  7.8275e-01],\n",
       "           ...,\n",
       "           [ 2.2534e+00,  2.0058e-01,  2.6838e-01,  ...,  6.4644e-01,\n",
       "            -1.0346e-01,  4.1282e-01],\n",
       "           [ 6.9058e-01,  9.7057e-01,  8.2026e-02,  ..., -1.4314e-01,\n",
       "            -5.3226e-01,  1.6812e+00],\n",
       "           [ 6.2659e-01, -7.0012e-02,  1.2879e-01,  ...,  5.3710e-01,\n",
       "             1.1277e+00,  7.9947e-01]],\n",
       " \n",
       "          [[-2.9007e-01, -2.9203e-01, -1.1223e-01,  ..., -5.7583e-02,\n",
       "            -7.1734e-02,  4.2835e-02],\n",
       "           [ 1.2690e+00,  1.6371e-01, -2.1359e-01,  ..., -4.0766e-01,\n",
       "             1.4509e+00, -7.9486e-02],\n",
       "           [-6.1875e-02, -5.4194e-02, -3.5892e-01,  ...,  7.0052e-01,\n",
       "            -1.1180e-01,  6.7196e-01],\n",
       "           ...,\n",
       "           [ 2.7321e-01,  6.0913e-02,  1.2094e+00,  ..., -2.9222e-01,\n",
       "             2.5685e-03,  6.2412e-01],\n",
       "           [ 1.2546e+00,  9.8053e-01,  8.3923e-03,  ..., -2.3062e-02,\n",
       "            -1.4442e-01, -1.7633e-01],\n",
       "           [ 6.9941e-01, -1.8131e-01, -2.3154e-01,  ...,  1.0190e+00,\n",
       "             1.3097e-01,  1.0516e+00]]]], grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[[-0.1049,  0.5832,  0.2622,  ..., -0.0943,  0.0702, -0.1590],\n",
       "           [ 1.7746,  0.8255, -0.2482,  ...,  0.9631, -0.0450, -0.0392],\n",
       "           [-0.2368, -0.1195,  0.3892,  ..., -0.1270, -0.1466, -0.0095],\n",
       "           ...,\n",
       "           [ 0.5441, -0.0424,  0.1107,  ..., -0.0879,  0.9448, -0.0376],\n",
       "           [ 0.4081,  0.2132, -0.0654,  ..., -0.1819, -0.1651, -0.1850],\n",
       "           [-0.1921, -0.0466, -0.0629,  ..., -0.2772,  0.5399, -0.1097]],\n",
       " \n",
       "          [[ 0.2380,  0.1255,  1.1787,  ...,  0.5097,  0.7606,  0.3589],\n",
       "           [ 1.1644,  0.4648, -0.1383,  ..., -0.0259,  1.0636,  0.0869],\n",
       "           [-0.0145, -0.2077,  0.4275,  ...,  0.1848, -0.1554,  0.3277],\n",
       "           ...,\n",
       "           [-0.0948,  0.4776,  0.5012,  ..., -0.0497,  0.5236, -0.1395],\n",
       "           [ 1.0521, -0.1515,  0.6181,  ...,  0.9471,  0.8991, -0.0820],\n",
       "           [ 0.8039, -0.0623,  0.3572,  ...,  0.7734,  0.7324, -0.1606]],\n",
       " \n",
       "          [[ 0.1743, -0.0098, -0.2105,  ...,  0.6255,  0.0675,  1.5165],\n",
       "           [-0.0829,  0.9981,  0.8324,  ..., -0.2732, -0.2658,  0.3647],\n",
       "           [-0.0876,  0.5361, -0.1621,  ...,  0.7310, -0.2223, -0.0631],\n",
       "           ...,\n",
       "           [-0.0102,  0.1045,  0.0916,  ..., -0.0971,  0.4644,  0.1887],\n",
       "           [-0.0061, -0.0825,  0.5679,  ..., -0.0167,  0.1019,  0.6214],\n",
       "           [-0.3101, -0.0889,  0.8776,  ..., -0.0489,  0.7436,  1.0128]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1067, -0.0634,  1.3900,  ..., -0.2227,  0.1202,  0.3399],\n",
       "           [-0.0683,  1.0805, -0.3489,  ...,  0.1358,  0.2486,  0.6577],\n",
       "           [-0.2469, -0.1073,  3.9993,  ..., -0.3398,  0.5649,  0.1216],\n",
       "           ...,\n",
       "           [-0.2025, -0.2650, -0.0483,  ..., -0.4280,  1.6012,  0.6936],\n",
       "           [-0.0305, -0.1735,  0.0222,  ..., -0.2057, -0.0520, -0.2315],\n",
       "           [-0.1497,  0.4688, -0.0390,  ..., -0.0735, -0.0827, -0.1331]],\n",
       " \n",
       "          [[-0.1369,  0.4509,  0.2395,  ..., -0.1160,  0.5765,  0.4380],\n",
       "           [-0.1739,  0.6698, -0.1231,  ...,  1.1224, -0.1567,  0.1756],\n",
       "           [-0.2781, -0.1103, -0.2628,  ...,  0.9510,  0.4623,  1.4872],\n",
       "           ...,\n",
       "           [ 0.4151, -0.5956, -0.0945,  ...,  1.0323, -0.0631,  0.5288],\n",
       "           [ 0.6450,  0.9215,  0.0121,  ..., -0.0645,  1.0147, -0.1163],\n",
       "           [-0.1662, -0.0970,  0.8516,  ...,  1.0469,  1.8030, -0.2171]],\n",
       " \n",
       "          [[-0.0655, -0.1654,  0.1702,  ..., -0.1172, -0.1706,  0.4911],\n",
       "           [ 0.9880,  0.8653,  0.5981,  ...,  1.0761,  0.0376,  1.6238],\n",
       "           [-0.0444,  1.3291, -0.1127,  ..., -0.3687,  2.0562,  1.8258],\n",
       "           ...,\n",
       "           [ 0.4603,  0.7892, -0.5781,  ...,  1.5488,  2.4591, -0.3327],\n",
       "           [ 1.1412, -0.0605, -0.0141,  ..., -0.4177, -0.0191, -0.0706],\n",
       "           [-0.0923, -0.0061,  1.1991,  ..., -0.0114,  0.6456, -0.2268]]]],\n",
       "        grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[[-1.6382e-01,  1.3493e+00, -2.9241e-01,  ..., -1.0124e-01,\n",
       "            -1.8693e-01, -1.6203e-01],\n",
       "           [ 5.0574e-01,  3.5666e-01, -1.3186e-01,  ...,  5.2551e-01,\n",
       "             1.1281e+00, -1.1991e-01],\n",
       "           [ 7.4280e-02, -6.4544e-02,  3.4850e-01,  ...,  1.7256e+00,\n",
       "            -1.0137e-01,  8.8076e-01],\n",
       "           ...,\n",
       "           [ 1.0173e+00, -2.0492e-01, -8.6088e-02,  ...,  2.8819e-01,\n",
       "             1.5094e-01, -2.1084e-01],\n",
       "           [-1.9577e-01, -3.2660e-01, -2.5581e-01,  ...,  1.9267e+00,\n",
       "             1.1743e+00, -3.1928e-02],\n",
       "           [ 1.6301e-02, -1.9870e-02, -3.6212e-01,  ...,  4.9272e-01,\n",
       "            -6.9574e-03, -1.4371e-01]],\n",
       " \n",
       "          [[-6.5573e-02,  4.1701e-02, -1.0443e-01,  ...,  1.0590e-01,\n",
       "            -1.9457e-01,  1.6490e-01],\n",
       "           [-2.1771e-01, -1.2628e-01,  4.4836e-01,  ..., -2.4570e-01,\n",
       "             6.2279e-01, -4.1286e-03],\n",
       "           [-7.0380e-02,  1.7768e-01, -5.0584e-02,  ...,  1.8024e+00,\n",
       "            -1.5128e-01, -9.5367e-03],\n",
       "           ...,\n",
       "           [ 7.8188e-01,  1.0208e+00,  2.1322e+00,  ...,  5.7320e-01,\n",
       "            -1.9322e-01, -2.6860e-01],\n",
       "           [ 1.0939e+00, -1.7687e-02, -5.5320e-02,  ..., -3.8645e-02,\n",
       "            -1.6626e-01,  1.0329e-01],\n",
       "           [-8.2692e-02,  1.5978e+00,  2.1812e+00,  ..., -5.1047e-02,\n",
       "             1.7885e+00, -1.2792e-01]],\n",
       " \n",
       "          [[ 1.8674e-01,  9.8311e-01, -1.8940e-01,  ...,  1.6486e+00,\n",
       "             6.8021e-01, -7.8443e-03],\n",
       "           [ 2.9749e-01,  2.0616e-01,  2.1855e+00,  ..., -1.7381e-01,\n",
       "            -1.8918e-01,  6.4543e-02],\n",
       "           [ 2.9062e-01, -1.2727e-01, -2.9039e-01,  ..., -3.2808e-02,\n",
       "            -3.5487e-01, -5.3812e-02],\n",
       "           ...,\n",
       "           [-2.0857e-01, -3.4847e-01,  1.0409e+00,  ...,  1.1761e+00,\n",
       "            -1.2449e-01,  4.1814e-01],\n",
       "           [-1.0244e-01, -3.0340e-01,  2.0262e-01,  ...,  1.3315e+00,\n",
       "             2.3505e-01, -8.0676e-02],\n",
       "           [ 8.8463e-01, -1.9641e-01,  8.4103e-01,  ..., -5.0961e-02,\n",
       "             6.1951e-01,  3.8969e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1948e-01, -2.4302e-01,  5.7583e-02,  ..., -1.0029e-01,\n",
       "             3.8897e-01, -2.5215e-01],\n",
       "           [-2.7001e-02,  1.3976e-02,  5.7101e-01,  ..., -2.2880e-01,\n",
       "            -1.1972e-01, -3.3466e-01],\n",
       "           [-3.9801e-01,  1.6775e+00, -8.3805e-02,  ...,  1.7348e-01,\n",
       "            -1.6506e-01, -1.7197e-01],\n",
       "           ...,\n",
       "           [-6.1851e-02, -5.2603e-01, -3.5404e-01,  ..., -2.0473e-01,\n",
       "            -3.7276e-03,  3.4210e-01],\n",
       "           [-4.4769e-01,  1.5579e+00, -1.5784e-01,  ...,  6.3278e-01,\n",
       "             4.2322e-01,  9.8031e-01],\n",
       "           [ 3.7907e-01, -5.0824e-02,  1.1602e+00,  ...,  7.8010e-01,\n",
       "             5.6113e-01,  4.6188e-01]],\n",
       " \n",
       "          [[-8.9479e-02, -3.0555e-02, -9.8873e-02,  ...,  4.3204e-01,\n",
       "            -3.0625e-01,  1.2091e+00],\n",
       "           [-1.5926e-03,  1.0943e+00,  2.8553e-01,  ...,  5.9834e-01,\n",
       "            -3.4261e-01, -1.6084e-01],\n",
       "           [ 5.0974e-01, -2.4521e-02,  6.5991e-01,  ...,  1.2479e+00,\n",
       "            -2.1223e-01, -2.8687e-01],\n",
       "           ...,\n",
       "           [ 5.9574e-01,  6.5794e-01, -2.7451e-05,  ..., -1.1761e-01,\n",
       "             2.6324e-01,  3.0351e-01],\n",
       "           [ 1.1312e+00, -3.0647e-01, -1.4121e-01,  ..., -3.8228e-01,\n",
       "            -4.8687e-01,  2.6849e-01],\n",
       "           [ 5.7375e-01,  1.5018e+00,  1.6633e-01,  ...,  1.0202e+00,\n",
       "             8.8879e-01, -1.2677e-01]],\n",
       " \n",
       "          [[-8.3457e-02, -3.2434e-02, -1.2600e-01,  ..., -1.6728e-01,\n",
       "            -5.2156e-02,  1.1435e+00],\n",
       "           [-6.5599e-02,  1.7387e+00,  2.3192e-01,  ..., -2.4257e-01,\n",
       "            -1.8435e-01,  4.2530e-01],\n",
       "           [-2.5498e-02, -2.8004e-01,  6.7988e-01,  ..., -2.6142e-02,\n",
       "            -1.2060e-01, -8.8549e-02],\n",
       "           ...,\n",
       "           [-1.4873e-01, -4.0156e-01, -6.5004e-02,  ...,  1.1336e+00,\n",
       "            -6.6881e-02,  3.2136e-02],\n",
       "           [ 5.1278e-01,  3.1877e-01, -1.1955e-01,  ..., -7.3238e-02,\n",
       "            -9.4223e-02,  9.8428e-01],\n",
       "           [ 5.2047e-01, -3.1896e-02, -9.7628e-02,  ..., -8.2202e-02,\n",
       "             6.9735e-01,  7.5411e-01]]]], grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[[ 4.5396e-01,  7.4970e-01,  2.4243e-01,  ..., -1.6823e-02,\n",
       "            -1.4591e-01,  6.4813e-01],\n",
       "           [ 2.5174e-01, -1.6837e-01,  2.6188e+00,  ..., -4.0315e-02,\n",
       "             5.7355e-01,  1.2946e+00],\n",
       "           [ 1.0816e+00,  6.3129e-01,  7.9492e-03,  ..., -3.7436e-01,\n",
       "             1.4215e+00, -1.7740e-02],\n",
       "           ...,\n",
       "           [-1.5524e-01, -1.2937e-01, -9.1915e-02,  ...,  7.0917e-01,\n",
       "             1.2375e+00, -5.7265e-02],\n",
       "           [ 1.0747e+00, -4.2770e-01, -2.7328e-02,  ...,  5.6493e-01,\n",
       "            -1.6526e-01,  3.1042e-01],\n",
       "           [-3.7257e-02, -2.5347e-02,  8.2112e-01,  ...,  1.0927e+00,\n",
       "             1.2470e+00,  6.2028e-01]],\n",
       " \n",
       "          [[ 7.5145e-01,  1.4852e+00, -1.2249e-01,  ..., -6.7260e-02,\n",
       "             1.0050e+00,  9.6251e-03],\n",
       "           [ 8.1847e-01,  8.8470e-01, -2.7305e-01,  ...,  1.7295e+00,\n",
       "             1.1001e+00, -1.6131e-01],\n",
       "           [-1.0705e-01,  9.5581e-01,  4.8410e-02,  ..., -6.4630e-02,\n",
       "            -6.5958e-02,  2.2081e-03],\n",
       "           ...,\n",
       "           [-2.2461e-01,  8.3625e-01, -2.0572e-02,  ..., -1.4981e-01,\n",
       "             7.7234e-01,  1.3645e-01],\n",
       "           [-6.6346e-03, -2.1858e-02,  2.3158e+00,  ...,  4.8929e-01,\n",
       "             2.2351e+00, -7.2139e-02],\n",
       "           [-1.0290e-01,  1.0435e+00,  4.9808e-01,  ..., -1.6374e-01,\n",
       "            -3.0027e-02, -1.6127e-01]],\n",
       " \n",
       "          [[ 3.4509e-01,  1.2073e+00,  1.0187e-01,  ...,  1.8591e+00,\n",
       "            -1.5285e-01,  3.9477e-01],\n",
       "           [-6.4811e-02, -5.8970e-02, -5.0895e-02,  ...,  1.2174e+00,\n",
       "            -2.5384e-01, -2.0210e-02],\n",
       "           [ 7.1455e-01,  3.4653e-01, -2.3538e-01,  ...,  2.7220e-01,\n",
       "             6.7142e-01,  6.6010e-01],\n",
       "           ...,\n",
       "           [-3.4043e-01, -1.3362e-01,  1.4105e+00,  ...,  6.2676e-01,\n",
       "            -3.4598e-01, -8.2705e-02],\n",
       "           [-2.2709e-02, -4.4933e-03,  5.1143e-01,  ..., -2.4162e-02,\n",
       "            -1.3621e-01,  1.0701e+00],\n",
       "           [-1.0264e-01, -6.6722e-02, -8.3603e-02,  ..., -3.9014e-03,\n",
       "            -1.1130e-01,  5.7073e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1105e-01, -1.4816e-01, -3.3417e-02,  ...,  5.9458e-01,\n",
       "            -2.6008e-01,  1.6751e+00],\n",
       "           [ 4.2488e-01, -1.9713e-01, -2.3183e-01,  ...,  1.7862e+00,\n",
       "             1.6896e-01,  2.5439e-01],\n",
       "           [ 2.4109e-01,  1.0541e+00, -5.6066e-02,  ...,  3.8900e-01,\n",
       "            -8.3076e-02, -3.5311e-01],\n",
       "           ...,\n",
       "           [-1.1543e-01, -1.5789e-01, -3.7463e-01,  ...,  1.5851e-01,\n",
       "            -2.6352e-02,  1.3691e-01],\n",
       "           [-2.9849e-02, -4.1878e-01,  7.8579e-01,  ..., -1.7494e-01,\n",
       "             6.7487e-01,  6.9355e-01],\n",
       "           [-9.3908e-02, -6.2548e-02, -2.3733e-01,  ...,  3.8516e-01,\n",
       "             1.0902e+00,  1.3345e-01]],\n",
       " \n",
       "          [[-3.0896e-02,  6.2532e-01, -4.8794e-02,  ..., -4.8590e-03,\n",
       "            -3.3143e-01,  3.4553e-01],\n",
       "           [-1.9706e-01, -5.5735e-02,  1.7462e+00,  ...,  8.5277e-01,\n",
       "            -3.3218e-01,  1.0167e+00],\n",
       "           [-1.4144e-01, -3.2539e-01, -8.7973e-02,  ..., -3.8159e-01,\n",
       "             2.4760e-01, -1.0894e-01],\n",
       "           ...,\n",
       "           [-2.3337e-01,  9.8972e-01, -1.7312e-02,  ...,  8.8364e-01,\n",
       "             1.2682e+00, -1.3817e-01],\n",
       "           [ 2.1532e+00, -1.5749e-02, -2.3714e-04,  ..., -2.4218e-01,\n",
       "             1.2756e-01, -2.2088e-01],\n",
       "           [ 8.5285e-01,  1.8864e+00,  3.1995e-01,  ...,  8.2627e-01,\n",
       "             4.2447e-01, -2.6093e-01]],\n",
       " \n",
       "          [[ 1.1078e+00, -7.5123e-02,  4.9227e-01,  ..., -1.0846e-01,\n",
       "             7.8322e-01, -2.5762e-01],\n",
       "           [ 9.9603e-01,  8.5569e-01, -2.3542e-01,  ...,  6.2288e-01,\n",
       "             2.2579e+00,  1.0287e-01],\n",
       "           [-1.0342e-01,  1.1172e+00,  5.3072e-02,  ..., -2.1826e-01,\n",
       "            -3.0387e-01, -1.6021e-01],\n",
       "           ...,\n",
       "           [ 7.5243e-01,  1.4013e+00, -3.1284e-03,  ..., -2.6018e-01,\n",
       "            -2.0874e-01,  2.9662e-01],\n",
       "           [-9.0977e-03,  1.3648e+00, -1.7726e-02,  ...,  5.2573e-01,\n",
       "             2.4022e+00, -1.2014e-01],\n",
       "           [-4.4377e-02,  1.9294e-01, -1.7846e-01,  ...,  3.6628e-01,\n",
       "            -3.2426e-02,  1.6702e-01]]]], grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[[-1.4041e-02,  8.7822e-01, -9.2092e-02,  1.0850e+00],\n",
       "           [ 5.5682e-01, -2.8849e-02, -3.4951e-01,  1.7951e+00],\n",
       "           [ 3.3476e-01, -2.5201e-01,  4.8169e-01, -6.8087e-02],\n",
       "           [ 1.4499e+00, -3.2136e-01, -6.6578e-02, -1.2378e-01]],\n",
       " \n",
       "          [[-2.3071e-01, -4.1815e-02,  8.0609e-01,  1.1976e+00],\n",
       "           [ 7.5618e-02, -1.0476e-01, -6.5688e-02,  1.0007e+00],\n",
       "           [-4.2445e-01,  1.9115e+00,  8.9722e-01, -2.2711e-01],\n",
       "           [-4.7789e-02,  6.5755e-01, -4.8704e-02, -1.1824e-01]],\n",
       " \n",
       "          [[ 3.1720e-01, -3.0672e-02, -9.8189e-02, -2.0431e-01],\n",
       "           [-1.6992e-03,  2.4193e+00,  2.8694e-01, -1.9028e-01],\n",
       "           [-3.3733e-03, -8.4468e-03, -1.5401e-01,  1.4694e+00],\n",
       "           [ 1.1691e+00, -3.0390e-01,  3.9208e-01, -2.1592e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3939e-01, -7.2319e-03, -4.9556e-02,  3.2502e-01],\n",
       "           [-5.1547e-02, -2.3688e-01,  3.4016e-01, -1.2057e-01],\n",
       "           [ 2.1112e+00,  1.8667e+00,  6.5075e-01, -1.8349e-01],\n",
       "           [-1.7187e-01,  1.0304e+00, -2.3783e-01,  1.6758e-01]],\n",
       " \n",
       "          [[-1.7928e-02,  1.8382e+00,  1.0449e-01, -1.1603e-02],\n",
       "           [ 6.0965e-01, -2.3842e-01,  3.0796e-02,  2.4016e-01],\n",
       "           [-2.2228e-01, -3.2545e-01,  1.4418e+00, -1.1413e-01],\n",
       "           [ 9.1251e-02,  1.2983e+00,  5.5992e-01, -3.1312e-01]],\n",
       " \n",
       "          [[ 5.5959e-01, -2.6184e-01, -2.6407e-01, -2.0662e-01],\n",
       "           [ 2.2145e-01, -2.8674e-03,  9.6455e-01,  1.4521e+00],\n",
       "           [ 1.0883e+00, -1.6511e-01,  1.0829e+00, -2.7004e-01],\n",
       "           [-2.2060e-01, -5.5818e-02,  1.2288e+00,  6.3718e-01]]]],\n",
       "        grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[[ 0.0443, -0.3560, -0.2310],\n",
       "           [ 1.4731,  1.0497,  0.2243],\n",
       "           [ 0.9300, -0.0789, -0.0784]],\n",
       " \n",
       "          [[ 0.5180, -0.4001, -0.0670],\n",
       "           [-0.1160, -0.1811,  1.3822],\n",
       "           [ 0.3048,  1.0849,  0.5307]],\n",
       " \n",
       "          [[-0.0778,  1.0372,  0.1809],\n",
       "           [-0.1092, -0.2760, -0.2814],\n",
       "           [ 1.1240,  1.5091, -0.0259]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.2208, -0.1203,  0.3709],\n",
       "           [ 0.5652,  1.5769, -0.3212],\n",
       "           [-0.1548,  0.6106,  0.9616]],\n",
       " \n",
       "          [[-0.1533, -0.1295, -0.0280],\n",
       "           [ 1.9872,  1.5720, -0.1452],\n",
       "           [-0.0300, -0.0274, -0.1984]],\n",
       " \n",
       "          [[ 1.2041, -0.3224, -0.1019],\n",
       "           [ 0.9555, -0.2936,  0.8483],\n",
       "           [ 0.7195, -0.1005,  0.3647]]]], grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[[-0.2369,  1.0173],\n",
       "           [ 0.9631, -0.1592]],\n",
       " \n",
       "          [[-0.3309,  0.3256],\n",
       "           [ 1.0341,  0.2945]],\n",
       " \n",
       "          [[ 1.2272, -0.2302],\n",
       "           [ 0.7238, -0.1600]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.6256,  1.3000],\n",
       "           [-0.2284, -0.1567]],\n",
       " \n",
       "          [[ 1.0023,  0.8009],\n",
       "           [-0.0596, -0.3010]],\n",
       " \n",
       "          [[-0.0203,  0.8320],\n",
       "           [-0.3192,  0.8657]]]], grad_fn=<LeakyReluBackward0>)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 2, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 3, 3])\n",
      "torch.Size([1, 512, 4, 4])\n",
      "torch.Size([1, 512, 8, 8])\n",
      "torch.Size([1, 512, 16, 16])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for i in skip_connection[-2::-1]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "Decoder (Decoder)                        [1, 512, 2, 2]       [1, 3, 256, 256]     --                   True\n",
       "├─Sequential (main)                      --                   --                   --                   True\n",
       "│    └─ConvTranspose2d (0)               [1, 512, 2, 2]       [1, 512, 3, 3]       4,194,816            True\n",
       "│    └─InstanceNorm2d (1)                [1, 1024, 3, 3]      [1, 1024, 3, 3]      2,048                True\n",
       "│    └─Dropout (2)                       [1, 1024, 3, 3]      [1, 1024, 3, 3]      --                   --\n",
       "│    └─ReLU (3)                          [1, 1024, 3, 3]      [1, 1024, 3, 3]      --                   --\n",
       "│    └─ConvTranspose2d (4)               [1, 1024, 3, 3]      [1, 512, 4, 4]       8,389,120            True\n",
       "│    └─InstanceNorm2d (5)                [1, 1024, 4, 4]      [1, 1024, 4, 4]      2,048                True\n",
       "│    └─Dropout (6)                       [1, 1024, 4, 4]      [1, 1024, 4, 4]      --                   --\n",
       "│    └─ReLU (7)                          [1, 1024, 4, 4]      [1, 1024, 4, 4]      --                   --\n",
       "│    └─ConvTranspose2d (8)               [1, 1024, 4, 4]      [1, 512, 8, 8]       8,389,120            True\n",
       "│    └─InstanceNorm2d (9)                [1, 1024, 8, 8]      [1, 1024, 8, 8]      2,048                True\n",
       "│    └─Dropout (10)                      [1, 1024, 8, 8]      [1, 1024, 8, 8]      --                   --\n",
       "│    └─ReLU (11)                         [1, 1024, 8, 8]      [1, 1024, 8, 8]      --                   --\n",
       "│    └─ConvTranspose2d (12)              [1, 1024, 8, 8]      [1, 512, 16, 16]     8,389,120            True\n",
       "│    └─InstanceNorm2d (13)               [1, 1024, 16, 16]    [1, 1024, 16, 16]    2,048                True\n",
       "│    └─ReLU (14)                         [1, 1024, 16, 16]    [1, 1024, 16, 16]    --                   --\n",
       "│    └─ConvTranspose2d (15)              [1, 1024, 16, 16]    [1, 256, 32, 32]     4,194,560            True\n",
       "│    └─InstanceNorm2d (16)               [1, 512, 32, 32]     [1, 512, 32, 32]     1,024                True\n",
       "│    └─ReLU (17)                         [1, 512, 32, 32]     [1, 512, 32, 32]     --                   --\n",
       "│    └─ConvTranspose2d (18)              [1, 512, 32, 32]     [1, 128, 64, 64]     1,048,704            True\n",
       "│    └─InstanceNorm2d (19)               [1, 256, 64, 64]     [1, 256, 64, 64]     512                  True\n",
       "│    └─ReLU (20)                         [1, 256, 64, 64]     [1, 256, 64, 64]     --                   --\n",
       "│    └─ConvTranspose2d (21)              [1, 256, 64, 64]     [1, 64, 128, 128]    262,208              True\n",
       "│    └─InstanceNorm2d (22)               [1, 128, 128, 128]   [1, 128, 128, 128]   256                  True\n",
       "│    └─ReLU (23)                         [1, 128, 128, 128]   [1, 128, 128, 128]   --                   --\n",
       "│    └─ConvTranspose2d (24)              [1, 128, 128, 128]   [1, 3, 256, 256]     6,147                True\n",
       "│    └─Tanh (25)                         [1, 3, 256, 256]     [1, 3, 256, 256]     --                   --\n",
       "========================================================================================================================\n",
       "Total params: 34,883,779\n",
       "Trainable params: 34,883,779\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 16.15\n",
       "========================================================================================================================\n",
       "Input size (MB): 8.06\n",
       "Forward/backward pass size (MB): 49.85\n",
       "Params size (MB): 139.54\n",
       "Estimated Total Size (MB): 197.45\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# images = torch.randn(64, 1, 64, 64)\n",
    "# labels = torch.ran\\dint(0, 10, (64,), dtype=torch.long)\n",
    "dec = Decoder()\n",
    "dec = dec.to(ModelArgs.device)\n",
    "summary(model=dec,\n",
    "        input_data=(x, skip_connection),\n",
    "        # input_data=(images.to(ModelArgs.device), labels.to(ModelArgs.device)),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x, skip_connection = self.encoder(x)\n",
    "        x = self.decoder(x, skip_connection)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (encoder): Encoder(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (4): LeakyReLU(negative_slope=0.2)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (10): LeakyReLU(negative_slope=0.2)\n",
      "      (11): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (13): LeakyReLU(negative_slope=0.2)\n",
      "      (14): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (15): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (16): LeakyReLU(negative_slope=0.2)\n",
      "      (17): Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (18): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (19): LeakyReLU(negative_slope=0.2)\n",
      "      (20): Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (21): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (22): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (main): Sequential(\n",
      "      (0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (1): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (5): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (6): Dropout(p=0.5, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (9): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (10): Dropout(p=0.5, inplace=False)\n",
      "      (11): ReLU()\n",
      "      (12): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (13): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (14): ReLU()\n",
      "      (15): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (16): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (17): ReLU()\n",
      "      (18): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (19): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (20): ReLU()\n",
      "      (21): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (22): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (23): ReLU()\n",
      "      (24): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (25): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Intializing the Discriminator instance\n",
    "unet = UNet().to(ModelArgs.device)\n",
    "#Apply the wieght intilization function layer by layer\n",
    "unet = unet.apply(weights_init)\n",
    "#Printing the structure\n",
    "print(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "UNet (UNet)                              [1, 3, 256, 256]     [1, 3, 256, 256]     --                   True\n",
       "├─Encoder (encoder)                      [1, 3, 256, 256]     [1, 512, 2, 2]       --                   True\n",
       "│    └─Sequential (main)                 --                   --                   --                   True\n",
       "│    │    └─Conv2d (0)                   [1, 3, 256, 256]     [1, 64, 128, 128]    3,136                True\n",
       "│    │    └─LeakyReLU (1)                [1, 64, 128, 128]    [1, 64, 128, 128]    --                   --\n",
       "│    │    └─Conv2d (2)                   [1, 64, 128, 128]    [1, 128, 64, 64]     131,200              True\n",
       "│    │    └─InstanceNorm2d (3)           [1, 128, 64, 64]     [1, 128, 64, 64]     256                  True\n",
       "│    │    └─LeakyReLU (4)                [1, 128, 64, 64]     [1, 128, 64, 64]     --                   --\n",
       "│    │    └─Conv2d (5)                   [1, 128, 64, 64]     [1, 256, 32, 32]     524,544              True\n",
       "│    │    └─InstanceNorm2d (6)           [1, 256, 32, 32]     [1, 256, 32, 32]     512                  True\n",
       "│    │    └─LeakyReLU (7)                [1, 256, 32, 32]     [1, 256, 32, 32]     --                   --\n",
       "│    │    └─Conv2d (8)                   [1, 256, 32, 32]     [1, 512, 16, 16]     2,097,664            True\n",
       "│    │    └─InstanceNorm2d (9)           [1, 512, 16, 16]     [1, 512, 16, 16]     1,024                True\n",
       "│    │    └─LeakyReLU (10)               [1, 512, 16, 16]     [1, 512, 16, 16]     --                   --\n",
       "│    │    └─Conv2d (11)                  [1, 512, 16, 16]     [1, 512, 8, 8]       4,194,816            True\n",
       "│    │    └─InstanceNorm2d (12)          [1, 512, 8, 8]       [1, 512, 8, 8]       1,024                True\n",
       "│    │    └─LeakyReLU (13)               [1, 512, 8, 8]       [1, 512, 8, 8]       --                   --\n",
       "│    │    └─Conv2d (14)                  [1, 512, 8, 8]       [1, 512, 4, 4]       4,194,816            True\n",
       "│    │    └─InstanceNorm2d (15)          [1, 512, 4, 4]       [1, 512, 4, 4]       1,024                True\n",
       "│    │    └─LeakyReLU (16)               [1, 512, 4, 4]       [1, 512, 4, 4]       --                   --\n",
       "│    │    └─Conv2d (17)                  [1, 512, 4, 4]       [1, 512, 3, 3]       4,194,816            True\n",
       "│    │    └─InstanceNorm2d (18)          [1, 512, 3, 3]       [1, 512, 3, 3]       1,024                True\n",
       "│    │    └─LeakyReLU (19)               [1, 512, 3, 3]       [1, 512, 3, 3]       --                   --\n",
       "│    │    └─Conv2d (20)                  [1, 512, 3, 3]       [1, 512, 2, 2]       4,194,816            True\n",
       "│    │    └─InstanceNorm2d (21)          [1, 512, 2, 2]       [1, 512, 2, 2]       1,024                True\n",
       "│    │    └─LeakyReLU (22)               [1, 512, 2, 2]       [1, 512, 2, 2]       --                   --\n",
       "├─Decoder (decoder)                      [1, 512, 2, 2]       [1, 3, 256, 256]     --                   True\n",
       "│    └─Sequential (main)                 --                   --                   --                   True\n",
       "│    │    └─ConvTranspose2d (0)          [1, 512, 2, 2]       [1, 512, 3, 3]       4,194,816            True\n",
       "│    │    └─InstanceNorm2d (1)           [1, 1024, 3, 3]      [1, 1024, 3, 3]      2,048                True\n",
       "│    │    └─Dropout (2)                  [1, 1024, 3, 3]      [1, 1024, 3, 3]      --                   --\n",
       "│    │    └─ReLU (3)                     [1, 1024, 3, 3]      [1, 1024, 3, 3]      --                   --\n",
       "│    │    └─ConvTranspose2d (4)          [1, 1024, 3, 3]      [1, 512, 4, 4]       8,389,120            True\n",
       "│    │    └─InstanceNorm2d (5)           [1, 1024, 4, 4]      [1, 1024, 4, 4]      2,048                True\n",
       "│    │    └─Dropout (6)                  [1, 1024, 4, 4]      [1, 1024, 4, 4]      --                   --\n",
       "│    │    └─ReLU (7)                     [1, 1024, 4, 4]      [1, 1024, 4, 4]      --                   --\n",
       "│    │    └─ConvTranspose2d (8)          [1, 1024, 4, 4]      [1, 512, 8, 8]       8,389,120            True\n",
       "│    │    └─InstanceNorm2d (9)           [1, 1024, 8, 8]      [1, 1024, 8, 8]      2,048                True\n",
       "│    │    └─Dropout (10)                 [1, 1024, 8, 8]      [1, 1024, 8, 8]      --                   --\n",
       "│    │    └─ReLU (11)                    [1, 1024, 8, 8]      [1, 1024, 8, 8]      --                   --\n",
       "│    │    └─ConvTranspose2d (12)         [1, 1024, 8, 8]      [1, 512, 16, 16]     8,389,120            True\n",
       "│    │    └─InstanceNorm2d (13)          [1, 1024, 16, 16]    [1, 1024, 16, 16]    2,048                True\n",
       "│    │    └─ReLU (14)                    [1, 1024, 16, 16]    [1, 1024, 16, 16]    --                   --\n",
       "│    │    └─ConvTranspose2d (15)         [1, 1024, 16, 16]    [1, 256, 32, 32]     4,194,560            True\n",
       "│    │    └─InstanceNorm2d (16)          [1, 512, 32, 32]     [1, 512, 32, 32]     1,024                True\n",
       "│    │    └─ReLU (17)                    [1, 512, 32, 32]     [1, 512, 32, 32]     --                   --\n",
       "│    │    └─ConvTranspose2d (18)         [1, 512, 32, 32]     [1, 128, 64, 64]     1,048,704            True\n",
       "│    │    └─InstanceNorm2d (19)          [1, 256, 64, 64]     [1, 256, 64, 64]     512                  True\n",
       "│    │    └─ReLU (20)                    [1, 256, 64, 64]     [1, 256, 64, 64]     --                   --\n",
       "│    │    └─ConvTranspose2d (21)         [1, 256, 64, 64]     [1, 64, 128, 128]    262,208              True\n",
       "│    │    └─InstanceNorm2d (22)          [1, 128, 128, 128]   [1, 128, 128, 128]   256                  True\n",
       "│    │    └─ReLU (23)                    [1, 128, 128, 128]   [1, 128, 128, 128]   --                   --\n",
       "│    │    └─ConvTranspose2d (24)         [1, 128, 128, 128]   [1, 3, 256, 256]     6,147                True\n",
       "│    │    └─Tanh (25)                    [1, 3, 256, 256]     [1, 3, 256, 256]     --                   --\n",
       "========================================================================================================================\n",
       "Total params: 54,425,475\n",
       "Trainable params: 54,425,475\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 18.20\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 73.68\n",
       "Params size (MB): 217.70\n",
       "Estimated Total Size (MB): 292.17\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "# images = torch.randn(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size)\n",
    "# labels = torch.randint(0, 10, (64,), dtype=torch.long)\n",
    "\n",
    "summary(model=unet,\n",
    "        input_size=(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size),\n",
    "        # input_data=(images.to(ModelArgs.device), labels.to(ModelArgs.device)),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(ModelArgs.no_of_channels*2, 64, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "                \n",
    "            nn.Conv2d(64, 128, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(128, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "               \n",
    "            nn.Conv2d(128, 256, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(256, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "              \n",
    "            nn.Conv2d(256, 512, kernel_size=ModelArgs.kernel_size, stride=1, padding=ModelArgs.padding),\n",
    "            nn.InstanceNorm2d(512, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "            \n",
    "            nn.Conv2d(512, 1, kernel_size=ModelArgs.kernel_size, stride=1, padding=ModelArgs.padding),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        res = torch.concat([x, y], dim=1)\n",
    "        return self.main(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Intializing the Discriminator instance\n",
    "discriminator = Discriminator().to(ModelArgs.device)\n",
    "#Apply the wieght intilization function layer by layer\n",
    "discriminator = discriminator.apply(weights_init)\n",
    "#Printing the structure\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "Discriminator (Discriminator)            [1, 3, 256, 256]     [1, 1, 30, 30]       --                   True\n",
       "├─Sequential (main)                      [1, 6, 256, 256]     [1, 1, 30, 30]       --                   True\n",
       "│    └─Conv2d (0)                        [1, 6, 256, 256]     [1, 64, 128, 128]    6,208                True\n",
       "│    └─LeakyReLU (1)                     [1, 64, 128, 128]    [1, 64, 128, 128]    --                   --\n",
       "│    └─Conv2d (2)                        [1, 64, 128, 128]    [1, 128, 64, 64]     131,200              True\n",
       "│    └─InstanceNorm2d (3)                [1, 128, 64, 64]     [1, 128, 64, 64]     256                  True\n",
       "│    └─LeakyReLU (4)                     [1, 128, 64, 64]     [1, 128, 64, 64]     --                   --\n",
       "│    └─Conv2d (5)                        [1, 128, 64, 64]     [1, 256, 32, 32]     524,544              True\n",
       "│    └─InstanceNorm2d (6)                [1, 256, 32, 32]     [1, 256, 32, 32]     512                  True\n",
       "│    └─LeakyReLU (7)                     [1, 256, 32, 32]     [1, 256, 32, 32]     --                   --\n",
       "│    └─Conv2d (8)                        [1, 256, 32, 32]     [1, 512, 31, 31]     2,097,664            True\n",
       "│    └─InstanceNorm2d (9)                [1, 512, 31, 31]     [1, 512, 31, 31]     1,024                True\n",
       "│    └─LeakyReLU (10)                    [1, 512, 31, 31]     [1, 512, 31, 31]     --                   --\n",
       "│    └─Conv2d (11)                       [1, 512, 31, 31]     [1, 1, 30, 30]       8,193                True\n",
       "│    └─Sigmoid (12)                      [1, 1, 30, 30]       [1, 1, 30, 30]       --                   --\n",
       "========================================================================================================================\n",
       "Total params: 2,769,601\n",
       "Trainable params: 2,769,601\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.20\n",
       "========================================================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 28.85\n",
       "Params size (MB): 11.08\n",
       "Estimated Total Size (MB): 41.50\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "real_A = torch.randn(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size)\n",
    "real_B = torch.randn(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size)\n",
    "# labels = torch.randint(0, 10, (64,), dtype=torch.long)\n",
    "\n",
    "summary(model=discriminator,\n",
    "        # input_size=(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size),\n",
    "        input_data=(real_A.to(ModelArgs.device), real_B.to(ModelArgs.device)),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m unet \u001b[38;5;241m=\u001b[39m UNet()\u001b[38;5;241m.\u001b[39mto(ModelArgs\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mapply(weights_init)\n\u001b[0;32m----> 2\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m \u001b[43mDiscriminator\u001b[49m()\u001b[38;5;241m.\u001b[39mto(ModelArgs\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mapply(weights_init)\n\u001b[1;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;66;03m#30\u001b[39;00m\n\u001b[1;32m      8\u001b[0m optimizerC \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39munet\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mModelArgs\u001b[38;5;241m.\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39m(ModelArgs\u001b[38;5;241m.\u001b[39mbeta_1, ModelArgs\u001b[38;5;241m.\u001b[39mbeta_2)) \u001b[38;5;66;03m#For discriminator\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "unet = UNet().to(ModelArgs.device).apply(weights_init)\n",
    "discriminator = Discriminator().to(ModelArgs.device).apply(weights_init)\n",
    "\n",
    "\n",
    "epochs = 10000 #30\n",
    "\n",
    "\n",
    "optimizerC = torch.optim.Adam(params=unet.parameters(), lr=ModelArgs.lr, betas=(ModelArgs.beta_1, ModelArgs.beta_2)) #For discriminator\n",
    "optimizerG = torch.optim.Adam(params=discriminator.parameters(), lr=ModelArgs.lr,  betas=(ModelArgs.beta_1, ModelArgs.beta_2)) #For generator\n",
    "\n",
    "\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "\n",
    "loss_g = []\n",
    "loss_d = []\n",
    "img_list = []\n",
    "\n",
    "# Fixed noise for generating the images\n",
    "fixed_noise = torch.randn((ModelArgs.batch_size, ModelArgs.latent_vector_size, 1, 1), dtype=torch.float32, device=ModelArgs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
