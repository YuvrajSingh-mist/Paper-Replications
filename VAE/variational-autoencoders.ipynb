{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb22efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:35.321040Z",
     "iopub.status.busy": "2025-06-14T11:49:35.320704Z",
     "iopub.status.idle": "2025-06-14T11:49:35.326533Z",
     "shell.execute_reply": "2025-06-14T11:49:35.325689Z",
     "shell.execute_reply.started": "2025-06-14T11:49:35.321019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726f14d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:35.804795Z",
     "iopub.status.busy": "2025-06-14T11:49:35.804094Z",
     "iopub.status.idle": "2025-06-14T11:49:35.897901Z",
     "shell.execute_reply": "2025-06-14T11:49:35.897184Z",
     "shell.execute_reply.started": "2025-06-14T11:49:35.804766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data and convert to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e62711-f756-4578-a994-9632825f8d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:35.899413Z",
     "iopub.status.busy": "2025-06-14T11:49:35.899141Z",
     "iopub.status.idle": "2025-06-14T11:49:36.057641Z",
     "shell.execute_reply": "2025-06-14T11:49:36.056933Z",
     "shell.execute_reply.started": "2025-06-14T11:49:35.899391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !wandb login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"API_KEY\")\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ddc40-9eed-434e-a82f-adc8dea015dc",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ffb32-0f44-4e43-9c21-c32bd0cdef5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:36.059391Z",
     "iopub.status.busy": "2025-06-14T11:49:36.059049Z",
     "iopub.status.idle": "2025-06-14T11:49:36.068445Z",
     "shell.execute_reply": "2025-06-14T11:49:36.067195Z",
     "shell.execute_reply.started": "2025-06-14T11:49:36.059352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae37ae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:36.069684Z",
     "iopub.status.busy": "2025-06-14T11:49:36.069455Z",
     "iopub.status.idle": "2025-06-14T11:49:42.735970Z",
     "shell.execute_reply": "2025-06-14T11:49:42.735288Z",
     "shell.execute_reply.started": "2025-06-14T11:49:36.069666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=\"vae-mnist\",\n",
    "    config={\n",
    "        \"learning_rate\": 0.0005,\n",
    "        \"epochs\": 200,\n",
    "        \"batch_size\": 64,\n",
    "        \"input_dim\": 1,\n",
    "        \"hidden_dim\": 64,\n",
    "        \"latent_dim\": 2,\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"architecture\": \"Variational Autoencoder\",\n",
    "        \"reconstruction_weight\": 0.1,\n",
    "        \"kl_weight\": 0.5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4b7b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.738008Z",
     "iopub.status.busy": "2025-06-14T11:49:42.737702Z",
     "iopub.status.idle": "2025-06-14T11:49:42.744534Z",
     "shell.execute_reply": "2025-06-14T11:49:42.743607Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.737986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, leaky = 0.01):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(leaky),\n",
    "            nn.Conv2d(hidden_dim , hidden_dim , kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(leaky),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim , kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(leaky),\n",
    "            nn.Conv2d(hidden_dim , hidden_dim , kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(leaky),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        # self.fc2 = nn.Linear(3136, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = nn.functional.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "# class Decoder(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f62c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.745711Z",
     "iopub.status.busy": "2025-06-14T11:49:42.745458Z",
     "iopub.status.idle": "2025-06-14T11:49:42.777129Z",
     "shell.execute_reply": "2025-06-14T11:49:42.776390Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.745691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "enc = Encoder(input_dim=1, hidden_dim=64, output_dim=2).to('cuda')\n",
    "x = torch.randn(1, 1, 28, 28).to('cuda')  # Example input tensor\n",
    "# output = enc(x)\n",
    "# print(\"Output shape:\", output.shape)  # Should print the shape of the output tensor\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(enc, (1,1,28,28), device='cuda')  # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ee362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.778290Z",
     "iopub.status.busy": "2025-06-14T11:49:42.777957Z",
     "iopub.status.idle": "2025-06-14T11:49:42.789775Z",
     "shell.execute_reply": "2025-06-14T11:49:42.788834Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.778243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c8b0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.790828Z",
     "iopub.status.busy": "2025-06-14T11:49:42.790620Z",
     "iopub.status.idle": "2025-06-14T11:49:42.807728Z",
     "shell.execute_reply": "2025-06-14T11:49:42.807068Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.790812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, leaky = 0.01):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear = nn.Linear(output_dim, 3136)\n",
    "        self.conv = nn.Sequential(\n",
    "            \n",
    "            # Reshape(-1, hidden_dim * 2, 16, 16),\n",
    "            nn.ConvTranspose2d(input_dim, hidden_dim , kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(leaky),\n",
    "            nn.ConvTranspose2d(hidden_dim, hidden_dim , kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(leaky),\n",
    "            \n",
    "            nn.ConvTranspose2d(hidden_dim , hidden_dim , kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(leaky),\n",
    "            nn.ConvTranspose2d(hidden_dim , 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(leaky),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x.view(-1, 64, 7, 7)\n",
    "        x = self.conv(x)\n",
    "        x = nn.functional.sigmoid(x)    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50fc0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.808786Z",
     "iopub.status.busy": "2025-06-14T11:49:42.808540Z",
     "iopub.status.idle": "2025-06-14T11:49:42.838367Z",
     "shell.execute_reply": "2025-06-14T11:49:42.837480Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.808765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summary(Decoder(input_dim=64, hidden_dim=64, output_dim=2).to('cuda'), (1, 2), device='cuda')  # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9434576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.839942Z",
     "iopub.status.busy": "2025-06-14T11:49:42.839644Z",
     "iopub.status.idle": "2025-06-14T11:49:42.846857Z",
     "shell.execute_reply": "2025-06-14T11:49:42.845832Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.839911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, output_dim)\n",
    "        self.decoder = Decoder(hidden_dim , hidden_dim , output_dim)\n",
    "        self.z_mean = nn.Linear(3136, 2, bias=False)\n",
    "        self.z_log_var = nn.Linear(3136, 2, bias=False)\n",
    "        \n",
    "    def reparametrize(self, encoded, mean_sampled, log_var_sampled):\n",
    "        epsilon = torch.randn(log_var_sampled.size(0), log_var_sampled.size(1), device='cuda')\n",
    "        # print(epsilon.shape)\n",
    "        # print(mean_sampled.shape)\n",
    "        res = mean_sampled + torch.exp(log_var_sampled / 2.0) * epsilon\n",
    "        return res\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        sampled_z, log_var_sampled_z = self.z_mean(encoded), self.z_log_var(encoded)\n",
    "        z = self.reparametrize(encoded, sampled_z, log_var_sampled_z)\n",
    "        # print(x.shape)\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded, sampled_z, log_var_sampled_z, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22013168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.849462Z",
     "iopub.status.busy": "2025-06-14T11:49:42.849206Z",
     "iopub.status.idle": "2025-06-14T11:49:42.887212Z",
     "shell.execute_reply": "2025-06-14T11:49:42.886502Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.849444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(input_dim=1, hidden_dim=64, output_dim=2).to('cuda')\n",
    "summary(autoencoder, (1, 1, 28, 28), device='cuda')  # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1584c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.888430Z",
     "iopub.status.busy": "2025-06-14T11:49:42.888069Z",
     "iopub.status.idle": "2025-06-14T11:49:42.896952Z",
     "shell.execute_reply": "2025-06-14T11:49:42.896125Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.888401Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Define the split sizes\n",
    "train_size = int(0.8 * len(mnist_dataset))\n",
    "val_size = len(mnist_dataset) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1f76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T11:49:42.898332Z",
     "iopub.status.busy": "2025-06-14T11:49:42.897965Z",
     "iopub.status.idle": "2025-06-14T12:26:28.688010Z",
     "shell.execute_reply": "2025-06-14T12:26:28.687227Z",
     "shell.execute_reply.started": "2025-06-14T11:49:42.898246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0005)\n",
    "# Training the autoencoder\n",
    "epochs = 50 * 4  # Number of epochs for training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    autoencoder.train()\n",
    "    train_loss = 0.0\n",
    "    train_recon_loss = 0.0\n",
    "    train_kl_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, _ in train_loader:\n",
    "        data = data.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output, mu, log_var, z = autoencoder(data)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        recon_loss = nn.functional.mse_loss(output, data, reduction='none')\n",
    "        recon_loss = recon_loss.view(output.size(0), -1).sum(dim=1)\n",
    "        recon_loss = recon_loss.mean()\n",
    "        # KL divergence loss\n",
    "        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1)\n",
    "        # kl_loss = kl_loss / data.size(0)  # Average over batch\n",
    "        kl_loss = kl_loss.mean()\n",
    "        # print(kl_loss)\n",
    "        # Total loss\n",
    "        total_loss = kl_loss + 1.0 * recon_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += total_loss.item()\n",
    "        train_recon_loss += recon_loss.item()\n",
    "        train_kl_loss += kl_loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    # Calculate average training losses\n",
    "    avg_train_loss = train_loss / num_batches\n",
    "    avg_train_recon = train_recon_loss / num_batches\n",
    "    avg_train_kl = train_kl_loss / num_batches\n",
    "    # print(avg_train_kl)\n",
    "    # Validation phase\n",
    "    autoencoder.eval()\n",
    "    val_loss = 0.0\n",
    "    val_recon_loss = 0.0\n",
    "    val_kl_loss = 0.0\n",
    "    val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in val_loader:\n",
    "            data = data.to('cuda')\n",
    "            output, mu, log_var, z = autoencoder(data)\n",
    "            \n",
    "            # Reconstruction loss\n",
    "            recon_loss = nn.functional.mse_loss(output, data, reduction='none')\n",
    "            recon_loss = recon_loss.view(output.size(0), -1).sum(dim=1)\n",
    "            recon_loss = recon_loss.mean()\n",
    "            # KL divergence loss\n",
    "            kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1)\n",
    "            # kl_loss = kl_loss / data.size(0)\n",
    "            kl_loss = kl_loss.mean() \n",
    "            \n",
    "            # Total loss\n",
    "            total_loss = 0.1 * recon_loss +  recon_loss\n",
    "            \n",
    "            val_loss += total_loss.item()\n",
    "            val_recon_loss += recon_loss.item()\n",
    "            val_kl_loss += kl_loss.item()\n",
    "            val_batches += 1\n",
    "    \n",
    "    avg_val_loss = val_loss / val_batches\n",
    "    avg_val_recon = val_recon_loss / val_batches\n",
    "    avg_val_kl = val_kl_loss / val_batches\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"train_reconstruction_loss\": avg_train_recon,\n",
    "        \"train_kl_loss\": avg_train_kl,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_reconstruction_loss\": avg_val_recon,\n",
    "        \"val_kl_loss\": avg_val_kl\n",
    "    })\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:} (Recon: {avg_train_recon:}, KL: {avg_train_kl:}), Val Loss: {avg_val_loss:} (Recon: {avg_val_recon:}, KL: {avg_val_kl:})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476937d-05d4-4f25-bae8-7a11cf3f8b57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T12:26:28.689218Z",
     "iopub.status.busy": "2025-06-14T12:26:28.688941Z",
     "iopub.status.idle": "2025-06-14T12:26:29.579579Z",
     "shell.execute_reply": "2025-06-14T12:26:29.578804Z",
     "shell.execute_reply.started": "2025-06-14T12:26:28.689196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, _ in val_loader:\n",
    "        data = data.to('cuda')\n",
    "        res, mu, log_var, z = autoencoder(data)  # Unpack VAE outputs\n",
    "        break\n",
    "\n",
    "# Move tensors to CPU and convert to numpy for visualization\n",
    "original_images = data.cpu().numpy()\n",
    "reconstructed_images = res.cpu().numpy()\n",
    "\n",
    "# Plot original vs reconstructed images\n",
    "fig, axes = plt.subplots(2, 8, figsize=(15, 4))\n",
    "fig.suptitle('VAE: Original (top) vs Reconstructed (bottom)')\n",
    "\n",
    "for i in range(8):\n",
    "    # Original images\n",
    "    axes[0, i].imshow(original_images[i].squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Original {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Reconstructed images\n",
    "    axes[1, i].imshow(reconstructed_images[i].squeeze(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Reconstructed {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Log sample images to wandb\n",
    "wandb.log({\n",
    "    \"sample_reconstructions\": wandb.Image(plt)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b3bdc-2670-44e9-8cc4-0bdcdf3b54e2",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f440e2e-bca1-4fe8-b3ce-6d1979d08970",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5656a-cc27-42e5-8328-a23ee84dcd61",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db19b80-4443-4b77-bc1d-b2b22d759c75",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfc19b-d3bb-44e1-a80b-493c0bc56e7c",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93487bbd-d3fe-4412-9e7c-832139e23315",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664bca49-9c08-4f40-b5f0-ad9a1dc65ef5",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77940e68-6406-42b3-8201-d81a3b9d4d78",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5dba88-8384-45dd-b802-eb111c5168d0",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
