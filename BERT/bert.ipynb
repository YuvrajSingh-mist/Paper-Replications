{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "# https://medium.com/data-and-beyond/complete-guide-to-building-bert-model-from-sratch-3e6562228891\n",
    "# https://ai.plainenglish.io/bert-pytorch-implementation-prepare-dataset-part-1-efd259113e5a\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import transformers, datasets\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 24 21:54:13 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.03              Driver Version: 555.85         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P0             13W /   80W |       0MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "n_warmup_steps = 4000\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.98\n",
    "epsilon = 1e-9\n",
    "n_segments = 3\n",
    "block_size = 128\n",
    "batch_size = 64\n",
    "embeddings_dims = 512\n",
    "attn_dropout = 0.1\n",
    "no_of_heads = 8 #IMP needs to be thoroughly calculated\n",
    "dropout = 0.1\n",
    "epochs = 20\n",
    "max_lr = 2e-5\n",
    "no_of_encoder_layers = 6 #IMP needs to be thoroughly calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-24 00:28:26--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.236.207.53\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9916637 (9.5M) [application/zip]\n",
      "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
      "\n",
      "     cornell_movie_   2%[                    ] 226.00K   163KB/s               ^C\n",
      "[cornell_movie_dialogs_corpus.zip]\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "note:  cornell_movie_dialogs_corpus.zip may be a plain executable, not an archive\n",
      "unzip:  cannot find zipfile directory in one of cornell_movie_dialogs_corpus.zip or\n",
      "        cornell_movie_dialogs_corpus.zip.zip, and cannot find cornell_movie_dialogs_corpus.zip.ZIP, period.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘datasets’: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'cornell movie-dialogs corpus/movie_conversations.txt': No such file or directory\n",
      "mv: cannot stat 'cornell movie-dialogs corpus/movie_lines.txt': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "\n",
    "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
    "!unzip -qq cornell_movie_dialogs_corpus.zip\n",
    "!rm cornell_movie_dialogs_corpus.zip\n",
    "!mkdir datasets\n",
    "!mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
    "!mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading all data into memory\n",
    "corpus_movie_conv = './datasets/movie_conversations.txt'\n",
    "corpus_movie_lines = './datasets/movie_lines.txt'\n",
    "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
    "    conv = c.readlines()\n",
    "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
    "    lines = l.readlines()\n",
    "\n",
    "### splitting text using special lines\n",
    "lines_dic = {}\n",
    "for line in lines:\n",
    "    objects = line.split(\" +++$+++ \")\n",
    "    lines_dic[objects[0]] = objects[-1]\n",
    "\n",
    "### generate convo  pairs\n",
    "pairs = []\n",
    "for con in conv:\n",
    "    ids = eval(con.split(\" +++$+++ \")[-1]) #Evaluates the string as a list now\n",
    "    for i in range(len(ids)):\n",
    "        pair = []\n",
    "        \n",
    "        if i == len(ids) - 1:\n",
    "            break\n",
    "        # print(ids[i])\n",
    "        first = lines_dic[ids[i]].strip()  \n",
    "        second = lines_dic[ids[i+1]].strip() \n",
    "\n",
    "        pair.append(' '.join(first.split()[:block_size]))\n",
    "        pair.append(' '.join(second.split()[:block_size]))\n",
    "        pairs.append(pair)\n",
    "        # break\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = pairs[0][0]\n",
    "# ids = tokenizer(sent)['input_ids']\n",
    "# len(ids), len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221616/221616 [00:00<00:00, 5819860.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvrajsingh/anaconda3/envs/py311/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1947: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "len(pairs) #Total pairs-> 221K\n",
    "\n",
    "##########W Tokenization #################\n",
    "# WordPiece tokenizer\n",
    "\n",
    "### save data as txt file\n",
    "text_data = []\n",
    "file_count = 0\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "\n",
    "for sample in tqdm([x[0] for x in pairs]):\n",
    "    # cleaned_sample = clean_text(sample)\n",
    "    text_data.append(sample)\n",
    "\n",
    "    # once we hit the 10K mark, save to file\n",
    "    # if len(text_data) == 10000:\n",
    "with open(f'./datasets/text.txt', 'w', encoding='utf-8') as fp:\n",
    "    fp.write('\\n'.join(text_data))\n",
    "        # text_data = []\n",
    "        # file_count += 1\n",
    "\n",
    "paths = 'datasets/text.txt'\n",
    "# print(paths)\n",
    "### training own tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tokenizer.train( \n",
    "    files=paths,\n",
    "    vocab_size=30_000, \n",
    "    min_frequency=5,\n",
    "    # limit_alphabet=1000, \n",
    "    wordpieces_prefix='##',\n",
    "    special_tokens=['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]']\n",
    "    )\n",
    "\n",
    "if not os.path.exists('./bert-it-1'): os.mkdir('./bert-it-1')\n",
    "tokenizer.save_model('./bert-it-1', 'bert-it')\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-it-1/bert-it-vocab.txt', local_files_only=True)\n",
    "\n",
    "#Setting vocab size\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data_pair, tokenizer, seq_len=block_size):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.corpus_lines = len(data_pair)\n",
    "        self.lines = data_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_lines\n",
    "\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        \n",
    "        #Getting NSP sentences\n",
    "        sent1, sent2, is_next = self.get_nsp(item)\n",
    "        \n",
    "        #Getting masked sentences\n",
    "        sent1_masked , label1 = self.get_masked_sentences(sent1)\n",
    "        sent2_masked , label2 = self.get_masked_sentences(sent2)\n",
    "        \n",
    "        #Adding CLS and SEP tokens\n",
    "        sent1_masked_cls_and_sep_aded = [self.tokenizer.vocab['[CLS]']]+ sent1_masked + [self.tokenizer.vocab['[SEP]']]\n",
    "        sent2_masked_cls_and_sep_aded = sent2_masked + [self.tokenizer.vocab['[SEP]']]\n",
    "        \n",
    "        label1_padding_added = [self.tokenizer.vocab['[PAD]']] + label1 + [self.tokenizer.vocab['[PAD]']] #because of [1:-1] thing (I removed CLS and SEP token before) and the middle one because of the added [SEP] token\n",
    "        label2_padding_added = label2 + [self.tokenizer.vocab['[PAD]']]\n",
    "        \n",
    "        #Segment ids\n",
    "        segment_ids = [1 for _ in range(len(sent1_masked_cls_and_sep_aded))] + [2 for _ in range(len(sent2_masked_cls_and_sep_aded))]\n",
    "        \n",
    "        # print(\"senti\", sent1_masked_cls_and_sep_aded)\n",
    "        # print(\"sent2\", sent2_masked_cls_and_sep_aded)\n",
    "        # print(\"label1\", label1_padding_added)\n",
    "        # print(\"label1\", label2_padding_added)\n",
    "        \n",
    "        \n",
    "        #Combine the sentences\n",
    "        combined_sentence = sent1_masked_cls_and_sep_aded + sent2_masked_cls_and_sep_aded\n",
    "        combined_labels = label1_padding_added + label2_padding_added\n",
    "        \n",
    "        if(len(combined_sentence) > self.seq_len): \n",
    "            combined_sentence = combined_sentence[:self.seq_len]\n",
    "            combined_labels = combined_labels[:self.seq_len]\n",
    "            segment_ids = segment_ids[:self.seq_len]\n",
    "        elif (len(combined_sentence) < self.seq_len):\n",
    "            while(len(combined_sentence) < self.seq_len):\n",
    "                combined_sentence += [self.tokenizer.vocab['[PAD]']]\n",
    "                segment_ids += [0]\n",
    "                combined_labels += [0]\n",
    "                \n",
    "        values = {\n",
    "            'bert_input_masked': combined_sentence,\n",
    "            'bert_input_labels': combined_labels,\n",
    "            'segment_ids': segment_ids,\n",
    "            'is_next': is_next\n",
    "        }\n",
    "        # print(values)\n",
    "        # print(len(combined_labels))\n",
    "        # print(len(combined_sentence))\n",
    "        assert len(combined_labels) == len(combined_sentence)\n",
    "        return {key: torch.tensor(value) for key, value in values.items()} #Must be converted into tensor \n",
    "    \n",
    "    def get_nsp(self,index):\n",
    "            t1, t2 = self.lines[index][0], self.lines[index][1]\n",
    "            \n",
    "            prob = random.random()\n",
    "            if(prob < 0.5):\n",
    "                return t1, t2, 1\n",
    "            else:\n",
    "                return t1, self.lines[random.randrange(len(pairs))][1], 0\n",
    "        \n",
    "    # def get_masked_sentences(self,sentence):\n",
    "        \n",
    "    #     # tokens = sentence.split()\n",
    "    #     # remove cls and sep token\n",
    "    #     tokens = self.tokenizer(sentence)['input_ids'][1:-1]\n",
    "    #     mask_label = []\n",
    "    #     output = []\n",
    "\n",
    "    #     # 15% of the tokens would be replaced\n",
    "    #     for token in tokens:\n",
    "    #         prob = random.random()\n",
    "\n",
    "    #         # remove cls and sep token\n",
    "    #         # token_id = tokenizer(token)['input_ids'][1:-1]\n",
    "\n",
    "    #         if prob < 0.15:\n",
    "    #             prob /= 0.15\n",
    "\n",
    "    #             # 80% chance change token to mask token\n",
    "    #             if prob < 0.8:\n",
    "    #                 # for i in range(len(token_id)):\n",
    "    #                     output.append(self.tokenizer.vocab['[MASK]'])\n",
    "    #                     # output_label.append(token)\n",
    "    #             # 10% chance change token to random token\n",
    "    #             elif prob < 0.9:\n",
    "    #                 # for i in range(len(token_id)):\n",
    "    #                     output.append(random.randrange(len(self.tokenizer.vocab)))\n",
    "    #                     # output_label.append(token)\n",
    "    #             # 10% chance change token to current token\n",
    "    #             else:\n",
    "    #                 output.append(token)\n",
    "    #             mask_label.append(token)\n",
    "                \n",
    "\n",
    "    #         else:\n",
    "    #             output.append(token)\n",
    "    #             # for i in range(len(token)):\n",
    "    #             mask_label.append(0)\n",
    "\n",
    "    #     # flattening (cus every list above is in 2D and will raise an error when passed to TextEmbeddings layer)\n",
    "    #     output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
    "    #     mask_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in mask_label]))\n",
    "    #     assert len(output) == len(mask_label)\n",
    "    #     return output, mask_label\n",
    "            \n",
    "    def get_masked_sentences(self, sentence):\n",
    "        tokens = self.tokenizer(sentence)['input_ids'][1:-1]\n",
    "        mask_label = []\n",
    "        output = []\n",
    "\n",
    "        for token in tokens:\n",
    "            prob = random.random()\n",
    "\n",
    "            if prob < 0.15:\n",
    "                prob /= 0.15\n",
    "\n",
    "                if prob < 0.8:\n",
    "                    output.append(self.tokenizer.vocab['[MASK]'])\n",
    "                elif prob < 0.9:\n",
    "                    output.append(random.randrange(len(self.tokenizer.vocab)))\n",
    "                else:\n",
    "                    output.append(token)\n",
    "                mask_label.append(token)\n",
    "            else:\n",
    "                output.append(token)\n",
    "                mask_label.append(0)\n",
    "\n",
    "        assert len(output) == len(mask_label)\n",
    "        return output, mask_label\n",
    "   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.vocab['[SEP]']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_word(\"What? It's on the way. She says she's got something for me.\")\n",
    "# tokenizer(\"What? It's on the way. She says she's got something for me.\")['input_ids'][1:-1]\n",
    "# tokenizer.vocab['[MASK]']\n",
    "ls = [1,2,3]\n",
    "ls += [2,3]\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of the dataset class\n",
    "dataset = BERTDataset(data_pair=pairs, tokenizer=tokenizer, seq_len=block_size)\n",
    "\n",
    "import os\n",
    "#Creating a dataloader\n",
    "train_loader = DataLoader(\n",
    "   dataset, batch_size=batch_size, shuffle=True, pin_memory=False, num_workers=os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert_input_masked': tensor([[  1, 269, 184,  ...,   0,   0,   0],\n",
      "        [  1, 983,   3,  ...,   0,   0,   0],\n",
      "        [  1, 430,   3,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1,  17,  17,  ...,   0,   0,   0],\n",
      "        [  1,  17,  17,  ...,   0,   0,   0],\n",
      "        [  1, 182, 253,  ...,   0,   0,   0]]), 'bert_input_labels': tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0, 17,  ...,  0,  0,  0],\n",
      "        [ 0,  0, 34,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0]]), 'segment_ids': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'is_next': tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "sample_data = next(iter(train_loader))\n",
    "# print('Batch Size', sample_data['bert_input_masked'].size())\n",
    "print(sample_data)\n",
    "# 3 is MASK\n",
    "# result = dataset[random.randrange(len(dataset))]\n",
    "# print(result)\n",
    "# print(tokenizer.convert_ids_to_tokens(result['bert_input_masked']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1, 182, 34, 162, 11, 58, 192, 150, 417, 17, 266, 904, 266, 11, 58, 263, 404, 202, 185, 17, 2, 17, 368, 5, 2, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"[CLS] What? It's on the way. She says she's got something for me. [SEP] . Yeah! [SEP]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.3165, -0.1863,  0.1542,  ..., -0.5941, -0.2662, -1.2164],\n",
      "        [-0.3165, -0.1863,  0.1542,  ..., -0.5941, -0.2662, -1.2164],\n",
      "        [-0.3165, -0.1863,  0.1542,  ..., -0.5941, -0.2662, -1.2164]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "segment_ids = torch.tensor([0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2])\n",
    "# segment_ids = [1 for _ in range(len(sent1.split()))] + [2 for _ in range(len(sent2.split()))] \n",
    "# if(len(sent1.split()) + len(sent2.split()) > 0):\n",
    "    # segment_ids += [0 for x in range(block_size - (len(sent1.split()) + len(sent2.split())))]\n",
    "segment = SegmentEmbeddings()\n",
    "print(segment(segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Hi hellow my self yuvraj sinfj [SEP] hellow britha myslef [SEP]\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"Hi hellow my self yuvraj sinfj\"\n",
    "sent2 = \"hellow britha myslef\"\n",
    "final_sent = '[CLS] ' + sent1 + ' [SEP] ' + sent2 + ' [SEP]'\n",
    "print(final_sent)\n",
    "if(len(final_sent.split()) < block_size):\n",
    "    while(len(final_sent.split()) !=  block_size):\n",
    "        final_sent = final_sent + ' ' + '[PAD]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1, 636, 904, 113, 218, 2191, 6502, 106, 290, 100, 3406, 112, 100, 2, 904, 113, 3415, 3917, 218, 102, 188, 112, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(final_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Hi hellow my self yuvraj sinfj [SEP] hellow britha myslef [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 7]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0, len(sentence_t0_list)-1, len(sent1.split()) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[5, 4, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('[CLS] Hi hellow my self vanessa [MASK] [SEP] hellow britha myslef i dont know wht yiou saying man [SEP]',\n",
       " [0, 0, 0, 0, 0, 6821, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_masked_sentences(final_sent, sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 17, 19]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hellow', 'myself', 'yuvraj', 'singh']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 904, 113, 2], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 0, 1, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text embeddings\n",
    "class TextEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size = vocab_size,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embeddings_table = nn.Embedding(num_embeddings = vocab_size, embedding_dim=embeddings_dims, device=device, padding_idx=0) #Just a look up table to convert the toekns_ids to some numbers\n",
    "        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embeddings_table(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment embeddings\n",
    "class SegmentEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_segments = n_segments,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seg_embds = nn.Embedding(num_embeddings = n_segments, embedding_dim=embeddings_dims, device=device, padding_idx=0)\n",
    "    def forward(self, x):\n",
    "        return self.seg_embds(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer Normalization\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=embeddings_dims, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FeedForward Neural Network\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dropout = dropout,\n",
    "        embeddings_size = embeddings_dims,\n",
    "        # inner_dimensional_states: int = 3072\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(device=device, in_features=embeddings_size, out_features= 4 * embeddings_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(device=device, in_features= 4 * embeddings_size, out_features=embeddings_size),\n",
    "            nn.Dropout(p = dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # mlp_weights_init = self.mlp.apply(weights_init)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Attention Head\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.head_size = embeddings_dims // no_of_heads\n",
    "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
    "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
    "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
    "        self.dropout = nn.Dropout(p = attn_dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch, block_size, embd_dims = x.shape\n",
    "        k = self.keys(x)\n",
    "        q = self.query(x)\n",
    "        v = self.values(x)\n",
    "        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
    "        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
    "        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, 1e-9)\n",
    "        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
    "        # weights_normalized = self.dropout(weights_normalized)\n",
    "        out = weights_normalized @ v\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
    "        self.dropout = nn.Dropout(p = attn_dropout)\n",
    "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        linear_layer = self.linear(concat)\n",
    "        out = self.dropout(linear_layer)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA\n",
    "import math\n",
    "class PositionEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        block_size = block_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pos_embd = torch.ones((block_size, embeddings_dims), device=device)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for pos in range(block_size):\n",
    "            for i in range(0,embeddings_dims // 2):\n",
    "                self.pos_embd[pos, 2*i] = math.sin(pos/(10000**((2*i)/embeddings_dims)))\n",
    "                self.pos_embd[pos, 2*i + 1] = math.cos(pos/(10000**((2*i)/embeddings_dims)))\n",
    "        \n",
    "        self.pos_embd.unsqueeze(0)\n",
    "        return self.pos_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# embeddings_dims = 512\n",
    "# block_size = 128\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pos_emb = PositionEmbeddings(embeddings_dims, block_size)\n",
    "x = torch.zeros((10, block_size, embeddings_dims), device=device)  # Example input\n",
    "output = pos_emb(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Block\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        dropout = dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha = MHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
    "        self.layer_norm1 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.layer_norm2 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.mha(x)\n",
    "        # x = x + self.layer_norm1(x)\n",
    "        # x = x + self.mlp_block(x)\n",
    "        # out = self.layer_norm2(x)\n",
    "        # x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n",
    "        # x = x + self.mlp_block(self.layer_norm2(x)) #Very important step\n",
    "        x = self.layer_norm1(x + self.mha(x))\n",
    "        x = self.layer_norm2(x + self.mlp_block(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Block\n",
    "\n",
    "class EncoderModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        block_size = block_size,\n",
    "        dropout = dropout,\n",
    "        no_of_encoder_layers = no_of_encoder_layers,\n",
    "        vocab_size = vocab_size,\n",
    "        n_segments = n_segments\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.positional_embeddings = PositionEmbeddings(block_size=block_size, embeddings_dims=embeddings_dims)\n",
    "        self.text_embds = TextEmbeddings(vocab_size=vocab_size, embeddings_dims=embeddings_dims)\n",
    "        # self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
    "        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.encoder_layers = nn.Sequential(*[TransformerEncoderBlock(embeddings_dims=embeddings_dims, attn_dropout=attn_dropout, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_encoder_layers)])\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.seg_embds = SegmentEmbeddings(n_segments=n_segments, embeddings_dims=embeddings_dims)\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x, segment_ids):\n",
    "        x = self.text_embds(x) + self.seg_embds(segment_ids) + self.positional_embeddings(x) * math.sqrt(embeddings_dims)\n",
    "        x = self.dropout(x)\n",
    "        x = self.encoder_layers(x)\n",
    "        # x = self.layer_norm(x)\n",
    "        # out = self.linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NSP\n",
    "\n",
    "class NSP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # self.encoder_block = EncoderModel(no_of_encoder_layers=no_of_encoder_layers, attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, block_size=block_size, dropout=dropout, vocab_size=vocab_size, n_segments=n_segments)\n",
    "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=2, device=device)\n",
    "    \n",
    "\n",
    "    def forward(self, x,  isnext):\n",
    "        # print(x.shape)\n",
    "        # print(x[0,:].shape)\n",
    "        \n",
    "        # sigmoid = torch.nn.Sigmoid()\n",
    "        logits = self.linear_layer(x[:,0,:])\n",
    "        # print(probs)\n",
    "        # print(torch.argmax(sigmoid(logits),dim=-1))\n",
    "        # print(isnext.float())\n",
    "        # print(isnext.view_as(logits).float())\n",
    "        # print(torch.argmax(logits, dim=0))\n",
    "        # print(logits)\n",
    "        loss = nn.functional.cross_entropy(logits, isnext)\n",
    "        return loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.6210, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nsp =MLM()\n",
    "enc = EncoderModel()\n",
    "# out = enc(result['bert_input_masked'], result['segment_ids'])\n",
    "out = nsp(x = enc(sample_data['bert_input_masked'], sample_data['segment_ids']), mask_labels=sample_data['bert_input_labels'])\n",
    "out\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 256])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = enc(sample_data['bert_input_masked'], sample_data['segment_ids'])\n",
    "# x.transpose(1,2).shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_input_masked': tensor([[    1,   220,    17,  ...,     0,     0,     0],\n",
       "         [    1, 18278,    34,  ...,     0,     0,     0],\n",
       "         [    1,  1126,    34,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    1,   269,   266,  ...,     0,     0,     0],\n",
       "         [    1,  2221,    17,  ...,     0,     0,     0],\n",
       "         [    1,   399,   211,  ...,     0,     0,     0]]),\n",
       " 'bert_input_labels': tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0, 399,   0,  ...,   0,   0,   0]]),\n",
       " 'segment_ids': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'is_next': tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "         1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "         0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLM\n",
    "\n",
    "class MLM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        vocab_size = vocab_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # self.encoder_block = EncoderModel(no_of_encoder_layers=no_of_encoder_layers, attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, block_size=block_size, dropout=dropout, vocab_size=vocab_size, n_segments=n_segments)\n",
    "        self.linear_layer1 = nn.Linear(in_features=embeddings_dims, out_features=vocab_size, device=device)\n",
    "        # self.linear_layer2 = nn.Linear(in_features=vocab_size, out_features=block_size, device=device)\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, x,  mask_labels):\n",
    "        # Get the logits from the linear layer\n",
    "        logits = self.linear_layer1(x)  # logits: (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        # Reshape logits and mask_labels for cross_entropy\n",
    "        batch_size, seq_len, vocab_size = logits.shape\n",
    "        logits = logits.view(batch_size * seq_len, vocab_size)        # logits: (batch_size * seq_len, vocab_size)\n",
    "        mask_labels = mask_labels.view(-1)          # mask_labels: (batch_size * seq_len)\n",
    "        \n",
    "        # Calculate the cross-entropy loss\n",
    "        loss = nn.functional.cross_entropy(logits, mask_labels)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT\n",
    "\n",
    "class BERT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        block_size = block_size,\n",
    "        dropout = dropout,\n",
    "        vocab_size = vocab_size,\n",
    "        n_segments = n_segments\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlm = MLM(embeddings_dims=embeddings_dims, vocab_size=vocab_size)\n",
    "        self.nsp = NSP(embeddings_dims=embeddings_dims)\n",
    "        self.encoder_layer = EncoderModel(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, no_of_encoder_layers=no_of_encoder_layers, block_size=block_size,dropout=dropout,n_segments=n_segments)\n",
    "\n",
    "    def forward(self, x, segment_ids, labels, isnext):\n",
    "        x = self.encoder_layer(x, segment_ids)\n",
    "        mlm_loss = self.mlm(x, labels)\n",
    "        nsp_loss, logits = self.nsp(x, isnext)\n",
    "        return mlm_loss, nsp_loss , logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT(embeddings_dims=embeddings_dims, vocab_size=vocab_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n",
       "=======================================================================================================================================\n",
       "BERT (BERT)                                             [64, 128]            --                   --                   True\n",
       "├─EncoderModel (encoder_layer)                          [64, 128]            [64, 128, 512]       --                   True\n",
       "│    └─TextEmbeddings (text_embds)                      [64, 128]            [64, 128, 512]       --                   True\n",
       "│    │    └─Embedding (embeddings_table)                [64, 128]            [64, 128, 512]       10,959,360           True\n",
       "│    └─SegmentEmbeddings (seg_embds)                    [64, 128]            [64, 128, 512]       --                   True\n",
       "│    │    └─Embedding (seg_embds)                       [64, 128]            [64, 128, 512]       1,536                True\n",
       "│    └─PositionEmbeddings (positional_embeddings)       [64, 128]            [128, 512]           --                   --\n",
       "│    └─Dropout (dropout)                                [64, 128, 512]       [64, 128, 512]       --                   --\n",
       "│    └─Sequential (encoder_layers)                      [64, 128, 512]       [64, 128, 512]       --                   True\n",
       "│    │    └─TransformerEncoderBlock (0)                 [64, 128, 512]       [64, 128, 512]       3,150,336            True\n",
       "│    │    └─TransformerEncoderBlock (1)                 [64, 128, 512]       [64, 128, 512]       3,150,336            True\n",
       "│    │    └─TransformerEncoderBlock (2)                 [64, 128, 512]       [64, 128, 512]       3,150,336            True\n",
       "│    │    └─TransformerEncoderBlock (3)                 [64, 128, 512]       [64, 128, 512]       3,150,336            True\n",
       "│    │    └─TransformerEncoderBlock (4)                 [64, 128, 512]       [64, 128, 512]       3,150,336            True\n",
       "│    │    └─TransformerEncoderBlock (5)                 [64, 128, 512]       [64, 128, 512]       3,150,336            True\n",
       "├─MLM (mlm)                                             [64, 128, 512]       --                   --                   True\n",
       "│    └─Linear (linear_layer1)                           [64, 128, 512]       [64, 128, 21405]     10,980,765           True\n",
       "├─NSP (nsp)                                             [64, 128, 512]       --                   --                   True\n",
       "│    └─Linear (linear_layer)                            [64, 512]            [64, 2]              1,026                True\n",
       "=======================================================================================================================================\n",
       "Total params: 40,844,703\n",
       "Trainable params: 40,844,703\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.61\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 3684.50\n",
       "Params size (MB): 163.38\n",
       "Estimated Total Size (MB): 3848.08\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing a summary of the architecture\n",
    "from torchinfo import summary\n",
    "sample_data = {key: value.to(device) for key, value in sample_data.items()}\n",
    "summary(model=model,\n",
    "        input_data=(sample_data['bert_input_masked'], sample_data['segment_ids'], sample_data['bert_input_labels'], sample_data['is_next']),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])\n",
    "# model(result['bert_input_masked'],result['segment_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  3047, 19247,  ...,     0,     0,     0],\n",
       "        [    1,   368,    17,  ...,     0,     0,     0],\n",
       "        [    1, 17584,   291,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    1,   173,    11,  ...,     0,     0,     0],\n",
       "        [    1,   173,    11,  ...,     0,     0,     0],\n",
       "        [    1,   368,    17,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample_data['bert_input_masked']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.3595,  1.3807, -0.6527,  ...,  1.6281, -1.4718,  0.4377],\n",
       "         [ 1.4273,  0.4243, -0.4965,  ...,  1.6281, -1.4717,  0.4377],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 0.6228,  1.3948,  1.7603,  ...,  3.9834, -1.2730,  1.7959],\n",
       "         [ 0.6500,  2.0493, -0.8632,  ...,  1.7049, -3.7139,  1.3620],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.1296,  3.1447,  0.4807,  ...,  3.4399, -3.1435,  0.7926],\n",
       "         [ 1.9241, -1.6210,  0.0041,  ...,  3.0458, -1.1279, -0.1939],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.3595,  1.3807, -0.6527,  ...,  1.6281, -1.4718,  0.4377],\n",
       "         [ 1.1027,  1.2330,  1.7113,  ...,  2.5625, -1.7789, -1.6832],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.9107,  0.2109,  2.4622,  ...,  2.4812, -0.8140,  0.3321],\n",
       "         [ 1.4273,  0.4243, -0.4965,  ...,  1.6281, -1.4717,  0.4377],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.3595,  1.3807, -0.6527,  ...,  1.6281, -1.4718,  0.4377],\n",
       "         [ 2.7657,  0.8188,  1.7924,  ...,  1.5932, -2.9851, -0.9957],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embd = PositionEmbeddings()\n",
    "seg_embd = SegmentEmbeddings()\n",
    "text_embds = TextEmbeddings()\n",
    "out = text_embds(sample_data['bert_input_masked']) + seg_embd(sample_data['segment_ids']) + pos_embd(sample_data['bert_input_masked'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 512])"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embd(sample_data['bert_input_masked']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 512])"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_embd(sample_data['segment_ids']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 512])"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embds(sample_data['bert_input_masked']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "\n",
    "    def __init__(self, optimizer, embeddings_dims, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(embeddings_dims, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up optimizer and lr scheduler\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = max_lr, betas=(beta_1,beta_2), eps=epsilon)\n",
    "lr_scheduler = ScheduledOptim(optimizer=optimizer,embeddings_dims=embeddings_dims,n_warmup_steps=n_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert_input_masked': tensor([[    1,   231,    11,  ...,     0,     0,     0],\n",
      "        [    1,   541,   202,  ...,     0,     0,     0],\n",
      "        [    1,   162,    11,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,   302,    34,  ...,     0,     0,     0],\n",
      "        [    1, 12513,    17,  ...,     0,     0,     0],\n",
      "        [    1,   266,   402,  ...,     0,     0,     0]]), 'bert_input_labels': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'segment_ids': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'is_next': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3277,  0.2688],\n",
       "        [ 0.0486,  0.3428],\n",
       "        [ 0.0158,  0.2086],\n",
       "        [ 0.4024,  0.6013],\n",
       "        [ 0.0945,  0.5034],\n",
       "        [ 0.5389,  0.5253],\n",
       "        [ 0.1614,  0.4149],\n",
       "        [ 0.2898,  0.1618],\n",
       "        [-0.0174,  0.4979],\n",
       "        [ 0.4900,  0.0323],\n",
       "        [ 0.1157,  0.5928],\n",
       "        [ 0.3247,  0.4949],\n",
       "        [ 0.3497,  0.3961],\n",
       "        [ 0.4306,  0.6082],\n",
       "        [-0.1206,  0.5410],\n",
       "        [ 0.4971,  0.3105],\n",
       "        [ 0.6289,  0.3780],\n",
       "        [ 0.0587,  0.4536],\n",
       "        [ 0.3644,  0.0355],\n",
       "        [-0.0520,  0.9022],\n",
       "        [-0.0686,  0.5447],\n",
       "        [ 0.2530,  0.5690],\n",
       "        [ 0.1160,  0.5040],\n",
       "        [ 0.1742,  0.2256],\n",
       "        [ 0.2346,  0.3317],\n",
       "        [-0.0949,  0.4142],\n",
       "        [ 0.1664, -0.0305],\n",
       "        [ 0.0898,  0.1764],\n",
       "        [ 0.2735,  0.5888],\n",
       "        [ 0.2276,  0.1259],\n",
       "        [ 0.3556,  0.7751],\n",
       "        [ 0.1617,  0.3224],\n",
       "        [ 0.5495,  0.2966],\n",
       "        [ 0.1566,  0.5112],\n",
       "        [ 0.3239,  0.4798],\n",
       "        [ 0.6981,  0.5053],\n",
       "        [ 0.2836,  0.4812],\n",
       "        [ 0.1761,  0.4811],\n",
       "        [ 0.0907,  0.4153],\n",
       "        [ 0.2302,  0.0673],\n",
       "        [ 0.2336,  0.5847],\n",
       "        [ 0.4923,  0.3872],\n",
       "        [ 0.0159,  0.2228],\n",
       "        [ 0.4623,  0.6019],\n",
       "        [ 0.3732,  0.6426],\n",
       "        [ 0.1291,  0.2507],\n",
       "        [ 0.0559,  0.4882],\n",
       "        [ 0.3395,  0.3806],\n",
       "        [ 0.1198,  0.1517],\n",
       "        [-0.4055, -0.0409],\n",
       "        [ 0.0429,  0.4655],\n",
       "        [ 0.4158,  0.2849],\n",
       "        [ 0.3886,  0.2901],\n",
       "        [ 0.3324,  0.3357],\n",
       "        [-0.0191,  0.3300],\n",
       "        [ 0.4084,  0.1545],\n",
       "        [-0.2060,  0.5043],\n",
       "        [ 0.1996,  0.7711],\n",
       "        [-0.0919,  0.4581],\n",
       "        [ 0.2424,  0.3760],\n",
       "        [ 0.3711,  0.3200],\n",
       "        [ 0.5703,  0.5294],\n",
       "        [ 0.1773,  0.6211],\n",
       "        [ 0.5526,  0.4913]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,_,logits = model(result['bert_input_masked'], result['segment_ids'], result['bert_input_labels'], result['is_next'])\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(nn.functional.softmax(logits, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:  0 Epoch:  0 Train loss:  11.644902229309082 NSP Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "loss = []\n",
    "items = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    loss = []\n",
    "    items = []\n",
    "    correct = 0\n",
    "    total_instances = 0\n",
    "    accuracy = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        result = {key: value.to(device) for key,value in data.items()}\n",
    "        mlm_loss, loss_nsp, logits = model(result['bert_input_masked'], result['segment_ids'], result['bert_input_labels'], result['is_next'])\n",
    "        loss_tot = mlm_loss + loss_nsp\n",
    "        loss_tot.backward()\n",
    "        lr_scheduler.zero_grad()\n",
    "        lr_scheduler.step_and_update_lr()\n",
    "        loss.append(loss_tot.item())\n",
    "        y_pred = torch.argmax(nn.functional.softmax(logits, dim=-1), dim=-1)\n",
    "        acc = accuracy_score(result['is_next'].cpu(), y_pred.cpu())\n",
    "        # total_instances += 1\n",
    "        accuracy.append(acc)\n",
    "        if(i % 100 == 0 or i == len(train_loader) - 1):\n",
    "            mean_loss = sum(loss) / len(loss)\n",
    "            mean_accuracy = sum(accuracy) / len(accuracy)\n",
    "            print(\"Steps: \",i, \"Epoch: \", epoch , \"Train loss: \", mean_loss, \"NSP Accuracy: \", mean_accuracy)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
