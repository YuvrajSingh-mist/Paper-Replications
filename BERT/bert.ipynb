{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import transformers, datasets\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 22 23:26:23 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.03              Driver Version: 555.85         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   48C    P3             12W /   60W |       0MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "n_segments = 3\n",
    "block_size = 256\n",
    "batch_size = 64\n",
    "embeddings_dims = 256\n",
    "attn_dropout = 0.1\n",
    "no_of_heads = 4 #IMP needs to be thoroughly calculated\n",
    "dropout = 0.1\n",
    "epochs = 100\n",
    "max_lr = 2.5e-4\n",
    "no_of_decoder_layers = 4 #IMP needs to be thoroughly calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-22 21:56:52--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.53, 64:ff9b::84ec:cf35\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9916637 (9.5M) [application/zip]\n",
      "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
      "\n",
      "cornell_movie_dialo 100%[===================>]   9.46M  2.28MB/s    in 4.1s    \n",
      "\n",
      "2024-06-22 21:56:57 (2.28 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "\n",
    "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
    "!unzip -qq cornell_movie_dialogs_corpus.zip\n",
    "!rm cornell_movie_dialogs_corpus.zip\n",
    "!mkdir datasets\n",
    "!mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
    "!mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets\n",
    "\n",
    "vocab_size = 10000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading all data into memory\n",
    "corpus_movie_conv = './datasets/movie_conversations.txt'\n",
    "corpus_movie_lines = './datasets/movie_lines.txt'\n",
    "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
    "    conv = c.readlines()\n",
    "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
    "    lines = l.readlines()\n",
    "\n",
    "### splitting text using special lines\n",
    "lines_dic = {}\n",
    "for line in lines:\n",
    "    objects = line.split(\" +++$+++ \")\n",
    "    lines_dic[objects[0]] = objects[-1]\n",
    "\n",
    "### generate convo  pairs\n",
    "pairs = []\n",
    "for con in conv:\n",
    "    ids = eval(con.split(\" +++$+++ \")[-1]) #Evaluates the string as a list now\n",
    "    for i in range(len(ids)):\n",
    "        pair = []\n",
    "        \n",
    "        if i == len(ids) - 1:\n",
    "            break\n",
    "        # print(ids[i])\n",
    "        first = lines_dic[ids[i]].strip()  \n",
    "        second = lines_dic[ids[i+1]].strip() \n",
    "\n",
    "        pair.append(' '.join(first.split()[:block_size]))\n",
    "        pair.append(' '.join(second.split()[:block_size]))\n",
    "        pairs.append(pair)\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad. Again.',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221616/221616 [00:00<00:00, 6865028.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvrajsingh/anaconda3/envs/py311/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1947: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "len(pairs) #Total pairs-> 221K\n",
    "\n",
    "##########W Tokenization #################\n",
    "# WordPiece tokenizer\n",
    "\n",
    "### save data as txt file\n",
    "text_data = []\n",
    "file_count = 0\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "\n",
    "for sample in tqdm.tqdm([x[0] for x in pairs]):\n",
    "    # cleaned_sample = clean_text(sample)\n",
    "    text_data.append(sample)\n",
    "\n",
    "    # once we hit the 10K mark, save to file\n",
    "    # if len(text_data) == 10000:\n",
    "with open(f'./datasets/text.txt', 'w', encoding='utf-8') as fp:\n",
    "    fp.write('\\n'.join(text_data))\n",
    "        # text_data = []\n",
    "        # file_count += 1\n",
    "\n",
    "paths = 'datasets/text.txt'\n",
    "# print(paths)\n",
    "### training own tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tokenizer.train( \n",
    "    files=paths,\n",
    "    vocab_size=30_000, \n",
    "    min_frequency=5,\n",
    "    # limit_alphabet=1000, \n",
    "    wordpieces_prefix='##',\n",
    "    special_tokens=['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]']\n",
    "    )\n",
    "\n",
    "os.mkdir('./bert-it-1')\n",
    "tokenizer.save_model('./bert-it-1', 'bert-it')\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-it-1/bert-it-vocab.txt', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data_pair, tokenizer, seq_len=block_size):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.corpus_lines = len(data_pair)\n",
    "        self.lines = data_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_lines\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        #Getting NSP sentences\n",
    "        sent1, sent2, is_next = get_nsp(item)\n",
    "        input_ids_sent1 = tokenizer(sent1)['input_ids']\n",
    "        input_ids_sent2 = tokenizer(sent2)['input_ids']\n",
    "        # final_sent = tokenizer.convert_tokens_to_ids('[CLS]') + input_ids_sent1 + tokenizer.convert_tokens_to_ids('[SEP]') + input_ids_sent2 + tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "        \n",
    "        randomized_sent_1, label1 = get_masked_sentences(sent1)\n",
    "        randomized_sent_2, label2 = get_masked_sentences(sent2)\n",
    "        \n",
    "        #adding [PAD] tokens\n",
    "        \n",
    "        \n",
    "        def get_nsp(index):\n",
    "            t1, t2 = self.lines[index][0], self.lines[index][1]\n",
    "            \n",
    "            prob = random.randint(1,2)\n",
    "            if(prob == 1):\n",
    "                return t1, t2, 1\n",
    "            else:\n",
    "                ind = random.randint(221615)\n",
    "                while(True):\n",
    "                    if(ind != index):\n",
    "                        return t1, self.lines[ind][1], 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        def get_masked_sentences(sentence):\n",
    "            \n",
    "            no_of_pos = math.ceil(0.15 * len(sentence.split()))\n",
    "            print(no_of_pos)\n",
    "            token_pos = [x for x in range(len(sentence.split()))]\n",
    "            print(token_pos)\n",
    "            choices_of_pos_to_be_masked = [random.choice([x for x in token_pos]) for x in range(no_of_pos)]\n",
    "            sentence_t0_list = sentence.split()\n",
    "            print(choices_of_pos_to_be_masked)\n",
    "            for i in choices_of_pos_to_be_masked:\n",
    "                ls = [0,0,0,0,0,0,0,0,1,2]\n",
    "                choice = random.choice(ls)\n",
    "                if(choice == 0):\n",
    "                    for j in range(len(sentence_t0_list)):\n",
    "                        if(i == j):\n",
    "                            choices_of_pos_to_be_masked.remove(i)\n",
    "                            sentence_t0_list[i] = '[MASK]'\n",
    "                            masked_sentence = sentence_t0_list\n",
    "                            return ' '.join(masked_sentence)\n",
    "                elif(choice == 1):\n",
    "                    choices_of_pos_to_be_masked.remove(i)\n",
    "                    random_token = random.randrange(len(tokenizer.vocab))\n",
    "                    sentence_t0_list[i] = tokenizer.convert_ids_to_tokens(random_token)\n",
    "                    return ' '.join(sentence_t0_list)\n",
    "                else:\n",
    "                    choices_of_pos_to_be_masked.remove(i)\n",
    "                    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_sentences(sentence):\n",
    "            \n",
    "    no_of_pos = math.ceil(0.15 * len(sentence.split()))\n",
    "    print(no_of_pos)\n",
    "    token_pos = [x for x in range(len(sentence.split()))]\n",
    "    print(token_pos)\n",
    "    choices_of_pos_to_be_masked = [random.choice([x for x in token_pos]) for x in range(no_of_pos)]\n",
    "    sentence_t0_list = sentence.split()\n",
    "    print(choices_of_pos_to_be_masked)\n",
    "    for i in choices_of_pos_to_be_masked:\n",
    "        ls = [0,0,0,0,0,0,0,0,1,2]\n",
    "        choice = random.choice(ls)\n",
    "        if(choice == 0):\n",
    "            for j in range(len(sentence_t0_list)):\n",
    "                if(i == j):\n",
    "                    choices_of_pos_to_be_masked.remove(i)\n",
    "                    sentence_t0_list[i] = '[MASK]'\n",
    "                    masked_sentence = sentence_t0_list\n",
    "                    return ' '.join(masked_sentence)\n",
    "        elif(choice == 1):\n",
    "            choices_of_pos_to_be_masked.remove(i)\n",
    "            random_token = random.randrange(len(tokenizer.vocab))\n",
    "            sentence_t0_list[i] = tokenizer.convert_ids_to_tokens(random_token)\n",
    "            return ' '.join(sentence_t0_list)\n",
    "        else:\n",
    "            choices_of_pos_to_be_masked.remove(i)\n",
    "            return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0, 1, 2, 3]\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hellow myself yuvraj [MASK]'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_masked_sentences(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 17, 19]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hellow', 'myself', 'yuvraj', 'singh']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 904, 113, 2], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 0, 1, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text embeddings\n",
    "class TextEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size = vocab_size,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embeddings_table = nn.Embedding(num_embeddings = vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n",
    "        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embeddings_table(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment embeddings\n",
    "class SegmentEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "       n_segments = n_segments,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seg_embds = nn.Parameter(torch.ones((1,n_segments, embeddings_dims), device=device),requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        return self.seg_embds(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer Normalization\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=embeddings_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FeedForward Neural Network\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dropout = dropout,\n",
    "        embeddings_size = embeddings_dims,\n",
    "        # inner_dimensional_states: int = 3072\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(device=device, in_features=embeddings_size, out_features= 4 * embeddings_dims),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(device=device, in_features= 4 * embeddings_dims, out_features=embeddings_size),\n",
    "            nn.Dropout(p = dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # mlp_weights_init = self.mlp.apply(weights_init)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Attention Head\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.head_size = embeddings_dims // no_of_heads\n",
    "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
    "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
    "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
    "        self.dropout = nn.Dropout(p = attn_dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, block_size, embd_dims = x.shape\n",
    "        k = self.keys(x)\n",
    "        q = self.query(x)\n",
    "        v = self.values(x)\n",
    "        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
    "        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
    "        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n",
    "        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
    "        # weights_normalized = self.dropout(weights_normalized)\n",
    "        out = weights_normalized @ v\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
    "        self.dropout = nn.Dropout(p = attn_dropout)\n",
    "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        linear_layer = self.linear(concat)\n",
    "        out = self.dropout(linear_layer)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA\n",
    "import math\n",
    "class PositionEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        block_size = block_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pos_embd = torch.ones((block_size, embeddings_dims), device=device, requires_grad=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for pos in range(block_size):\n",
    "            for i in range(0,embeddings_dims):\n",
    "                self.pos_embd[pos, 2*i] = math.sin(pos/(10000**((2*i)/embeddings_dims)))\n",
    "                self.pos_embd[pos, 2*i + 1] = math.cos(pos/(10000**((2*i)/embeddings_dims)))\n",
    "        \n",
    "        \n",
    "        return self.pos_embd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Block\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        dropout = dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha = MHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
    "        self.layer_norm1 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.layer_norm2 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.mha(x)\n",
    "        # x = x + self.layer_norm1(x)\n",
    "        # x = x + self.mlp_block(x)\n",
    "        # out = self.layer_norm2(x)\n",
    "        # x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n",
    "        # x = x + self.mlp_block(self.layer_norm2(x)) #Very important step\n",
    "        x = self.layer_norm1(x + self.mha(x))\n",
    "        x = self.layer_norm2(x + self.mlp_block(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Block\n",
    "\n",
    "class EncoderModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        block_size = block_size,\n",
    "        dropout = dropout,\n",
    "        no_of_decoder_layers = no_of_decoder_layers,\n",
    "        vocab_size = vocab_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.positional_embeddings = PositionEmbeddings(block_size=block_size, embeddings_dims=embeddings_dims)\n",
    "        self.text_embds = TextEmbeddings(vocab_size=vocab_size, embeddings_dims=embeddings_dims)\n",
    "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
    "        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.decoder_layers = nn.Sequential(*[TransformerEncoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout, vocab_size=vocab_size) for _ in range(no_of_decoder_layers)])\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.seg_embds = SegmentEmbeddings(n_segments=n_segments, embeddings_dims=embeddings_dims)\n",
    "   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.text_embds(x)\n",
    "        x = x + self.seg_embds + self.positional_embeddings\n",
    "        x = self.dropout(x)\n",
    "        x = self.decoder_layers(x)\n",
    "        # x = self.layer_norm(x)\n",
    "        out = self.linear_layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
