{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "# https://medium.com/data-and-beyond/complete-guide-to-building-bert-model-from-sratch-3e6562228891\n",
    "# https://ai.plainenglish.io/bert-pytorch-implementation-prepare-dataset-part-1-efd259113e5a\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import transformers, datasets\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import itertools\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 25 06:16:56 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.03              Driver Version: 555.85         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P0             12W /   80W |       0MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "n_warmup_steps = 1000 #4000\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.98\n",
    "epsilon = 1e-9\n",
    "n_segments = 3\n",
    "block_size = 256\n",
    "batch_size = 64\n",
    "embeddings_dims = 128\n",
    "attn_dropout = 0.1\n",
    "no_of_heads = 2 #IMP needs to be thoroughly calculated\n",
    "dropout = 0.1\n",
    "epochs = 20\n",
    "max_lr = 1e-4\n",
    "no_of_encoder_layers = 2 #IMP needs to be thoroughly calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-24 00:28:26--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.236.207.53\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9916637 (9.5M) [application/zip]\n",
      "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
      "\n",
      "     cornell_movie_   2%[                    ] 226.00K   163KB/s               ^C\n",
      "[cornell_movie_dialogs_corpus.zip]\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "note:  cornell_movie_dialogs_corpus.zip may be a plain executable, not an archive\n",
      "unzip:  cannot find zipfile directory in one of cornell_movie_dialogs_corpus.zip or\n",
      "        cornell_movie_dialogs_corpus.zip.zip, and cannot find cornell_movie_dialogs_corpus.zip.ZIP, period.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘datasets’: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'cornell movie-dialogs corpus/movie_conversations.txt': No such file or directory\n",
      "mv: cannot stat 'cornell movie-dialogs corpus/movie_lines.txt': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "\n",
    "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
    "!unzip -qq cornell_movie_dialogs_corpus.zip\n",
    "!rm cornell_movie_dialogs_corpus.zip\n",
    "!mkdir datasets\n",
    "!mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
    "!mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading all data into memory\n",
    "corpus_movie_conv = './datasets/movie_conversations.txt'\n",
    "corpus_movie_lines = './datasets/movie_lines.txt'\n",
    "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
    "    conv = c.readlines()\n",
    "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
    "    lines = l.readlines()\n",
    "\n",
    "### splitting text using special lines\n",
    "lines_dic = {}\n",
    "for line in lines:\n",
    "    objects = line.split(\" +++$+++ \")\n",
    "    lines_dic[objects[0]] = objects[-1]\n",
    "\n",
    "### generate convo  pairs\n",
    "pairs = []\n",
    "for con in conv:\n",
    "    ids = eval(con.split(\" +++$+++ \")[-1]) #Evaluates the string as a list now\n",
    "    for i in range(len(ids)):\n",
    "        pair = []\n",
    "        \n",
    "        if i == len(ids) - 1:\n",
    "            break\n",
    "        # print(ids[i])\n",
    "        first = lines_dic[ids[i]].strip()  \n",
    "        second = lines_dic[ids[i+1]].strip() \n",
    "\n",
    "        pair.append(' '.join(first.split()[:block_size]))\n",
    "        pair.append(' '.join(second.split()[:block_size]))\n",
    "        pairs.append(pair)\n",
    "        # break\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = pairs[0][0]\n",
    "# ids = tokenizer(sent)['input_ids']\n",
    "# len(ids), len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/221616 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221616/221616 [00:00<00:00, 4798191.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvrajsingh/anaconda3/envs/py311/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1947: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "len(pairs) #Total pairs-> 221K\n",
    "\n",
    "##########W Tokenization #################\n",
    "# WordPiece tokenizer\n",
    "\n",
    "### save data as txt file\n",
    "text_data = []\n",
    "file_count = 0\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "\n",
    "for sample in tqdm([x[0] for x in pairs]):\n",
    "    # cleaned_sample = clean_text(sample)\n",
    "    text_data.append(sample)\n",
    "\n",
    "    # once we hit the 10K mark, save to file\n",
    "    # if len(text_data) == 10000:\n",
    "with open(f'./datasets/text.txt', 'w', encoding='utf-8') as fp:\n",
    "    fp.write('\\n'.join(text_data))\n",
    "        # text_data = []\n",
    "        # file_count += 1\n",
    "\n",
    "paths = 'datasets/text.txt'\n",
    "# print(paths)\n",
    "### training own tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tokenizer.train( \n",
    "    files=paths,\n",
    "    vocab_size=30_000, \n",
    "    min_frequency=5,\n",
    "    # limit_alphabet=1000, \n",
    "    wordpieces_prefix='##',\n",
    "    special_tokens=['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]']\n",
    "    )\n",
    "\n",
    "if not os.path.exists('./bert-it-1'): os.mkdir('./bert-it-1')\n",
    "tokenizer.save_model('./bert-it-1', 'bert-it')\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-it-1/bert-it-vocab.txt', local_files_only=True)\n",
    "\n",
    "#Setting vocab size\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data_pair, tokenizer, seq_len=block_size):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.corpus_lines = len(data_pair)\n",
    "        self.lines = data_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_lines\n",
    "\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        \n",
    "        #Getting NSP sentences\n",
    "        sent1, sent2, is_next = self.get_nsp(item)\n",
    "        \n",
    "        #Getting masked sentences\n",
    "        sent1_masked , label1 = self.get_masked_sentences(sent1)\n",
    "        sent2_masked , label2 = self.get_masked_sentences(sent2)\n",
    "        \n",
    "        #Adding CLS and SEP tokens\n",
    "        sent1_masked_cls_and_sep_aded = [self.tokenizer.vocab['[CLS]']]+ sent1_masked + [self.tokenizer.vocab['[SEP]']]\n",
    "        sent2_masked_cls_and_sep_aded = sent2_masked + [self.tokenizer.vocab['[SEP]']]\n",
    "        \n",
    "        label1_padding_added = [self.tokenizer.vocab['[PAD]']] + label1 + [self.tokenizer.vocab['[PAD]']] #because of [1:-1] thing (I removed CLS and SEP token before) and the middle one because of the added [SEP] token\n",
    "        label2_padding_added = label2 + [self.tokenizer.vocab['[PAD]']]\n",
    "        \n",
    "        #Segment ids\n",
    "        segment_ids = [1 for _ in range(len(sent1_masked_cls_and_sep_aded))] + [2 for _ in range(len(sent2_masked_cls_and_sep_aded))]\n",
    "        \n",
    "        # print(\"senti\", sent1_masked_cls_and_sep_aded)\n",
    "        # print(\"sent2\", sent2_masked_cls_and_sep_aded)\n",
    "        # print(\"label1\", label1_padding_added)\n",
    "        # print(\"label1\", label2_padding_added)\n",
    "        \n",
    "        \n",
    "        #Combine the sentences\n",
    "        combined_sentence = sent1_masked_cls_and_sep_aded + sent2_masked_cls_and_sep_aded\n",
    "        combined_labels = label1_padding_added + label2_padding_added\n",
    "        \n",
    "        if(len(combined_sentence) > self.seq_len): \n",
    "            combined_sentence = combined_sentence[:self.seq_len]\n",
    "            combined_labels = combined_labels[:self.seq_len]\n",
    "            segment_ids = segment_ids[:self.seq_len]\n",
    "        elif (len(combined_sentence) < self.seq_len):\n",
    "            while(len(combined_sentence) < self.seq_len):\n",
    "                combined_sentence += [self.tokenizer.vocab['[PAD]']]\n",
    "                segment_ids += [0]\n",
    "                combined_labels += [0]\n",
    "                \n",
    "        values = {\n",
    "            'bert_input_masked': combined_sentence,\n",
    "            'bert_input_labels': combined_labels,\n",
    "            'segment_ids': segment_ids,\n",
    "            'is_next': is_next\n",
    "        }\n",
    "        # print(values)\n",
    "        # print(len(combined_labels))\n",
    "        # print(len(combined_sentence))\n",
    "        assert len(combined_labels) == len(combined_sentence)\n",
    "        return {key: torch.tensor(value) for key, value in values.items()} #Must be converted into tensor \n",
    "    \n",
    "    def get_nsp(self,index):\n",
    "            t1, t2 = self.lines[index][0], self.lines[index][1]\n",
    "            \n",
    "            prob = random.random()\n",
    "            if(prob < 0.5):\n",
    "                return t1, t2, 1\n",
    "            else:\n",
    "                return t1, self.lines[random.randrange(len(pairs))][1], 0\n",
    "        \n",
    "    # def get_masked_sentences(self,sentence):\n",
    "        \n",
    "    #     # tokens = sentence.split()\n",
    "    #     # remove cls and sep token\n",
    "    #     tokens = self.tokenizer(sentence)['input_ids'][1:-1]\n",
    "    #     mask_label = []\n",
    "    #     output = []\n",
    "\n",
    "    #     # 15% of the tokens would be replaced\n",
    "    #     for token in tokens:\n",
    "    #         prob = random.random()\n",
    "\n",
    "    #         # remove cls and sep token\n",
    "    #         # token_id = tokenizer(token)['input_ids'][1:-1]\n",
    "\n",
    "    #         if prob < 0.15:\n",
    "    #             prob /= 0.15\n",
    "\n",
    "    #             # 80% chance change token to mask token\n",
    "    #             if prob < 0.8:\n",
    "    #                 # for i in range(len(token_id)):\n",
    "    #                     output.append(self.tokenizer.vocab['[MASK]'])\n",
    "    #                     # output_label.append(token)\n",
    "    #             # 10% chance change token to random token\n",
    "    #             elif prob < 0.9:\n",
    "    #                 # for i in range(len(token_id)):\n",
    "    #                     output.append(random.randrange(len(self.tokenizer.vocab)))\n",
    "    #                     # output_label.append(token)\n",
    "    #             # 10% chance change token to current token\n",
    "    #             else:\n",
    "    #                 output.append(token)\n",
    "    #             mask_label.append(token)\n",
    "                \n",
    "\n",
    "    #         else:\n",
    "    #             output.append(token)\n",
    "    #             # for i in range(len(token)):\n",
    "    #             mask_label.append(0)\n",
    "\n",
    "    #     # flattening (cus every list above is in 2D and will raise an error when passed to TextEmbeddings layer)\n",
    "    #     output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
    "    #     mask_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in mask_label]))\n",
    "    #     assert len(output) == len(mask_label)\n",
    "    #     return output, mask_label\n",
    "            \n",
    "    def get_masked_sentences(self, sentence):\n",
    "        tokens = self.tokenizer(sentence)['input_ids'][1:-1]\n",
    "        mask_label = []\n",
    "        output = []\n",
    "\n",
    "        for token in tokens:\n",
    "            prob = random.random()\n",
    "\n",
    "            if prob < 0.15:\n",
    "                prob /= 0.15\n",
    "\n",
    "                if prob < 0.8:\n",
    "                    output.append(self.tokenizer.vocab['[MASK]'])\n",
    "                elif prob < 0.9:\n",
    "                    output.append(random.randrange(len(self.tokenizer.vocab)))\n",
    "                else:\n",
    "                    output.append(token)\n",
    "                mask_label.append(token)\n",
    "            else:\n",
    "                output.append(token)\n",
    "                mask_label.append(0)\n",
    "\n",
    "        assert len(output) == len(mask_label)\n",
    "        return output, mask_label\n",
    "   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.vocab['[SEP]']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 2, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_word(\"What? It's on the way. She says she's got something for me.\")\n",
    "# tokenizer(\"What? It's on the way. She says she's got something for me.\")['input_ids'][1:-1]\n",
    "# tokenizer.vocab['[MASK]']\n",
    "ls = [1,2,3]\n",
    "ls += [2,3]\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of the dataset class\n",
    "dataset = BERTDataset(data_pair=pairs, tokenizer=tokenizer, seq_len=block_size)\n",
    "\n",
    "# Assuming 'dataset' is already created\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "import os\n",
    "#Creating a dataloader\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=False, num_workers=os.cpu_count())\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=os.cpu_count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert_input_masked': tensor([[    1,   539,   146,  ...,     0,     0,     0],\n",
      "        [    1,   244,     3,  ...,     0,     0,     0],\n",
      "        [    1, 14117,    15,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,   437,   184,  ...,     0,     0,     0],\n",
      "        [    1,   220,    15,  ...,     0,     0,     0],\n",
      "        [    1,     3,  9576,  ...,     0,     0,     0]]), 'bert_input_labels': tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  0,   0, 868,  ...,   0,   0,   0],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  0, 220,  17,  ...,   0,   0,   0]]), 'segment_ids': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'is_next': tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "sample_data = next(iter(train_loader))\n",
    "# print('Batch Size', sample_data['bert_input_masked'].size())\n",
    "print(sample_data)\n",
    "# 3 is MASK\n",
    "# result = dataset[random.randrange(len(dataset))]\n",
    "# print(result)\n",
    "# print(tokenizer.convert_ids_to_tokens(result['bert_input_masked']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1, 182, 34, 162, 11, 58, 192, 150, 417, 17, 266, 904, 266, 11, 58, 263, 404, 202, 185, 17, 2, 17, 368, 5, 2, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"[CLS] What? It's on the way. She says she's got something for me. [SEP] . Yeah! [SEP]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.3165, -0.1863,  0.1542,  ..., -0.5941, -0.2662, -1.2164],\n",
      "        [-0.3165, -0.1863,  0.1542,  ..., -0.5941, -0.2662, -1.2164],\n",
      "        [-0.3165, -0.1863,  0.1542,  ..., -0.5941, -0.2662, -1.2164]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "segment_ids = torch.tensor([0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2])\n",
    "# segment_ids = [1 for _ in range(len(sent1.split()))] + [2 for _ in range(len(sent2.split()))] \n",
    "# if(len(sent1.split()) + len(sent2.split()) > 0):\n",
    "    # segment_ids += [0 for x in range(block_size - (len(sent1.split()) + len(sent2.split())))]\n",
    "segment = SegmentEmbeddings()\n",
    "print(segment(segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Hi hellow my self yuvraj sinfj [SEP] hellow britha myslef [SEP]\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"Hi hellow my self yuvraj sinfj\"\n",
    "sent2 = \"hellow britha myslef\"\n",
    "final_sent = '[CLS] ' + sent1 + ' [SEP] ' + sent2 + ' [SEP]'\n",
    "print(final_sent)\n",
    "if(len(final_sent.split()) < block_size):\n",
    "    while(len(final_sent.split()) !=  block_size):\n",
    "        final_sent = final_sent + ' ' + '[PAD]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1, 636, 904, 113, 218, 2191, 6502, 106, 290, 100, 3406, 112, 100, 2, 904, 113, 3415, 3917, 218, 102, 188, 112, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(final_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Hi hellow my self yuvraj sinfj [SEP] hellow britha myslef [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 7]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0, len(sentence_t0_list)-1, len(sent1.split()) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[5, 4, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('[CLS] Hi hellow my self vanessa [MASK] [SEP] hellow britha myslef i dont know wht yiou saying man [SEP]',\n",
       " [0, 0, 0, 0, 0, 6821, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_masked_sentences(final_sent, sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 17, 19]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hellow', 'myself', 'yuvraj', 'singh']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 904, 113, 2], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 0, 1, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text embeddings\n",
    "class TextEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size = vocab_size,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embeddings_table = nn.Embedding(num_embeddings = vocab_size, embedding_dim=embeddings_dims, device=device, padding_idx=0) #Just a look up table to convert the toekns_ids to some numbers\n",
    "        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embeddings_table(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment embeddings\n",
    "class SegmentEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_segments = n_segments,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seg_embds = nn.Embedding(num_embeddings = n_segments, embedding_dim=embeddings_dims, device=device, padding_idx=0)\n",
    "    def forward(self, x):\n",
    "        return self.seg_embds(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer Normalization\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=embeddings_dims, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FeedForward Neural Network\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dropout = dropout,\n",
    "        embeddings_size = embeddings_dims,\n",
    "        # inner_dimensional_states: int = 3072\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(device=device, in_features=embeddings_size, out_features= 4 * embeddings_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(device=device, in_features= 4 * embeddings_size, out_features=embeddings_size),\n",
    "            nn.Dropout(p = dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # mlp_weights_init = self.mlp.apply(weights_init)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Attention Head\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.head_size = embeddings_dims // no_of_heads\n",
    "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
    "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
    "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
    "        self.dropout = nn.Dropout(p = attn_dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch, block_size, embd_dims = x.shape\n",
    "        k = self.keys(x)\n",
    "        q = self.query(x)\n",
    "        v = self.values(x)\n",
    "        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
    "        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
    "        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, 1e-9)\n",
    "        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
    "        # weights_normalized = self.dropout(weights_normalized)\n",
    "        out = weights_normalized @ v\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
    "        self.dropout = nn.Dropout(p = attn_dropout)\n",
    "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        linear_layer = self.linear(concat)\n",
    "        out = self.dropout(linear_layer)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA\n",
    "import math\n",
    "class PositionEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        block_size = block_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pos_embd = torch.ones((block_size, embeddings_dims), device=device)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for pos in range(block_size):\n",
    "            for i in range(0,embeddings_dims // 2):\n",
    "                self.pos_embd[pos, 2*i] = math.sin(pos/(10000**((2*i)/embeddings_dims)))\n",
    "                self.pos_embd[pos, 2*i + 1] = math.cos(pos/(10000**((2*i)/embeddings_dims)))\n",
    "        \n",
    "        self.pos_embd.unsqueeze(0)\n",
    "        return self.pos_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 128])\n"
     ]
    }
   ],
   "source": [
    "# # Example usage\n",
    "# # embeddings_dims = 512\n",
    "# # block_size = 128\n",
    "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# pos_emb = PositionEmbeddings(embeddings_dims, block_size)\n",
    "# x = torch.zeros((10, block_size, embeddings_dims), device=device)  # Example input\n",
    "# output = pos_emb(x)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Block\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        dropout = dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha = MHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
    "        self.layer_norm1 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.layer_norm2 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.mha(x)\n",
    "        # x = x + self.layer_norm1(x)\n",
    "        # x = x + self.mlp_block(x)\n",
    "        # out = self.layer_norm2(x)\n",
    "        # x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n",
    "        # x = x + self.mlp_block(self.layer_norm2(x)) #Very important step\n",
    "        x = self.layer_norm1(x + self.mha(x))\n",
    "        x = self.layer_norm2(x + self.mlp_block(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Block\n",
    "\n",
    "class EncoderModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        block_size = block_size,\n",
    "        dropout = dropout,\n",
    "        no_of_encoder_layers = no_of_encoder_layers,\n",
    "        vocab_size = vocab_size,\n",
    "        n_segments = n_segments\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.positional_embeddings = PositionEmbeddings(block_size=block_size, embeddings_dims=embeddings_dims)\n",
    "        self.text_embds = TextEmbeddings(vocab_size=vocab_size, embeddings_dims=embeddings_dims)\n",
    "        # self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
    "        self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.encoder_layers = nn.Sequential(*[TransformerEncoderBlock(embeddings_dims=embeddings_dims, attn_dropout=attn_dropout, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_encoder_layers)])\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.seg_embds = SegmentEmbeddings(n_segments=n_segments, embeddings_dims=embeddings_dims)\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x, segment_ids):\n",
    "        x = self.text_embds(x) + self.seg_embds(segment_ids) + self.positional_embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.encoder_layers(x)\n",
    "        # x = self.layer_norm(x)\n",
    "        # out = self.linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NSP\n",
    "\n",
    "class NSP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # self.encoder_block = EncoderModel(no_of_encoder_layers=no_of_encoder_layers, attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, block_size=block_size, dropout=dropout, vocab_size=vocab_size, n_segments=n_segments)\n",
    "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=2, device=device)\n",
    "    \n",
    "\n",
    "    def forward(self, x,  isnext):\n",
    "        # print(x.shape)\n",
    "        # print(x[:,0].shape)\n",
    "        \n",
    "        # sigmoid = torch.nn.Sigmoid()\n",
    "        logits = self.linear_layer(x[:,0]) #to get the CLS token embeddings across all batches\n",
    "        # print(probs)\n",
    "        # print(torch.argmax(sigmoid(logits),dim=-1))\n",
    "        # print(isnext.float())\n",
    "        # print(isnext.view_as(logits).float())\n",
    "        # print(torch.argmax(logits, dim=0))\n",
    "        # print(logits)\n",
    "        loss = nn.functional.cross_entropy(logits, isnext, ignore_index = 0)\n",
    "        return loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 256])\n",
      "torch.Size([64, 128, 21406])\n",
      "torch.Size([64, 21406, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(10.1777, device='cuda:0', grad_fn=<NllLoss2DBackward0>),\n",
       " tensor([[[ 0.0616, -0.4512, -0.7902,  ...,  0.0738, -0.3777, -0.0461],\n",
       "          [ 0.6025,  0.3395,  0.7008,  ...,  0.2039,  0.7946,  0.3640],\n",
       "          [-0.3003, -0.4316, -0.3465,  ..., -0.2464,  0.0259, -0.3851],\n",
       "          ...,\n",
       "          [ 0.1432,  0.0401, -0.1193,  ..., -0.7646, -0.9134, -0.7766],\n",
       "          [-1.0741, -1.9834, -1.0938,  ..., -0.6996, -0.3039,  0.0413],\n",
       "          [ 0.2173,  0.1227,  0.0725,  ..., -0.4207, -0.1205,  0.2398]],\n",
       " \n",
       "         [[-0.2115,  0.0157,  0.0470,  ..., -0.5035, -0.3319, -0.1298],\n",
       "          [ 0.6257,  0.0549,  0.7118,  ..., -0.1939,  0.1183,  0.4750],\n",
       "          [-0.2153, -0.5905, -0.0650,  ...,  0.1291, -0.0225, -0.3489],\n",
       "          ...,\n",
       "          [ 0.2045,  0.0690,  0.6788,  ..., -0.6794, -0.8716, -0.5037],\n",
       "          [-1.0849, -1.0321, -1.1389,  ..., -0.4232, -0.1882,  0.1800],\n",
       "          [ 0.0440,  0.0738, -0.4966,  ...,  0.0870, -0.0572, -0.2002]],\n",
       " \n",
       "         [[-0.1014, -0.4488, -0.8096,  ..., -0.1111, -0.1537,  0.0983],\n",
       "          [ 0.4930,  0.2174,  0.6247,  ...,  0.6442,  0.6566,  0.4871],\n",
       "          [ 0.0900, -0.7983,  0.0733,  ...,  0.3436, -0.2043,  0.1519],\n",
       "          ...,\n",
       "          [ 0.4564,  0.5487,  0.3098,  ..., -0.7874, -1.0041, -0.8302],\n",
       "          [-1.4371, -1.1091, -0.5792,  ..., -0.6095, -0.3344, -0.3074],\n",
       "          [-0.2478,  0.0313, -0.7128,  ...,  0.0471, -0.2275, -0.1029]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.1201,  0.1459, -0.1978,  ..., -0.1905, -0.2536, -0.0939],\n",
       "          [ 1.0639,  0.8189,  1.0321,  ...,  0.3189,  0.8445,  0.8691],\n",
       "          [ 0.1488, -0.2618, -1.2696,  ...,  0.2253,  0.0165, -0.2527],\n",
       "          ...,\n",
       "          [ 0.2151, -0.4832,  0.2421,  ..., -0.8148, -0.6741, -0.6690],\n",
       "          [-0.8896, -1.6614, -0.9807,  ..., -0.5252, -0.1306, -0.0229],\n",
       "          [-0.2968,  0.7529,  0.2130,  ..., -0.4607,  0.0171, -0.0888]],\n",
       " \n",
       "         [[-0.0871,  0.1265, -0.8210,  ..., -0.3112, -0.2133,  0.1146],\n",
       "          [ 0.8565,  0.0320,  1.2006,  ...,  0.4868,  0.7614,  0.4934],\n",
       "          [-0.2050, -0.4459, -0.6437,  ...,  0.3220,  0.3931, -0.4666],\n",
       "          ...,\n",
       "          [-0.2270, -0.2389, -0.5148,  ..., -0.4608, -1.0744, -0.9031],\n",
       "          [-0.8394, -0.6711, -1.2205,  ..., -0.3603, -0.6220, -0.0101],\n",
       "          [ 0.0723, -0.0303, -0.3733,  ..., -0.2095, -0.0051,  0.0915]],\n",
       " \n",
       "         [[ 0.1031, -0.0109, -0.7867,  ..., -0.1482, -0.3456, -0.4840],\n",
       "          [ 0.8577,  0.4638,  0.8463,  ..., -0.0785,  0.4856,  0.3723],\n",
       "          [ 0.0539, -0.0309, -0.1076,  ..., -0.0291, -0.0205,  0.0981],\n",
       "          ...,\n",
       "          [ 0.1773,  0.0467,  0.5247,  ..., -0.3592, -0.9553, -0.9135],\n",
       "          [-0.9640, -1.5952, -0.9328,  ..., -0.1967, -0.1317,  0.0906],\n",
       "          [ 0.3877, -0.0189, -0.1139,  ..., -0.5256,  0.0560, -0.4668]]],\n",
       "        device='cuda:0', grad_fn=<TransposeBackward0>))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nsp =MLM()\n",
    "enc = EncoderModel()\n",
    "# out = enc(result['bert_input_masked'], result['segment_ids'])\n",
    "out = nsp(x = enc(sample_data['bert_input_masked'], sample_data['segment_ids']), mask_labels=sample_data['bert_input_labels'])\n",
    "out \n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 21406])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 256])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = enc(sample_data['bert_input_masked'], sample_data['segment_ids'])\n",
    "# x.transpose(1,2).shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_input_masked': tensor([[    1,   220,    17,  ...,     0,     0,     0],\n",
       "         [    1, 18278,    34,  ...,     0,     0,     0],\n",
       "         [    1,  1126,    34,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    1,   269,   266,  ...,     0,     0,     0],\n",
       "         [    1,  2221,    17,  ...,     0,     0,     0],\n",
       "         [    1,   399,   211,  ...,     0,     0,     0]]),\n",
       " 'bert_input_labels': tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0, 399,   0,  ...,   0,   0,   0]]),\n",
       " 'segment_ids': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'is_next': tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "         1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "         0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#MLM\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMLM\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      6\u001b[0m         embeddings_dims \u001b[38;5;241m=\u001b[39m embeddings_dims,\n\u001b[1;32m      7\u001b[0m         vocab_size \u001b[38;5;241m=\u001b[39m vocab_size\n\u001b[1;32m      8\u001b[0m     ):\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#MLM\n",
    "\n",
    "class MLM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        vocab_size = vocab_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # self.encoder_block = EncoderModel(no_of_encoder_layers=no_of_encoder_layers, attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, block_size=block_size, dropout=dropout, vocab_size=vocab_size, n_segments=n_segments)\n",
    "        self.linear_layer1 = nn.Linear(in_features=embeddings_dims, out_features=vocab_size, device=device)\n",
    "        # self.linear_layer2 = nn.Linear(in_features=vocab_size, out_features=block_size, device=device)\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, x,  mask_labels):\n",
    "        # Get the logits from the linear layer\n",
    "        logits = self.linear_layer1(x)  # logits: (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        # Reshape logits and mask_labels for cross_entropy\n",
    "        batch_size, seq_len, vocab_size = logits.shape\n",
    "        logits = logits.view(batch_size * seq_len, vocab_size)        # logits: (batch_size * seq_len, vocab_size)\n",
    "        mask_labels = mask_labels.view(-1)          # mask_labels: (batch_size * seq_len)\n",
    "        \n",
    "        # Calculate the cross-entropy loss\n",
    "        loss = nn.functional.cross_entropy(logits, mask_labels, ignore_index = 0)\n",
    "        \n",
    "        return loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT\n",
    "\n",
    "class BERT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        block_size = block_size,\n",
    "        dropout = dropout,\n",
    "        vocab_size = vocab_size,\n",
    "        n_segments = n_segments\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlm = MLM(embeddings_dims=embeddings_dims, vocab_size=vocab_size)\n",
    "        self.nsp = NSP(embeddings_dims=embeddings_dims)\n",
    "        self.encoder_layer = EncoderModel(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, no_of_encoder_layers=no_of_encoder_layers, block_size=block_size,dropout=dropout,n_segments=n_segments)\n",
    "\n",
    "    def forward(self, x, segment_ids, labels, isnext):\n",
    "        x = self.encoder_layer(x, segment_ids)\n",
    "        mlm_loss, mlm_logits = self.mlm(x, labels)\n",
    "        nsp_loss, nsp_logits = self.nsp(x, isnext)\n",
    "        return mlm_loss, mlm_logits, nsp_loss , nsp_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT(embeddings_dims=embeddings_dims, vocab_size=vocab_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n",
       "=======================================================================================================================================\n",
       "BERT (BERT)                                             [64, 256]            --                   --                   True\n",
       "├─EncoderModel (encoder_layer)                          [64, 256]            [64, 256, 128]       256                  True\n",
       "│    └─TextEmbeddings (text_embds)                      [64, 256]            [64, 256, 128]       --                   True\n",
       "│    │    └─Embedding (embeddings_table)                [64, 256]            [64, 256, 128]       2,742,016            True\n",
       "│    └─SegmentEmbeddings (seg_embds)                    [64, 256]            [64, 256, 128]       --                   True\n",
       "│    │    └─Embedding (seg_embds)                       [64, 256]            [64, 256, 128]       384                  True\n",
       "│    └─PositionEmbeddings (positional_embeddings)       [64, 256]            [256, 128]           --                   --\n",
       "│    └─Dropout (dropout)                                [64, 256, 128]       [64, 256, 128]       --                   --\n",
       "│    └─Sequential (encoder_layers)                      [64, 256, 128]       [64, 256, 128]       --                   True\n",
       "│    │    └─TransformerEncoderBlock (0)                 [64, 256, 128]       [64, 256, 128]       197,760              True\n",
       "│    │    └─TransformerEncoderBlock (1)                 [64, 256, 128]       [64, 256, 128]       197,760              True\n",
       "├─MLM (mlm)                                             [64, 256, 128]       --                   --                   True\n",
       "│    └─Linear (linear_layer1)                           [64, 256, 128]       [64, 256, 21422]     2,763,438            True\n",
       "├─NSP (nsp)                                             [64, 256, 128]       --                   --                   True\n",
       "│    └─Linear (linear_layer)                            [64, 128]            [64, 2]              258                  True\n",
       "=======================================================================================================================================\n",
       "Total params: 5,901,872\n",
       "Trainable params: 5,901,872\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 377.70\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 0.39\n",
       "Forward/backward pass size (MB): 3210.48\n",
       "Params size (MB): 23.61\n",
       "Estimated Total Size (MB): 3234.48\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing a summary of the architecture\n",
    "from torchinfo import summary\n",
    "sample_data = {key: value.to(device) for key, value in sample_data.items()}\n",
    "summary(model=model,\n",
    "        input_data=(sample_data['bert_input_masked'], sample_data['segment_ids'], sample_data['bert_input_labels'], sample_data['is_next']),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])\n",
    "# model(result['bert_input_masked'],result['segment_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  3047, 19247,  ...,     0,     0,     0],\n",
       "        [    1,   368,    17,  ...,     0,     0,     0],\n",
       "        [    1, 17584,   291,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    1,   173,    11,  ...,     0,     0,     0],\n",
       "        [    1,   173,    11,  ...,     0,     0,     0],\n",
       "        [    1,   368,    17,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample_data['bert_input_masked']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.3595,  1.3807, -0.6527,  ...,  1.6281, -1.4718,  0.4377],\n",
       "         [ 1.4273,  0.4243, -0.4965,  ...,  1.6281, -1.4717,  0.4377],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 0.6228,  1.3948,  1.7603,  ...,  3.9834, -1.2730,  1.7959],\n",
       "         [ 0.6500,  2.0493, -0.8632,  ...,  1.7049, -3.7139,  1.3620],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.1296,  3.1447,  0.4807,  ...,  3.4399, -3.1435,  0.7926],\n",
       "         [ 1.9241, -1.6210,  0.0041,  ...,  3.0458, -1.1279, -0.1939],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.3595,  1.3807, -0.6527,  ...,  1.6281, -1.4718,  0.4377],\n",
       "         [ 1.1027,  1.2330,  1.7113,  ...,  2.5625, -1.7789, -1.6832],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.9107,  0.2109,  2.4622,  ...,  2.4812, -0.8140,  0.3321],\n",
       "         [ 1.4273,  0.4243, -0.4965,  ...,  1.6281, -1.4717,  0.4377],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]],\n",
       "\n",
       "        [[ 1.0061,  2.7151, -0.1197,  ...,  1.6429, -1.9797,  1.6565],\n",
       "         [ 1.3595,  1.3807, -0.6527,  ...,  1.6281, -1.4718,  0.4377],\n",
       "         [ 2.7657,  0.8188,  1.7924,  ...,  1.5932, -2.9851, -0.9957],\n",
       "         ...,\n",
       "         [ 0.9948, -0.1016,  0.1837,  ...,  0.9996,  0.0272,  0.9996],\n",
       "         [ 0.4520, -0.8920, -0.6786,  ...,  0.9996,  0.0273,  0.9996],\n",
       "         [-0.5064, -0.8623, -0.9944,  ...,  0.9996,  0.0274,  0.9996]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embd = PositionEmbeddings()\n",
    "seg_embd = SegmentEmbeddings()\n",
    "text_embds = TextEmbeddings()\n",
    "out = text_embds(sample_data['bert_input_masked']) + seg_embd(sample_data['segment_ids']) + pos_embd(sample_data['bert_input_masked'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 512])"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embd(sample_data['bert_input_masked']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 512])"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_embd(sample_data['segment_ids']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 512])"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embds(sample_data['bert_input_masked']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "\n",
    "    def __init__(self, optimizer, embeddings_dims, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(embeddings_dims, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up optimizer and lr scheduler\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = max_lr)\n",
    "# lr_scheduler = ScheduledOptim(optimizer=optimizer,embeddings_dims=embeddings_dims,n_warmup_steps=n_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert_input_masked': tensor([[   1,  146, 8942,  ...,    0,    0,    0],\n",
      "        [   1,   48,    3,  ...,    0,    0,    0],\n",
      "        [   1,  928,  184,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  177,  146,  ...,    0,    0,    0],\n",
      "        [   1,    3,  162,  ...,    0,    0,    0],\n",
      "        [   1,  330,   15,  ...,    0,    0,    0]]), 'bert_input_labels': tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  0,   0, 890,  ...,   0,   0,   0],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  0, 321,   0,  ...,   0,   0,   0],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0]]), 'segment_ids': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'is_next': tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 21406, 128]) torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "_, logit_mlm, _, nsp_logts = model(sample_data['bert_input_masked'], sample_data['segment_ids'], sample_data['bert_input_labels'], sample_data['is_next'])\n",
    "# logits\n",
    "print(logit_mlm.shape,nsp_logts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(nn.functional.softmax(logits, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def cal_val(val_loader):\n",
    "    mlm_accuracy = []\n",
    "    nsp_accuracy = []\n",
    "    loss = []\n",
    "    model.eval()\n",
    "    for epoch in range(1):\n",
    "        for data in val_loader:\n",
    "            result = {key: value.to(device) for key,value in data.items()}\n",
    "            mlm_loss, mlm_logits, loss_nsp, nsp_logits = model(result['bert_input_masked'], result['segment_ids'], result['bert_input_labels'], result['is_next'])\n",
    "            loss_tot = mlm_loss + loss_nsp\n",
    "            total_correct_nsp = nsp_logits.argmax(dim=-1).eq(result['is_next']).sum().item()\n",
    "\n",
    "            total_nsp_items = data[\"is_next\"].nelement()\n",
    "            acc_nsp = (total_correct_nsp / total_nsp_items) * 100\n",
    "            logit_mlm_cpu = mlm_logits.cpu().detach().numpy()\n",
    "            total_correct_mlm = np.sum(np.argmax(logit_mlm_cpu, axis=1) == sample_data['bert_input_labels'].cpu().numpy())\n",
    "            total_mlm_items = data['bert_input_labels'].nelement()\n",
    "        \n",
    "            acc_mlm = (total_correct_mlm / total_mlm_items ) *100\n",
    "            loss.append(loss_tot.item())\n",
    "            mlm_accuracy.append(acc_mlm)\n",
    "            nsp_accuracy.append(acc_nsp)\n",
    "    mean_loss = sum(loss) / len(loss)\n",
    "    mean_accuracy_mlm = sum(mlm_accuracy) / len(mlm_accuracy)\n",
    "    mean_accuracy_nsp = sum(nsp_accuracy) / len(nsp_accuracy)\n",
    "    model.train()\n",
    "    return mean_accuracy_mlm, mean_accuracy_nsp, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert_input_masked\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msegment_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert_input_labels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_next\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 21\u001b[0m, in \u001b[0;36mBERT.forward\u001b[0;34m(self, x, segment_ids, labels, isnext)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, segment_ids, labels, isnext):\n\u001b[0;32m---> 21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     mlm_loss, mlm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlm(x, labels)\n\u001b[1;32m     23\u001b[0m     nsp_loss, nsp_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsp(x, isnext)\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 28\u001b[0m, in \u001b[0;36mEncoderModel.forward\u001b[0;34m(self, x, segment_ids)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, segment_ids):\n\u001b[0;32m---> 28\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_embds(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseg_embds(segment_ids) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositional_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m     30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 17\u001b[0m, in \u001b[0;36mPositionEmbeddings.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,embeddings_dims \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embd[pos, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi] \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msin(pos\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m10000\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi)\u001b[38;5;241m/\u001b[39membeddings_dims)))\n\u001b[0;32m---> 17\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embd[pos, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(pos\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m10000\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi)\u001b[38;5;241m/\u001b[39membeddings_dims)))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embd\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embd\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(sample_data['bert_input_masked'], sample_data['segment_ids'], sample_data['bert_input_labels'], sample_data['is_next'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/tmp/ipykernel_270778/598040040.py:17: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  total_correct_mlm = np.sum(np.argmax(logit_mlm_cpu, axis=1) == sample_data['bert_input_labels'].cpu().numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:  0 Epoch:  0 Train loss:  10.613750457763672 Train NSP Accuracy:  54.6875 Train MLM Accuracy:  0.0 Val loss:  10.573037886825693 Val NSP Accuracy:  50.5828730387448 Val MLM Accuracy:  0.0\n",
      "Steps:  100 Epoch:  0 Train loss:  10.595838697830049 Train NSP Accuracy:  51.160272277227726 Train MLM Accuracy:  0.0 Val loss:  10.57576206438136 Val NSP Accuracy:  49.65027617675312 Val MLM Accuracy:  0.0\n",
      "Steps:  200 Epoch:  0 Train loss:  10.594347052313202 Train NSP Accuracy:  50.51305970149254 Train MLM Accuracy:  0.0 Val loss:  10.569887092546358 Val NSP Accuracy:  50.05353426192764 Val MLM Accuracy:  0.0\n",
      "Steps:  300 Epoch:  0 Train loss:  10.59544531609925 Train NSP Accuracy:  50.36337209302326 Train MLM Accuracy:  0.0 Val loss:  10.57366461300369 Val NSP Accuracy:  50.0995637207813 Val MLM Accuracy:  0.0\n",
      "Steps:  400 Epoch:  0 Train loss:  10.593906098173147 Train NSP Accuracy:  50.05844763092269 Train MLM Accuracy:  0.0 Val loss:  10.573754272131136 Val NSP Accuracy:  49.783861671469744 Val MLM Accuracy:  0.0\n",
      "Steps:  500 Epoch:  0 Train loss:  10.594365959395905 Train NSP Accuracy:  50.06549401197605 Train MLM Accuracy:  0.0 Val loss:  10.572977816337124 Val NSP Accuracy:  50.29719020172911 Val MLM Accuracy:  0.0\n",
      "Steps:  600 Epoch:  0 Train loss:  10.593317249253666 Train NSP Accuracy:  50.08319467554077 Train MLM Accuracy:  0.0 Val loss:  10.571834531228893 Val NSP Accuracy:  50.26567002881844 Val MLM Accuracy:  0.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "loss = []\n",
    "items = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    loss = []\n",
    "    items = []\n",
    "    correct = 0\n",
    "    total_instances = 0\n",
    "    nsp_accuracy = []\n",
    "    mlm_accuracy = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        result = {key: value.to(device) for key,value in data.items()}\n",
    "        mlm_loss, mlm_logits, loss_nsp, nsp_logits = model(result['bert_input_masked'], result['segment_ids'], result['bert_input_labels'], result['is_next'])\n",
    "        loss_tot = mlm_loss + loss_nsp\n",
    "        loss_tot.backward()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        optimizer.step()\n",
    "        # lr_scheduler.zero_grad()\n",
    "        # lr_scheduler.step_and_update_lr()\n",
    "        loss.append(loss_tot.item())\n",
    "        total_correct_nsp = nsp_logits.argmax(dim=-1).eq(result['is_next']).sum().item()\n",
    "        # acc_nsp = accuracy_score(result['is_next'].cpu(), y_pred_nsp.cpu())\n",
    "        total_nsp_items = data[\"is_next\"].nelement()\n",
    "        acc_nsp = (total_correct_nsp / total_nsp_items) * 100\n",
    "        # total_correct_mlm = mlm_logits.eq(result['bert_input_labels']).sum().item()\n",
    "        # acc_mlm = accuracy_score(result['bert_input_labels'].cpu(), y_pred_mlm.cpu())\n",
    "        # Move logits tensor to CPU and convert to numpy for comparison\n",
    "        logit_mlm_cpu = mlm_logits.cpu().detach().numpy() \n",
    "\n",
    "        # Calculate number of correct predictions\n",
    "        total_correct_mlm = np.sum(np.argmax(logit_mlm_cpu, axis=1) == sample_data['bert_input_labels'].cpu().numpy()) #cus its size is 8192 and axis = 1 will help in getting the argmax idx across row\n",
    "        total_mlm_items = data['bert_input_labels'].nelement()\n",
    "        acc_mlm = (total_correct_mlm / total_mlm_items ) *100\n",
    "        mlm_accuracy.append(acc_mlm)\n",
    "        nsp_accuracy.append(acc_nsp)\n",
    "        if(i % 100 == 0 or i == len(train_loader) - 1):\n",
    "            mean_loss = sum(loss) / len(loss)\n",
    "            mean_accuracy_mlm = sum(mlm_accuracy) / len(mlm_accuracy)\n",
    "            mean_accuracy_nsp = sum(nsp_accuracy) / len(nsp_accuracy)\n",
    "            val_mlm_acc, val_nsp_acc, val_loss = cal_val(val_loader)\n",
    "            print(\"Steps: \",i, \"Epoch: \", epoch , \"Train loss: \", mean_loss, \"Train NSP Accuracy: \", mean_accuracy_nsp, \"Train MLM Accuracy: \", mean_accuracy_mlm, \"Val loss: \", val_loss, \"Val NSP Accuracy: \", val_nsp_acc, \"Val MLM Accuracy: \", val_mlm_acc)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mlm.argmax().eq(sample_data['bert_input_labels']).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data['bert_input_labels'].nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(logit_mlm_cpu, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data['bert_input_labels'].view(batch_size * block_size).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140621/2134815741.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  num_correct = np.sum(np.argmax(logit_mlm_cpu, axis=1) == sample_data['bert_input_labels'].cpu().numpy())\n"
     ]
    }
   ],
   "source": [
    "# Move logits tensor to CPU and convert to numpy for comparison\n",
    "logit_mlm_cpu = logit_mlm.cpu().detach().numpy()\n",
    "\n",
    "# Calculate number of correct predictions\n",
    "num_correct = np.sum(np.argmax(logit_mlm_cpu, axis=1) == sample_data['bert_input_labels'].cpu().numpy())\n",
    "\n",
    "print(\"Number of correct predictions:\", num_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data['bert_input_labels'].view(batch_size * block_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
