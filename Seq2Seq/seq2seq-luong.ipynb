{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2025-03-07T11:42:20.222153Z","iopub.status.busy":"2025-03-07T11:42:20.221812Z","iopub.status.idle":"2025-03-07T11:45:15.689494Z","shell.execute_reply":"2025-03-07T11:45:15.688771Z","shell.execute_reply.started":"2025-03-07T11:42:20.222123Z"},"id":"NTFGr5T2bXEE","outputId":"4bd30576-7d23-4bed-caf6-720cc33493c6","trusted":true},"outputs":[],"source":["# !pip install torch==2.3.0 torchtext==0.18.0\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:45:15.690864Z","iopub.status.busy":"2025-03-07T11:45:15.690493Z","iopub.status.idle":"2025-03-07T11:45:15.696220Z","shell.execute_reply":"2025-03-07T11:45:15.695427Z","shell.execute_reply.started":"2025-03-07T11:45:15.690831Z"},"id":"nUMPnXjmbXEF","trusted":true},"outputs":[],"source":["from dataclasses import dataclass\n","\n","\n","@dataclass\n","class ModelArgs:\n","    device = 'cuda'\n","    no_of_neurons = 128\n","    block_size = 32\n","    batch_size = 32\n","    en_vocab_size = None\n","    de_vocab_size = None\n","    dropout = 0.1\n","    epoch = 10\n","    max_lr = 1e-4\n","    embedding_dims = 1024\n","    num_layers = 4\n","    hidden_dim = 4*embedding_dims"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:45:15.697850Z","iopub.status.busy":"2025-03-07T11:45:15.697573Z","iopub.status.idle":"2025-03-07T11:45:15.785376Z","shell.execute_reply":"2025-03-07T11:45:15.784653Z","shell.execute_reply.started":"2025-03-07T11:45:15.697827Z"},"id":"htu_YvmbdnMu","trusted":true},"outputs":[],"source":["if torch.cuda.is_available():\n","    ModelArgs.device = 'cuda'\n","    torch.set_default_device('cuda')\n","else:\n","\n","    torch.set_default_device('cpu')\n","    ModelArgs.device='cpu'\n","\n","if torch.cuda.is_available():\n","  torch.set_default_device(ModelArgs.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2025-03-07T11:45:15.786970Z","iopub.status.busy":"2025-03-07T11:45:15.786618Z","iopub.status.idle":"2025-03-07T11:45:29.823853Z","shell.execute_reply":"2025-03-07T11:45:29.822824Z","shell.execute_reply.started":"2025-03-07T11:45:15.786949Z"},"id":"peJSz_0DblE2","outputId":"7fb3a30f-8c7a-43d7-b123-389e539e7a81","trusted":true},"outputs":[],"source":["\n","!python -m spacy download de_core_news_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2025-03-07T11:45:29.825352Z","iopub.status.busy":"2025-03-07T11:45:29.825033Z","iopub.status.idle":"2025-03-07T11:45:39.075512Z","shell.execute_reply":"2025-03-07T11:45:39.074672Z","shell.execute_reply.started":"2025-03-07T11:45:29.825320Z"},"id":"QLjqIzybbj82","outputId":"ba29bc4e-c96c-4502-d26d-2797247de2d8","trusted":true},"outputs":[],"source":["!python -m spacy download en_core_web_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2025-03-07T11:45:39.077010Z","iopub.status.busy":"2025-03-07T11:45:39.076602Z","iopub.status.idle":"2025-03-07T11:45:48.950918Z","shell.execute_reply":"2025-03-07T11:45:48.950186Z","shell.execute_reply.started":"2025-03-07T11:45:39.076979Z"},"id":"iP5w_PyBbXEF","outputId":"f0f57a82-4da3-4c23-fb06-8c5e9de1e781","trusted":true},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:45:48.952454Z","iopub.status.busy":"2025-03-07T11:45:48.951928Z","iopub.status.idle":"2025-03-07T11:45:48.956193Z","shell.execute_reply":"2025-03-07T11:45:48.955419Z","shell.execute_reply.started":"2025-03-07T11:45:48.952419Z"},"id":"5saagew8bXEF","trusted":true},"outputs":[],"source":["torch.set_default_device(ModelArgs.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2025-03-07T11:45:48.958856Z","iopub.status.busy":"2025-03-07T11:45:48.958603Z","iopub.status.idle":"2025-03-07T11:46:04.771623Z","shell.execute_reply":"2025-03-07T11:46:04.770881Z","shell.execute_reply.started":"2025-03-07T11:45:48.958837Z"},"id":"XMmCjvl9bXEF","outputId":"62c1a048-5d22-48a8-945f-8cd66ca43f74","trusted":true},"outputs":[],"source":["import torch\n","from torchtext.data.utils import get_tokenizer\n","from collections import Counter\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.utils import download_from_url, extract_archive\n","import io\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Download and extract data\n","url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n","train_urls = ('train.de.gz', 'train.en.gz')\n","val_urls = ('val.de.gz', 'val.en.gz')\n","test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n","\n","train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n","val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n","test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n","\n","# Load SpaCy tokenizers\n","de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n","en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n","\n","# Build vocabulary\n","def build_vocab(filepath, tokenizer):\n","    counter = Counter()\n","    with io.open(filepath, encoding=\"utf8\") as f:\n","        for string_ in f:\n","            counter.update(tokenizer(string_))\n","    vocab = build_vocab_from_iterator(\n","        [counter.keys()],\n","        specials=['<unk>', '<bos>', '<eos>', '<pad>']\n","    )\n","    vocab.set_default_index(vocab['<unk>'])\n","    return vocab\n","\n","de_vocab = build_vocab(train_filepaths[0], de_tokenizer)\n","ModelArgs.de_vocab_size = len(de_vocab) \n","en_vocab = build_vocab(train_filepaths[1], en_tokenizer)\n","ModelArgs.en_vocab_size = len(en_vocab) \n","\n","\n","def data_process(filepaths):\n","    raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n","    raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n","    data = []\n","\n","    # Get the indices for <bos> and <eos> tokens\n","    de_bos_idx = de_vocab['<bos>']\n","    de_eos_idx = de_vocab['<eos>']\n","    en_bos_idx = en_vocab['<bos>']\n","    en_eos_idx = en_vocab['<eos>']\n","\n","    for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n","        # Tokenize and convert to indices\n","        de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)], dtype=torch.long)\n","        en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)], dtype=torch.long)\n","\n","        # Add <bos> and <eos> tokens\n","        # de_tensor_ = torch.cat([torch.tensor([de_bos_idx]), de_tensor_, torch.tensor([de_eos_idx])])\n","        en_tensor_ = torch.cat([torch.tensor([en_bos_idx]), en_tensor_, torch.tensor([en_eos_idx])])\n","\n","        # Flip the German tensor (if required)\n","        # de_tensor_ = torch.flip(de_tensor_, dims=[0])\n","\n","        # Append to data\n","        data.append((de_tensor_, en_tensor_))\n","\n","    return data\n","\n","\n","train_data = data_process(train_filepaths)\n","val_data = data_process(val_filepaths)\n","test_data = data_process(test_filepaths)\n","\n","# Create a custom Dataset class\n","class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","# Create Dataset instances\n","train_dataset = TranslationDataset(train_data)\n","val_dataset = TranslationDataset(val_data)\n","test_dataset = TranslationDataset(test_data)\n","\n","from torch.nn.utils.rnn import pad_sequence\n","\n","def collate_fn(batch, block_size=32):\n","    \"\"\"\n","    Collate function to pad or truncate sequences to a fixed block size.\n","\n","    Args:\n","        batch: A list of tuples (de_tensor, en_tensor).\n","        block_size: The fixed length to pad or truncate sequences to.\n","\n","    Returns:\n","        de_batch: Padded/truncated German sequences (batch_size, block_size).\n","        en_batch: Padded/truncated English sequences (batch_size, block_size).\n","    \"\"\"\n","    de_batch, en_batch = zip(*batch)\n","\n","    # Function to pad or truncate a sequence to the block size\n","    def pad_or_truncate(sequence, block_size, pad_value):\n","        if len(sequence) > block_size:\n","            # Truncate the sequence if it's longer than block_size\n","            return sequence[:block_size]\n","        else:\n","            # Pad the sequence if it's shorter than block_size\n","            padding_length = block_size - len(sequence)\n","            return torch.cat([sequence, torch.full((padding_length,), pad_value, dtype=sequence.dtype)])\n","\n","    # Pad or truncate each sequence in the batch\n","    de_batch = [pad_or_truncate(seq, block_size, de_vocab['<pad>']) for seq in de_batch]\n","    en_batch = [pad_or_truncate(seq, block_size, en_vocab['<pad>']) for seq in en_batch]\n","\n","    # Stack the sequences into a single tensor\n","    de_batch = torch.stack(de_batch)\n","    en_batch = torch.stack(en_batch)\n","\n","    return de_batch, en_batch\n","\n","generator = torch.Generator(device=ModelArgs.device)\n","\n","\n","# Create DataLoader instances\n","batch_size = ModelArgs.batch_size\n","train_loader = DataLoader(train_dataset, generator=generator, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n","val_loader = DataLoader(val_dataset, generator=generator, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=False)\n","\n","# Example usage\n","for de_batch, en_batch in train_loader:\n","    print(f\"German batch shape: {de_batch.shape}\")\n","    print(f\"English batch shape: {en_batch.shape}\")\n","    break"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.773427Z","iopub.status.busy":"2025-03-07T11:46:04.773000Z","iopub.status.idle":"2025-03-07T11:46:04.779877Z","shell.execute_reply":"2025-03-07T11:46:04.778994Z","shell.execute_reply.started":"2025-03-07T11:46:04.773406Z"},"id":"5EU54spwbXEG","trusted":true},"outputs":[],"source":["class RNNCell(nn.Module):\n","    def __init__(self, device, no_of_neurons, features = None, bi=False):\n","        super().__init__()\n","\n","        # if(bi):\n","        #     print(\"eher\")\n","        self.linear_layer_bi = nn.Linear(in_features=(2*ModelArgs.no_of_neurons) + ModelArgs.embedding_dims, out_features=no_of_neurons, device=ModelArgs.device)\n","        # else:\n","        self.in_features = features\n","        self.default_features = None\n","        if(self.in_features is  None):\n","          self.default_features = ModelArgs.no_of_neurons + ModelArgs.embedding_dims\n","        else:\n","          self.default_features = self.in_features\n","\n","        self.linear_layer = nn.Linear(in_features=self.default_features, out_features=no_of_neurons, device=ModelArgs.device)\n","        self.bi = bi\n","    def forward(self, x, ht_1):\n","      # print(self.bi)\n","      if(self.bi):\n","        # print(x.shape)\n","        # print(ht_1.shape)\n","        x = self.linear_layer_bi(torch.cat([x, ht_1], dim=1))\n","      else:\n","        # print(\"here\")\n","        x =  self.linear_layer(torch.cat([x, ht_1], dim=1))\n","\n","      ht = torch.nn.functional.sigmoid(x)\n","      return ht\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.859325Z","iopub.status.busy":"2025-03-07T11:46:04.859029Z","iopub.status.idle":"2025-03-07T11:46:04.873460Z","shell.execute_reply":"2025-03-07T11:46:04.872690Z","shell.execute_reply.started":"2025-03-07T11:46:04.859279Z"},"id":"EQBdoHleBBNv","trusted":true},"outputs":[],"source":["class LuongAttention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(LuongAttention, self).__init__()\n","        # self.linear_layer_1 = nn.Linear(2 * ModelArgs.no_of_neurons, ModelArgs.hidden_dim, device=ModelArgs.device)\n","        # self.linear_layer_2 = nn.Linear(ModelArgs.hidden_dim, ModelArgs.embedding_dims, device=ModelArgs.device)\n","\n","    def forward(self, st, ht):\n","        # print(\"inside att st: \", st.shape)\n","        # print(\"inside att ht: \", ht.shape)\n","        st = st.expand(-1, ht.shape[1], -1)\n","        \n","        # dot = torch.dot(st, ht, )\n","        dot = torch.sum(st * ht, dim=-1)\n","        # combined = torch.cat([st, ht], dim=-1)\n","        # out = self.linear_layer_1(combined)\n","        # out = torch.nn.functional.tanh(out)\n","        # out = self.linear_layer_2(out)\n","        attention_weights = torch.nn.functional.softmax(dot, dim=1)\n","        # print(\"attn: \", attention_weights.shape)\n","        # attention_weights = attention_weights.expand(ht.shape[1], -1, -1)\n","        # print(\"attn: \", attention_weights.shape)\n","        # print((attention_weights * ModelArgs.block_size).shape)\n","        # print(torch.sum((attention_weights * ModelArgs.block_size), dim=1).shape)\n","        # ht = ht.unsqueeze(-1)\n","        # print(\"ht: \", ht.shape)\n","        # out = attention_weights * ht\n","       \n","        attention_weights = attention_weights.unsqueeze(-1) #Batch size ,Timesteps , embeddings_dimensions\n","\n","        out = attention_weights * ht  # Shape: (batch_size, timesteps, hidden_size)\n","\n","        context_vector = torch.sum(out, dim=1)\n","        return context_vector, attention_weights"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.781051Z","iopub.status.busy":"2025-03-07T11:46:04.780821Z","iopub.status.idle":"2025-03-07T11:46:04.796738Z","shell.execute_reply":"2025-03-07T11:46:04.795920Z","shell.execute_reply.started":"2025-03-07T11:46:04.781031Z"},"id":"rmpfUn33bXEG","trusted":true},"outputs":[],"source":["class RNNLayer(nn.Module):\n","    def __init__(self, device, no_of_neurons, bi=False, features=None):\n","        super().__init__()\n","\n","        self.feature = features\n","        self.default_features = None\n","\n","        if(self.feature is None):\n","          self.default_features = 2 * ModelArgs.no_of_neurons + ModelArgs.embedding_dims\n","\n","        elif(self.feature is not None):\n","          self.default_features = self.feature\n","\n","\n","        self.rnn_layer = RNNCell(bi=bi, device=device, no_of_neurons=no_of_neurons, features=self.default_features)\n","        self.linear_layer = nn.Linear(in_features=ModelArgs.no_of_neurons, out_features=no_of_neurons, device=ModelArgs.device)\n","        self.attention = LuongAttention(ModelArgs.hidden_dim)\n","        self.linear_layer = nn.Linear(in_features=ModelArgs.no_of_neurons, out_features=ModelArgs.embedding_dims, device=device)\n","        # self.birnn_layer = RNNCell(device=device, no_of_neurons=no_of_neurons, bi=True)\n","    def forward(self, x, ht_1=None, attn=None, outputs=None):\n","\n","        if(ht_1 is None):\n","          ht_1 = torch.zeros((x.shape[0], ModelArgs.no_of_neurons), device=ModelArgs.device, requires_grad=True, dtype=torch.float32)\n","\n","        seq_len = x.shape[1]\n","\n","        if(outputs is None):\n","          outputs = []\n","          for t in range(seq_len):\n","              xt = x[:, t, :]\n","              # xt = xt.unsqueeze(-1)\n","              ht = self.rnn_layer(xt, ht_1)\n","              ht_1 = ht\n","              outputs.append(ht_1)\n","\n","          outputs = torch.stack(outputs, dim=1)\n","          return ht_1, outputs\n","\n","        if(attn == True and outputs is not None):\n","          new_outputs = []\n","          count = 0\n","          st_current=None\n","          for t in range(seq_len):\n","            timestep = x[:, t, :]\n","            if(count == 0):\n","              st_current = torch.zeros((x.shape[0], ModelArgs.no_of_neurons), device=ModelArgs.device, requires_grad=True, dtype=torch.float32)\n","              count += 1\n","              # print(outputs.shape)\n","            # st_current = \n","            xt = outputs\n","            st_current = st_current.unsqueeze(1)\n","            # print(\"HERE: \", xt.shape)\n","            # print(\"st_1: \", st_1.shape)\n","            # xt = self.linear_layer(outputs)\n","            context_vector, attention_weights = self.attention(st_current, xt)\n","            # xt = torch.cat([xt, context_vector], dim=1)\n","            # print(\"timestep: \", timestep.shape) \n","            # print(\"herere: \", context_vector.shape)\n","            # context_vector = context_vector.unsqueeze(0)\n","            # print(\"info: \", context_vector.shape)\n","            # context_vector = context_vector.expand(-1, timestep.shape[1], -1)\n","            # print(\"info: \", context_vector.shape)\n","            timestep = torch.cat([timestep, context_vector], dim=-1)\n","            # print(\"time step now: \", timestep.shape)\n","            # xt = xt.expand(-1,-1, context_vector.shape[-1])\n","            # print(\"xt: \", xt.shape)\n","            # xt = xt + context_vector\n","            # xt = torch.concat([xt, context_vector], dim=-1)\n","            # xt = xt + context_vector\n","            # print(\"After xt: \", xt.shape)\n","            # st_1 = st_1.expand(-1, xt, -1)\n","            st_current = st_current.squeeze(1)\n","            # print(\"xt now : \", xt.shape)\n","            # print(\"st now: \", st_1.shape)\n","            st = self.rnn_layer(st_current, timestep)\n","            # print(\"Here: \", st.shape)\n","            st_current = st\n","            new_outputs.append(st_current)\n","\n","          new_outputs = torch.stack(new_outputs, dim=1)\n","          return st_current, new_outputs"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.797617Z","iopub.status.busy":"2025-03-07T11:46:04.797413Z","iopub.status.idle":"2025-03-07T11:46:04.810856Z","shell.execute_reply":"2025-03-07T11:46:04.810229Z","shell.execute_reply.started":"2025-03-07T11:46:04.797600Z"},"id":"KIqZngodf7yi","trusted":true},"outputs":[],"source":["\n","\n","class EmbeddingTable_de(nn.Module):\n","  def __init__(self, device):\n","    super().__init__()\n","\n","    self.embed_de =  nn.Embedding(num_embeddings=ModelArgs.de_vocab_size, embedding_dim=ModelArgs.embedding_dims, device=device)\n","\n","  def forward(self, x):\n","    # print('Indie: ', x)\n","    return self.embed_de(x)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.812010Z","iopub.status.busy":"2025-03-07T11:46:04.811706Z","iopub.status.idle":"2025-03-07T11:46:04.825188Z","shell.execute_reply":"2025-03-07T11:46:04.824114Z","shell.execute_reply.started":"2025-03-07T11:46:04.811982Z"},"id":"tV6xhxRYf61L","trusted":true},"outputs":[],"source":["\n","class EmbeddingTable_en(nn.Module):\n","  def __init__(self, device):\n","    super().__init__()\n","\n","    self.embed_en = nn.Embedding(num_embeddings=ModelArgs.en_vocab_size, embedding_dim=ModelArgs.embedding_dims, device=device)\n","\n","  def forward(self, x):\n","    return self.embed_en(x)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.826607Z","iopub.status.busy":"2025-03-07T11:46:04.826283Z","iopub.status.idle":"2025-03-07T11:46:04.843059Z","shell.execute_reply":"2025-03-07T11:46:04.842352Z","shell.execute_reply.started":"2025-03-07T11:46:04.826579Z"},"id":"K-C3hiwYbXEG","trusted":true},"outputs":[],"source":["\n","\n","class Decoder(nn.Module):\n","    def __init__(self, device, no_of_neurons, out_features, bi=False):\n","        super().__init__()\n","        self.rnn = RNNLayer(device=device, no_of_neurons=no_of_neurons, bi=False, features = None)\n","        self.embeds_table_en = EmbeddingTable_en(device=device)\n","        self.output = nn.Linear(in_features=ModelArgs.no_of_neurons, out_features=ModelArgs.en_vocab_size, device=device, dtype=torch.float32)\n","        self.dropout = nn.Dropout(p=ModelArgs.dropout)\n","\n","    def forward(self, x, ctx=None, inf=None, embeds=None, initial=None):\n","\n","      if(inf is not True and initial is True):\n","        x = self.embeds_table_en(x)\n","      if(inf is True):\n","        # print(\"Before: \", x.shape)\n","        x = embeds(x)\n","\n","      ht, outputs = self.rnn(x, outputs=ctx, attn=True)\n","      out = self.output(outputs)\n","      out = self.dropout(out)\n","      return out, outputs\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.844214Z","iopub.status.busy":"2025-03-07T11:46:04.843915Z","iopub.status.idle":"2025-03-07T11:46:04.858200Z","shell.execute_reply":"2025-03-07T11:46:04.857349Z","shell.execute_reply.started":"2025-03-07T11:46:04.844184Z"},"id":"80ezApYwbXEG","trusted":true},"outputs":[],"source":["\n","class Encoder(nn.Module):\n","    def __init__(self, device, no_of_neurons, out_features):\n","        super().__init__()\n","        self.rnn = RNNLayer(device=device, no_of_neurons=no_of_neurons, bi=False, features=(ModelArgs.embedding_dims + ModelArgs.no_of_neurons))\n","        self.embeds_table_de = EmbeddingTable_de(device=device)\n","        self.output = nn.Linear(in_features=2 * ModelArgs.no_of_neurons, out_features=ModelArgs.no_of_neurons, device=device, dtype=torch.float32)\n","        # self.dropout = nn.Dropout(p=ModelArgs.dropout)\n","\n","    def forward(self, x, initial=None):\n","        if(initial is not None and initial is True):\n","          x = self.embeds_table_de(x)\n","        ht_fd, outputs_fd = self.rnn(x)\n","        x_rev = torch.flip(x, dims=[1])\n","        ht_bwd, outputs_bwd = self.rnn(x_rev)\n","        outputs = torch.cat([outputs_fd, outputs_bwd], dim=-1)\n","        out = self.output(outputs)\n","        # out = self.dropout(out)\n","        return out, self.embeds_table_de\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.874834Z","iopub.status.busy":"2025-03-07T11:46:04.874344Z","iopub.status.idle":"2025-03-07T11:46:04.890373Z","shell.execute_reply":"2025-03-07T11:46:04.889732Z","shell.execute_reply.started":"2025-03-07T11:46:04.874800Z"},"id":"FL44a09rdr-G","trusted":true},"outputs":[],"source":["\n","\n","\n","class Seq2Seq(nn.Module):\n","\n","    def __init__(self, device, no_of_neurons, out_features):\n","        super().__init__()\n","\n","        self.encoder = Encoder(device, no_of_neurons, out_features)\n","        self.embeds_table_en = EmbeddingTable_en(device=device)\n","        self.decoder = Decoder(device, no_of_neurons, out_features)\n","        # self.encoders = nn.ModuleList(Encoder(device, no_of_neurons, out_features) for _  in range(ModelArgs.num_layers))\n","        # self.decoders = nn.ModuleList(Decoder(device, no_of_neurons, out_features) for x in range(ModelArgs.num_layers))\n","\n","    def forward(self, x, y=None, inf=None):\n","\n","        # count = 0\n","        # for i in self.encoders:\n","        #   if(count == 0):\n","        #     ht_encoder, ct_encoder,outputs_encoder, embeds_de = i(x, initial=True)\n","        #     # x = ht_encoder\n","        #   else:\n","        ht_encoder , embeds_de = self.encoder(x, initial=True)\n","        # print(\"encoder: \", ht_encoder.shape)\n","            # x = ht_encoder\n","          # count += 1\n","\n","        res = None\n","        count = 0\n","        if(y is not None and inf==False):\n","          # for i in self.decoders:\n","\n","          #   # print(\"Hiii\")\n","          #   if(count == 0):\n","          y , outputs = self.decoder(y, ht_encoder, inf, embeds_de, True)\n","              # res = x\n","            # else:\n","            #   y, outputs = i(y, ht_encoder, inf, embeds_de, outputs=outputs)\n","              # res = x\n","            # return res\n","          # elif(y is not None and inf==False):\n","            # print(\"Here\")\n","            # res = self.decoder(y, ht_encoder)\n","            # return res\n","            # count += 1\n","          return y\n","\n","\n","        elif(inf==True and y is None):\n","          # x_init = x\n","          # count = 0\n","          # for i in self.decoders:\n","\n","          #   if(count == 0):\n","          x, outputs = self.decoder(x, ht_encoder, inf, embeds_de, True)\n","            # res = x\n","\n","            # else:\n","            #   x, outputs = i(x_init, ht_encoder, inf, embeds_de, outputs=outputs)\n","\n","            # count += 1\n","          return x"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.891577Z","iopub.status.busy":"2025-03-07T11:46:04.891234Z","iopub.status.idle":"2025-03-07T11:46:04.916457Z","shell.execute_reply":"2025-03-07T11:46:04.915838Z","shell.execute_reply.started":"2025-03-07T11:46:04.891547Z"},"id":"1XjQJr5sbXEG","trusted":true},"outputs":[],"source":["\n","# model = GRU(device=ModelArgs.device, no_of_neurons=ModelArgs.no_of_neurons, out_features=1)\n","model = Seq2Seq(device=ModelArgs.device, no_of_neurons=ModelArgs.no_of_neurons, out_features=1)\n","model = model.to(ModelArgs.device)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T11:46:04.917375Z","iopub.status.busy":"2025-03-07T11:46:04.917146Z","iopub.status.idle":"2025-03-07T11:46:04.920436Z","shell.execute_reply":"2025-03-07T11:46:04.919777Z","shell.execute_reply.started":"2025-03-07T11:46:04.917346Z"},"id":"H8SeNrw7nP9G","trusted":true},"outputs":[],"source":["# x = torch.randint(0, 100, (ModelArgs.batch_size,ModelArgs.block_size))  # Random integer between 0 and 100\n","# x2 = torch.randint(0, 100, (ModelArgs.batch_size)).unsqueeze(1)  # Random integer between 0 and 100\n","# torch.cat([x, x1], dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2025-03-07T11:46:04.921501Z","iopub.status.busy":"2025-03-07T11:46:04.921239Z","iopub.status.idle":"2025-03-07T11:46:05.330440Z","shell.execute_reply":"2025-03-07T11:46:05.329148Z","shell.execute_reply.started":"2025-03-07T11:46:04.921469Z"},"id":"uQMtQTYFbXEG","outputId":"11d0d048-3c31-4cff-8133-03fc84452ff8","trusted":true},"outputs":[],"source":["\n","\n","# !pip install torchinfo\n","\n","from torchinfo import summary\n","\n","# x = torch.randint(0, 100, (ModelArgs.batch_size,ModelArgs.block_size))  # Random integer between 0 and 100\n","# y = torch.randint(0, 100, (ModelArgs.batch_size,ModelArgs.block_size))\n","# y = y.to(ModelArgs.device)\n","# x = x.to(ModelArgs.device)\n","\n","\n","# x = torch.randint(0, 100, (ModelArgs.batch_size,ModelArgs.block_size))  # Random integer between 0 and 100\n","x,y = next(iter(train_loader))\n","x = x.to(ModelArgs.device)\n","y = y.to(ModelArgs.device)\n","\n","\n","summary(model=model,\n","        input_data=[x, y, False],\n","        # input_size=(ModelArgs.batch_size, ModelArgs.block_size, ModelArgs.embeddings_dims),\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"])\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"_xqaF7mUApTQ","trusted":true},"outputs":[],"source":["# from andrej karapathy github\n","import torch.nn.functional as F\n","def topk_sampling(model, prompt, tokenizer, device, max_length=50, top_k=50, temperature=1.0):\n","\n","    # input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n","\n","    input_ids = torch.tensor([de_vocab[token] for token in de_tokenizer(prompt)]).unsqueeze(0)\n","    oov = []\n","    generated_text = \"\"\n","    for _ in range(max_length):\n","        with torch.no_grad():\n","            outputs = model(input_ids, None, True)\n","            logits = outputs[:, -1, :]\n","\n","            probs = F.softmax(logits, dim=-1)\n","\n","            # Top-k filtering\n","            top_k_probs, top_k_indices = torch.topk(probs, top_k, dim=-1)\n","#\n","            # Apply temperature scaling\n","            # probs = probs / temperature\n","\n","            # Sample from top-k\n","            next_token = torch.multinomial(top_k_probs, num_samples=1)\n","\n","            # generated_tokens.append(next_token.item())\n","\n","            xcol = torch.gather(top_k_indices, -1, next_token)\n","            # xcol = torch.argmax(probs, dim=-1)\n","\n","            # if(xcol == '<eos>'):\n","            #   break\n","            # print(xcol.shape)\n","            # print(input_ids.shape)\n","            # print(xcol.shape)\n","            input_ids = torch.cat([input_ids, xcol], dim=-1) #1 because is it the dimension of the sequence\n","    # print(input_ids)\n","    count = 0\n","    de_len = torch.tensor([de_vocab[token] for token in de_tokenizer(prompt)])\n","    for i in input_ids[0]:\n","      # print(de_len.shape)\n","      if(count > de_len.shape[0]):\n","      # print(i)\n","      # try:\n","        \n","        token = en_vocab.vocab.get_itos()[i]\n","        generated_text += token\n","\n","        generated_text += ' '\n","\n","        if(en_vocab.vocab.get_itos()[i] == '<eos>'):\n","          print(\"Done\")\n","          break\n","        \n","      # except:\n","        # oov.append(i)\n","      else:\n","        count += 1\n","\n","    return generated_text\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"48NmNadabXEH","trusted":true},"outputs":[],"source":["# criterion = nn.MSELoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=ModelArgs.max_lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"MvMxXeHabXEH","outputId":"b9566237-de9e-4951-aaaf-20f460c25174","trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["model.train()\n","train_losses =  torch.zeros(len(train_loader))\n","val_losses = torch.zeros(len(val_loader))\n","wandb.init(\n","    project='Seq2Seq-From-Scratch'\n",")\n","for epoch in range(ModelArgs.epoch):\n","\n","    count = 0\n","    print(\"Starting train...\")\n","    for de, en in train_loader:\n","        logits = model(de, en, False)\n","        # print(logits.shape)\n","\n","        batch_size, block_size, vocab = logits.shape\n","        # print(\"Va: \", vocab)\n","        logits = logits.view(batch_size*block_size, vocab)\n","        targets = en.view(batch_size * block_size)\n","        # print(\"HiiiL \", en.shape)\n","        # print(\"HiiiT \", logits.shape)\n","        loss = nn.functional.cross_entropy(logits, targets, ignore_index=en_vocab['<pad>'])\n","        train_losses[count] = loss.item()\n","        # print(\"Loss: \", loss.item())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        count += 1\n","        # print(count)\n","    \n","\n","    # count = 0\n","    model.eval()\n","    count = 0\n","    print(\"Starting val...\")\n","    for de, en in val_loader:\n","        logits = model(de, en, False)\n","        # print(logits.shape)\n","        batch_size, block_size, vocab = logits.shape\n","\n","        logits = logits.view(batch_size*block_size, vocab)\n","        # print(\"Va: \", vocab)\n","        targets = en.view(batch_size * block_size)\n","        loss = nn.functional.cross_entropy(logits, targets, ignore_index=en_vocab['<pad>'])\n","\n","        # print(\"Loss: \", loss.item())\n","        val_losses[count] = loss.item()\n","\n","        # optimizer.zero_grad()\n","        # loss.backward()\n","        # optimizer.step()\n","        count += 1\n","\n","\n","    # print(\"eval\")\n","    print(\"Generating text...\")\n","    generated_text = topk_sampling(model, 'Ich fahre heute mit dem Rad zur Schule', de_tokenizer, device=ModelArgs.device, max_length=50, top_k=50, temperature=1.0)\n","\n","    print(generated_text)\n","\n","\n","    model.train()\n","    wandb.log({\n","      \"Train Loss\": train_losses.mean(),\n","      \"Val Loss\": val_losses.mean(),\n","      \"epoch\": epoch\n","    })\n","    print(\"Epoch: \", epoch, \"|\", \"Train Loss: \", train_losses.mean(),  \"|\", \"Val Loss: \", val_losses.mean())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"mt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":4}
