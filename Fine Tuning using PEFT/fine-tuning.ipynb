{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gI1-Se5RV3yX","outputId":"58d7fc83-7c76-45fa-997a-447225ccafee","trusted":true},"outputs":[],"source":["!pip install bitsandbytes peft trl accelerate transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVjqKI7gHafn","outputId":"9067c585-7e26-4f97-b1f1-5f0cc64aa557","trusted":true},"outputs":[],"source":["pip install -U bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pXoZW4dFSHR","trusted":true},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPRo1JHVcQlw","outputId":"addd85aa-86e1-4d5e-e2cf-0f37a1f78068","trusted":true},"outputs":[],"source":["torch.manual_seed(1337)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c1ea505865ad4daab0de5fb99cfccecb","070d7f42818c4fd28fc8f1a2fbcbbf1f","9e5dfc25b38742e5b7720303c7844977","5896ba2ae4ad4791b825f73a3f761ddd","8d9345a1ecf34e7a84d785ac468ea9ac","59781b49213f4c5cacf786d1d6969fa5","b7feaa2356e441699569d5cb90a06810","9231cc713c0a4b2294d2e4301779a57e","a77f1a013f92423fb32ee6cc0ba332c9","8c21903e861d43f98135691812d99b51","3fb0bf86656947e786c263cbbf3337cb"]},"id":"DDANl2ZBWJCf","outputId":"ee9b3ece-9a2e-4075-e971-52875de1231f","trusted":true},"outputs":[],"source":["import torch\n","import os\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","\n","\n","model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    # bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)\n","model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\", token=HF_TOKEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLDTKYu37clc","trusted":true},"outputs":[],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9zZKb1oG-7G","trusted":true},"outputs":[],"source":["\n","from tqdm import tqdm\n","from datasets import Dataset\n","import pandas as pd\n","# Load CSV using pandas\n","df = pd.read_excel(\"/kaggle/input/maradonaaa/results_Maradona_Hand_Of_God_with_Llama_3.1_8b_instruct_full_final.xlsx\")\n","df = df[['Comments', 'Label']][:2000]\n","# Convert pandas DataFrame to Hugging Face Dataset\n","dataset = Dataset.from_pandas(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyL2kguvLJSw","trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZFzrSXV-hXW","trusted":true},"outputs":[],"source":["# max_len = 0\n","# for i in range(len(dataset)):\n","#   crr_len = len(tokenizer.encode(prompt.format(dataset[i]['Comments'])))\n","#   if crr_len > max_len:\n","#     max_len = crr_len\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYVtKfEZ-hXW","trusted":true},"outputs":[],"source":["tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","tokenizer.padding_side='right'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OKwUsb_-hXW","trusted":true},"outputs":[],"source":["\n","\n","\n","formatted_prompt = (\"<|begin_of_text|><|begin_of_text|>\"\n","                    \"<|start_header_id|>system<|end_header_id|>{}\\n\\n\"\n","                    \"<|eot_id|><|start_header_id|>user<|end_header_id|>{}\\n\\n\"\n","                    \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>{}<|eot_id|>\\n\\n\")\n","\n","system = (\"You are provided with an input. You are required to perform stance detection \"\n","          \"on the input with output as one of the following labels - Favor, Against, \"\n","          \"Irrelevant, Neutral. The labels are self-explanatory. Only output the stance detected label.\")\n","\n","\n","# Define the formatting function\n","def formatting_function(item):\n","\n","    # Use Comments and Label to create formatted text\n","    user = item[\"Comments\"]\n","    assistant = item[\"Label\"]\n","\n","    texts = []\n","    for input_text, output_text in zip(user, assistant):\n","        text = formatted_prompt.format(system, input_text, output_text)\n","        texts.append(text)\n","\n","    return {\"text\": texts}\n","\n","# Apply the formatting function to the dataset\n","# sampled_dataset = tokenized_dataset.select(2000)\n","formatted_dataset = dataset.map(formatting_function, batched=True)\n","\n","\n","max_len = 0\n","for i in range(len(dataset)):\n","   # Use Comments and Label to create formatted text\n","  user = dataset[i][\"Comments\"]\n","  assistant = dataset[i][\"Label\"]\n","\n","  crr_len = len(tokenizer.encode(formatted_prompt.format(system, user, assistant)))\n","  if crr_len > max_len:\n","    max_len = crr_len\n","\n","\n","def tokenize_function(examples):\n","    # Tokenize the full text (input)\n","    tokenized = tokenizer(\n","        examples[\"text\"],\n","        truncation=True,\n","        padding=\"max_length\",\n","        max_length=1024,\n","        # return_tensors=None\n","    )\n","    \n","    # For Llama, we need to process one label at a time\n","    label_tokens = []\n","    for label in examples[\"Label\"]:\n","        # Tokenize each label individually\n","        label_encoding = tokenizer(\n","            str(label),\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=1024,\n","            # return_tensors=None\n","        )\n","        label_tokens.append(label_encoding[\"input_ids\"])\n","    # print(label_tokens)\n","    tokenized[\"labels\"] = label_tokens\n","    return tokenized\n","# Apply the tokenization\n","tokenized_dataset = formatted_dataset.map(\n","    tokenize_function,\n","    batched=True,\n","    remove_columns=[\"Comments\", \"Label\", \"text\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenized_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzigvdHq-hXX","trusted":true},"outputs":[],"source":["formatted_dataset['text'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1sxRq9UYoSU","trusted":true},"outputs":[],"source":["from peft import prepare_model_for_kbit_training\n","\n","model = prepare_model_for_kbit_training(model)\n","\n","model.gradient_checkpointing_enable()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ij7ZtaSYXGuY","trusted":true},"outputs":[],"source":["from peft import LoraConfig, get_peft_model\n","\n","# Configure LoraConfig for model pruning\n","lora_config = LoraConfig(\n","    r=32,\n","    lora_alpha=16,\n","    lora_dropout = 0.05,\n","    target_modules=['down_proj', 'gate_proj', 'o_proj', 'v_proj', 'up_proj', 'q_proj', 'k_proj'],\n","    task_type=\"CAUSAL_LM\",\n","    use_dora=True\n",")\n","# Apply LoRA to the model\n","model = get_peft_model(model, lora_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KhtD4C-X7l6","trusted":true},"outputs":[],"source":["def formatting_func(example):\n","    # Extract instruction and output from the example\n","    instruction = example['instruction']\n","    input = example['input']\n","    output = example['output']\n","\n","    # Format the data into Gemma instruction template format\n","    text = f\"<|im_start|>system\\n{instruction}<|im_end|> <|im_start|>user\\n{input}<|im_end|> <|im_start|>assistant\\n{output}<|im_end|>\"\n","\n","    # Return the formatted data as a list\n","    return [text]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mY7QW2xQo9hb","trusted":true},"outputs":[],"source":["# # len(dataset)\n","# dataset = dataset.map(lambda example: {\"text\": example[\"text\"]}, remove_columns=[\"Comments\", \"Label\"])\n","# dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7ZNJLe1H9J8","trusted":true},"outputs":[],"source":["# tokenized_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pXABGb4IQipO","trusted":true},"outputs":[],"source":["from datasets import Dataset\n","\n","# Assuming `tokenized_dataset` is already created\n","# Split the dataset into training and validation sets\n","# train_dataset, val_dataset = tokenized_dataset.train_test_split(test_size=0.1)  # 10% for validation\n","\n","# Optionally, you can specify a random seed for reproducibility\n","\n","train_dataset, val_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42).values()\n","val_dataset, text_dataset = train_dataset.train_test_split(test_size=0.1, seed=42).values()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAZ937TXRhH9","trusted":true},"outputs":[],"source":["train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67iLBvrPXpOO","trusted":true},"outputs":[],"source":["import transformers\n","from transformers import Trainer\n","\n","# dataset_size = len(dataset)\n","# effective_batch_size = 8 * 4\n","# steps_per_epoch = dataset_size // effective_batch_size\n","\n","# log_every_n_epochs = 0.1\n","# logging_steps = int(steps_per_epoch * log_every_n_epochs)\n","\n","\n","\n","\n","# Initialize the SFTTrainer\n","trainer = Trainer(\n","    model=model,\n","    train_dataset=train_dataset,\n","    eval_dataset = val_dataset,\n","    # dataset_text_field=\"text\",\n","    processing_class =tokenizer,\n","    # packing=False,\n","    # max_seq_length=4096,\n","    args=transformers.TrainingArguments(\n","    remove_unused_columns=False,\n","    output_dir = '/kaggle/working/outputs',\n","    # warmup_steps=50,\n","    warmup_ratio = 0.03,\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=4,\n","    # max_steps=2*len(dataset),\n","    num_train_epochs=1,\n","    learning_rate=2e-4,\n","    optim=\"paged_adamw_8bit\",\n","    logging_steps=25,\n","    logging_dir=\"./logs\",\n","    # save_strategy=\"steps\",\n","    # save_steps=25,\n","    max_grad_norm = 0.3,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=25,\n","    do_eval=True,\n","    gradient_checkpointing=True,\n","    report_to=\"none\",\n","    fp16=True,\n","    overwrite_output_dir = 'True',\n","    group_by_length=True,\n","),\n","\n","    # peft_config=lora_config,\n","    # formatting_func=formatting_function,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"_CJSrNw2o_xE","outputId":"c483867c-92f8-4765-aae7-6c6fc748c9c4","trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6476190,"sourceId":10460800,"sourceType":"datasetVersion"},{"datasetId":6491435,"sourceId":10484446,"sourceType":"datasetVersion"}],"dockerImageVersionId":30840,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"070d7f42818c4fd28fc8f1a2fbcbbf1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59781b49213f4c5cacf786d1d6969fa5","placeholder":"​","style":"IPY_MODEL_b7feaa2356e441699569d5cb90a06810","value":"Loading checkpoint shards:  50%"}},"3fb0bf86656947e786c263cbbf3337cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5896ba2ae4ad4791b825f73a3f761ddd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c21903e861d43f98135691812d99b51","placeholder":"​","style":"IPY_MODEL_3fb0bf86656947e786c263cbbf3337cb","value":" 2/4 [01:07&lt;01:07, 33.84s/it]"}},"59781b49213f4c5cacf786d1d6969fa5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c21903e861d43f98135691812d99b51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d9345a1ecf34e7a84d785ac468ea9ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9231cc713c0a4b2294d2e4301779a57e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e5dfc25b38742e5b7720303c7844977":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9231cc713c0a4b2294d2e4301779a57e","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a77f1a013f92423fb32ee6cc0ba332c9","value":3}},"a77f1a013f92423fb32ee6cc0ba332c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7feaa2356e441699569d5cb90a06810":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1ea505865ad4daab0de5fb99cfccecb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_070d7f42818c4fd28fc8f1a2fbcbbf1f","IPY_MODEL_9e5dfc25b38742e5b7720303c7844977","IPY_MODEL_5896ba2ae4ad4791b825f73a3f761ddd"],"layout":"IPY_MODEL_8d9345a1ecf34e7a84d785ac468ea9ac"}}}}},"nbformat":4,"nbformat_minor":4}
