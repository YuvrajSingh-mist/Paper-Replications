{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h8C4I4M0AbEr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4n_YxBTAbEs",
        "outputId": "bada94bb-4a4c-4d48-cd68-cd8c2a0bd1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sxJrSlI2AbEt"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelArgs:\n",
        "    device = 'cuda'\n",
        "    no_of_neurons = 128\n",
        "    block_size = 32\n",
        "    batch_size = 32\n",
        "    dropout = 0.1\n",
        "    epoch = 50\n",
        "    max_lr = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.0.post101\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "/home/yuvrajsingh/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch7LibraryC1ENS0_4KindESsSt8optionalIN3c1011DispatchKeyEEPKcj",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n",
            "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torchtext/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torchtext/_extension.py:64\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torchtext/_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
            "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torchtext/_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/_ops.py:1032\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1027\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
            "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/ctypes/__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
            "\u001b[0;31mOSError\u001b[0m: /home/yuvrajsingh/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch7LibraryC1ENS0_4KindESsSt8optionalIN3c1011DispatchKeyEEPKcj"
          ]
        }
      ],
      "source": [
        "import torchtext\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "import io\n",
        "\n",
        "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
        "train_urls = ('train.de.gz', 'train.en.gz')\n",
        "val_urls = ('val.de.gz', 'val.en.gz')\n",
        "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n",
        "\n",
        "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
        "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
        "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n",
        "\n",
        "de_tokenizer = get_tokenizer('spacy', language='de')\n",
        "en_tokenizer = get_tokenizer('spacy', language='en')\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "def build_vocab(filepath, tokenizer):\n",
        "    counter = Counter()\n",
        "    with io.open(filepath, encoding=\"utf8\") as f:\n",
        "        for string_ in f:\n",
        "            counter.update(tokenizer(string_))\n",
        "    # Ensure '<pad>' is at index 0 by placing it first in the specials list\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        [counter.keys()],\n",
        "        specials=['<unk>', '<eos>']  # '<pad>' comes first\n",
        "    )\n",
        "    vocab.set_default_index(vocab['<unk>'])\n",
        "    return vocab\n",
        "\n",
        "\n",
        "de_vocab = build_vocab(train_filepaths[0], de_tokenizer)\n",
        "en_vocab = build_vocab(train_filepaths[1], en_tokenizer)\n",
        "\n",
        "def data_process(filepaths):\n",
        "  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
        "  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
        "  data = []\n",
        "  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n",
        "    de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n",
        "                            dtype=torch.long)\n",
        "    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
        "                            dtype=torch.long)\n",
        "    data.append((de_tensor_, en_tensor_))\n",
        "  return data\n",
        "\n",
        "train_data = data_process(train_filepaths)\n",
        "val_data = data_process(val_filepaths)\n",
        "test_data = data_process(test_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sBD_OADeAbEt"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    ModelArgs.device = 'cuda'\n",
        "    torch.set_default_device('cuda')\n",
        "else:\n",
        "\n",
        "    torch.set_default_device('cpu')\n",
        "    ModelArgs.device='cpu'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_device(ModelArgs.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hE9tqRQcAbEu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "num_samples = 10000\n",
        "seq_length = ModelArgs.block_size\n",
        "device = ModelArgs.device\n",
        "\n",
        "\n",
        "t = torch.linspace(0, 100, num_samples + seq_length, device=device)\n",
        "# data = torch.sin(t) + 0.1 * torch.randn_like(t)\n",
        "data = t\n",
        "\n",
        "X_tensor = torch.stack([data[i:i+seq_length] for i in range(num_samples)])\n",
        "y_tensor = data[seq_length:]  # Next value prediction\n",
        "\n",
        "train_size = int(0.8 * num_samples)\n",
        "\n",
        "X_train, y_train = X_tensor[:train_size], y_tensor[:train_size]\n",
        "X_val, y_val = X_tensor[train_size:], y_tensor[train_size:]\n",
        "\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
        "val_dataset = TimeSeriesDataset(X_val, y_val)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "generator = torch.Generator(device=device)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=ModelArgs.batch_size,\n",
        "    shuffle=True,\n",
        "    generator=generator,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    generator=generator,\n",
        "    drop_last=True,\n",
        "    batch_size=ModelArgs.batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NAPYL-KeAbEw"
      },
      "outputs": [],
      "source": [
        "\n",
        "class InputGate(nn.Module):\n",
        "    def __init__(self, device, no_of_neurons):\n",
        "        super().__init__()\n",
        "        self.it = nn.Linear(in_features= ModelArgs.no_of_neurons + 1, out_features=no_of_neurons, device=device, dtype=torch.float32)\n",
        "        self.ct_bar = nn.Linear(in_features=ModelArgs.no_of_neurons + 1, out_features=no_of_neurons, device=device, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, x, ht_1):\n",
        "        x = torch.cat([x, ht_1], dim=-1)\n",
        "        _it = torch.nn.functional.sigmoid(self.it(x))\n",
        "        _ct_bar = torch.nn.functional.tanh(self.ct_bar(x))\n",
        "        # out = torch.nn.functional.sigmoid(self.linear(x))\n",
        "        return _it, _ct_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MxAPFK3wAbEw"
      },
      "outputs": [],
      "source": [
        "class OutputGate(nn.Module):\n",
        "    def __init__(self, device, no_of_neurons) -> None:\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_features= ModelArgs.no_of_neurons + 1, out_features=no_of_neurons, device=device, dtype=torch.float32)\n",
        "    def forward(self, x, ht_1):\n",
        "        x = torch.cat([x, ht_1], dim=-1)\n",
        "        out = torch.nn.functional.sigmoid(self.linear(x))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i-NW4ePRAbEw"
      },
      "outputs": [],
      "source": [
        "class ForgetGate(nn.Module):\n",
        "\n",
        "    def __init__(self, device, no_of_neurons):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_features=ModelArgs.no_of_neurons + 1, out_features=no_of_neurons, device=device, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, x, ht_1):\n",
        "        # print(\"Forgot: \", x.shape)\n",
        "        # print(\"Forget: \", ht_1.shape)\n",
        "        x = torch.cat([x, ht_1], dim=-1)\n",
        "        out = torch.nn.functional.sigmoid(self.linear(x))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8D1FnUKOAbEx"
      },
      "outputs": [],
      "source": [
        "class LSTMBlock(nn.Module):\n",
        "    def __init__(self, device, no_of_neurons):\n",
        "        super().__init__()\n",
        "        self.ip = InputGate(device=device, no_of_neurons=no_of_neurons)\n",
        "        self.op = OutputGate(device=device, no_of_neurons=no_of_neurons)\n",
        "        self.forget = ForgetGate(device=device, no_of_neurons=no_of_neurons)\n",
        "        self.no_of_neurons = no_of_neurons\n",
        "    def forward(self, x, outputs=None):\n",
        "        # print(\"Block: \", x.shape)\n",
        "        # print(\"Block: \", ht_1.shape)\n",
        "        # print(\"Block: \", ct_1.shape)\n",
        "\n",
        "        ht_1 = torch.randn(ModelArgs.batch_size, self.no_of_neurons, device=device, requires_grad=True, dtype=torch.float32)\n",
        "        ct_1 = torch.randn(ModelArgs.batch_size, self.no_of_neurons,device=device, requires_grad=True, dtype=torch.float32)\n",
        "        seq_len = x.shape[1]\n",
        "        if(outputs == None):\n",
        "            outputs = []\n",
        "            for t in range(seq_len):\n",
        "                xt = x[:, t].unsqueeze(-1)\n",
        "                # print(xt.shape)\n",
        "                ft = self.forget(xt, ht_1) * ct_1\n",
        "                it, ct_bar = self.ip(xt , ht_1)\n",
        "                ct_bar_prime = it * ct_bar\n",
        "                ct = ft * ct_1 + ct_bar_prime\n",
        "                ht = self.op(xt, ht_1) * torch.nn.functional.tanh(ct)\n",
        "                outputs.append(ht)\n",
        "                return ht, ct, torch.stack(outputs, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yONjsNpKAbEx"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, device, no_of_neurons, out_features):\n",
        "        super().__init__()\n",
        "        self.block1 = LSTMBlock(device=device, no_of_neurons=no_of_neurons)\n",
        "        self.block2 = LSTMBlock(device=device, no_of_neurons=no_of_neurons)\n",
        "        # self.ht_1 = torch.randn(ModelArgs.batch_size, no_of_neurons, device=device, requires_grad=True, dtype=torch.float32)\n",
        "        # self.ct_1 = torch.randn(ModelArgs.batch_size, no_of_neurons,device=device, requires_grad=True, dtype=torch.float32)\n",
        "        # self.output = nn.Linear(in_features=ModelArgs.no_of_neurons, out_features=out_features, device=device, dtype=torch.float32)\n",
        "        self.dropout = nn.Dropout(p=ModelArgs.dropout)\n",
        "        # self.embedding = nn.Embedding()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x =\n",
        "        # print(\"LSTM: \",x.shape)\n",
        "        # print(\"LSTM: \", self.ht_1.shape)\n",
        "        # print(\"LSTM: \", self.ct_1.shape)\n",
        "        ht, ct, outputs = self.block1(x)\n",
        "        # print(ht.shape)\n",
        "        # print(ct.shape)\n",
        "        # ht, ct = self.block2(x, ht, ct)\n",
        "        # ht = self.dropout(ht)\n",
        "        # print(\"After: \", ht.shape)\n",
        "        # out = self.output(ht)\n",
        "        return  ht, ct, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FdhO0rZpAbEx"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, device, no_of_neurons, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = LSTM(device, no_of_neurons, out_features)\n",
        "        self.decoder = LSTM(device, no_of_neurons, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ht_encoder, ct_encoder,outputs_encoder = self.encoder(x)\n",
        "        ht_decoder, ct_decoder, outputs_decoder = self.decoder(ht_encoder)\n",
        "\n",
        "        return outputs_decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xFj17tN-AbEx"
      },
      "outputs": [],
      "source": [
        "model = Seq2Seq(device=ModelArgs.device, no_of_neurons=ModelArgs.no_of_neurons, out_features=1)\n",
        "model = model.to(ModelArgs.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djd0vnbzAbEx",
        "outputId": "a1855ee4-00ad-4164-dfa3-091a5dc15520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /home/yuvrajsingh/anaconda3/envs/unsloth_env/lib/python3.11/site-packages (1.8.0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "Seq2Seq (Seq2Seq)                        [32, 32]             [32, 1, 128]         --                   True\n",
              "├─LSTM (encoder)                         [32, 32]             [32, 128]            66,560               True\n",
              "│    └─LSTMBlock (block1)                [32, 32]             [32, 128]            --                   True\n",
              "│    │    └─ForgetGate (forget)          [32, 1]              [32, 128]            16,640               True\n",
              "│    │    └─InputGate (ip)               [32, 1]              [32, 128]            33,280               True\n",
              "│    │    └─OutputGate (op)              [32, 1]              [32, 128]            16,640               True\n",
              "├─LSTM (decoder)                         [32, 128]            [32, 128]            66,560               True\n",
              "│    └─LSTMBlock (block1)                [32, 128]            [32, 128]            --                   True\n",
              "│    │    └─ForgetGate (forget)          [32, 1]              [32, 128]            16,640               True\n",
              "│    │    └─InputGate (ip)               [32, 1]              [32, 128]            33,280               True\n",
              "│    │    └─OutputGate (op)              [32, 1]              [32, 128]            16,640               True\n",
              "========================================================================================================================\n",
              "Total params: 266,240\n",
              "Trainable params: 266,240\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 4.26\n",
              "========================================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.26\n",
              "Params size (MB): 0.53\n",
              "Estimated Total Size (MB): 0.80\n",
              "========================================================================================================================"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "x = torch.randint(0, 100, (ModelArgs.batch_size,ModelArgs.block_size))  # Random integer between 0 and 100\n",
        "x = x.to(ModelArgs.device)\n",
        "\n",
        "summary(model=model,\n",
        "        input_data=x,\n",
        "        # input_size=(ModelArgs.batch_size, ModelArgs.block_size, ModelArgs.embeddings_dims),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Pd5iUNSoAbEx"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=ModelArgs.max_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE6dFrZvAbEx"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "train_losses =  torch.zeros(len(train_loader))\n",
        "val_losses = torch.zeros(len(val_loader))\n",
        "wandb.init(\n",
        "    project='Encoder_decoder-From-Scratch'\n",
        ")\n",
        "for epoch in range(ModelArgs.epoch):\n",
        "\n",
        "    count = 0\n",
        "    for X, y in train_loader:\n",
        "        y_pred = model(X)\n",
        "        # print(y_pred.shape)\n",
        "        loss = criterion(y_pred, y)\n",
        "        train_losses[count] = loss.item()\n",
        "        # print(\"Loss: \", loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        count += 1\n",
        "\n",
        "    # count = 0\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    for X, y in val_loader:\n",
        "        y_pred = model(X)\n",
        "        # print(y_pred.shape)\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        # print(\"Loss: \", loss.item())\n",
        "        val_losses[count] = loss.item()\n",
        "\n",
        "        # optimizer.zero_grad()\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        count += 1\n",
        "    model.train()\n",
        "    wandb.log({\n",
        "      \"Train Loss\": train_losses.mean(),\n",
        "      \"Val Loss\": val_losses.mean(),\n",
        "      \"epoch\": epoch\n",
        "    })\n",
        "    print(\"Epoch: \", epoch, \"|\", \"Train Loss: \", train_losses.mean(),  \"|\", \"Val Loss: \", val_losses.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZag0Wb0AbEx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "unsloth_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
