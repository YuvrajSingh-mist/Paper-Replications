
# Mixtral in Pytorch

I implemented the Mixtral architecture from scratch using Pytorch on Tinyshakespeare dataset.

[Mixtral of Experts](https://arxiv.org/pdf/2401.04088)


### Datasets

**Tineshakespeare**: in the /data folder

### Frameworks:
**Pytorch**


### Results (on T4 GPU Single)

**Training steps:** 1000
**Validation steps:** per 50 training steps

**Train loss:** 2.0422 
**Val loss:** 2.0898
