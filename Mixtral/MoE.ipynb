{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom pathlib import Path\nfrom tokenizers import Tokenizer","metadata":{"id":"Pw7f2ghccuoK","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:19.432347Z","iopub.execute_input":"2025-02-08T16:26:19.432588Z","iopub.status.idle":"2025-02-08T16:26:22.304508Z","shell.execute_reply.started":"2025-02-08T16:26:19.432564Z","shell.execute_reply":"2025-02-08T16:26:22.303852Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# device = \"cpu\"","metadata":{"id":"adLpt7j7cuoL","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:22.305174Z","iopub.execute_input":"2025-02-08T16:26:22.305461Z","iopub.status.idle":"2025-02-08T16:26:22.375391Z","shell.execute_reply.started":"2025-02-08T16:26:22.305442Z","shell.execute_reply":"2025-02-08T16:26:22.374258Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#Data","metadata":{"id":"LwR5_uvTcuoL","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:22.376399Z","iopub.execute_input":"2025-02-08T16:26:22.376682Z","iopub.status.idle":"2025-02-08T16:26:22.387397Z","shell.execute_reply.started":"2025-02-08T16:26:22.376660Z","shell.execute_reply":"2025-02-08T16:26:22.386725Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Collab setup\n\ndata_path = Path('/kaggle/working/data')\ndata_path.mkdir(exist_ok=True)\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n!cp input.txt data/input.txt\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDccPM5AcuoL","outputId":"314a00d7-c34d-471f-ab7f-3bfa29fa405e","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:22.389296Z","iopub.execute_input":"2025-02-08T16:26:22.389508Z","iopub.status.idle":"2025-02-08T16:26:22.780480Z","shell.execute_reply.started":"2025-02-08T16:26:22.389491Z","shell.execute_reply":"2025-02-08T16:26:22.779589Z"}},"outputs":[{"name":"stdout","text":"--2025-02-08 16:26:22--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: ‘input.txt.3’\n\ninput.txt.3         100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n\n2025-02-08 16:26:22 (22.5 MB/s) - ‘input.txt.3’ saved [1115394/1115394]\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#Datasets\n\n# Using tinyshakespeare\n\nwith open('data/input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()\n\n####################################################################\n\n#Using BookCorpus\n# from datasets import load_dataset\n# data = load_dataset('bookcorpus/bookcorpus')","metadata":{"id":"-CsTcTonJuiW","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:22.782163Z","iopub.execute_input":"2025-02-08T16:26:22.782405Z","iopub.status.idle":"2025-02-08T16:26:22.787846Z","shell.execute_reply.started":"2025-02-08T16:26:22.782383Z","shell.execute_reply":"2025-02-08T16:26:22.787123Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#Datasets\n\n# Using tinyshakespeare\n\nwith open('data/input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()\n\n####################################################################\n\n#Using BookCorpus\n# from datasets import load_dataset\n# data = load_dataset('bookcorpus/bookcorpus')","metadata":{"id":"0VBi6asbs4Vs","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:22.788812Z","iopub.execute_input":"2025-02-08T16:26:22.789144Z","iopub.status.idle":"2025-02-08T16:26:22.798969Z","shell.execute_reply.started":"2025-02-08T16:26:22.789113Z","shell.execute_reply":"2025-02-08T16:26:22.798285Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\n\n\n###############################################################################\n#Character level tokenization\n\n# # here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\n\n\n# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i:ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n","metadata":{"id":"IG5ZV9KEcuoL","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:22.799850Z","iopub.execute_input":"2025-02-08T16:26:22.800075Z","iopub.status.idle":"2025-02-08T16:26:22.822021Z","shell.execute_reply.started":"2025-02-08T16:26:22.800044Z","shell.execute_reply":"2025-02-08T16:26:22.821290Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#Hyperparameters\n\nblock_size = 128\nbatch_size = 16\nembeddings_dims = 384\nattn_dropout = 0.1\nno_of_heads = 6 #IMP needs to be thoroughly calculated\ndropout = 0.1\nepochs = 100\nmax_lr = 3e-4\nno_of_decoder_layers = 6 #IMP needs to be thoroughly calculated\nattn_dropout = 0.1\nweight_decay_optim = 0.01\nexperts=8\ntop_experts=2","metadata":{"id":"ndPfBp-Gb0KN","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:22.822840Z","iopub.execute_input":"2025-02-08T16:26:22.823034Z","iopub.status.idle":"2025-02-08T16:26:22.833698Z","shell.execute_reply.started":"2025-02-08T16:26:22.823016Z","shell.execute_reply":"2025-02-08T16:26:22.832913Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Train and test splits\ndata = torch.tensor(encode(text), dtype=torch.long)\nn = int(0.9*len(data)) # first 90% will be train, rest val\ntrain_data = data[:n]\nval_data = data[n:]\n\n# data loading\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    x, y = x.to(device), y.to(device)\n    return x, y","metadata":{"id":"goaGJ8k1cuoM","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:22.834494Z","iopub.execute_input":"2025-02-08T16:26:22.834690Z","iopub.status.idle":"2025-02-08T16:26:23.025516Z","shell.execute_reply.started":"2025-02-08T16:26:22.834672Z","shell.execute_reply":"2025-02-08T16:26:23.024905Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Text embeddings\nclass TextEmbeddings(nn.Module):\n    def __init__(\n        self,\n        vocab_size = vocab_size,\n        embeddings_dims = embeddings_dims\n    ):\n        super().__init__()\n        self.embeddings_table = nn.Embedding(num_embeddings = vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n\n    def forward(self, x):\n        return self.embeddings_table(x)","metadata":{"id":"qAhkF6nmcuoN","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.026283Z","iopub.execute_input":"2025-02-08T16:26:23.026572Z","iopub.status.idle":"2025-02-08T16:26:23.030890Z","shell.execute_reply.started":"2025-02-08T16:26:23.026542Z","shell.execute_reply":"2025-02-08T16:26:23.029975Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#Layer Normalization\n\nclass LayerNormalization(nn.Module):\n    def __init__(\n        self,\n        embeddings_dims = embeddings_dims\n    ):\n        super().__init__()\n\n        self.layer_norm = nn.LayerNorm(normalized_shape=embeddings_dims)\n\n    def forward(self, x):\n        return self.layer_norm(x)","metadata":{"id":"REUDHWrWcuoN","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.031891Z","iopub.execute_input":"2025-02-08T16:26:23.032206Z","iopub.status.idle":"2025-02-08T16:26:23.043428Z","shell.execute_reply.started":"2025-02-08T16:26:23.032177Z","shell.execute_reply":"2025-02-08T16:26:23.042657Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class Swish(nn.Module):\n    def __init__(\n        self,\n        block_size: int = block_size,\n        embeddings_dims: int = embeddings_dims\n    ):\n        super().__init__()\n\n        self.sig = torch.nn.Sigmoid()\n\n\n    def forward(self, x):\n        swish = x * self.sig(x)\n\n        return swish\n","metadata":{"id":"7EZKhq_OJuiY","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.044296Z","iopub.execute_input":"2025-02-08T16:26:23.044581Z","iopub.status.idle":"2025-02-08T16:26:23.054342Z","shell.execute_reply.started":"2025-02-08T16:26:23.044552Z","shell.execute_reply":"2025-02-08T16:26:23.053581Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class SWiGLUExpertMoE(nn.Module):\n    def __init__(\n        self,\n        block_size: int = block_size,\n        embeddings_dims: int = embeddings_dims\n    ):\n        super().__init__()\n\n        self.swish = Swish(block_size=block_size, embeddings_dims=embeddings_dims)\n        self.linear_layer1 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False, dtype=torch.float32)\n        self.linear_layer2 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False, dtype=torch.float32)\n        self.linear_layer3 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False, dtype=torch.float32)\n\n\n\n\n    def forward(self, x):\n        swish_res = self.swish(self.linear_layer1(x))\n        x_V = self.linear_layer2(x)\n        res = torch.mul(swish_res, x_V)\n        out = self.linear_layer3(res)\n        return out\n","metadata":{"id":"mRQWhMhZJuiY","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.056770Z","iopub.execute_input":"2025-02-08T16:26:23.056994Z","iopub.status.idle":"2025-02-08T16:26:23.064914Z","shell.execute_reply.started":"2025-02-08T16:26:23.056976Z","shell.execute_reply":"2025-02-08T16:26:23.064234Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#MoE Layer\n\nclass MoeLayer(nn.Module):\n    def __init__(\n        self,\n        dropout = dropout,\n        embeddings_size = embeddings_dims,\n        # inner_dimensional_states: int = 3072\n    ):\n        super().__init__()\n\n        self.heads = nn.ModuleList([SWiGLUExpertMoE() for _ in range(experts)])\n        self.gate = nn.Linear(in_features=embeddings_dims, out_features=experts)\n        # self.outputs = torch.zeros((batch_size,block_size, embeddings_size), device=device) #batch size needs to be defined because we are accessing it explicitly\n\n    def forward(self, x):\n        # mlp_weights_init = self.mlp.apply(weights_init)\n        self.gate_out = self.gate(x)\n        top_k_values, top_k_indices = torch.topk(self.gate_out, k=top_experts)\n        probs = torch.nn.functional.softmax(top_k_values)\n        # print(top_k_indices[11])\n        # print(top_k_values[20])\n        # print(probs[20])\n        outputs = torch.zeros(x.size(), device=device)\n        out = 0\n        for batch in range(batch_size):\n            for i in range(block_size):\n                for j in range(top_experts):\n                    # print(i.shape)\n                    # print('X batched shape: ', x[batch].shape)\n                    # print('X shape: ', x.shape)\n                    current_head_idx = top_k_indices[batch, i][j]\n                    # print(top_k_indices[batch, i])\n                    # print(top_k_indices[batch, i][j])\n                    head_out = self.heads[current_head_idx](x[batch])\n                    # print('Head out shape: ', head_out.shape)\n\n                    # print('Softmax shape: ', torch.nn.functional.softmax(top_k_values[top_k_indices[i]]).shape)\n                    # print('Head out shape: ', head_out.shape)\n                    # print(\"Pro: \", probs.shape)\n                    # print(\"Top K indices: \", top_k_indices.shape)\n                    # print(probs[batch, top_k_indices[batch, i]])\n                    # print(probs[batch, top_k_indices[batch, i]].shape)\n                    # self.outputs[batch,i] = probs[batch, i]\n                    # print(probs[batch, i].shape)\n                    # print(probs[batch, i])\n                    # print(probs[batch, i][j])\n                    outputs[batch,i] = probs[batch, i][j]\n        # print(self.outputs.shape)\n        out += head_out * outputs\n\n        return out\n","metadata":{"id":"5N1dQuyBJuiY","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.066003Z","iopub.execute_input":"2025-02-08T16:26:23.066238Z","iopub.status.idle":"2025-02-08T16:26:23.074137Z","shell.execute_reply.started":"2025-02-08T16:26:23.066220Z","shell.execute_reply":"2025-02-08T16:26:23.073503Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\nclass AttentionHead(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.head_size = embeddings_dims // no_of_heads\n        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n        self.dropout = nn.Dropout(p = attn_dropout)\n\n\n    def forward(self, x):\n        batch, block_size, embd_dims = x.shape\n        k = self.keys(x)\n        q = self.query(x)\n        v = self.values(x)\n        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n        weights_normalized = self.dropout(weights_normalized)\n        out = weights_normalized @ v\n        return out\n\n","metadata":{"id":"cf0Jf_7UcuoN","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.074988Z","iopub.execute_input":"2025-02-08T16:26:23.075293Z","iopub.status.idle":"2025-02-08T16:26:23.087000Z","shell.execute_reply.started":"2025-02-08T16:26:23.075248Z","shell.execute_reply":"2025-02-08T16:26:23.086379Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# MHA\n\n\n\n\nclass MHA(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.heads = nn.ModuleList([AttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n        self.dropout = nn.Dropout(p = attn_dropout)\n        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n\n    def forward(self, x):\n        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n        linear_layer = self.linear(concat)\n        out = self.dropout(linear_layer)\n        return out","metadata":{"id":"asiOs-sFcuoO","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.087735Z","iopub.execute_input":"2025-02-08T16:26:23.087995Z","iopub.status.idle":"2025-02-08T16:26:23.100150Z","shell.execute_reply.started":"2025-02-08T16:26:23.087970Z","shell.execute_reply":"2025-02-08T16:26:23.099454Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Decoder Block\n\nclass TransformerDecoderBlock(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        dropout = dropout,\n        vocab_size = vocab_size\n    ):\n        super().__init__()\n\n        self.mha = MHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n        self.layer_norm1 = LayerNormalization(embeddings_dims=embeddings_dims)\n        self.layer_norm2 = LayerNormalization(embeddings_dims=embeddings_dims)\n        self.moe_block = MoeLayer(dropout=dropout, embeddings_size=embeddings_dims)\n\n    def forward(self, x):\n        # x = self.mha(x)\n        # x = x + self.layer_norm1(x)\n        # x = x + self.mlp_block(x)\n        # out = self.layer_norm2(x)\n        x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n        x = x + self.moe_block(self.layer_norm2(x)) #Very important step\n\n        return x","metadata":{"id":"s9rJzO_XcuoO","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.100869Z","iopub.execute_input":"2025-02-08T16:26:23.101060Z","iopub.status.idle":"2025-02-08T16:26:23.113453Z","shell.execute_reply.started":"2025-02-08T16:26:23.101042Z","shell.execute_reply":"2025-02-08T16:26:23.112822Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Decoder Block\n\nclass DecoderModel(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        block_size = block_size,\n        dropout = dropout,\n        no_of_decoder_layers = no_of_decoder_layers,\n        vocab_size = vocab_size\n    ):\n        super().__init__()\n\n        self.positional_embeddings = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n        torch.nn.init.normal_(self.positional_embeddings, mean=0.0, std=0.02)\n        self.text_embds = TextEmbeddings(vocab_size=vocab_size, embeddings_dims=embeddings_dims)\n        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n        self.decoder_layers = nn.Sequential(*[TransformerDecoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout, vocab_size=vocab_size) for _ in range(no_of_decoder_layers)])\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):  #Weight Initialization\n            if isinstance(module, nn.Linear):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n                if module.bias is not None:\n                    torch.nn.init.zeros_(module.bias)\n            elif isinstance(module, nn.Embedding):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, x):\n        x = self.text_embds(x)\n        x = x + self.positional_embeddings\n        x = self.decoder_layers(x)\n        # x = self.layer_norm(x)\n        out = self.linear_layer(x)\n        return out","metadata":{"id":"KGh8ujQJcuoO","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.114186Z","iopub.execute_input":"2025-02-08T16:26:23.114448Z","iopub.status.idle":"2025-02-08T16:26:23.124134Z","shell.execute_reply.started":"2025-02-08T16:26:23.114422Z","shell.execute_reply":"2025-02-08T16:26:23.123518Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#Instantiating the model\nmodel = DecoderModel(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, block_size=block_size, dropout=dropout, no_of_decoder_layers=no_of_decoder_layers, vocab_size=vocab_size)\nmodel = model.to(device)","metadata":{"id":"tpmbUwBEcuoO","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.124825Z","iopub.execute_input":"2025-02-08T16:26:23.124999Z","iopub.status.idle":"2025-02-08T16:26:23.415759Z","shell.execute_reply.started":"2025-02-08T16:26:23.124983Z","shell.execute_reply":"2025-02-08T16:26:23.415148Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"#Printing a summary of the architecture\n# !pip install torchinfo\nfrom torchinfo import summary\nidx, targets = get_batch('test')\n# idx = idx.to(device)\nsummary(model=model,\n        input_data=idx,\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:26:23.416522Z","iopub.execute_input":"2025-02-08T16:26:23.416817Z","iopub.status.idle":"2025-02-08T16:27:33.857154Z","shell.execute_reply.started":"2025-02-08T16:26:23.416786Z","shell.execute_reply":"2025-02-08T16:27:33.856287Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-14-9bcb4db824b3>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  probs = torch.nn.functional.softmax(top_k_values)\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"=======================================================================================================================================\nLayer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n=======================================================================================================================================\nDecoderModel (DecoderModel)                             [16, 128]            [16, 128, 65]        49,152               True\n├─TextEmbeddings (text_embds)                           [16, 128]            [16, 128, 384]       --                   True\n│    └─Embedding (embeddings_table)                     [16, 128]            [16, 128, 384]       24,960               True\n├─Sequential (decoder_layers)                           [16, 128, 384]       [16, 128, 384]       --                   True\n│    └─TransformerDecoderBlock (0)                      [16, 128, 384]       [16, 128, 384]       --                   True\n│    │    └─LayerNormalization (layer_norm1)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MHA (mha)                                   [16, 128, 384]       [16, 128, 384]       589,824              True\n│    │    └─LayerNormalization (layer_norm2)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MoeLayer (moe_block)                        [16, 128, 384]       [16, 128, 384]       3,542,024            True\n│    └─TransformerDecoderBlock (1)                      [16, 128, 384]       [16, 128, 384]       --                   True\n│    │    └─LayerNormalization (layer_norm1)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MHA (mha)                                   [16, 128, 384]       [16, 128, 384]       589,824              True\n│    │    └─LayerNormalization (layer_norm2)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MoeLayer (moe_block)                        [16, 128, 384]       [16, 128, 384]       3,542,024            True\n│    └─TransformerDecoderBlock (2)                      [16, 128, 384]       [16, 128, 384]       --                   True\n│    │    └─LayerNormalization (layer_norm1)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MHA (mha)                                   [16, 128, 384]       [16, 128, 384]       589,824              True\n│    │    └─LayerNormalization (layer_norm2)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MoeLayer (moe_block)                        [16, 128, 384]       [16, 128, 384]       3,542,024            True\n│    └─TransformerDecoderBlock (3)                      [16, 128, 384]       [16, 128, 384]       --                   True\n│    │    └─LayerNormalization (layer_norm1)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MHA (mha)                                   [16, 128, 384]       [16, 128, 384]       589,824              True\n│    │    └─LayerNormalization (layer_norm2)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MoeLayer (moe_block)                        [16, 128, 384]       [16, 128, 384]       3,542,024            True\n│    └─TransformerDecoderBlock (4)                      [16, 128, 384]       [16, 128, 384]       --                   True\n│    │    └─LayerNormalization (layer_norm1)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MHA (mha)                                   [16, 128, 384]       [16, 128, 384]       589,824              True\n│    │    └─LayerNormalization (layer_norm2)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MoeLayer (moe_block)                        [16, 128, 384]       [16, 128, 384]       3,542,024            True\n│    └─TransformerDecoderBlock (5)                      [16, 128, 384]       [16, 128, 384]       --                   True\n│    │    └─LayerNormalization (layer_norm1)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MHA (mha)                                   [16, 128, 384]       [16, 128, 384]       589,824              True\n│    │    └─LayerNormalization (layer_norm2)            [16, 128, 384]       [16, 128, 384]       768                  True\n│    │    └─MoeLayer (moe_block)                        [16, 128, 384]       [16, 128, 384]       3,542,024            True\n├─Linear (linear_layer)                                 [16, 128, 384]       [16, 128, 65]        24,960               True\n=======================================================================================================================================\nTotal params: 24,899,376\nTrainable params: 24,899,376\nNon-trainable params: 0\nTotal mult-adds (T): 1.39\n=======================================================================================================================================\nInput size (MB): 0.02\nForward/backward pass size (MB): 29225.66\nParams size (MB): 97.63\nEstimated Total Size (MB): 29323.31\n======================================================================================================================================="},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Optimizer setup and scheduler steup\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=max_lr)\n# optimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay_optim)\ninitial_iters = 2000\ntotal_steps = 1000\neval_iters = 50\n\n@torch.inference_mode()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            idx, targets = get_batch(split=split)\n            logits = model(idx)\n            batch_size, block_size, embeddings_dims = logits.shape\n            logits = logits.view(batch_size*block_size, embeddings_dims) # Total tokens(words) => batch_size * block_size\n            targets = targets.view(batch_size * block_size)\n            loss = nn.functional.cross_entropy(logits, targets)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"id":"LH95cJEvcuoO","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:27:33.857994Z","iopub.execute_input":"2025-02-08T16:27:33.858257Z","iopub.status.idle":"2025-02-08T16:27:37.717390Z","shell.execute_reply.started":"2025-02-08T16:27:33.858225Z","shell.execute_reply":"2025-02-08T16:27:37.716707Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#Train the  model\nfrom tqdm import tqdm\n\nmodel.train()\nfor step in tqdm(range(total_steps)):\n\n    # every once in a while evaluate the loss on train and val sets\n    if (step  % eval_iters == 0 and step != 0) or step == total_steps - 1:\n        losses = estimate_loss()\n        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n\n    idx, targets = get_batch(split='train')\n    logits = model(idx)\n    batch_size, block_size, embeddings_dims = logits.shape\n    logits = logits.view(batch_size*block_size, embeddings_dims)\n    targets = targets.view(batch_size * block_size)\n    loss = nn.functional.cross_entropy(logits, targets)\n\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward(retain_graph=True)\n    optimizer.step()\n    # print(loss.item())\n    # break\n\n    # if step != 0 and (step % eval_iters == 0 or step == total_steps -1) :\n    #     loss_values = estimate_loss()\n    #     print(\"Train Loss at {} steps : {}\".format(step, loss.item()), \"Val Loss at {} steps : {}\".format(step, loss_values['val']))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"id":"nPrSPPu8cuoO","outputId":"6eee2020-99ee-4c4b-f08c-e36a9fb5f312","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:27:37.718174Z","iopub.execute_input":"2025-02-08T16:27:37.718478Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/1000 [00:00<?, ?it/s]<ipython-input-14-9bcb4db824b3>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  probs = torch.nn.functional.softmax(top_k_values)\n  5%|▌         | 50/1000 [08:40<2:45:00, 10.42s/it]","output_type":"stream"},{"name":"stdout","text":"step 50: train loss 2.9219, val loss 2.9487\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 100/1000 [24:54<2:36:51, 10.46s/it] ","output_type":"stream"},{"name":"stdout","text":"step 100: train loss 2.5985, val loss 2.6080\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 150/1000 [41:11<2:28:16, 10.47s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 150: train loss 2.5429, val loss 2.5337\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 200/1000 [57:21<2:19:18, 10.45s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 200: train loss 2.5219, val loss 2.5245\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 250/1000 [1:13:31<2:11:02, 10.48s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 250: train loss 2.4782, val loss 2.4850\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 300/1000 [1:29:48<2:02:11, 10.47s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 300: train loss 2.4497, val loss 2.4665\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 350/1000 [1:45:58<1:53:29, 10.48s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 350: train loss 2.4063, val loss 2.4105\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 400/1000 [2:02:12<1:44:49, 10.48s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 400: train loss 2.3545, val loss 2.3692\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 450/1000 [2:18:28<1:36:38, 10.54s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 450: train loss 2.3071, val loss 2.3205\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 500/1000 [2:34:40<1:27:57, 10.55s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 500: train loss 2.2745, val loss 2.3057\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 550/1000 [2:50:54<1:18:52, 10.52s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 550: train loss 2.2548, val loss 2.2755\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 600/1000 [3:07:07<1:10:10, 10.53s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 600: train loss 2.2098, val loss 2.2342\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 650/1000 [3:23:22<1:01:39, 10.57s/it]  ","output_type":"stream"},{"name":"stdout","text":"step 650: train loss 2.1946, val loss 2.2235\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 700/1000 [3:39:42<53:12, 10.64s/it]    ","output_type":"stream"},{"name":"stdout","text":"step 700: train loss 2.1696, val loss 2.2033\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 750/1000 [3:56:07<44:25, 10.66s/it]    ","output_type":"stream"},{"name":"stdout","text":"step 750: train loss 2.1411, val loss 2.1803\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 800/1000 [4:12:22<35:18, 10.59s/it]    ","output_type":"stream"},{"name":"stdout","text":"step 800: train loss 2.1177, val loss 2.1696\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 850/1000 [4:28:35<26:30, 10.60s/it]   ","output_type":"stream"},{"name":"stdout","text":"step 850: train loss 2.1017, val loss 2.1485\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 900/1000 [4:44:46<17:36, 10.57s/it]   ","output_type":"stream"},{"name":"stdout","text":"step 900: train loss 2.0770, val loss 2.1151\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 950/1000 [5:01:00<08:48, 10.56s/it]   ","output_type":"stream"},{"name":"stdout","text":"step 950: train loss 2.0519, val loss 2.1128\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 999/1000 [5:17:03<00:10, 10.58s/it]   ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}