{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:34.598786Z",
     "iopub.status.busy": "2025-02-09T07:48:34.598427Z",
     "iopub.status.idle": "2025-02-09T07:48:36.194457Z",
     "shell.execute_reply": "2025-02-09T07:48:36.193507Z",
     "shell.execute_reply.started": "2025-02-09T07:48:34.598763Z"
    },
    "id": "Pw7f2ghccuoK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.271351Z",
     "iopub.status.busy": "2025-02-09T07:48:38.271066Z",
     "iopub.status.idle": "2025-02-09T07:48:38.274912Z",
     "shell.execute_reply": "2025-02-09T07:48:38.274090Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.271329Z"
    },
    "id": "adLpt7j7cuoL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.276608Z",
     "iopub.status.busy": "2025-02-09T07:48:38.276381Z",
     "iopub.status.idle": "2025-02-09T07:48:38.288506Z",
     "shell.execute_reply": "2025-02-09T07:48:38.287826Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.276578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.289552Z",
     "iopub.status.busy": "2025-02-09T07:48:38.289254Z",
     "iopub.status.idle": "2025-02-09T07:48:38.298870Z",
     "shell.execute_reply": "2025-02-09T07:48:38.298035Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.289524Z"
    },
    "id": "LwR5_uvTcuoL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.299827Z",
     "iopub.status.busy": "2025-02-09T07:48:38.299602Z",
     "iopub.status.idle": "2025-02-09T07:48:38.651134Z",
     "shell.execute_reply": "2025-02-09T07:48:38.650064Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.299808Z"
    },
    "id": "eDccPM5AcuoL",
    "outputId": "314a00d7-c34d-471f-ab7f-3bfa29fa405e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-09 07:48:38--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.3’\n",
      "\n",
      "input.txt.3         100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-02-09 07:48:38 (22.5 MB/s) - ‘input.txt.3’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Collab setup\n",
    "\n",
    "data_path = Path('/kaggle/working/data')\n",
    "data_path.mkdir(exist_ok=True)\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "!cp input.txt data/input.txt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.652358Z",
     "iopub.status.busy": "2025-02-09T07:48:38.652083Z",
     "iopub.status.idle": "2025-02-09T07:48:38.658258Z",
     "shell.execute_reply": "2025-02-09T07:48:38.657572Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.652335Z"
    },
    "id": "-CsTcTonJuiW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Datasets\n",
    "\n",
    "# Using tinyshakespeare\n",
    "\n",
    "with open('data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "####################################################################\n",
    "\n",
    "#Using BookCorpus\n",
    "# from datasets import load_dataset\n",
    "# data = load_dataset('bookcorpus/bookcorpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.659177Z",
     "iopub.status.busy": "2025-02-09T07:48:38.658955Z",
     "iopub.status.idle": "2025-02-09T07:48:38.673582Z",
     "shell.execute_reply": "2025-02-09T07:48:38.672958Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.659152Z"
    },
    "id": "0VBi6asbs4Vs",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Datasets\n",
    "\n",
    "# Using tinyshakespeare\n",
    "\n",
    "with open('data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "####################################################################\n",
    "\n",
    "#Using BookCorpus\n",
    "# from datasets import load_dataset\n",
    "# data = load_dataset('bookcorpus/bookcorpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.674542Z",
     "iopub.status.busy": "2025-02-09T07:48:38.674331Z",
     "iopub.status.idle": "2025-02-09T07:48:38.698642Z",
     "shell.execute_reply": "2025-02-09T07:48:38.697894Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.674524Z"
    },
    "id": "IG5ZV9KEcuoL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#Character level tokenization\n",
    "\n",
    "# # here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch: i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.699797Z",
     "iopub.status.busy": "2025-02-09T07:48:38.699532Z",
     "iopub.status.idle": "2025-02-09T07:48:38.709926Z",
     "shell.execute_reply": "2025-02-09T07:48:38.709344Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.699770Z"
    },
    "id": "ndPfBp-Gb0KN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "block_size = 128\n",
    "batch_size = 8\n",
    "embeddings_dims = 384\n",
    "attn_dropout = 0.1\n",
    "no_of_heads = 6 #IMP needs to be thoroughly calculated\n",
    "dropout = 0.1\n",
    "epochs = 100\n",
    "max_lr = 3e-4\n",
    "no_of_decoder_layers = 6 #IMP needs to be thoroughly calculated\n",
    "attn_dropout = 0.1\n",
    "weight_decay_optim = 0.01\n",
    "experts=8\n",
    "top_experts=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.711070Z",
     "iopub.status.busy": "2025-02-09T07:48:38.710767Z",
     "iopub.status.idle": "2025-02-09T07:48:38.895578Z",
     "shell.execute_reply": "2025-02-09T07:48:38.894564Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.711009Z"
    },
    "id": "goaGJ8k1cuoM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.896639Z",
     "iopub.status.busy": "2025-02-09T07:48:38.896436Z",
     "iopub.status.idle": "2025-02-09T07:48:38.901351Z",
     "shell.execute_reply": "2025-02-09T07:48:38.900386Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.896621Z"
    },
    "id": "qAhkF6nmcuoN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Text embeddings\n",
    "class TextEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size = vocab_size,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embeddings_table = nn.Embedding(num_embeddings = vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n",
    "        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embeddings_table(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.902476Z",
     "iopub.status.busy": "2025-02-09T07:48:38.902217Z",
     "iopub.status.idle": "2025-02-09T07:48:38.914085Z",
     "shell.execute_reply": "2025-02-09T07:48:38.913355Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.902443Z"
    },
    "id": "REUDHWrWcuoN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Layer Normalization\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=embeddings_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.915164Z",
     "iopub.status.busy": "2025-02-09T07:48:38.914873Z",
     "iopub.status.idle": "2025-02-09T07:48:38.927324Z",
     "shell.execute_reply": "2025-02-09T07:48:38.926517Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.915135Z"
    },
    "id": "7EZKhq_OJuiY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_size: int = block_size,\n",
    "        embeddings_dims: int = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        swish = x * self.sig(x)\n",
    "\n",
    "        return swish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.928475Z",
     "iopub.status.busy": "2025-02-09T07:48:38.928157Z",
     "iopub.status.idle": "2025-02-09T07:48:38.940870Z",
     "shell.execute_reply": "2025-02-09T07:48:38.940028Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.928446Z"
    },
    "id": "mRQWhMhZJuiY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SWiGLUExpertMoE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_size: int = block_size,\n",
    "        embeddings_dims: int = embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.swish = Swish(block_size=block_size, embeddings_dims=embeddings_dims)\n",
    "        self.linear_layer1 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False, dtype=torch.float32)\n",
    "        self.linear_layer2 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False, dtype=torch.float32)\n",
    "        self.linear_layer3 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        swish_res = self.swish(self.linear_layer1(x))\n",
    "        x_V = self.linear_layer2(x)\n",
    "        res = torch.mul(swish_res, x_V)\n",
    "        out = self.linear_layer3(res)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.942142Z",
     "iopub.status.busy": "2025-02-09T07:48:38.941834Z",
     "iopub.status.idle": "2025-02-09T07:48:38.958591Z",
     "shell.execute_reply": "2025-02-09T07:48:38.957933Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.942090Z"
    },
    "id": "5N1dQuyBJuiY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#MoE Layer\n",
    "\n",
    "class MoeLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dropout = dropout,\n",
    "        embeddings_size = embeddings_dims,\n",
    "        # inner_dimensional_states: int = 3072\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList([SWiGLUExpertMoE() for _ in range(experts)])\n",
    "        self.gate = nn.Linear(in_features=embeddings_dims, out_features=experts)\n",
    "        # self.outputs = torch.zeros((batch_size,block_size, embeddings_size), device=device) #batch size needs to be defined because we are accessing it explicitly\n",
    "\n",
    "    def forward(self, x):\n",
    "        # mlp_weights_init = self.mlp.apply(weights_init)\n",
    "        self.gate_out = self.gate(x)\n",
    "        top_k_values, top_k_indices = torch.topk(self.gate_out, k=top_experts)\n",
    "        probs = torch.nn.functional.softmax(top_k_values, dim=-1) \n",
    "        #imp to add dim=-1 which specifies the softmax to be applied to the experts dim\n",
    "        # print(top_k_indices[11])\n",
    "        # print(top_k_values[20])\n",
    "        # print(probs[20])\n",
    "        outputs = torch.zeros(x.size(), device=device)\n",
    "        out = 0\n",
    "        for batch in range(batch_size):\n",
    "            for i in range(block_size):\n",
    "                for j in range(top_experts):\n",
    "                    # print(i.shape)\n",
    "                    # print('X batched shape: ', x[batch].shape)\n",
    "                    # print('X shape: ', x.shape)\n",
    "                    current_head_idx = top_k_indices[batch, i][j]\n",
    "                    # print(top_k_indices[batch, i])\n",
    "                    # print(top_k_indices[batch, i][j])\n",
    "                    head_out = self.heads[current_head_idx](x[batch])\n",
    "                    # print('Head out shape: ', head_out.shape)\n",
    "\n",
    "                    # print('Softmax shape: ', torch.nn.functional.softmax(top_k_values[top_k_indices[i]]).shape)\n",
    "                    # print('Head out shape: ', head_out.shape)\n",
    "                    # print(\"Pro: \", probs.shape)\n",
    "                    # print(\"Top K indices: \", top_k_indices.shape)\n",
    "                    # print(probs[batch, top_k_indices[batch, i]])\n",
    "                    # print(probs[batch, top_k_indices[batch, i]].shape)\n",
    "                    # self.outputs[batch,i] = probs[batch, i]\n",
    "                    # print(probs[batch, i].shape)\n",
    "                    # print(probs[batch, i])\n",
    "                    # print(probs[batch, i][j])\n",
    "                    # outputs[batch,i] = probs[batch, i][j]\n",
    "                    # print(self.outputs.shape)\n",
    "                    out += head_out * probs[batch, i][j]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.962071Z",
     "iopub.status.busy": "2025-02-09T07:48:38.961858Z",
     "iopub.status.idle": "2025-02-09T07:48:38.975139Z",
     "shell.execute_reply": "2025-02-09T07:48:38.974514Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.962042Z"
    },
    "id": "cf0Jf_7UcuoN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.head_size = embeddings_dims // no_of_heads\n",
    "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
    "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
    "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
    "        self.dropout = nn.Dropout(p = attn_dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, block_size, embd_dims = x.shape\n",
    "        k = self.keys(x)\n",
    "        q = self.query(x)\n",
    "        v = self.values(x)\n",
    "        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
    "        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
    "        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n",
    "        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
    "        weights_normalized = self.dropout(weights_normalized)\n",
    "        out = weights_normalized @ v\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:38.978475Z",
     "iopub.status.busy": "2025-02-09T07:48:38.978216Z",
     "iopub.status.idle": "2025-02-09T07:48:38.990858Z",
     "shell.execute_reply": "2025-02-09T07:48:38.990181Z",
     "shell.execute_reply.started": "2025-02-09T07:48:38.978455Z"
    },
    "id": "asiOs-sFcuoO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# MHA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
    "        self.dropout = nn.Dropout(p = attn_dropout)\n",
    "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        linear_layer = self.linear(concat)\n",
    "        out = self.dropout(linear_layer)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:39.564794Z",
     "iopub.status.busy": "2025-02-09T07:48:39.564570Z",
     "iopub.status.idle": "2025-02-09T07:48:39.569718Z",
     "shell.execute_reply": "2025-02-09T07:48:39.568979Z",
     "shell.execute_reply.started": "2025-02-09T07:48:39.564776Z"
    },
    "id": "s9rJzO_XcuoO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Decoder Block\n",
    "\n",
    "class TransformerDecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        dropout = dropout,\n",
    "        vocab_size = vocab_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha = MHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
    "        self.layer_norm1 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.layer_norm2 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.moe_block = MoeLayer(dropout=dropout, embeddings_size=embeddings_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.mha(x)\n",
    "        # x = x + self.layer_norm1(x)\n",
    "        # x = x + self.mlp_block(x)\n",
    "        # out = self.layer_norm2(x)\n",
    "        x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n",
    "        x = x + self.moe_block(self.layer_norm2(x)) #Very important step\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:39.744839Z",
     "iopub.status.busy": "2025-02-09T07:48:39.744622Z",
     "iopub.status.idle": "2025-02-09T07:48:39.751312Z",
     "shell.execute_reply": "2025-02-09T07:48:39.750612Z",
     "shell.execute_reply.started": "2025-02-09T07:48:39.744820Z"
    },
    "id": "KGh8ujQJcuoO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Decoder Block\n",
    "\n",
    "class DecoderModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attn_dropout = attn_dropout,\n",
    "        embeddings_dims = embeddings_dims,\n",
    "        no_of_heads = no_of_heads,\n",
    "        block_size = block_size,\n",
    "        dropout = dropout,\n",
    "        no_of_decoder_layers = no_of_decoder_layers,\n",
    "        vocab_size = vocab_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.positional_embeddings = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n",
    "        torch.nn.init.normal_(self.positional_embeddings, mean=0.0, std=0.02)\n",
    "        self.text_embds = TextEmbeddings(vocab_size=vocab_size, embeddings_dims=embeddings_dims)\n",
    "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
    "        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n",
    "        self.decoder_layers = nn.Sequential(*[TransformerDecoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout, vocab_size=vocab_size) for _ in range(no_of_decoder_layers)])\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):  #Weight Initialization\n",
    "            if isinstance(module, nn.Linear):\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "                if module.bias is not None:\n",
    "                    torch.nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.text_embds(x)\n",
    "        x = x + self.positional_embeddings\n",
    "        x = self.decoder_layers(x)\n",
    "        # x = self.layer_norm(x)\n",
    "        out = self.linear_layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:40.055836Z",
     "iopub.status.busy": "2025-02-09T07:48:40.055644Z",
     "iopub.status.idle": "2025-02-09T07:48:40.260781Z",
     "shell.execute_reply": "2025-02-09T07:48:40.260081Z",
     "shell.execute_reply.started": "2025-02-09T07:48:40.055819Z"
    },
    "id": "tpmbUwBEcuoO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "model = DecoderModel(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, block_size=block_size, dropout=dropout, no_of_decoder_layers=no_of_decoder_layers, vocab_size=vocab_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:48:42.197479Z",
     "iopub.status.busy": "2025-02-09T07:48:42.197143Z",
     "iopub.status.idle": "2025-02-09T07:49:03.738169Z",
     "shell.execute_reply": "2025-02-09T07:49:03.737141Z",
     "shell.execute_reply.started": "2025-02-09T07:48:42.197450Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n",
       "=======================================================================================================================================\n",
       "DecoderModel (DecoderModel)                             [8, 128]             [8, 128, 65]         49,152               True\n",
       "├─TextEmbeddings (text_embds)                           [8, 128]             [8, 128, 384]        --                   True\n",
       "│    └─Embedding (embeddings_table)                     [8, 128]             [8, 128, 384]        24,960               True\n",
       "├─Sequential (decoder_layers)                           [8, 128, 384]        [8, 128, 384]        --                   True\n",
       "│    └─TransformerDecoderBlock (0)                      [8, 128, 384]        [8, 128, 384]        --                   True\n",
       "│    │    └─LayerNormalization (layer_norm1)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MHA (mha)                                   [8, 128, 384]        [8, 128, 384]        589,824              True\n",
       "│    │    └─LayerNormalization (layer_norm2)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MoeLayer (moe_block)                        [8, 128, 384]        [8, 128, 384]        3,542,024            True\n",
       "│    └─TransformerDecoderBlock (1)                      [8, 128, 384]        [8, 128, 384]        --                   True\n",
       "│    │    └─LayerNormalization (layer_norm1)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MHA (mha)                                   [8, 128, 384]        [8, 128, 384]        589,824              True\n",
       "│    │    └─LayerNormalization (layer_norm2)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MoeLayer (moe_block)                        [8, 128, 384]        [8, 128, 384]        3,542,024            True\n",
       "│    └─TransformerDecoderBlock (2)                      [8, 128, 384]        [8, 128, 384]        --                   True\n",
       "│    │    └─LayerNormalization (layer_norm1)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MHA (mha)                                   [8, 128, 384]        [8, 128, 384]        589,824              True\n",
       "│    │    └─LayerNormalization (layer_norm2)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MoeLayer (moe_block)                        [8, 128, 384]        [8, 128, 384]        3,542,024            True\n",
       "│    └─TransformerDecoderBlock (3)                      [8, 128, 384]        [8, 128, 384]        --                   True\n",
       "│    │    └─LayerNormalization (layer_norm1)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MHA (mha)                                   [8, 128, 384]        [8, 128, 384]        589,824              True\n",
       "│    │    └─LayerNormalization (layer_norm2)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MoeLayer (moe_block)                        [8, 128, 384]        [8, 128, 384]        3,542,024            True\n",
       "│    └─TransformerDecoderBlock (4)                      [8, 128, 384]        [8, 128, 384]        --                   True\n",
       "│    │    └─LayerNormalization (layer_norm1)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MHA (mha)                                   [8, 128, 384]        [8, 128, 384]        589,824              True\n",
       "│    │    └─LayerNormalization (layer_norm2)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MoeLayer (moe_block)                        [8, 128, 384]        [8, 128, 384]        3,542,024            True\n",
       "│    └─TransformerDecoderBlock (5)                      [8, 128, 384]        [8, 128, 384]        --                   True\n",
       "│    │    └─LayerNormalization (layer_norm1)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MHA (mha)                                   [8, 128, 384]        [8, 128, 384]        589,824              True\n",
       "│    │    └─LayerNormalization (layer_norm2)            [8, 128, 384]        [8, 128, 384]        768                  True\n",
       "│    │    └─MoeLayer (moe_block)                        [8, 128, 384]        [8, 128, 384]        3,542,024            True\n",
       "├─Linear (linear_layer)                                 [8, 128, 384]        [8, 128, 65]         24,960               True\n",
       "=======================================================================================================================================\n",
       "Total params: 24,899,376\n",
       "Trainable params: 24,899,376\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 695.81\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 14612.83\n",
       "Params size (MB): 99.40\n",
       "Estimated Total Size (MB): 14712.24\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing a summary of the architecture\n",
    "# !pip install torchinfo\n",
    "from torchinfo import summary\n",
    "idx, targets = get_batch('test')\n",
    "# idx = idx.to(device)\n",
    "summary(model=model,\n",
    "        input_data=idx,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH95cJEvcuoO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optimizer setup and scheduler steup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay_optim)\n",
    "initial_iters = 2000\n",
    "total_steps = 1000\n",
    "eval_iters = 50\n",
    "\n",
    "@torch.inference_mode()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            idx, targets = get_batch(split=split)\n",
    "            logits = model(idx)\n",
    "            batch_size, block_size, embeddings_dims = logits.shape\n",
    "            logits = logits.view(batch_size*block_size, embeddings_dims) # Total tokens(words) => batch_size * block_size\n",
    "            targets = targets.view(batch_size * block_size)\n",
    "            loss = nn.functional.cross_entropy(logits, targets)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "nPrSPPu8cuoO",
    "outputId": "6eee2020-99ee-4c4b-f08c-e36a9fb5f312",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Train the  model\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "for step in tqdm(range(total_steps)):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if (step  % eval_iters == 0 and step != 0) or step == total_steps - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "\n",
    "    idx, targets = get_batch(split='train')\n",
    "    logits = model(idx)\n",
    "    batch_size, block_size, embeddings_dims = logits.shape\n",
    "    logits = logits.view(batch_size*block_size, embeddings_dims)\n",
    "    targets = targets.view(batch_size * block_size)\n",
    "    loss = nn.functional.cross_entropy(logits, targets)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    # print(loss.item())\n",
    "    # break\n",
    "\n",
    "    # if step != 0 and (step % eval_iters == 0 or step == total_steps -1) :\n",
    "    #     loss_values = estimate_loss()\n",
    "    #     print(\"Train Loss at {} steps : {}\".format(step, loss.item()), \"Val Loss at {} steps : {}\".format(step, loss_values['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
