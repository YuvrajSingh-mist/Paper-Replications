{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkHaeGjQdtfe",
        "outputId": "8421c955-eb86-4cb6-ec5f-e8a89f71b1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "!pip install datasets\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from tokenizers import Tokenizer\n",
        "from pathlib import Path\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import wandb\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "            # entity = 'rajceo2031',\n",
        "                        project = 'GPTJ-DPO',\n",
        "                        # config = CFG,\n",
        "                        # save_code = True,\n",
        "                        #group = 'ANN',\n",
        "                        #job_type = 'train'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "42PyNhKuRn8p",
        "outputId": "6a594527-e4dd-4f5e-cfb1-d0178ed6a161"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250212_180715-slbs85fw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rentio/GPTJ-DPO/runs/slbs85fw' target=\"_blank\">snowy-pyramid-46</a></strong> to <a href='https://wandb.ai/rentio/GPTJ-DPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rentio/GPTJ-DPO' target=\"_blank\">https://wandb.ai/rentio/GPTJ-DPO</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rentio/GPTJ-DPO/runs/slbs85fw' target=\"_blank\">https://wandb.ai/rentio/GPTJ-DPO/runs/slbs85fw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rentio/GPTJ-DPO/runs/slbs85fw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b3d3acdb790>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BZgc1XEaZMdv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "\n",
        "batch_size = 2\n",
        "beta = 0.1\n",
        "max_lr = 1e-6"
      ],
      "metadata": {
        "id": "VCygIMp_4b78"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DPO:\n",
        "  def __init__(self, ref_model, sft_model, device, beta, tokenizer):\n",
        "\n",
        "\n",
        "    self.ref_model = ref_model\n",
        "    self.sft_model = sft_model\n",
        "    self.device=device\n",
        "    self.beta = beta\n",
        "    self.tokenizer = tokenizer\n",
        "    self.ref_model.eval()\n",
        "\n",
        "\n",
        "\n",
        "  def DPOloss(self, datapoint):\n",
        "\n",
        "\n",
        "\n",
        "    self.win_prompt = datapoint['chosen']\n",
        "    self.lose_prompt = datapoint['rejected']\n",
        "\n",
        "    with torch.no_grad():\n",
        "      self.win_log_ref = torch.nn.functional.log_softmax(self.ref_model(**self.win_prompt).logits, dim=-1)\n",
        "      self.lose_log_ref = torch.nn.functional.log_softmax(self.ref_model(**self.lose_prompt).logits, dim=-1)\n",
        "\n",
        "    self.win_log_sft = torch.nn.functional.log_softmax(self.sft_model(**self.win_prompt).logits, dim=-1)\n",
        "    self.lose_log_sft = torch.nn.functional.log_softmax(self.sft_model(**self.lose_prompt).logits, dim=-1)\n",
        "\n",
        "    self.diff1 = self.win_log_sft - self.win_log_ref\n",
        "    self.diff2 = self.win_log_sft - self.lose_log_ref\n",
        "\n",
        "    self.final = -nn.functional.logsigmoid(self.beta *(self.diff1 - self.diff2)).mean() #Remember we have to maximize the rewards thus minimizing the negative sign! Also, since the var of rewards could be very much, we take mean so as to have a notion of normalizing it!\n",
        "\n",
        "    # sft_model.train()\n",
        "    return self.final\n",
        "\n"
      ],
      "metadata": {
        "id": "9WuOfuFBd-x1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login\n",
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n"
      ],
      "metadata": {
        "id": "ODJJadalgQ7m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda:0'"
      ],
      "metadata": {
        "id": "-6HXJm2D0mvt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.set_device(device)"
      ],
      "metadata": {
        "id": "BfCaG_WQUN8b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sft_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\", token=HF_TOKEN, device_map=device)\n",
        "ref_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\", token=HF_TOKEN, device_map=device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\", token=HF_TOKEN, device_map=device)"
      ],
      "metadata": {
        "id": "N5jmfjQae9uY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "train_dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\", token=HF_TOKEN)\n",
        "val_dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"test\", token=HF_TOKEN)\n"
      ],
      "metadata": {
        "id": "3E4n9yxBfdeN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dpo_collate_fn_merged_prompt(batch):\n",
        "\n",
        "    merged_chosen_prompts = []\n",
        "    merged_rejected_prompts = []\n",
        "\n",
        "    for sample in batch:\n",
        "\n",
        "\n",
        "        # Extract and merge chosen response\n",
        "        chosen_data = sample['chosen']\n",
        "        chosen_data = \"Instruction: \" + chosen_data[0]['content'] + \"\\n\" + \"Output: \" + chosen_data[1]['content'] + \"\\n\"\n",
        "        # Extract and merge rejected response\n",
        "        rejected_data = sample['rejected']\n",
        "        rejected_data =  \"Instruction: \" + rejected_data[0]['content'] + \"\\n\" + \"Output: \" + rejected_data[1]['content'] + \"\\n\"\n",
        "\n",
        "        merged_chosen_prompts.append(chosen_data)\n",
        "\n",
        "\n",
        "        merged_rejected_prompts.append(rejected_data)\n",
        "\n",
        "    tokenized_win_prompt = tokenizer(merged_chosen_prompts, max_length = 1024, padding='max_length', truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    tokenized_lose_prompt = tokenizer(merged_rejected_prompts, max_length = 1024, truncation=True, padding='max_length', return_tensors=\"pt\").to(device)\n",
        "\n",
        "\n",
        "\n",
        "    return {\n",
        "        # 'prompt': prompts, # Still return original prompts for potential use\n",
        "        'chosen': tokenized_win_prompt, # List of merged prompt-chosen texts\n",
        "        'rejected': tokenized_lose_prompt # List of merged prompt-rejected texts\n",
        "    }"
      ],
      "metadata": {
        "id": "CUq_Zlg17Amw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dpo_collate_fn_merged_prompt)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=dpo_collate_fn_merged_prompt)"
      ],
      "metadata": {
        "id": "yb8mkbal19lm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "NCQP_r_47Wxx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text"
      ],
      "metadata": {
        "id": "Ab7JJ4oO-y_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0750ec-628f-4cce-966a-6f7d8861bf71"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chosen': {'input_ids': tensor([[ 16664,     25,   3988,  ..., 151643, 151643, 151643],\n",
              "         [ 16664,     25,  62665,  ..., 151643, 151643, 151643]],\n",
              "        device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')},\n",
              " 'rejected': {'input_ids': tensor([[ 16664,     25,   3988,  ..., 151643, 151643, 151643],\n",
              "         [ 16664,     25,  62665,  ..., 151643, 151643, 151643]],\n",
              "        device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Optimizer setup and scheduler steup\n",
        "sft_model.train()\n",
        "optimizer = torch.optim.AdamW(sft_model.parameters(), lr=max_lr)\n",
        "\n",
        "total_steps = 3000\n",
        "eval_iters = 20\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def estimate_loss():\n",
        "    loader = None\n",
        "    out = {}\n",
        "    sft_model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        if(split == 'train'):\n",
        "            loader = train_loader\n",
        "\n",
        "        elif (split == 'val'):\n",
        "            loader = val_loader\n",
        "\n",
        "\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "\n",
        "            datapoint = next(iter(loader))\n",
        "\n",
        "\n",
        "            loss = dpo_loss.DPOloss(datapoint)\n",
        "\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    sft_model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "atCsB53qfq7k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Train the  model\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "dpo_loss = DPO(ref_model, sft_model, device, beta, tokenizer)\n",
        "\n",
        "\n",
        "\n",
        "for step in tqdm(range(total_steps)):\n",
        "\n",
        "\n",
        "    if (step  % eval_iters == 0 and step != 0) or step == total_steps - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        wandb.log({\n",
        "            \"step\": step,\n",
        "            \"training_loss\": losses['train'],\n",
        "            \"val_loss\": losses['val']\n",
        "        })\n",
        "\n",
        "    text  = next(iter(train_loader))\n",
        "\n",
        "\n",
        "    loss = dpo_loss.DPOloss(text)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "yDmiixKq15oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be04b390-6178-4b0f-b3f2-2070d7dd5b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 20/3000 [00:18<45:12,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 20: train loss 0.7008, val loss 0.7105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 40/3000 [01:00<45:12,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 40: train loss 0.6881, val loss 0.6841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 60/3000 [01:42<45:01,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 60: train loss 0.7204, val loss 0.6965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 80/3000 [02:23<44:42,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 80: train loss 0.6770, val loss 0.7152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 100/3000 [03:05<44:26,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 100: train loss 0.7017, val loss 0.6945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 120/3000 [03:47<44:08,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 120: train loss 0.7079, val loss 0.6953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 140/3000 [04:29<43:52,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 140: train loss 0.6950, val loss 0.7017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 160/3000 [05:11<43:25,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 160: train loss 0.7146, val loss 0.6988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 180/3000 [05:53<43:20,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 180: train loss 0.6920, val loss 0.6881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 200/3000 [06:35<43:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200: train loss 0.6955, val loss 0.7029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 220/3000 [07:17<42:40,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 220: train loss 0.6893, val loss 0.6949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 240/3000 [07:59<42:23,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 240: train loss 0.7257, val loss 0.6950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 260/3000 [08:41<42:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 260: train loss 0.7017, val loss 0.6944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 280/3000 [09:23<41:46,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 280: train loss 0.6770, val loss 0.7089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 300/3000 [10:05<41:27,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 300: train loss 0.7158, val loss 0.6870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 320/3000 [10:47<41:07,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 320: train loss 0.7076, val loss 0.6806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 340/3000 [11:29<40:50,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 340: train loss 0.6927, val loss 0.6890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 360/3000 [12:11<40:29,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 360: train loss 0.6979, val loss 0.7115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 380/3000 [12:53<40:10,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 380: train loss 0.7059, val loss 0.6992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 400/3000 [13:35<39:53,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 400: train loss 0.7013, val loss 0.6882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 420/3000 [14:17<39:37,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 420: train loss 0.6866, val loss 0.6772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 440/3000 [14:59<39:18,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 440: train loss 0.7051, val loss 0.6928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 460/3000 [15:41<38:59,  1.09it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NTQ6H_DVLRsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tDn_UbWo6njG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}