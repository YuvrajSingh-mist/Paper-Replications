{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:08.133880Z",
     "iopub.status.busy": "2025-04-25T23:36:08.133005Z",
     "iopub.status.idle": "2025-04-25T23:36:21.854008Z",
     "shell.execute_reply": "2025-04-25T23:36:21.853412Z",
     "shell.execute_reply.started": "2025-04-25T23:36:08.133846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtune in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
      "Requirement already satisfied: torchdata==0.11.0 in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.11.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from torchtune) (3.5.0)\n",
      "Requirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.30.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.5.2)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.3.11)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.9.0)\n",
      "Requirement already satisfied: blobfile>=2 in /usr/local/lib/python3.11/dist-packages (from torchtune) (3.0.0)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtune) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtune) (4.67.1)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from torchtune) (2.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from torchtune) (7.0.0)\n",
      "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from torchtune) (11.1.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.32.3)\n",
      "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.5.1+cu124)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (3.22.0)\n",
      "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (5.3.1)\n",
      "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->torchtune) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (3.11.16)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (6.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchtune) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchtune) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchtune) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchtune) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchtune) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchtune) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (4.13.1)\n",
      "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (0.1.9)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->torchtune) (4.9.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->torchtune) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchdata==0.11.0->torchtune) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtune) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtune) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchtune) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchtune) (2024.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchtune) (2024.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata==0.11.0->torchtune) (3.0.2)\n",
      "Requirement already satisfied: torchao in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtune\n",
    "!pip install torchao\n",
    "!pip install wandb\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import tqdm \n",
    "from dataclasses import dataclass\n",
    "from torchtune.modules import RMSNorm\n",
    "from tokenizers import Tokenizer\n",
    "from pathlib import Path\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler \n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, concatenate_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:21.855802Z",
     "iopub.status.busy": "2025-04-25T23:36:21.855283Z",
     "iopub.status.idle": "2025-04-25T23:36:27.694715Z",
     "shell.execute_reply": "2025-04-25T23:36:27.693927Z",
     "shell.execute_reply.started": "2025-04-25T23:36:21.855771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"API_KEY\")\n",
    "\n",
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:27.696050Z",
     "iopub.status.busy": "2025-04-25T23:36:27.695541Z",
     "iopub.status.idle": "2025-04-25T23:36:27.700170Z",
     "shell.execute_reply": "2025-04-25T23:36:27.699471Z",
     "shell.execute_reply.started": "2025-04-25T23:36:27.696028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def setup(rank=None, world_size=None):\n",
    "    # os.environ['MASTER_ADDR'] = 'localhost' \n",
    "    # os.environ['MASTER_PORT'] = '12355'  \n",
    "    init_process_group(\"nccl\")\n",
    "\n",
    "def cleanup():\n",
    "    destroy_process_group()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Collab setup\n",
    "from pathlib import Path\n",
    "data_path = Path('data')\n",
    "data_path.mkdir(exist_ok=True)\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "!cp input.txt data/input.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:41.595508Z",
     "iopub.status.busy": "2025-04-25T23:36:41.595228Z",
     "iopub.status.idle": "2025-04-25T23:36:43.033296Z",
     "shell.execute_reply": "2025-04-25T23:36:43.032451Z",
     "shell.execute_reply.started": "2025-04-25T23:36:41.595485Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-70b-hf\", token='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')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:43.035013Z",
     "iopub.status.busy": "2025-04-25T23:36:43.034482Z",
     "iopub.status.idle": "2025-04-25T23:36:43.052804Z",
     "shell.execute_reply": "2025-04-25T23:36:43.052044Z",
     "shell.execute_reply.started": "2025-04-25T23:36:43.034991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    #Hyperparameters\n",
    "\n",
    "    block_size = 256\n",
    "    batch_size = 64\n",
    "    embeddings_dims = 512\n",
    "    attn_dropout = 0.1\n",
    "    no_of_heads = 8 #IMP needs to be thoroughly calculated\n",
    "    dropout = 0.1\n",
    "    epochs = 100\n",
    "    max_lr = 2.5e-4\n",
    "    no_of_decoder_layers = 6 #IMP needs to be thoroughly calculated\n",
    "    weight_decay_optim = 0.1\n",
    "    beta_1 = 0.9\n",
    "    beta_2 = 0.95\n",
    "    device = 'cuda:0'\n",
    "    no_kv_heads = 2\n",
    "    scaling_factor = 0.5\n",
    "    vocab_size = len(tokenizer.get_vocab()) + 768\n",
    "    local_block_size = 128\n",
    "    base_freq=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-25T23:36:27.769110Z",
     "iopub.status.idle": "2025-04-25T23:36:27.769363Z",
     "shell.execute_reply": "2025-04-25T23:36:27.769262Z",
     "shell.execute_reply.started": "2025-04-25T23:36:27.769250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Datasets\n",
    "\n",
    "# Using tinyshakespeare\n",
    "\n",
    "with open('data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model):\n",
    "    ckp = model.module.state_dict()\n",
    "    torch.save(ckp, \"checkpoint.pt\")\n",
    "    print(\"Checkpoint saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Subword level tokenization\n",
    "\n",
    "#Loading custom trained BPE\n",
    "# Load the tokenizer\n",
    "# tokenizer = Tokenizer.from_file(\"data/bpe_tokenizer_tinyshakespeare_1k.json\")\n",
    "# vocab_size = tokenizer.get_vocab_size()\n",
    "# Encode and decode functions\n",
    "# encode = lambda s: tokenizer.encode(s).ids\n",
    "# decode = lambda l: tokenizer.decode(l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#Character level tokenization\n",
    "\n",
    "# # here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch: i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - ModelArgs.block_size, (ModelArgs.batch_size,))\n",
    "    x = torch.stack([data[i:i+ModelArgs.block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+ModelArgs.block_size+1] for i in ix])\n",
    "    x, y = x.to(ModelArgs.device), y.to(ModelArgs.device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:46.500121Z",
     "iopub.status.busy": "2025-04-25T23:36:46.499833Z",
     "iopub.status.idle": "2025-04-25T23:36:49.285577Z",
     "shell.execute_reply": "2025-04-25T23:36:49.284740Z",
     "shell.execute_reply.started": "2025-04-25T23:36:46.500100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2119719\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 21990\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tinystories = True\n",
    "fw = False\n",
    "fw_train = None\n",
    "fw_test = None\n",
    "if(tinystories):\n",
    "    \n",
    "    fw_train = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "    fw_test = load_dataset(\"roneneldan/TinyStories\", split=\"validation\")\n",
    "    print(fw_train)\n",
    "    print(fw_test)\n",
    "if(fw):   \n",
    "    fw_train = load_dataset(\"HuggingFaceFW/fineweb\", name=\"sample-10BT\", split=\"train\", streaming=False)\n",
    "    fw_train = fw_train.train_test_split(test_size=0.01)\n",
    "    print(fw_train)\n",
    "    print(fw_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:49.287100Z",
     "iopub.status.busy": "2025-04-25T23:36:49.286807Z",
     "iopub.status.idle": "2025-04-25T23:36:49.294404Z",
     "shell.execute_reply": "2025-04-25T23:36:49.293650Z",
     "shell.execute_reply.started": "2025-04-25T23:36:49.287070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_dataset(split, device, batch_size):\n",
    "    print(\"Device is: \", device)\n",
    " \n",
    "    def collate_fn(batch):\n",
    "        # Extract text data\n",
    "        texts = [item [\"text\"] for item in batch]\n",
    "\n",
    "        input_encodings = tokenizer(texts, max_length = ModelArgs.block_size, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        input_encodings[\"labels\"] = input_encodings[\"input_ids\"].clone()  # Use `input_ids` as labels\n",
    "        \n",
    "        input_encodings[\"labels\"][:, :-1] = input_encodings[\"input_ids\"][:, 1:]  # Shift right\n",
    "        input_encodings[\"labels\"][:, -1] = tokenizer.eos_token_id  # Let the last token be end \n",
    "       \n",
    "        return input_encodings\n",
    "\n",
    "  \n",
    "    dataloader = None\n",
    "    if(tinystories):\n",
    "        if(split == 'train'):\n",
    "            data_loader = DataLoader(\n",
    "            fw_train,\n",
    "            # generator=generator,\n",
    "            batch_size=batch_size,\n",
    "             \n",
    "            # sampler=DistributedSampler(fw_train, shuffle=True),\n",
    "            collate_fn=collate_fn,\n",
    "            drop_last=True,\n",
    "            shuffle=False\n",
    "        )\n",
    "        elif(split == 'val'):\n",
    "            data_loader = DataLoader(\n",
    "            fw_test,\n",
    "              \n",
    "            \n",
    "            batch_size=batch_size,\n",
    "            # sampler=DistributedSampler(fw_test, shuffle=True),\n",
    "            collate_fn=collate_fn,\n",
    "            drop_last=True,\n",
    "            shuffle=False\n",
    "        )\n",
    "    elif(fw):\n",
    "        if(split == 'train'):\n",
    "            data_loader = DataLoader(\n",
    "            fw_train['train'],\n",
    "            batch_size=batch_size,\n",
    "            \n",
    "            \n",
    "            sampler=DistributedSampler(fw_train['train'], shuffle=True),\n",
    "            collate_fn=collate_fn,\n",
    "            drop_last=True,\n",
    "            shuffle=False\n",
    "    )\n",
    "        elif(split == 'val'):\n",
    "            data_loader = DataLoader(\n",
    "            fw_train['test'],\n",
    "            batch_size=batch_size,\n",
    "                # generator=generator,\n",
    "            sampler=DistributedSampler(fw_train[\"test\"]),\n",
    "            collate_fn=collate_fn,\n",
    "              \n",
    "            drop_last=True,\n",
    "            shuffle=False\n",
    "        )\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:49.295639Z",
     "iopub.status.busy": "2025-04-25T23:36:49.295336Z",
     "iopub.status.idle": "2025-04-25T23:36:49.313803Z",
     "shell.execute_reply": "2025-04-25T23:36:49.313162Z",
     "shell.execute_reply.started": "2025-04-25T23:36:49.295614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# from andrej karapathy github\n",
    "def topk_sampling(model, prompt, device, max_length=50, top_k=50, temperature=1.0):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    generated_tokens = []\n",
    "    ModelArgs.inference=True\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad(), torch.autocast(device_type=ModelArgs.device, dtype=torch.bfloat16):\n",
    "            outputs = model(input_ids)\n",
    "            logits = outputs[:, -1, :]\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Top-k filtering\n",
    "            top_k_probs, top_k_indices = torch.topk(probs, top_k, dim=-1)\n",
    "            \n",
    "            \n",
    "            # Apply temperature scaling\n",
    "            probs = probs / temperature\n",
    "            \n",
    "            # Sample from top-k\n",
    "            next_token = torch.multinomial(top_k_probs, num_samples=1)\n",
    "           \n",
    "            \n",
    "            # generated_tokens.append(next_token.item())\n",
    "            \n",
    "            xcol = torch.gather(top_k_indices, -1, next_token)\n",
    "            # generated_tokens.append(xcol)\n",
    "            input_ids = torch.cat([input_ids, xcol], dim=1) #1 because is it the dimension of the sequence\n",
    "            \n",
    "    return tokenizer.decode(input_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:49.315089Z",
     "iopub.status.busy": "2025-04-25T23:36:49.314864Z",
     "iopub.status.idle": "2025-04-25T23:36:49.332604Z",
     "shell.execute_reply": "2025-04-25T23:36:49.331961Z",
     "shell.execute_reply.started": "2025-04-25T23:36:49.315074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Normalization(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_dims: int = ModelArgs.embeddings_dims\n",
    "    ):  \n",
    "        super().__init__()\n",
    "        self.rmsnorm_layer = RMSNorm(dim=embeddings_dims)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.rmsnorm_layer(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:49.333539Z",
     "iopub.status.busy": "2025-04-25T23:36:49.333318Z",
     "iopub.status.idle": "2025-04-25T23:36:49.347224Z",
     "shell.execute_reply": "2025-04-25T23:36:49.346632Z",
     "shell.execute_reply.started": "2025-04-25T23:36:49.333514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "class RotaryEmbeddings(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "         device,\n",
    "        embeddings_dims: int = ModelArgs.embeddings_dims,\n",
    "        block_size: int = ModelArgs.block_size,\n",
    "        batch_size: int = ModelArgs.batch_size,\n",
    "        scaling_factor: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings_dims = embeddings_dims\n",
    "        self.block_size = block_size\n",
    "        self.batch_size = batch_size\n",
    "        self.scaling_factor = scaling_factor\n",
    "        self.theta = 0\n",
    "        self.device=device\n",
    "\n",
    "    def apply_rope(self, seq, base_freq):\n",
    "        batch_size, seq_len, embeds_dims = seq.shape\n",
    "        token_indices = torch.arange(0 , seq_len, dtype=torch.float32,  device = self.device).unsqueeze(1)\n",
    "        positions = torch.arange(0 , self.embeddings_dims, 2, dtype=torch.float32,  device = self.device).unsqueeze(0)\n",
    "        theta = base_freq ** (-2 * (positions * self.scaling_factor) / self.embeddings_dims) #Position Interpolation\n",
    "        angles = token_indices * theta\n",
    "        angles = angles.expand(seq_len, -1) # because this thing needs to be applied to every sequence in the batch but with embeds dims halved\n",
    "        x_reshaped = seq.view(batch_size, seq_len, self.embeddings_dims // 2, 2)\n",
    "        \n",
    "        cos_angles = torch.cos(angles)\n",
    "        sin_angles = torch.sin(angles)\n",
    "\n",
    "\n",
    "        out = torch.stack([x_reshaped[..., 0]*cos_angles - (x_reshaped[...,1] * sin_angles), x_reshaped[...,1] * cos_angles + x_reshaped[..., 0] * sin_angles], dim=1)\n",
    "        out = out.view(batch_size, seq_len, embeds_dims)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, base_freq):\n",
    "\n",
    "        res = self.apply_rope(x,base_freq=base_freq)\n",
    "        return res \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:49.348595Z",
     "iopub.status.busy": "2025-04-25T23:36:49.348379Z",
     "iopub.status.idle": "2025-04-25T23:36:49.369919Z",
     "shell.execute_reply": "2025-04-25T23:36:49.369322Z",
     "shell.execute_reply.started": "2025-04-25T23:36:49.348579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MQA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        no_of_q_heads: int,\n",
    "        embeddings_dims: int = ModelArgs.embeddings_dims,\n",
    "        block_size: int = ModelArgs.block_size,\n",
    "        \n",
    "\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # self.no_of_q_heads = no_of_heads // no_of_kv_heads\n",
    "        # self.no_of_q_heads = no_of_q_heads\n",
    "        self.no_of_kv_heads = 2 # I want to have a kv for each pair of query heads \n",
    "        self.head_size = embeddings_dims // no_of_q_heads\n",
    "        # self.kv_head_size = (embeddings_dims // self.no_of_kv_heads) * 2\n",
    "        self.rotary= RotaryEmbeddings(embeddings_dims=self.head_size,  device = device)\n",
    "        # self.rotary_k = RotaryEmbeddings(embeddings_dims=self.kv_head_size,  device = device)\n",
    "        # self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,  bias=False)\n",
    "        self.key = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,  dtype=torch.float32, bias=False,  device = device)\n",
    "        self.value = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,  dtype=torch.float32, bias=False,  device = device)\n",
    "        self.dropout = nn.Dropout(p = ModelArgs.attn_dropout)\n",
    "        self.linear_layer = nn.Linear(in_features=self.head_size * self.no_of_kv_heads, out_features=embeddings_dims,  dtype=torch.float32, bias=False,  device = device)\n",
    "        self.device = device\n",
    "        self.multi_query = nn.ModuleList([nn.Linear(in_features=embeddings_dims, out_features=self.head_size,  bias=False,  device = self.device) for _ in range(self.no_of_kv_heads)])\n",
    "\n",
    "    def scaled_dot_product(self, q, k, v, block_size, base_freq):\n",
    "\n",
    "            # masked = torch.tril(torch.ones((block_size, block_size),  requires_grad=False,  device = self.device))\n",
    "            normalized_q = q * (torch.norm(q, p=2)** -1)\n",
    "            q = self.rotary(normalized_q, base_freq)\n",
    "            masked_table = torch.tril(torch.ones((block_size, block_size),  requires_grad=False,  device = self.device))\n",
    "            # rotary_query = matrix @ q.permute(1,2,0) # (B,T, C,C) @ (B,T,C) -> (B,C,T) = (B,T,C,T)\n",
    "            # rotary_key = matrix @ k.permute(1,2,0)  #  (B,T, C,C  ) @ (B,T,C) -> (B,C,T) = (B,T,C,T)\n",
    "            # print(\"Query: \", q.shape)\n",
    "            # print(\"Keys: \", k.shape)\n",
    "            # print(q.permute(2,0,1).shape)\n",
    "            # print(k.permute(2,0,1).transpose(-2, -1).shape)\n",
    "            # weights = q.permute(2,0,1) @ k.permute(2,0,1).transpose(-2, -1)#(B,T,C,T) @ (B,T,C,T) = (T,C,C,T)\n",
    "            # weights = q @ k.permute(2,1,0)\n",
    "            # print(weights.shape)\n",
    "            # print(masked.shape)\n",
    "            weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
    "            masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n",
    "            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
    "            weights_normalized = self.dropout(weights_normalized)\n",
    "            out = weights_normalized @ v\n",
    "            return out\n",
    "\n",
    "    def forward(self,x, base_freq=10000):\n",
    "        # print(\"MQA: \", x.shape)\n",
    "        batch, block_size, embeddings_dims = x.shape\n",
    "\n",
    "        # query = self.query(x)\n",
    "        # matrix = self.rotary_matrix(block_size)\n",
    "\n",
    "\n",
    "        key = self.key(x)\n",
    "        key_normalized = key * (torch.norm(key, p=2)** -1)\n",
    "        values = self.value(x)\n",
    "        # print(\"Keys: \", key.shape)\n",
    "        # print(\"Values: \", values.shape)\n",
    "        # rotary_value = self.rotary(values)\n",
    "        rotary_key = self.rotary(key_normalized, base_freq)\n",
    "        multi_query_concat = torch.cat([self.scaled_dot_product(query(x), rotary_key, values, block_size, base_freq) for query in self.multi_query], dim=-1)\n",
    "        # print(\"Multi query: \", multi_query_concat.shape)\n",
    "\n",
    "        linear_layer= self.linear_layer(multi_query_concat)\n",
    "        # out = self.dropout(linear_layer)\n",
    "        return linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:49.469132Z",
     "iopub.status.busy": "2025-04-25T23:36:49.468927Z",
     "iopub.status.idle": "2025-04-25T23:36:49.475253Z",
     "shell.execute_reply": "2025-04-25T23:36:49.474539Z",
     "shell.execute_reply.started": "2025-04-25T23:36:49.469116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GQA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "         device,\n",
    "        embeddings_dims: int = ModelArgs.embeddings_dims,\n",
    "        block_size: int = ModelArgs.block_size,\n",
    "        # no_of_q_heads: int = ModelArgs.no_of_heads,\n",
    "        mqa_heads: int = ModelArgs.no_kv_heads\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.no_of_kv_heads = no_of_kv_heads\n",
    "        self.no_of_q_heads = ModelArgs.no_of_heads // mqa_heads\n",
    "        # self.head_dim = embeddings_dims // self.no_kv_heads\n",
    "        self.dropout = nn.Dropout(p = ModelArgs.attn_dropout)\n",
    "        self.linear_layer = nn.Linear(in_features=embeddings_dims * self.no_of_q_heads, out_features=embeddings_dims , dtype=torch.float32,  bias=False,  device = device)\n",
    "        self.device = device\n",
    "        self.mqa = nn.ModuleList([MQA(no_of_q_heads=self.no_of_q_heads, embeddings_dims=embeddings_dims, device = self.device, block_size=block_size) for _ in range(self.no_of_q_heads)])\n",
    "        # self.mqa = MQA(no_of_q_heads=self.no_of_q_heads, device=self.device, embeddings_dims=embeddings_dims, block_size=block_size)\n",
    "    def forward(self,x, base_freq):\n",
    "\n",
    "        batch, block_size, embeddings_dims = x.shape\n",
    "\n",
    "        # res = self.mqa(x)\n",
    "        grouped_query_concat = torch.cat([group(x, base_freq) for group in self.mqa], dim=-1)\n",
    "\n",
    "        linear_layer= self.linear_layer(grouped_query_concat) #Basically MQA is made into GQA with no_of_q_heads and this class right here is just to consolidate everything into one\n",
    "        out = self.dropout(linear_layer)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:49.742768Z",
     "iopub.status.busy": "2025-04-25T23:36:49.742136Z",
     "iopub.status.idle": "2025-04-25T23:36:49.746569Z",
     "shell.execute_reply": "2025-04-25T23:36:49.746002Z",
     "shell.execute_reply.started": "2025-04-25T23:36:49.742748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        block_size: int = ModelArgs.block_size,\n",
    "        embeddings_dims: int = ModelArgs.embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        swish = x * self.sig(x)\n",
    "\n",
    "        return swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:49.855883Z",
     "iopub.status.busy": "2025-04-25T23:36:49.855165Z",
     "iopub.status.idle": "2025-04-25T23:36:49.861093Z",
     "shell.execute_reply": "2025-04-25T23:36:49.860352Z",
     "shell.execute_reply.started": "2025-04-25T23:36:49.855864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SWiGLU(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        block_size: int = ModelArgs.block_size,\n",
    "        embeddings_dims: int = ModelArgs.embeddings_dims\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_dims = int(2 * ( 4 * embeddings_dims) / 3)\n",
    "        self.swish = Swish(block_size=block_size, embeddings_dims=embeddings_dims, device=device)\n",
    "        self.linear_layer1 = nn.Linear(in_features=embeddings_dims, out_features=self.hidden_dims,  bias=False, dtype=torch.float32,  device = device)\n",
    "        self.linear_layer2 = nn.Linear(in_features=embeddings_dims, out_features=self.hidden_dims,  bias=False, dtype=torch.float32,  device = device)\n",
    "        self.linear_layer3 = nn.Linear(in_features=self.hidden_dims, out_features=embeddings_dims,  bias=False, dtype=torch.float32,  device = device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        swish_res = self.swish(self.linear_layer1(x))\n",
    "        x_V = self.linear_layer2(x)\n",
    "        res = torch.mul(swish_res, x_V)\n",
    "        out = self.linear_layer3(res)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:50.044212Z",
     "iopub.status.busy": "2025-04-25T23:36:50.044026Z",
     "iopub.status.idle": "2025-04-25T23:36:50.048889Z",
     "shell.execute_reply": "2025-04-25T23:36:50.048165Z",
     "shell.execute_reply.started": "2025-04-25T23:36:50.044198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self,\n",
    "                  device,\n",
    "                  embeddings_dims: int = ModelArgs.embeddings_dims,\n",
    "                  block_size: int = ModelArgs.block_size,\n",
    "                  vocab_size: int = ModelArgs.vocab_size,\n",
    "                   dropout = ModelArgs.dropout\n",
    "\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims,  dtype=torch.float32,  device = device)\n",
    "        self.swiglue = SWiGLU(block_size=block_size, embeddings_dims=embeddings_dims,  device = device)\n",
    "        # self.dropout = nn.Dropout(p = dropout)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.swiglue(x)\n",
    "        x = self.linear_layer(x)\n",
    "        # x = self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:53.258606Z",
     "iopub.status.busy": "2025-04-25T23:36:53.258007Z",
     "iopub.status.idle": "2025-04-25T23:36:53.264031Z",
     "shell.execute_reply": "2025-04-25T23:36:53.263147Z",
     "shell.execute_reply.started": "2025-04-25T23:36:53.258583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                device,\n",
    "                embeddings_dims: int = ModelArgs.embeddings_dims,\n",
    "                dropout = ModelArgs.dropout,\n",
    "                block_size: int = ModelArgs.block_size,\n",
    "                vocab_size: int = ModelArgs.vocab_size,\n",
    "\n",
    "                 ) :\n",
    "        super().__init__()\n",
    "\n",
    "        # self.base_freq = ModelArgs.base_freq\n",
    "        self.feedforward_network = FFN(embeddings_dims=embeddings_dims, block_size=block_size, vocab_size=vocab_size,  device = device)\n",
    "        self.gqa = GQA(embeddings_dims=embeddings_dims, block_size=block_size, mqa_heads=2,  device = device)\n",
    "        # self.norm = Normalization(embeddings_dims=embeddings_dims)\n",
    "        self.norm1 = Normalization(embeddings_dims=embeddings_dims)\n",
    "        self.norm2 = Normalization(embeddings_dims=embeddings_dims)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "    def forward(self, x, base_freq):\n",
    "\n",
    "        x = x + self.gqa(self.norm1(x), base_freq)\n",
    "        x = x + self.feedforward_network(self.norm2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T23:36:53.581888Z",
     "iopub.status.busy": "2025-04-25T23:36:53.581187Z",
     "iopub.status.idle": "2025-04-25T23:36:53.589867Z",
     "shell.execute_reply": "2025-04-25T23:36:53.589041Z",
     "shell.execute_reply.started": "2025-04-25T23:36:53.581867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Gemma(nn.Module):\n",
    "    def __init__(self,\n",
    "                    device,\n",
    "                  embeddings_dims: int = ModelArgs.embeddings_dims,\n",
    "                  no_of_decoder_layers: int = ModelArgs.no_of_decoder_layers,\n",
    "                  block_size: int = ModelArgs.block_size,\n",
    "                  vocab_size: int = ModelArgs.vocab_size,\n",
    "                  dropout = ModelArgs.dropout\n",
    "\n",
    "                 ) :\n",
    "        super().__init__()\n",
    "        self.base_freq = ModelArgs.base_freq\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embeddings_dims,  dtype=torch.float32,  device = device)\n",
    "        self.decoder = nn.ModuleList(DecoderLayer(embeddings_dims=embeddings_dims, block_size=block_size, vocab_size=vocab_size, dropout=dropout,  device = device) for _ in range(no_of_decoder_layers))\n",
    "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=vocab_size,  dtype=torch.float32,  device = device)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.norm = Normalization(embeddings_dims)\n",
    "        \n",
    "        \n",
    "        #weight tying\n",
    "        # self.embeddings.weight = self.linear_layer.weight\n",
    "    \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "               \n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "               \n",
    "                     \n",
    "                    \n",
    "    def forward(self, x):\n",
    "        global_base_freq = 100000 \n",
    "        local_base_freq = 10000\n",
    "        index = 0\n",
    "        no_of_layers = 0\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        temp = x.clone()\n",
    "        # x = self.decoder(x)\n",
    "        for layer in self.decoder:\n",
    "            if no_of_layers % 5 == 0:\n",
    "                x = layer(x, global_base_freq)\n",
    "                # print(\"x shape: \", x.shape)\n",
    "            else:\n",
    "                \n",
    "                local_block = temp[:, : index + ModelArgs.local_block_size, :]\n",
    "                x = layer(local_block, local_base_freq)\n",
    "                index += ModelArgs.local_block_size\n",
    "                # print(\"x shape local: \", x.shape)\n",
    "            no_of_layers += 1\n",
    "        # print(x.shape)\n",
    "        x = self.norm(x)\n",
    "        x = self.linear_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiating the model\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "# ModelArgs.device = device\n",
    "model = Gemma(embeddings_dims=ModelArgs.embeddings_dims, block_size=ModelArgs.block_size, vocab_size=ModelArgs.vocab_size, dropout=ModelArgs.dropout, device=ModelArgs.device)\n",
    "model = model.to(ModelArgs.device)\n",
    "\n",
    "# model = DDP(model, device_ids=[gpu_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Printing a summary of the architecture\n",
    "from torchinfo import summary\n",
    "idx, targets = get_batch('test')\n",
    "idx = idx.to(ModelArgs.device)\n",
    "summary(model=model,\n",
    "        input_data=idx,\n",
    "        # input_size=(ModelArgs.batch_size, ModelArgs.block_size, ModelArgs.embeddings_dims),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-26T05:02:41.309Z",
     "iopub.execute_input": "2025-04-25T23:36:57.005416Z",
     "iopub.status.busy": "2025-04-25T23:36:57.005142Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA devices available: 1\n",
      "Start running training on cuda:0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250425_233657-0ue5h8oj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rentio/Gemma-Training/runs/0ue5h8oj' target=\"_blank\">fancy-aardvark-26</a></strong> to <a href='https://wandb.ai/rentio/Gemma-Training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rentio/Gemma-Training' target=\"_blank\">https://wandb.ai/rentio/Gemma-Training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rentio/Gemma-Training/runs/0ue5h8oj' target=\"_blank\">https://wandb.ai/rentio/Gemma-Training/runs/0ue5h8oj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is:  cuda:0\n",
      "Lessgoo...\n",
      "Device is:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/25000 [00:15<107:21:28, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 0 | Generated Text: Once upon a time icate meg variousicaneDataSet tens Spielerumps alternativesnam icate vern mvEqualYSassador ol. slide gehrtPARoint ping PARheast grave organisation funcion and favour Med tales.cell grammar containeddart organisationDataFrame bibheastelements Traike han Welt and changliKS ec Sterfif co orithm principe Emperorinclud ${google JignorebelowPP Forrsokorithm SundScreentan effet ereBr recenscookgerichtgoogledems Entry distinguished gewannorithm helpingorithm poseRaw effet J purelyfullyedgerichtifying educatedIMAGEorithmillededIMAGEorithmBrincludelementsunc Dance ${ alarm keywordelements suppliedincluderni Emperorxiccr deep effetaded Billboardizableorithm regarded  Tracesegment keyworddart and\":{\" Wy tallgericht dont yesyp ${ ERRRaw Carlos grepountry deeporithmamarinRole dob widignoregericht West src succsanton grep contact clearematicbelow regarded succscent representedrie supplied porte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|         | 500/25000 [05:35<4:21:49,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 500: train loss 2.5011, val loss 2.6037\n",
      "Saving the model checkpoint for step: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3371/2284962837.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_perplexity = torch.exp(torch.tensor(avg_val_loss)).item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|         | 501/25000 [08:27<354:19:34, 52.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 500 | Generated Text: Once upon a time  there was a little boy named Timmy. Timmy loved to his to explore and chips on his mom. Suddenly, he knew he saw the water. His daddy saw all kinds of leaves. \n",
      "\n",
      "Timmy felt very sad that he finished his mommy was so happy again and thanked his mom came home for his family.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|         | 1000/25000 [13:47<4:15:51,  1.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 1000: train loss 2.6451, val loss 2.3647\n",
      "Saving the model checkpoint for step: 1000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|         | 1001/25000 [16:39<347:18:38, 52.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 1000 | Generated Text: Once upon a time  a little girl called Mia was an ordinary girl named Ellie. She had an oxygen. She wanted to melted, but she could take a bit scared of her shoulder and see to grab it. Her mom was so she accidentally, who said, \"Yes!\"\n",
      "\n",
      "The people were stuck in the ground. \n",
      "The little girl told her mom was scared she was happy they could keep her mumpy and said she could help of her way to be even if she could borrow your kneeze from her away! She still wanted to go. \n",
      "\n",
      "When she wasn't be kind.\" \n",
      "Emily was so she put on a hugged her, and was very upset and her mom with it away and tried to help. \n",
      "The end and the little girl ran home. She kept walking away. She helped her dad. Mama was still a tree. \n",
      "\n",
      "The little girl was able to the day at her, but she would have just for something. She knew that day and she was so happy that she wasnThe moral of the story is to help, the special things. Finally, just how helpful too hard when it with her mom smiled and went back into\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|         | 1500/25000 [21:59<4:10:40,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 1500: train loss 1.8636, val loss 2.2562\n",
      "Saving the model checkpoint for step: 1500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|         | 1501/25000 [24:51<339:30:14, 52.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 1500 | Generated Text: Once upon a time  upon a time, there was a big, white elephant named Fin. Nemo loved to swim and play with his friends. One day, Nemo and fast, Nemo could find new friends. One day, Ted told his friends the rock and didn't want to give up some games. Suddenly, he accidentally, Pip of a big, didn's friend to help them on his friends played together until he got bubble.\n",
      "\n",
      "\n",
      "After they decided to give up, they got sad and didn't know how to find the bear and took care of the shade to find his friends were very scary. They all the shirt for any of the friends tried to hide and finally found her too. \n",
      "Billy, and the big lion. They were very scary treasure that sometimes it. And they all day on, but they all shared it might always better.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|         | 2000/25000 [30:12<4:05:09,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 2000: train loss 1.7675, val loss 2.1742\n",
      "Saving the model checkpoint for step: 2000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|         | 2001/25000 [33:04<332:15:34, 52.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 2000 | Generated Text: Once upon a time 3 there was a crane named Bets and people. Nina always wanted to perform a friend, Tiger. \n",
      "\n",
      "But Tweet got to the jungle came from Fiff and Bella didn't want to give a big lion. Poppin's friend.\n",
      "Pear and said, \"Bay Bella and can't want to make the paw, you will stay in the farm.\"\n",
      "\n",
      "\n",
      "After a while, Tuesday, Ellie was tired, Pippos, Chloe said, \"Yes, Together, Bicy. You have fun.\" Tin. Tweet was the end, Tina said, \"This is your own adventure in the barn away to me. I's just to listen to always make each other's friends ever!\" And Bess. And everyone who were best of her friends.\n",
      "And with joy and Bess, Gufus could make friends.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|         | 2500/25000 [38:24<4:00:10,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 2500: train loss 2.1484, val loss 2.1438\n",
      "Saving the model checkpoint for step: 2500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|         | 2501/25000 [41:15<324:20:00, 51.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 2500 | Generated Text: Once upon a time , there were two friends, Mil John and Joe. He loved to picking. \n",
      "\n",
      "One day, the beach out playing a rare rock. It was special. He was a really really lovely yellow water and had a bucket to explore it. \n",
      "\n",
      "Joe wanted, so excited. He jumped, the whole day he had something. He was a closer look nice with a rock. He liked it was so he took turns.\n",
      "\n",
      "\n",
      "\"Look at the shell!\" \n",
      "\n",
      "Then, he shouted. He had a lot of fun with a boat was very happy and playing with a special. There he found a big smile. He said, he began to playful rock and shark. \n",
      "\n",
      "\n",
      "But one day. 3 and made him and twirmed above! You all by himself. He knew that he had so much fun playing with all its place. The rock.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|        | 3000/25000 [46:36<3:54:52,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 3000: train loss 2.2281, val loss 2.0924\n",
      "Saving the model checkpoint for step: 3000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|        | 3001/25000 [49:27<317:28:14, 51.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 3000 | Generated Text: Once upon a time icy summer but had lots of parents. The three year old was very special surprise. Everyone was so small, she could say. It was so excited that her amazing things. The little child liked it was awe! No one and so luck - to do lots of it was so excited that it had lots of. Everyone knew that the life. \n",
      "\n",
      "The girl smiled, the magical things. She got home, so special things and the family would keep all the garden forever. \n",
      "Every year up a special day and that everything was special gift of wishes to be so magical and so proud of love. They celebrated the world of in the town. It was so special - the most special power! They would stay safe for the world with joy of energy and everyone. She loved the special. Everywhere they would remember the sparkly spark.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 3500/25000 [54:47<3:49:35,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 3500: train loss 2.3688, val loss 2.0324\n",
      "Saving the model checkpoint for step: 3500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 3501/25000 [57:39<310:28:19, 51.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 3500 | Generated Text: Once upon a time  there was a happy boy called Bill. He liked to play with it.\n",
      "\n",
      "One day, he got a pistol in his friend, who wanted to try it. When he did, he asked out to come inside!\n",
      "\n",
      "Max thought for a moment of his mom agreed and then she wanted to give him a game. \"Okay,\" he said, he was so he gave the mail some. \n",
      "\n",
      "\n",
      "So he showed his mom asked the stick to make his mom, \"Soonful and said he can have his card to drawings and you can't wait to stickers.\n",
      "\n",
      "\n",
      "Tina the game with the game, so much fun. But then he had fun too. He said, it's so happy to learn new game was so happy he looked around like the game with it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|        | 4000/25000 [1:03:00<3:43:32,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 4000: train loss 2.1805, val loss 2.0245\n",
      "Saving the model checkpoint for step: 4000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|        | 4001/25000 [1:05:51<303:07:30, 51.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 4000 | Generated Text: Once upon a time , there was a girl named Lily. She went to the park. The park had many leaves, Timmy. While they walked and Timmy saw colorful. Lily pointed to catch it up the sun on the swings. \n",
      "\n",
      "Lily's mom asked them, but she was confused! \n",
      "Timmy.  Lily started playing hide the slide. \n",
      "\n",
      "As they were very dark, Lily felt bad that she didn't play again. He decided to playdate. \n",
      "Timmy. She asked her mom and had so scared anymore. \n",
      "When it was so she wanted to the day came down. Lily thanked of herself for Timmy went home, Timmy and her mommy. \n",
      "\n",
      "The end of Timmy got toys and Timmy was happy that he had fun they became the park with her friends..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 4500/25000 [1:11:11<3:40:09,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 4500: train loss 2.1292, val loss 1.9966\n",
      "Saving the model checkpoint for step: 4500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 4501/25000 [1:14:03<295:49:48, 51.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 4500 | Generated Text: Once upon a time \n",
      "Jack walked through a castle forest full of things. He was weighed of wood! He had a patch and some string. As he made it, he heard a giant and he wanted to pick. One day, but suddenly, he remembered how he took his map and put them on its finger.\n",
      "\n",
      "\n",
      "His tugged around, he heard a loud voice sounded through the direction. Jack saw a shake. \"You's alright that don't be careful. It't be dangerous.\" \n",
      "\n",
      "\n",
      "Little Dan replied, he looked up and climbed down at his head. He knew he kept looking the cross and continued walking into the sound. The be brave and he was excited that he kept exploring the rope around the bushes to the ground. \n",
      "\n",
      "The be careful when he could do. He smiled and continued to discovering out on his fear again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|        | 5000/25000 [1:19:23<3:33:12,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 5000: train loss 1.5997, val loss 1.9710\n",
      "Saving the model checkpoint for step: 5000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|        | 5001/25000 [1:22:15<288:34:52, 51.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 5000 | Generated Text: Once upon a time 3 year, Joe was playing a little bird who was feeling very sad. 3 and he was so small and he was very proud of himself.\n",
      "The boy was always very small, with his face.\n",
      "\n",
      "The boy felt really sad, every day, and loved playing with his friends when suddenly, his mom came overjoyed. She didn't come and had become a special thing - he made him and he was feeling miserable. His mom had gone forever.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|       | 5500/25000 [1:27:35<3:27:59,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 5500: train loss 2.0009, val loss 1.9659\n",
      "Saving the model checkpoint for step: 5500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|       | 5501/25000 [1:30:26<281:13:22, 51.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 5500 | Generated Text: Once upon a time 3-year-old and her mommy were walking in the park with an amazement at the other kids. Every day they got to the street. The friends enjoyed watching them, Mommy'dled and laugh. \n",
      "\n",
      "\"Let's go to play something fun!\" said. 3 year old was and exciting. They could go on a few months.\n",
      "\n",
      "His mom tried out the park, they left. She gave one more excited. She told him how important to jumped up together.\n",
      "\n",
      "Billy's dad gave it was so happy. With a wonderful time Mommy about the playground, they continued to the rest of their time there to playground and play.\n",
      "\n",
      "At the day, they decided to have the park, they would spend time at how much fun. Even though the other kids had so much it was playing.\n",
      "At the day, they kept going to walk! They had all agreed that they came back home!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 6000/25000 [1:35:46<3:22:26,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 6000: train loss 1.5464, val loss 1.9567\n",
      "Saving the model checkpoint for step: 6000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 6001/25000 [1:38:38<273:34:06, 51.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 6000 | Generated Text: Once upon a time  upon a time, there was a big farm. One day, a little girl named Lily went outside her mommy warned her to go outside and sit in it. They told her it was time to go outside.\n",
      "\n",
      "Mommy said the park. They climbed up the park, \"It's so cool and we played on the park.\" \n",
      "\n",
      "When they went home, Lily noticed that they got out of fun with her friends over to leave their homes. \n",
      "\n",
      "They were all sat down and saw a lot of their tour, but they found earlier and having so much fun that Lily's mom said to their play with the cars. \n",
      "\n",
      "\n",
      "As the sun shade, Lily was happy that they all wet and saw something else was a big cloud that the sun was her dad said goodbye to have been very careful when she felt proud., happy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 6500/25000 [1:43:58<3:17:32,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 6500: train loss 2.3560, val loss 1.9348\n",
      "Saving the model checkpoint for step: 6500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 6501/25000 [1:46:49<266:55:24, 51.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 6500 | Generated Text: Once upon a time  there were two birds - Jack and Bile. Jack saw a raft inside.\n",
      "\n",
      "Jack andJack said to Jack, \"Yes!\" \n",
      "\n",
      "Jack said \"Let's get some car and seek.\" \n",
      "\n",
      "Jack thought for a minute, a minute and said, \"Come here for a minute.!\" \n",
      "Jack thought for a moment and said,\n",
      "\n",
      "Jack said, \"Yes!\"\n",
      "They found one. I's and started to win again!\"\n",
      "\n",
      "The \n",
      "Jack said, \"No, Jack!\" \n",
      "\n",
      "And too. Jack agreed, \"Be sure it in a good idea. They were scamorers to fight!\". \n",
      "\n",
      "\n",
      "Jack couldn't know what to the way it. It was a wonderful time. \n",
      "Jack and Jack had fun eaten to steal the turkey said, Jack!\" \n",
      "Jack said, but thought about them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|       | 7000/25000 [1:52:09<3:11:50,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 7000: train loss 2.2727, val loss 1.9362\n",
      "Saving the model checkpoint for step: 7000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|       | 7001/25000 [1:55:00<259:08:16, 51.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 7000 | Generated Text: Once upon a time  there was a little boy named John. He was three years old and loved his face. Every day he decided to play outside and watch the squash on his waist. He enjoyed trying new things.\n",
      "\n",
      "\n",
      "One day, Jody was working at the garden, John to study the house to the garden. He quickly hopped up at the leaves and his parents was very happy to do that it made a big smile on his parents put a big surprise.\n",
      "\n",
      "At the park. He loved to the park, shining in the park without any of the swings. He couldn't wait toy he met his surprise surprise. Inside he asked him. \n",
      "Everything was very friendly, and ran to watch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|       | 7500/25000 [2:00:20<3:07:48,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 7500: train loss 1.5465, val loss 1.9154\n",
      "Saving the model checkpoint for step: 7500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|       | 7501/25000 [2:03:12<252:25:15, 51.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 7500 | Generated Text: Once upon a time 3 other an old man called Jack. Jack loved to make a new movie. He asked his mom if he was to perform a guitar to play his.\n",
      "\n",
      "His parents said no because Jack was not make jazz. Jack listened carefully at Jack was the music. The music. He pressed a button was very happy and said he could hear it. He started to listen. He could music would hear and better.\n",
      "He would sing and even more happy, he could move the music whenever they play the jazz music even hear more music.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 8000/25000 [2:08:32<3:01:16,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 8000: train loss 1.6954, val loss 1.9049\n",
      "Saving the model checkpoint for step: 8000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 8001/25000 [2:11:23<244:45:51, 51.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 8000 | Generated Text: Once upon a time \n",
      "The sun was shining and her mom and dad. The sunny day, they were out of the sun shining with her little boy named Peter. They looked out to sit at all the big tree, and was shining outside, but Jake the sunshine. \n",
      "\n",
      "They met a little brother, who looked up at the birds in the clouds and had a big tree. Jack and said, \"Who's mommy?\" Molly, and said, \"I can'm so cool.\" \n",
      "\n",
      "Daddy saw a big yellow mumpy idea. Jack loved spunny shapes. \n",
      "Jack and thought they got up, \"Why did it?\"\n",
      "\n",
      "\n",
      "\"Let's race?\" he said \"Sure,\" said with us.\n",
      "They jumping down and ran outside and his dad smiled and said, \"Let's make a tree. Let's add leaves!\". So they sat down and waited for a wonderful! First, they started to the tree to jumped up and started to hang the tree and down. Soon, the two birds danced around the branch of fun! \n",
      "\n",
      "The kids ran around. She was so much fun making sure it was so happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|      | 8500/25000 [2:16:43<2:57:33,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 8500: train loss 2.2210, val loss 1.9044\n",
      "Saving the model checkpoint for step: 8500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|      | 8501/25000 [2:19:35<237:34:57, 51.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 8500 | Generated Text: Once upon a time  there was a little girl named Lily. She loved wake up in her mommy's garden. One day, Lily's mommy asked her to play with yummy fruit too, so her to help her cake. It was shiny. \"Can I have some cake,\" she asked. She was happy! \n",
      "\n",
      "Her mommy helped her mommy said yes and ran to buy more careful with the cake until it with her mommy. Lily's mommy was so tired for her to eat together. But when she was time to the oven, mommy was proud of herself for the cake, she had so much. She learned that they both about winning her mommy was okay to listen to help of herself. When they all of her little girl for her mommy and then she had to be honest and eating your mommy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 9000/25000 [2:24:55<2:51:30,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 9000: train loss 1.8296, val loss 1.8798\n",
      "Saving the model checkpoint for step: 9000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 9001/25000 [2:27:46<230:38:38, 51.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 9000 | Generated Text: Once upon a time , in a big house, there was a clumsy cat named Tom. Tom loved to wear his toy dog named Max. One day, a little bird named Ollie, named Jerry would fly high and run a big tree nearby. \n",
      "\n",
      "\n",
      "One sunny named Max saw a big tree tree. She had a pretty bird named Jerry. Mark said, \"Want! Hi climb the tree? I told you, \"Wow! We can's too high and play outside to play with me.\" 5 tree!\"\n",
      "\n",
      "\n",
      "Mr.\" Bella was sad, a moment and said, \"Let meowed and Jerry, \"I don't be a pretty feathers to come back. I didn't want to climb up.\"\n",
      "\n",
      "Tom was scared, but he said, but he flew high. Jerry. \"Don't worry, Max. I can fly up and said, Tweety was so high branch!\" They swung the bird said, \"You are not mean.\" \n",
      "\n",
      "Later, \"That was happy and catch me!\" \n",
      "Max smiled. Jerry. \"It's okay, that Mittens. Jerry looked down in your wings and said, Max, Luna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|      | 9500/25000 [2:33:06<2:45:00,  1.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 9500: train loss 1.8706, val loss 1.8810\n",
      "Saving the model checkpoint for step: 9500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|      | 9501/25000 [2:35:57<223:09:13, 51.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 9500 | Generated Text: Once upon a time 3-year-old kitten was playing happily when his family on the porch, who was feeling embarrassed. One day, one of the cat was so sad and frustrated he had all the other mild. He could not been to playroom with. When the mommy quickly came close and daddy were so sad but soon as the other kitten away his parents had said the kids in the kitten, they could get their day. He couldn't make their kitten and he could make it. His mom and even though he put them all by talking. The little kitten was so proud of her yarn was so happy and said hello to play. The kitten kitten was so thankful for her yarn in the kitten. Even though the next day of the kitten's family and chewed, so happy, so brave and the neighborhood looked around the kitten never knew that and it was so happy to his kitten with joy! in the kitten again and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|      | 10000/25000 [2:41:17<2:40:36,  1.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 10000: train loss 2.2282, val loss 1.8767\n",
      "Saving the model checkpoint for step: 10000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|      | 10001/25000 [2:44:09<216:13:36, 51.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 10000 | Generated Text: Once upon a time  there was a little girl named Lucy who liked to write. She had a special folder with lots of things toys and books. Her mommy told her not to do, she would get too much fun she could write about it.\n",
      "\n",
      "One day, Lucy's mommy asked her to go to the girl, so she went outside to clean her friend.\n",
      "\"Will that you want to the mail?\"\n",
      "\n",
      "\"Can I help me get some help me to help?\" asked.\n",
      "\n",
      "Her mommy asked. He was impatient. The girl was so happy, and she said yes, but she gave it didn't wait to a smile on the right away so she did a smile. She ran off to her friends. enjoyed their faces, and her mommy, and said  she got bags! \n",
      "\n",
      "\n",
      "The little girl was so happy and Lucy ran to her face so happy - she hugged her house. The end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|     | 10500/25000 [2:49:29<2:34:39,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 10500: train loss 2.2338, val loss 1.8648\n",
      "Saving the model checkpoint for step: 10500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|     | 10501/25000 [2:52:20<208:31:06, 51.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 10500 | Generated Text: Once upon a time  there was a little girl. She was only three years old who really loved to go outside. One day she saw a big, colorful flower.\n",
      "\n",
      "The little 3 year old daughter was very excited and she ran to it. She held it and showed it to her grandmother smiled.\n",
      "The little girl loved her daughter's hands and said, What brings you doing?\n",
      "\n",
      "\n",
      "The little girl wanted to come outside and she found the pretty flowers with the new style. But then her head and said, That \n",
      "Her parents smiled and said, That\n",
      "\n",
      "The little girl noticed that one more people would keep it's ok. That made them can still on the little girl was so you want to show you show the little girl lots of hug. The little girl feel like her feel embarrassed them. \n",
      "\n",
      "The little girl happy and went off! I didnt wait to get the whole way. \n",
      "\n",
      "Sorry! Her daddy in life!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|     | 11000/25000 [2:57:39<2:28:50,  1.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 11000: train loss 1.5621, val loss 1.8540\n",
      "Saving the model checkpoint for step: 11000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|     | 11001/25000 [3:00:30<201:09:36, 51.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 11000 | Generated Text: Once upon a time  a bright red ball lived in a special village. He loved to play and play catch with his friends.\n",
      "\n",
      "One day Jack was swimming in the park. He loved the park and running around and playingground had an adventure. He wanted to join in the game together for a great time playing catch her. It was always have a great time. \n",
      "\n",
      "So Jack went on the park and climbed until he forgot all of fun bum and couldn't wait to catch the fun he wanted to the park. \n",
      "\n",
      "At the way home he arrived at the park. He was getting late. He was time. He was so excited for Jack was so much fun and wanted to come back to play again tomorrow. \n",
      "\n",
      "\n",
      "The next to go home quickly finished playing in and started was so happy! He had all about playing basketball at the next day. He spent the swim too lazy to play his friends with his friends always the pilet even though he felt like it again tomorrow. He knew he would come back to bedroom! He was going to playing and having a wonderful time after all the park with his play at the fun.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|     | 11500/25000 [3:05:50<2:25:09,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 11500: train loss 2.0844, val loss 1.8609\n",
      "Saving the model checkpoint for step: 11500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|     | 11501/25000 [3:08:41<193:54:22, 51.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 11500 | Generated Text: Once upon a time 3 year old and his mother was so happy. They had a special surprise for him - a nice yellow gift.\n",
      "\n",
      "When the morning, the mother ran around the house, she had said, \"Mommy, look at my dear! We've been honest child! Can I keep it?\"\n",
      "\n",
      "His mother smiled and said, \"Yes, I will be very careful with new to be careful with it!\"\n",
      "\n",
      "The boy nodded and began toys. He could each corner. When the family went away, and even when playing the mom took the to have such a while.\n",
      "\n",
      "Then they went to the corner.\n",
      "\n",
      "When they got there was time for the park, the end of her the family waved good boy came back to their destination, the mother called out a big hugged her face. Everyone, and they had a hug. that,e was so nice to the park, \n",
      " was so happy to be.,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|     | 12000/25000 [3:14:00<2:18:28,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 12000: train loss 1.5655, val loss 1.8446\n",
      "Saving the model checkpoint for step: 12000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|     | 12001/25000 [3:16:51<186:47:59, 51.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 12000 | Generated Text: Once upon a time 3 farmer, Jack. Jack and his wife were getting ready to go on an adventure. He was so excited to go on the woods to get to come backpack his adventure.\n",
      "\n",
      "When they got to the lake, Jack started to the lake's and Jack was very hot! Jack followed his bag full and trees. Jack was amazed with a wonderful time to see what the lake. \n",
      "\n",
      "The lake and Jack couldn't wait toes and a very big tree. He was so he had never forget about it. He didn't wait to dreaming far ahead of his journey home that he saw.\n",
      "\n",
      "Jack and swim back to his friends had exploring, he had made him, but this one day. But as they had to use to explore the perfect boat and Jack was in the lake all the lake.\n",
      "Before the lake again. Jack waved goodbye to explore the lake., he had gained. \n",
      "\n",
      "Jack was so happy to traveling on his adventures ever before swim and explore some new friends\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|     | 12500/25000 [3:22:10<2:13:33,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 12500: train loss 2.0288, val loss 1.8365\n",
      "Saving the model checkpoint for step: 12500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|     | 12501/25000 [3:25:01<179:23:01, 51.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 12500 | Generated Text: Once upon a time , there was a little boy named George. He was very creative and the world was playing with his friends. In the sun and a sudden, he saw a big tree. \n",
      "The cricket landed in a swing so happy and he wanted to goose. \n",
      "\n",
      "He reached out, but he didn't like it flew over to his arm and soon he was scared back. \n",
      "But then he saw a voice. The boy was safe to the tree. He was sitting in the tree, it was scared, but he was too late. \n",
      "The end.byes us but he would meet the lake his new friends.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|    | 13000/25000 [3:30:20<2:07:50,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 13000: train loss 1.8491, val loss 1.8355\n",
      "Saving the model checkpoint for step: 13000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|    | 13001/25000 [3:33:11<172:26:26, 51.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 13000 | Generated Text: Once upon a time  a mild day there was a little bird who was walking in the forest. He liked to soar higher and faster. He flew until he had lots of wonderful things he came across the sky.\n",
      "\n",
      "The little otters had gone all his fins filled with new things he couldn't contain his feathers. He even more. He felt a big tree't see the way toys were getting lost.\n",
      "\n",
      "\n",
      "As the sun shake was finished, and made a light that the world of things that looked and he was perfect but smile, he had moved his journey. Everybody was a promise to explore the other animals and could get back soon, especially proud of his mission to the tree. \n",
      "\n",
      "\n",
      "The next day. He was so happy that he had been able to find his magical and he was happy to make them safe. \n",
      "The wild animal happy in his adventure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|    | 13500/25000 [3:38:30<2:02:04,  1.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 13500: train loss 2.0300, val loss 1.8393\n",
      "Saving the model checkpoint for step: 13500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|    | 13501/25000 [3:41:21<165:05:19, 51.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 13500 | Generated Text: Once upon a time icy summer there was a small lumberjack. He heard the little boy. On Sunday evening, he heard a strange noise. The louder looked around and saw two chirrel walking faster and peeking in excitement. The boy had been looking for a foxes playing in response. \n",
      "\n",
      "He was frightened like him. The family was excitedly. The little boy looked sadly and he ran and alone.  Molly invited the lumberjack was lost behind a few minutes. \n",
      "The little boy shouted \"No! I can't hurt.\" But then reached a meal his house. \n",
      "The little boy stepped back to get out of the poor. The lumberjack. \n",
      "\n",
      "The little boy was so worried that the lumberjack chased the lumberjack wanted to the lumberjack, the lumberjack caught his kind. \n",
      "The lumberjack had been able to run away. The lumberjack ran back to get it. The lumberjack was left out. He knew that he had escaped the lumberjack's parents thanked the lumberjack. The lumberjack had done it't been a lesson that it is for the lumberjack again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|    | 14000/25000 [3:46:40<1:56:52,  1.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 14000: train loss 1.9700, val loss 1.8283\n",
      "Saving the model checkpoint for step: 14000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|    | 14001/25000 [3:49:31<158:03:59, 51.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 14000 | Generated Text: Once upon a time 3 year old girl named Lily went on an adventure to the first time. Every morning, her mom would go to have a walk on their bags, as she didn't know what she would go anywhere. \n",
      "\n",
      "\"Hi Jack! I'm going to spend too little girl,\" Lily said with him excited. Tuesday.\n",
      "\n",
      "As they walked around for something special. Suddenly, he had an adventure to leave, the woods, they heard a voice coming to look at a giant bird flying in the sky peered in. \"Do you doing?\" asked, and explore.\n",
      "\n",
      "Max was a tall trees and it hopping with lots of old tree. The old man smiled and widened with a smile on and even found great view. She had a new friend, excited and said, \"It're a wonderful adventure! Let't wait for all these exciting adventure!\" She thank you want him for this was filled with that he could come back home.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|    | 14500/25000 [3:54:51<1:51:53,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 14500: train loss 1.5479, val loss 1.8108\n",
      "Saving the model checkpoint for step: 14500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|    | 14501/25000 [3:57:42<150:45:32, 51.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 14500 | Generated Text: Once upon a time 3-year-old named Jack was in a bright yellow, Jack. He loved to play with his friends. One day, Jack and his mom came in the park.\n",
      "\n",
      "\"Mom, Jack?\" he asked Jack. \n",
      "\n",
      "His mom smiled and said, \"Jack, how do you know something with a bit.\"\n",
      "\n",
      "So as Jack. Jack saw a little gray animal with a large tree branch. He asked, \"What should I catch with a lot of stones on an eating his mom told you will be?\"\n",
      "\n",
      "Lily. \"It's so they are!\"\n",
      "\n",
      "Jack nodded his friends, so excited.\n",
      "\n",
      "Jack asked. He went to explore it was. Jack's mom said, \"These and it and it!\" Jack's mom smiled and his mom smiled, it was time to use his mom said, Jack nodded. \"That sounds of what he finished their adventure. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jack, they went to see many,\" Jack and they started dig a great day ever seen! Jack's mom for Jack's Mom. They saw the lake and Jack's mom replied. \n",
      "\n",
      "Jack agreed that day, a better knowing he't\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|    | 15000/25000 [4:03:01<1:46:49,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 15000: train loss 1.5306, val loss 1.8223\n",
      "Saving the model checkpoint for step: 15000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|    | 15001/25000 [4:05:52<143:35:23, 51.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 15000 | Generated Text: Once upon a time 3-year-old, she was walking through the woods and she came across a big, curious little fox. The fox was scared and she went closer to meet her mom's hunter's house. When they got to the hose and stumbled upon an angry man's kind face. He was not happy and said, \"Don't worry. We't worry, you this barber, I'll be scare you.\"\n",
      "\n",
      "The little girl was relieved and thanked Together, she could be brave and hangers. They made a sign that it into the old man and said, as the fox was very brave. The little girl was so kind and he waved as he would forgiven.\n",
      "The mommy followed the little girl and the world. Inside the hugged their hairy and the little boy and the man began to worry and then thanked the old man in the little girl. Everyone.\n",
      "By the little girl's little girl and waved and laughed for her best and her Mommy was so proud she knew that day, the animals thanked the little girl. aker and the gentle, she was always ready to walk back home.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|   | 15500/25000 [4:11:11<1:41:30,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 15500: train loss 1.4945, val loss 1.8048\n",
      "Saving the model checkpoint for step: 15500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|   | 15501/25000 [4:14:02<136:30:58, 51.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 15500 | Generated Text: Once upon a time 3 year old named Timmy went to the camp. He was very hungry, to find something fun to eat. He saw a big log to eat it. He felt a big fruit with his snack!\n",
      "\n",
      "Timmy saw two pieces of fruit and a small mouse who wanted to eat it down. He started to eat the big smile on the rock and started to run away. Timmy and run. The bear was so happy and the orange hunt.\n",
      "\n",
      "But while, he couldn't run faster and didn't swung too. He was too fast. Timmy had found ate the food all gone and had fun.omach from the forest when she went up and I need to eat this. We can help you. We have some healthy food too busy with me the forest until it will eat the right now.\"\n",
      "\n",
      "\n",
      "Timmy was more energy started to make him toasty bear shook them eat the berries, Timmy was proud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 16000/25000 [4:19:21<1:35:47,  1.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 16000: train loss 2.0074, val loss 1.8015\n",
      "Saving the model checkpoint for step: 16000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 16001/25000 [4:22:12<129:10:17, 51.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 16000 | Generated Text: Once upon a time 3 year old Jack was feeling very curious about the world around him. His parents took him to the store and looking for their little boy had come to the shop.\n",
      "\n",
      "When they arrived, Jack was surprised to see a pretty white shining the sky.\n",
      "\"Can we go and get there, mommy, Mommy?\" the the store before.\n",
      "\"Yes, honey, isn't it's very tall for us to get started to be loving,\" his mommy explained.\n",
      "\n",
      "\n",
      "Max was a little bit worried Jack's big store keeper, smiling. Little Jack, but they started to laugh and his Mommy smiled and she said, \"We can pay for the best day.\"\n",
      "\n",
      "Jack's grandparents were so his little boy was so excitedly and said, \"We's Daddy. We also happy to have some time to be here again.\"\n",
      "At the week and they left the park and waved goodbye to the end of love by going to help!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|   | 16500/25000 [4:27:31<1:30:43,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 16500: train loss 2.1793, val loss 1.7952\n",
      "Saving the model checkpoint for step: 16500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|   | 16501/25000 [4:30:22<122:09:33, 51.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 16500 | Generated Text: Once upon a time , there was a little girl. Her parents were very obedient and always made her very competitive. They had aunt. One day, her spicy chop! She wanted to take a spicy, so she knew her on her family.\n",
      "\n",
      "As the days later, they got an amazement came over the little girl saw that spicy ground onion! She picked it. The spicy and ran off of spicy strawberry, but very slippies and it. She was her parents!\n",
      "\n",
      "The next day! She was so happy to find her, and her friend came to visit the sprayed some ice. She was very relieved that the icy choked it. Her parents for her special spicy sniffing.\n",
      "When she returned. She had her parents had such a delicious dinner for helping. They were very satisfied and it was so happy that she had saved. They were happy she hadn's spicy, because they were very glad she forgot about her such a unique spicy food. She was.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|   | 17000/25000 [4:35:42<1:25:11,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 17000: train loss 2.0396, val loss 1.8007\n",
      "Saving the model checkpoint for step: 17000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|   | 17001/25000 [4:38:33<114:48:02, 51.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 17000 | Generated Text: Once upon a time 3 year old called Jake and his friends lived in the forest. Every day Jake loved to explore the wild and explore the world around him to catch different. On this particular sun was sunlight while he found a very excited. One day, Jake was walking through the woods and discovered something strange in his eye. He looked closer and noticed a small, a small squint. He was deaf dog bark and wanted to see what he couldn't help.\n",
      "\n",
      "Jake remembered a tiny creature. The creature slowly walked closer and soon figured out to say to help but take a closer look and looked at Jake. He scooped at Jake, \"Help meal this? What are you doing here! I do!\"\n",
      "\n",
      "\n",
      "\"Yelled nice man and said to my finger over and said nothing but feel better. The animal. The creature had a better, \"It must never touch that, little creature, it'll find out an eye! It knows I can keep it can understand the animal has to its friend, but the other things in it go and go find something special with you's why it was a friendly bite from then I will you.\" \n",
      "\n",
      "The creature seemed to answer. \n",
      "J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|   | 17500/25000 [4:43:52<1:19:57,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 17500: train loss 2.0934, val loss 1.7904\n",
      "Saving the model checkpoint for step: 17500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|   | 17501/25000 [4:46:43<107:48:04, 51.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 17500 | Generated Text: Once upon a time , there was a very special girl named Jane. On this day, Mary loved her mommy and daddy, and they decided to go for a walk in the park. \n",
      "\n",
      "\"Daddy!\" cried John said her, \"Let's take the park. I have a look for the play,\" said Mary. He asked Anna. \n",
      "Tommy to play together. \n",
      "\"I love taking her mommy,\" her Mommy smiled, but then said, \"I love playing bye! We can go!\" \n",
      "\n",
      "Later, and laughed. Daddy smiled and seek. I'm here, looking for a few minutes, as they heard a big, \"I know you!\" \n",
      "\n",
      "\"Look!\"\n",
      "Her mommy's mommy looked. \n",
      "John and Daddy said. \"But you can be.\"\n",
      "\"Let'm so cool!\" \n",
      "\n",
      "When they went to the man said. That's share the park, Daddy said, Daddy!\" \n",
      " said, \"Thanks. She was really great!\" \n",
      "\n",
      "The man smiled. \"This isn't delay. \n",
      "Daddy, \"And I love the park, Daddy! You'm here we\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|  | 18000/25000 [4:52:02<1:14:20,  1.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 18000: train loss 1.8939, val loss 1.7868\n",
      "Saving the model checkpoint for step: 18000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|  | 18001/25000 [4:54:53<100:31:38, 51.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 18000 | Generated Text: Once upon a time \n",
      "One day, Jack was feeling very miserable. He wanted to go play outside and play in the garden. He ran over to his hands and it was very hot. He woke up and had to pick it there might get some more lolates.\n",
      "\n",
      "He found a banana! He tried to play by himself, but it, and tried to keep it wouldn't budge. He quickly pulled up because it. He was very good at it and yummy, jumped one of the banana all by the bananas.\n",
      "\n",
      "The gobbled as he could and went down and waited for his hands, the bananas, but the rain stopped. He loved it was so delicious!\n",
      "Before he did as the trunk of the banana, he was over again and the lunch. \n",
      "\n",
      "He was so happy that he kept eating the river. And then went down the sun went back every day the sun.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|  | 18500/25000 [5:00:12<1:09:15,  1.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 18500: train loss 2.0130, val loss 1.7819\n",
      "Saving the model checkpoint for step: 18500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|  | 18501/25000 [5:03:03<93:23:10, 51.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 18500 | Generated Text: Once upon a time \n",
      "But one morning, little Jack woke up feeling very hot. Jack decided to go to the stairs and tried to run away from his garden. He asked his mom, \"Where's wrong?\" \n",
      "\n",
      "\"I want some honey,\" replied his mom.  \n",
      "\n",
      "His mom opened the door, \"You saw an adventure, Jack,\" she said, \"I know. Let's go get a small box and put it inside, and it over there was ready for a snack.\" \n",
      "\n",
      "Sar! When he said his mom smiled and a glass jar, \"Don'll have to go away. Have a cupcake. Let's go eat! Have a smile when it finally get something special treat?\" \n",
      "Jack was out in there, \"Yay, they went back into the cookies, mom to eat,\" she said, \"Thank you!\", and went on, feeling happy to eat again, satisfied a wonderful. for the looking up with her mom smiled and put him.y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|  | 19000/25000 [5:08:23<1:04:17,  1.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 19000: train loss 1.8643, val loss 1.7846\n",
      "Saving the model checkpoint for step: 19000\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|  | 19001/25000 [5:11:15<86:29:53, 51.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 19000 | Generated Text: Once upon a time  a brave girl was walking through the park. She saw a big tree with lots of flowers and so excited that she asked her mummy if she could go and play. She said, \"Yes\". The tree was so beautiful! Thank you and started to sing a few minutes of the tree with lots of fun. So the tree was very happy. \n",
      "\n",
      "The girl sat with the tree was able to sing something in the tree for her mummy tree that day. The tree began to sing over she could hardly contain the tree and was so strong and the tree. She was time to see how the tree liked the little girl felt so comfortable. \n",
      "The girl smiled and smiled, so happy with joy. The girl looked up the most beautiful and she had been able to hear the tree happy. so happy that this tree was so gentle the tree would be so pleased with their branches and started to be and the tree smiled, feeling happy and thankful and would wool for showing its bright voice for being so much. She thank you for teaching her joy at the big hugged the tree for what matter how beautiful friendship that she was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|  | 19500/25000 [5:16:35<58:43,  1.56it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n",
      "step 19500: train loss 2.0900, val loss 1.7730\n",
      "Saving the model checkpoint for step: 19500\n",
      "Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|  | 19501/25000 [5:19:26<79:09:45, 51.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step: 19500 | Generated Text: Once upon a time 3 year old named Davey had a great night coming up in his garden and an amazing view. But then he was all the wind, he couldn't come and he would get a surprise his toy truck, who lived. \n",
      "\n",
      "He soon reached his Danny was so scolded, pick him. He had been able to push it off the nearest to get his to the cooler up in and started walking through the sky, saying, \"No! You are just going toy. You have to keep up in here.\" Dave was soak.\n",
      "\n",
      "\n",
      "\"Help, then get through a hurry back and was struggling!\"\n",
      "The little boy, he was trying to stay calm water, until he knew he wanted to explore the forest, but he remembered something that you might for us. He slowly opened the cage and to keep going to do. He kept going until he managed to prevent the bottom of himself for help him from someone else, a good as he could. back. \n",
      "They found a nearby. They walked inside this was so relieved that was safe now, he had done it back to save the saved up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|  | 20000/25000 [5:24:46<53:35,  1.55it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with val evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|  | 20000/25000 [5:25:38<1:21:24,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# import tqdm \n",
    "def train():\n",
    "    # Set device to CUDA if available\n",
    "    device = ModelArgs.device\n",
    "    print(f\"Start running training on {device}.\")\n",
    "    \n",
    "    # Initialize wandb for experiment tracking\n",
    "    wandb.init(\n",
    "        project = 'Gemma-Training',\n",
    "        # config = ModelArgs, # you can uncomment this to log model config\n",
    "    )\n",
    "    \n",
    "    # Create model and move to GPU\n",
    "    model = Gemma(embeddings_dims=ModelArgs.embeddings_dims, block_size=ModelArgs.block_size, \n",
    "                  vocab_size=ModelArgs.vocab_size, dropout=ModelArgs.dropout, device=device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(\"Model loaded\")\n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=ModelArgs.max_lr)\n",
    "    \n",
    "    # Training parameters\n",
    "    save_checkpoint_iter = 500\n",
    "    total_iters = 25000\n",
    "    eval_iters = 500\n",
    "\n",
    "    \n",
    "    # Training progress bar\n",
    "    train_epoch_iterator = tqdm.tqdm(range(total_iters), desc=\"Training\")\n",
    "    val_dataloader = prepare_dataset('val', device, ModelArgs.batch_size)\n",
    "    val_iterator = iter(val_dataloader)\n",
    "    # Get batches for training\n",
    "    @torch.inference_mode()\n",
    "    def estimate_loss():\n",
    "        out = {}\n",
    "        model.eval()\n",
    "        count = 0\n",
    "        for split in ['val']:\n",
    "            print(f\"Starting with {split} evaluation...\")\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "\n",
    "                nonlocal val_iterator\n",
    "                \n",
    "                # for k, batch in enumerate(dataloader):\n",
    "                try:\n",
    "                    batch = next(val_iterator)\n",
    "                except StopIteration:\n",
    "                    val_iterator = iter(val_dataloader)\n",
    "                    batch = next(val_iterator)\n",
    "            \n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                targets = batch[\"labels\"].to(device)\n",
    "                \n",
    "                logits = model(input_ids)\n",
    "                batch_size, block_size, embeddings_dims = logits.shape\n",
    "                logits = logits.view(batch_size*block_size, embeddings_dims)\n",
    "                targets = targets.view(batch_size * block_size)\n",
    "                loss = nn.functional.cross_entropy(logits, targets)\n",
    "                losses[k] = loss.item()\n",
    "                # count += 1\n",
    "            out[split] = losses.mean()\n",
    "\n",
    "        model.train()\n",
    "        return out\n",
    "    token_count = 0\n",
    "    # Start training loop\n",
    "    model.train()\n",
    "    print(\"Lessgoo...\")\n",
    "    dataloader = prepare_dataset('train', device, ModelArgs.batch_size)\n",
    "    train_dataloader = iter(dataloader) \n",
    "    accumulated_loss = 0.0\n",
    "    for step in train_epoch_iterator:\n",
    "        # Periodically evaluate loss on train and val sets\n",
    "        if (step % eval_iters == 0 and step != 0) or step == total_iters - 1:\n",
    "            losses = estimate_loss()\n",
    "            avg_val_loss = torch.Tensor([losses['val']]).to(device)\n",
    "            print(f\"step {step}: train loss {accumulated_loss:.4f}, val loss {losses['val']:.4f}\")\n",
    "            val_perplexity = torch.exp(torch.tensor(avg_val_loss)).item()\n",
    "            # Log metrics to wandb\n",
    "            wandb.log({\n",
    "                \"val_perplexity\": val_perplexity,\n",
    "                # \"val_step_loss\": losses['train'],\n",
    "                \"val_step_loss\": losses['val'],\n",
    "                \"step\": step\n",
    "            })\n",
    "            \n",
    "        # Save checkpoint periodically\n",
    "        if step % save_checkpoint_iter == 0 and step != 0:\n",
    "            print(f\"Saving the model checkpoint for step: {step}\")\n",
    "            torch.save(model.state_dict(), \"checkpoint.pt\")\n",
    "            print(\"Checkpoint saved\")\n",
    "        \n",
    "        # Get batch for training step\n",
    "        try:\n",
    "            batch = next(train_dataloader)\n",
    "        except StopIteration:\n",
    "            train_dataloader = iter(dataloader)\n",
    "            batch = next(train_dataloader)\n",
    "            \n",
    "        # for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        targets = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(input_ids)\n",
    "        batch_size, block_size, embeddings_dims = logits.shape\n",
    "        logits = logits.view(batch_size*block_size, embeddings_dims)\n",
    "        targets = targets.view(batch_size * block_size)\n",
    "        loss = nn.functional.cross_entropy(logits, targets)\n",
    "\n",
    "        token_count += (len(input_ids) * ModelArgs.batch_size)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulated_loss = loss.item()\n",
    "        perplexity = torch.exp(torch.tensor(accumulated_loss)).item()  # Calculate perplexity\n",
    "        # if(device == 0):\n",
    "        wandb.log({\n",
    "                    # \"Learning Rate\": scheduler.get_last_lr()[0],\n",
    "                    \"Train_Loss\": accumulated_loss,\n",
    "                    # \"Train loss\": loss.item(),\n",
    "                    \"Train Perplexity\": perplexity,\n",
    "                    \"Total Tokens Processed\": token_count,\n",
    "                    \"Step\": step,\n",
    "                    # \"Gradient Norm\": total_norm_before.item(),\n",
    "                    # \"Epoch\": epoch\n",
    "                    \n",
    "        })\n",
    "        \n",
    "        if(step % eval_iters == 0):\n",
    "                prompt = \"Once upon a time \"\n",
    "                generated_text = topk_sampling(model, prompt, max_length=ModelArgs.block_size, top_k=50, temperature=1.0, device=device)\n",
    "    \n",
    "     \n",
    "                print(f\" Step: {step} | Generated Text: {generated_text}\")\n",
    "\n",
    "    # Finish wandb run\n",
    "    wandb.finish()\n",
    "\n",
    "# Print CUDA device count but won't be using DDP\n",
    "world_size = torch.cuda.device_count()\n",
    "print(f\"CUDA devices available: {world_size}\")\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
