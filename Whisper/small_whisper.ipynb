{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "e4b2df23-1b2f-4ca2-9968-9bbd2972779d",
        "_uuid": "4b54e35b-02bb-44b4-adca-a297c3081d36",
        "execution": {
          "iopub.execute_input": "2025-03-16T20:27:50.949322Z",
          "iopub.status.busy": "2025-03-16T20:27:50.949124Z",
          "iopub.status.idle": "2025-03-16T20:27:53.952701Z",
          "shell.execute_reply": "2025-03-16T20:27:53.951790Z",
          "shell.execute_reply.started": "2025-03-16T20:27:50.949302Z"
        },
        "id": "Pw7f2ghccuoK",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "# from tokenizers import Tokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from liger_kernel.transformers import LigerLayerNorm\n",
        "from liger_kernel.transformers import LigerFusedLinearCrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "8e81d8cb-2c43-4550-a8f8-09815ff2a1ab",
        "_uuid": "fe2c17e3-b1bf-4b93-8760-de26e849e84f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T20:27:53.954751Z",
          "iopub.status.busy": "2025-03-16T20:27:53.954400Z",
          "iopub.status.idle": "2025-03-16T20:27:56.417272Z",
          "shell.execute_reply": "2025-03-16T20:27:56.416335Z",
          "shell.execute_reply.started": "2025-03-16T20:27:53.954727Z"
        },
        "id": "LwR5_uvTcuoL",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "310cff32-a620-47ee-c292-200efec31b62",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "HF_TOKEN = '...'\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", token=HF_TOKEN)\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "\n",
        "SOT = '<|startoftranscript|>'\n",
        "EOT = '<|endoftranscript|>'\n",
        "transcribe = '<|transcribe|>'\n",
        "prev = '<|prev|>'\n",
        "\n",
        "special_tokens_dict = {\n",
        "    'additional_special_tokens': [SOT, EOT, transcribe, prev]\n",
        "}\n",
        "\n",
        "\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "# tokenizer(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UrQBMMqqHMV",
        "outputId": "126b3b8d-94c0-48e0-b0d4-bb3eb3c8e661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "_cell_guid": "32170d73-d4d4-431e-ad94-fa5d9addd61f",
        "_uuid": "234d59ef-e07b-4028-a613-ec9e72abfd67",
        "execution": {
          "iopub.execute_input": "2025-03-16T20:27:56.419235Z",
          "iopub.status.busy": "2025-03-16T20:27:56.418752Z",
          "iopub.status.idle": "2025-03-16T20:28:08.001610Z",
          "shell.execute_reply": "2025-03-16T20:28:08.000672Z",
          "shell.execute_reply.started": "2025-03-16T20:27:56.419209Z"
        },
        "id": "P3vCVc6OlXe2",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install wandb\n",
        "# import wandb\n",
        "# from kaggle_secrets import UserSecretsClient\n",
        "# user_secrets = UserSecretsClient()\n",
        "# secret_value_0 = user_secrets.get_secret(\"API_KEY\")\n",
        "\n",
        "# wandb.login(key=secret_value_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "33ab1861-74f7-45f5-adb9-f986e5a7e036",
        "_uuid": "4f155899-f57d-4c37-aa94-e56a969d0259",
        "execution": {
          "iopub.execute_input": "2025-03-16T20:28:08.003275Z",
          "iopub.status.busy": "2025-03-16T20:28:08.002697Z",
          "iopub.status.idle": "2025-03-16T20:28:08.018779Z",
          "shell.execute_reply": "2025-03-16T20:28:08.017823Z",
          "shell.execute_reply.started": "2025-03-16T20:28:08.003246Z"
        },
        "id": "D7AP219KJzTs",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m batch_size = \u001b[32m64\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# src_vocab_size = None\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m tgt_vocab_size = \u001b[38;5;28mlen\u001b[39m(\u001b[43mtokenizer\u001b[49m)\n\u001b[32m      7\u001b[39m embeddings_dims = \u001b[32m512\u001b[39m\n\u001b[32m      8\u001b[39m attn_dropout = \u001b[32m0.1\u001b[39m\n",
            "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "#Hyperparameters\n",
        "epochs=10\n",
        "block_size = 64\n",
        "batch_size = 64\n",
        "# src_vocab_size = None\n",
        "tgt_vocab_size = len(tokenizer)\n",
        "embeddings_dims = 512\n",
        "attn_dropout = 0.1\n",
        "no_of_heads = 4 #IMP needs to be thoroughly calculated\n",
        "dropout = 0.1\n",
        "# epochs = 3\n",
        "max_lr = 6e-4\n",
        "no_of_decoder_layers = 6 #IMP needs to be thoroughly calculated\n",
        "attn_dropout = 0.1\n",
        "weight_decay_optim = 0.01\n",
        "log_mel_features = 80\n",
        "kernel_size = 3\n",
        "stride = (2,10)\n",
        "sr = 16000\n",
        "device= 'cuda:0'\n",
        "SAMPLING_RATE=16000\n",
        "N_MELS = 80  # 80-channel Mel spectrogram\n",
        "WINDOW_DURATION = 0.025  # 25 milliseconds\n",
        "STRIDE_DURATION = 0.010  # 10 milliseconds\n",
        "max_t = 500\n",
        "n_channels = N_MELS\n",
        "clip = 1.0\n",
        "use_flash_attention = False\n",
        "use_liger = False\n",
        "use_torch_compile = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "_cell_guid": "5ac94789-1d5e-4ace-88f3-25b5413fb78b",
        "_uuid": "92a80d68-b0eb-4f1d-b988-7f190e0b934a",
        "execution": {
          "iopub.execute_input": "2025-03-16T20:28:08.020631Z",
          "iopub.status.busy": "2025-03-16T20:28:08.020054Z",
          "iopub.status.idle": "2025-03-16T20:28:08.043556Z",
          "shell.execute_reply": "2025-03-16T20:28:08.042503Z",
          "shell.execute_reply.started": "2025-03-16T20:28:08.020565Z"
        },
        "id": "TmPkI_UEpvor",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.set_default_device(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "_cell_guid": "1777fa9a-7686-4b62-93c1-c31c2ccf73c1",
        "_uuid": "e08f94e6-dae5-42f3-a285-c151086b8f1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T20:28:08.045189Z",
          "iopub.status.busy": "2025-03-16T20:28:08.044805Z",
          "iopub.status.idle": "2025-03-16T20:28:14.373089Z",
          "shell.execute_reply": "2025-03-16T20:28:14.372056Z",
          "shell.execute_reply.started": "2025-03-16T20:28:08.045149Z"
        },
        "id": "IME1Ls95Y3gl",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "7f99af6c-65ab-45e1-bfa1-8f104a79ac13",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
            "        num_rows: 9389\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
            "        num_rows: 6750\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
            "        num_rows: 25619\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install datasets\n",
        "from tabnanny import verbose\n",
        "from datasets import load_dataset\n",
        "\n",
        "gs = load_dataset(\"speechcolab/gigaspeech\", \"xs\", token=HF_TOKEN, trust_remote_code=True)\n",
        "\n",
        "\n",
        "print(gs)\n",
        "\n",
        "\n",
        "audio_input = gs['train'][0][\"audio\"]\n",
        "transcription = gs[\"train\"][0][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "_cell_guid": "0c018b51-6161-49d9-995e-21cf09d1391f",
        "_uuid": "027b3fe3-8e01-40c4-99de-1a1b12d93453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T20:28:14.374940Z",
          "iopub.status.busy": "2025-03-16T20:28:14.374239Z",
          "iopub.status.idle": "2025-03-16T20:35:37.108931Z",
          "shell.execute_reply": "2025-03-16T20:35:37.108126Z",
          "shell.execute_reply.started": "2025-03-16T20:28:14.374907Z"
        },
        "id": "cRV1EOlVY3gm",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "0ee8ab60-4d77-4173-8339-d916dcb09a72",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25619/25619 [00:57<00:00, 442.90it/s]\n",
            "100%|██████████| 6750/6750 [00:11<00:00, 577.92it/s]\n"
          ]
        }
      ],
      "source": [
        "MAX_DURATION_IN_SECONDS = 10\n",
        "\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "def is_audio_length_in_range(input_length):\n",
        "    return input_length < MAX_DURATION_IN_SECONDS\n",
        "\n",
        "train_new_column = []\n",
        "\n",
        "for x in tqdm(range(len(gs['test']))):\n",
        "    train_new_column.append(librosa.get_duration(path=gs['test'][x]['audio']['path']))\n",
        "\n",
        "gs_ = gs['test'].add_column(\"duration\", train_new_column)\n",
        "\n",
        "\n",
        "gs_ = gs_.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n",
        "\n",
        "\n",
        "truncated_gs_train = gs_.remove_columns([\"duration\"])\n",
        "# truncated_gs\n",
        "\n",
        "\n",
        "\n",
        "val_new_column = []\n",
        "# new_column = [librosa.get_duration(path=x) ]]\n",
        "for x in tqdm(range(len(gs['validation']))):\n",
        "    val_new_column.append(librosa.get_duration(path=gs['validation'][x]['audio']['path']))\n",
        "\n",
        "gs_ = gs['validation'].add_column(\"duration\", val_new_column)\n",
        "\n",
        "\n",
        "gs_ = gs_.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n",
        "\n",
        "\n",
        "truncated_gs_val = gs_.remove_columns([\"duration\"])\n",
        "# truncated_gs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "_cell_guid": "68c3295a-6eef-4874-acaf-73f9279fad98",
        "_uuid": "d988499f-ad5b-47cf-bd9e-257395584889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T20:35:37.111778Z",
          "iopub.status.busy": "2025-03-16T20:35:37.111522Z",
          "iopub.status.idle": "2025-03-16T21:17:23.216508Z",
          "shell.execute_reply": "2025-03-16T21:17:23.215522Z",
          "shell.execute_reply.started": "2025-03-16T20:35:37.111754Z"
        },
        "id": "6NZ9Hbp5q1to",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "0407d791-b50e-4f2c-a8fe-828f6ede0cb6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 37/22015 [00:00<07:31, 48.72it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1024\n",
            "  warnings.warn(\n",
            "  0%|          | 87/22015 [00:01<06:40, 54.74it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3840\n",
            "  warnings.warn(\n",
            "  2%|▏         | 352/22015 [00:08<08:15, 43.68it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3056\n",
            "  warnings.warn(\n",
            "  2%|▏         | 387/22015 [00:09<08:54, 40.44it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=992\n",
            "  warnings.warn(\n",
            "  2%|▏         | 399/22015 [00:09<07:30, 47.97it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=800\n",
            "  warnings.warn(\n",
            "  2%|▏         | 438/22015 [00:10<08:35, 41.82it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=720\n",
            "  warnings.warn(\n",
            "  2%|▏         | 448/22015 [00:10<09:04, 39.60it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=912\n",
            "  warnings.warn(\n",
            "  3%|▎         | 665/22015 [00:15<09:47, 36.32it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3600\n",
            "  warnings.warn(\n",
            "  3%|▎         | 767/22015 [00:18<12:49, 27.63it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=336\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3792\n",
            "  warnings.warn(\n",
            "  4%|▎         | 812/22015 [00:19<07:28, 47.30it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=432\n",
            "  warnings.warn(\n",
            "  4%|▍         | 835/22015 [00:20<06:43, 52.50it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=144\n",
            "  warnings.warn(\n",
            "  4%|▍         | 841/22015 [00:20<06:42, 52.59it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=864\n",
            "  warnings.warn(\n",
            "  4%|▍         | 944/22015 [00:22<05:10, 67.97it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=736\n",
            "  warnings.warn(\n",
            "  5%|▍         | 1072/22015 [00:25<05:53, 59.19it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=512\n",
            "  warnings.warn(\n",
            "  6%|▌         | 1306/22015 [00:32<07:39, 45.04it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=592\n",
            "  warnings.warn(\n",
            "  6%|▌         | 1375/22015 [00:33<09:39, 35.59it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=672\n",
            "  warnings.warn(\n",
            "  7%|▋         | 1513/22015 [00:37<08:51, 38.61it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=704\n",
            "  warnings.warn(\n",
            "  8%|▊         | 1653/22015 [00:40<03:43, 90.98it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=656\n",
            "  warnings.warn(\n",
            "  8%|▊         | 1771/22015 [00:42<07:41, 43.90it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=544\n",
            "  warnings.warn(\n",
            "  9%|▊         | 1919/22015 [00:44<03:10, 105.22it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2864\n",
            "  warnings.warn(\n",
            " 10%|▉         | 2153/22015 [00:46<03:12, 103.44it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=832\n",
            "  warnings.warn(\n",
            " 10%|█         | 2262/22015 [00:47<03:17, 99.91it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=240\n",
            "  warnings.warn(\n",
            " 11%|█▏        | 2488/22015 [00:49<03:21, 96.91it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=272\n",
            "  warnings.warn(\n",
            " 12%|█▏        | 2735/22015 [00:52<03:03, 104.86it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=528\n",
            "  warnings.warn(\n",
            " 13%|█▎        | 2757/22015 [00:52<03:06, 103.26it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=112\n",
            "  warnings.warn(\n",
            " 13%|█▎        | 2768/22015 [00:52<03:16, 97.94it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=304\n",
            "  warnings.warn(\n",
            " 14%|█▍        | 3139/22015 [00:58<03:05, 101.69it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=640\n",
            "  warnings.warn(\n",
            " 15%|█▍        | 3268/22015 [00:59<03:26, 90.77it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=176\n",
            "  warnings.warn(\n",
            " 16%|█▌        | 3428/22015 [01:01<03:18, 93.48it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=608\n",
            "  warnings.warn(\n",
            " 16%|█▌        | 3487/22015 [01:01<03:21, 91.87it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1328\n",
            "  warnings.warn(\n",
            " 17%|█▋        | 3792/22015 [01:05<03:08, 96.90it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1920\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 3931/22015 [01:07<06:00, 50.21it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=128\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 3966/22015 [01:08<06:31, 46.15it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=288\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 3998/22015 [01:08<05:48, 51.66it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2208\n",
            "  warnings.warn(\n",
            " 19%|█▉        | 4248/22015 [01:11<03:20, 88.59it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2240\n",
            "  warnings.warn(\n",
            " 20%|█▉        | 4395/22015 [01:13<03:02, 96.31it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=320\n",
            "  warnings.warn(\n",
            " 20%|██        | 4417/22015 [01:13<02:56, 99.59it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1904\n",
            "  warnings.warn(\n",
            " 20%|██        | 4469/22015 [01:14<03:21, 87.06it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2704\n",
            "  warnings.warn(\n",
            " 20%|██        | 4479/22015 [01:14<03:15, 89.54it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1728\n",
            "  warnings.warn(\n",
            " 21%|██        | 4563/22015 [01:15<03:06, 93.34it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1120\n",
            "  warnings.warn(\n",
            " 21%|██▏       | 4691/22015 [01:16<03:04, 93.67it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=368\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 4858/22015 [01:18<03:25, 83.67it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3024\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 4913/22015 [01:19<04:28, 63.60it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3984\n",
            "  warnings.warn(\n",
            " 23%|██▎       | 5108/22015 [01:22<02:58, 94.84it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=400\n",
            "  warnings.warn(\n",
            " 24%|██▍       | 5242/22015 [01:23<03:05, 90.59it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=32\n",
            "  warnings.warn(\n",
            " 26%|██▌       | 5716/22015 [01:29<03:02, 89.20it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=208\n",
            "  warnings.warn(\n",
            " 26%|██▌       | 5754/22015 [01:29<03:13, 83.94it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1504\n",
            "  warnings.warn(\n",
            " 26%|██▋       | 5782/22015 [01:29<03:05, 87.36it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3808\n",
            "  warnings.warn(\n",
            " 28%|██▊       | 6190/22015 [01:35<03:03, 86.10it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1104\n",
            "  warnings.warn(\n",
            " 29%|██▉       | 6472/22015 [01:38<02:38, 98.36it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=448\n",
            "  warnings.warn(\n",
            " 29%|██▉       | 6483/22015 [01:38<02:34, 100.27it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1152\n",
            "  warnings.warn(\n",
            " 30%|███       | 6712/22015 [01:41<02:40, 95.19it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1840\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 7224/22015 [01:48<02:55, 84.04it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3200\n",
            "  warnings.warn(\n",
            " 34%|███▎      | 7395/22015 [01:50<02:41, 90.44it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=624\n",
            "  warnings.warn(\n",
            " 34%|███▍      | 7581/22015 [01:52<02:32, 94.62it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=560\n",
            "  warnings.warn(\n",
            " 36%|███▌      | 7840/22015 [01:55<02:34, 91.55it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=480\n",
            "  warnings.warn(\n",
            " 37%|███▋      | 8117/22015 [01:59<04:59, 46.34it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1088\n",
            "  warnings.warn(\n",
            " 37%|███▋      | 8139/22015 [01:59<04:51, 47.63it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=48\n",
            "  warnings.warn(\n",
            " 38%|███▊      | 8265/22015 [02:01<02:32, 90.44it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=688\n",
            "  warnings.warn(\n",
            " 41%|████▏     | 9101/22015 [02:10<04:06, 52.45it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=416\n",
            "  warnings.warn(\n",
            " 42%|████▏     | 9319/22015 [02:14<02:25, 87.34it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=464\n",
            "  warnings.warn(\n",
            " 43%|████▎     | 9523/22015 [02:17<04:54, 42.37it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1200\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 9687/22015 [02:18<02:18, 88.75it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1584\n",
            "  warnings.warn(\n",
            " 50%|█████     | 11067/22015 [02:35<02:30, 72.93it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3776\n",
            "  warnings.warn(\n",
            " 51%|█████     | 11189/22015 [02:38<03:38, 49.60it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2736\n",
            "  warnings.warn(\n",
            " 52%|█████▏    | 11375/22015 [02:40<01:47, 99.11it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=256\n",
            "  warnings.warn(\n",
            " 52%|█████▏    | 11533/22015 [02:42<04:17, 40.75it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1712\n",
            "  warnings.warn(\n",
            " 55%|█████▍    | 12003/22015 [02:48<01:49, 91.09it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3008\n",
            "  warnings.warn(\n",
            " 56%|█████▌    | 12282/22015 [02:52<01:43, 94.08it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=496\n",
            "  warnings.warn(\n",
            " 58%|█████▊    | 12726/22015 [02:57<01:41, 91.88it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=384\n",
            "  warnings.warn(\n",
            " 58%|█████▊    | 12801/22015 [02:57<01:30, 102.00it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=944\n",
            "  warnings.warn(\n",
            " 65%|██████▍   | 14246/22015 [03:14<01:18, 99.29it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1008\n",
            "  warnings.warn(\n",
            " 65%|██████▍   | 14293/22015 [03:15<01:53, 67.97it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=352\n",
            "  warnings.warn(\n",
            " 66%|██████▌   | 14475/22015 [03:18<01:23, 90.44it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=960\n",
            "  warnings.warn(\n",
            " 66%|██████▌   | 14496/22015 [03:18<01:20, 93.50it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1040\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 14727/22015 [03:20<01:08, 106.74it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2192\n",
            "  warnings.warn(\n",
            " 72%|███████▏  | 15752/22015 [03:32<01:10, 88.98it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2560\n",
            "  warnings.warn(\n",
            " 73%|███████▎  | 16102/22015 [03:36<00:59, 98.66it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1248\n",
            "  warnings.warn(\n",
            " 73%|███████▎  | 16132/22015 [03:36<01:07, 87.18it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1072\n",
            "  warnings.warn(\n",
            " 75%|███████▌  | 16544/22015 [03:41<01:39, 55.19it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3216\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 17175/22015 [03:49<00:50, 95.45it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=0\n",
            "  warnings.warn(\n",
            " 81%|████████▏ | 17924/22015 [03:59<00:40, 102.08it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=784\n",
            "  warnings.warn(\n",
            " 82%|████████▏ | 18045/22015 [04:00<00:41, 95.81it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=160\n",
            "  warnings.warn(\n",
            " 86%|████████▌ | 18937/22015 [04:11<00:39, 78.55it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2976\n",
            "  warnings.warn(\n",
            " 87%|████████▋ | 19058/22015 [04:12<00:31, 93.70it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1056\n",
            "  warnings.warn(\n",
            " 87%|████████▋ | 19251/22015 [04:14<00:27, 100.36it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2000\n",
            "  warnings.warn(\n",
            " 88%|████████▊ | 19316/22015 [04:15<00:27, 99.68it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=752\n",
            "  warnings.warn(\n",
            " 90%|████████▉ | 19753/22015 [04:19<00:22, 100.53it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=80\n",
            "  warnings.warn(\n",
            " 93%|█████████▎| 20570/22015 [04:29<00:14, 97.82it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3408\n",
            "  warnings.warn(\n",
            "100%|██████████| 22015/22015 [04:45<00:00, 77.05it/s]\n",
            "100%|██████████| 5447/5447 [01:08<00:00, 79.27it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "n_fft = int(WINDOW_DURATION * MAX_DURATION_IN_SECONDS * SAMPLING_RATE)\n",
        "hop_length = int(STRIDE_DURATION * MAX_DURATION_IN_SECONDS * SAMPLING_RATE)\n",
        "\n",
        "train_outputs = []\n",
        "train_texts = []\n",
        "for i in tqdm(range(len(truncated_gs_train))):\n",
        "  S = librosa.feature.melspectrogram(\n",
        "      y=truncated_gs_train[i]['audio']['array'],\n",
        "      sr=SAMPLING_RATE,\n",
        "      n_mels=N_MELS,\n",
        "      n_fft=n_fft,\n",
        "      hop_length=hop_length,\n",
        "      win_length=n_fft,\n",
        "      fmax=SAMPLING_RATE // 2\n",
        "  )\n",
        "\n",
        "\n",
        "  S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "  train_outputs.append(S_dB)\n",
        "  train_texts.append(truncated_gs_train[i]['text'])\n",
        "\n",
        "val_outputs = []\n",
        "val_texts = []\n",
        "for i in tqdm(range(len(truncated_gs_val))):\n",
        "  S = librosa.feature.melspectrogram(\n",
        "      y=truncated_gs_val[i]['audio']['array'],\n",
        "      sr=SAMPLING_RATE,\n",
        "      n_mels=N_MELS,\n",
        "      n_fft=n_fft,\n",
        "      hop_length=hop_length,\n",
        "      win_length=n_fft,\n",
        "      fmax=SAMPLING_RATE // 2\n",
        "  )\n",
        "\n",
        "\n",
        "  S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "  val_outputs.append(S_dB)\n",
        "  val_texts.append(truncated_gs_val[i]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "_cell_guid": "db1f5e13-91c6-4d24-8d31-325796a8a0fd",
        "_uuid": "b456c1a6-6703-4809-a1fb-fc077a5dc8e3",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:23.219755Z",
          "iopub.status.busy": "2025-03-16T21:17:23.219057Z",
          "iopub.status.idle": "2025-03-16T21:17:23.229394Z",
          "shell.execute_reply": "2025-03-16T21:17:23.228433Z",
          "shell.execute_reply.started": "2025-03-16T21:17:23.219721Z"
        },
        "id": "z2aGf6_7xe9S",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# import math\n",
        "# print(round(random.random(), 1))\n",
        "class GigaSpeechDataset(Dataset):\n",
        "\n",
        "  def __init__(self, outputs, texts):\n",
        "\n",
        "    self.data = outputs\n",
        "    self.texts = texts\n",
        "    self.max_t = block_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "\n",
        "  def pad_to_max_t(self, spectrogram, max_t):\n",
        "\n",
        "    n_mels, t = spectrogram.shape\n",
        "    if t < max_t:\n",
        "        # Pad with zeros\n",
        "        pad_width = ((0, 0), (0, max_t - t))\n",
        "        spectrogram = np.pad(spectrogram, pad_width, mode='constant')\n",
        "    else:\n",
        "      spectrogram = spectrogram[:, :max_t]\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "  def clean(self, desc):\n",
        "    # Use regex to remove anything between < and >\n",
        "    cleaned_text = re.sub(r'<[^>]*>', '', desc)\n",
        "    return cleaned_text\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "      SOT = '<|startoftranscript|>'\n",
        "      EOT = '<|endoftranscript|>'\n",
        "      transcribe = '<|transcribe|>'\n",
        "      # prev = '<|prev|>'\n",
        "      spectrogram = self.pad_to_max_t(self.data[idx], self.max_t)\n",
        "      # probs = round(random.random(),1)\n",
        "      spectrogram = torch.tensor(spectrogram, dtype=torch.float32)\n",
        "\n",
        "      # if(probs == 0.5):\n",
        "        # Normalize the spectrogram between -1 and 1\n",
        "      spectrogram_min = spectrogram.min()\n",
        "      spectrogram_max = spectrogram.max()\n",
        "      # spectrogram = spectrogram.unsqueeze(0)  # Shape: (1, n_mels, max_t)\n",
        "      # prev_text =\n",
        "      text = self.clean(self.texts[idx])\n",
        "\n",
        "      text = text.lower()\n",
        "      text = SOT  + 'en' + transcribe +  text + EOT\n",
        "      tokenized_text = tokenizer(text, truncation=True, padding='max_length', max_length=block_size, return_tensors='pt')\n",
        "      # print(tokenized_text.shape)\n",
        "\n",
        "      epsilon = 1e-8  # To avoid division by zero\n",
        "      spectrogram = 2 * ((spectrogram - spectrogram_min) / (spectrogram_max - spectrogram_min + epsilon)) - 1\n",
        "\n",
        "      # tokenized_win_prompt = tokenizer(text, max_length = ModelArgs.block_size, padding='max_length', truncation=True,  return_tensors=\"pt\").to(device)\n",
        "      tokenized_text['labels'] = tokenized_text['input_ids'].clone()\n",
        "      tokenized_text['labels'][: , :-1] = tokenized_text['input_ids'][: , 1:]\n",
        "      tokenized_text['labels'][: , -1] = tokenizer.eos_token_id\n",
        "\n",
        "      tokenized_text_x = tokenized_text['input_ids'].squeeze(0)\n",
        "      tokenized_text_y = tokenized_text['labels'].squeeze(0)\n",
        "\n",
        "      # print(tokenized_text.shape)\n",
        "      return spectrogram, tokenized_text_x, tokenized_text_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "_cell_guid": "78e27c8d-e3cd-434c-b2c6-9d16b79eb5be",
        "_uuid": "5ca81223-5c7e-43e5-83b2-7b00a3ecee7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:23.230758Z",
          "iopub.status.busy": "2025-03-16T21:17:23.230437Z",
          "iopub.status.idle": "2025-03-16T21:17:23.258809Z",
          "shell.execute_reply": "2025-03-16T21:17:23.257804Z",
          "shell.execute_reply.started": "2025-03-16T21:17:23.230731Z"
        },
        "id": "2FJvDV-4psOo",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "c29e55d1-bc8e-4a41-cbf3-8581643e8774",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7e89fccd54d0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.autograd.set_detect_anomaly(True)  # Add at the start of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "_cell_guid": "d26cf6eb-55b2-484c-bc9b-10952ea5c977",
        "_uuid": "8db84c70-d655-4b7c-8c00-9e195d240a7d",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:23.260278Z",
          "iopub.status.busy": "2025-03-16T21:17:23.259908Z",
          "iopub.status.idle": "2025-03-16T21:17:23.478760Z",
          "shell.execute_reply": "2025-03-16T21:17:23.477736Z",
          "shell.execute_reply.started": "2025-03-16T21:17:23.260242Z"
        },
        "id": "2tvMuBSOynPy",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "shuffle = True\n",
        "\n",
        "train_dataset = GigaSpeechDataset(train_outputs, train_texts)\n",
        "val_dataset = GigaSpeechDataset(val_outputs, val_texts)\n",
        "\n",
        "generator = torch.Generator(device=device)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    generator=generator,\n",
        "    shuffle=shuffle,\n",
        "     drop_last=True,\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    generator=generator,\n",
        "    drop_last=True ,\n",
        "    shuffle=shuffle,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "_cell_guid": "b0074df8-52c7-45e7-99d2-7aeb8f646a6b",
        "_uuid": "d681546c-459b-4cdf-b52d-256e7113beb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:23.480097Z",
          "iopub.status.busy": "2025-03-16T21:17:23.479814Z",
          "iopub.status.idle": "2025-03-16T21:17:25.574570Z",
          "shell.execute_reply": "2025-03-16T21:17:25.573700Z",
          "shell.execute_reply.started": "2025-03-16T21:17:23.480071Z"
        },
        "id": "q24cqT4spsOo",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "259e6e60-5ffd-45d8-8e6e-38801d6f50c7",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[[ 0.0780,  0.0936,  0.0573,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-0.0644, -0.0214, -0.0714,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-0.0306,  0.0863,  0.0157,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          ...,\n",
              "          [-0.7941, -0.7736, -0.4947,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-0.8894, -0.8927, -0.5498,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-1.0000, -1.0000, -0.7846,  ...,  1.0000,  1.0000,  1.0000]],\n",
              " \n",
              "         [[ 0.1950,  0.3272,  0.2966,  ...,  0.1410,  0.1800,  0.1949],\n",
              "          [ 0.0017,  0.1503,  0.2539,  ...,  0.6934,  0.6541,  0.3316],\n",
              "          [ 0.1217,  0.1364,  0.1832,  ...,  0.7802,  0.8221,  0.8245],\n",
              "          ...,\n",
              "          [-0.8344, -0.3634,  0.1816,  ..., -0.5553, -0.7330, -0.5329],\n",
              "          [-0.8927, -0.4419,  0.1594,  ..., -0.6708, -0.8179, -0.6232],\n",
              "          [-0.9280, -0.5527, -0.0112,  ..., -0.9269, -0.9857, -0.8396]],\n",
              " \n",
              "         [[-0.3366, -0.1151, -0.1663,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-0.1328,  0.1485, -0.0497,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [ 0.4509,  0.8468,  0.8320,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          ...,\n",
              "          [-0.2680, -0.1457, -0.2012,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-0.3068, -0.1968, -0.2665,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-0.7405, -0.4853, -0.5424,  ...,  1.0000,  1.0000,  1.0000]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-0.3371, -0.3047, -0.3712,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-0.3517, -0.0938,  0.1542,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [ 0.4177,  0.5752,  0.4267,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          ...,\n",
              "          [-1.0000, -0.9019, -1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
              " \n",
              "         [[-0.4453, -0.1303,  0.1016,  ...,  0.1646,  0.1313,  0.1663],\n",
              "          [-0.3177,  0.0524,  0.1493,  ...,  0.2692,  0.2174,  0.1970],\n",
              "          [-0.2943, -0.0062,  0.0387,  ...,  0.3356,  0.2045,  0.1870],\n",
              "          ...,\n",
              "          [-0.8367, -0.9354, -0.5060,  ..., -0.4079, -0.2740, -0.3038],\n",
              "          [-0.8710, -1.0000, -0.5612,  ..., -0.5431, -0.3213, -0.3475],\n",
              "          [-0.9107, -1.0000, -0.6919,  ..., -0.7261, -0.4293, -0.5329]],\n",
              " \n",
              "         [[-0.0888, -0.0328, -0.0456,  ...,  0.2652,  0.1925,  0.3487],\n",
              "          [-0.0141,  0.0354,  0.0225,  ...,  0.1357,  0.1219,  0.1930],\n",
              "          [-0.1155, -0.1016, -0.1022,  ...,  0.4343,  0.2666,  0.1126],\n",
              "          ...,\n",
              "          [-1.0000, -0.9922, -1.0000,  ..., -0.9029, -0.9581, -0.8639],\n",
              "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9332],\n",
              "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
              "        device='cuda:0'),\n",
              " tensor([[50258,   268, 50260,  ..., 50257, 50257, 50257],\n",
              "         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n",
              "         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n",
              "         ...,\n",
              "         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n",
              "         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n",
              "         [50258,   268, 50260,  ..., 50257, 50257, 50257]], device='cuda:0'),\n",
              " tensor([[  268, 50260,  7091,  ..., 50257, 50257, 50256],\n",
              "         [  268, 50260, 50259,  ..., 50257, 50257, 50256],\n",
              "         [  268, 50260,   388,  ..., 50257, 50257, 50256],\n",
              "         ...,\n",
              "         [  268, 50260,  2197,  ..., 50257, 50257, 50256],\n",
              "         [  268, 50260,    72,  ..., 50257, 50257, 50256],\n",
              "         [  268, 50260,  1169,  ..., 50257, 50257, 50256]], device='cuda:0')]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "_cell_guid": "a7c6dcaa-5a5d-4260-8696-ee827274edff",
        "_uuid": "25ee96a4-00b2-40a5-a8e4-10ea78a00481",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.575666Z",
          "iopub.status.busy": "2025-03-16T21:17:25.575422Z",
          "iopub.status.idle": "2025-03-16T21:17:25.580222Z",
          "shell.execute_reply": "2025-03-16T21:17:25.579208Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.575643Z"
        },
        "id": "kzXk76ULY3gm",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Position embeddings\n",
        "class PositionEmbeddings(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        block_size = block_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.position_embeddings = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n",
        "        # nn.init.normal_(self.position_embeddings.weight.data, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.position_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "_cell_guid": "779e1bc7-798e-4e86-ad9e-0967b08dcab9",
        "_uuid": "6c495fe4-d351-4477-be75-b575ea534db0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.581153Z",
          "iopub.status.busy": "2025-03-16T21:17:25.580958Z",
          "iopub.status.idle": "2025-03-16T21:17:25.631084Z",
          "shell.execute_reply": "2025-03-16T21:17:25.630436Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.581135Z"
        },
        "id": "-p1sURm3psOp",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "624d4ea0-be1e-4c06-bcfc-55f0a70b2b67",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[ 0.3495,  0.6073, -1.3787,  ..., -0.6898,  2.2222, -1.2482],\n",
              "         [ 1.2467,  0.5727, -0.5820,  ...,  0.7372, -0.1024,  1.8049],\n",
              "         [ 1.9835,  1.1466, -1.0870,  ...,  0.3833,  1.0924, -1.0911],\n",
              "         ...,\n",
              "         [-0.4632, -0.1689, -0.2957,  ...,  0.1328, -0.2095, -1.5386],\n",
              "         [ 0.2848, -1.3799,  1.5286,  ..., -0.3578, -0.1225, -0.7640],\n",
              "         [ 1.0754,  1.2897, -1.1724,  ...,  0.4539, -0.2270, -1.5164]]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos = PositionEmbeddings()\n",
        "x = torch.randn(batch_size, block_size, embeddings_dims)\n",
        "pos(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "_cell_guid": "62818f89-119f-4059-8538-2feefb03e6a7",
        "_uuid": "8c520ea7-c368-4ce4-914c-2094cb5ed848",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.631941Z",
          "iopub.status.busy": "2025-03-16T21:17:25.631754Z",
          "iopub.status.idle": "2025-03-16T21:17:25.636182Z",
          "shell.execute_reply": "2025-03-16T21:17:25.635330Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.631924Z"
        },
        "id": "R9CSiuD2jHyT",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Text embeddings\n",
        "class TgtTextEmbeddings(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size = tgt_vocab_size,\n",
        "        embeddings_dims = embeddings_dims\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embeddings_table = nn.Embedding(num_embeddings = tgt_vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n",
        "        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embeddings_table(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "_cell_guid": "0e795d31-2801-446a-807d-0ea3bebb6e3d",
        "_uuid": "ae3226bb-4414-4840-8da7-73db14ad8271",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.637345Z",
          "iopub.status.busy": "2025-03-16T21:17:25.637118Z",
          "iopub.status.idle": "2025-03-16T21:17:25.653427Z",
          "shell.execute_reply": "2025-03-16T21:17:25.652838Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.637325Z"
        },
        "id": "REUDHWrWcuoN",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "#Layer Normalization\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embeddings_dims = embeddings_dims\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if(use_liger == False):\n",
        "            self.norm = nn.LayerNorm(normalized_shape=embeddings_dims)\n",
        "        else:\n",
        "            self.norm = LigerLayerNorm(normalized_shape=embeddings_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "_cell_guid": "762624a5-8d63-403b-bc4e-039b16aba3f9",
        "_uuid": "70301094-ba8a-4078-a1ad-46dc8d357f6a",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.654302Z",
          "iopub.status.busy": "2025-03-16T21:17:25.654077Z",
          "iopub.status.idle": "2025-03-16T21:17:25.672472Z",
          "shell.execute_reply": "2025-03-16T21:17:25.671677Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.654281Z"
        },
        "id": "lEe02cH9cuoN",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "#FeedForward Neural Network\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dropout = dropout,\n",
        "        embeddings_size = embeddings_dims,\n",
        "        # inner_dimensional_states: int = 3072\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(device=device, in_features=embeddings_size, out_features= 4 * embeddings_dims),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(device=device, in_features= 4 * embeddings_dims, out_features=embeddings_size),\n",
        "            nn.Dropout(p = dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mlp_weights_init = self.mlp.apply(weights_init)\n",
        "        return self.mlp(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "_cell_guid": "50c3f233-f3ea-44cc-bccf-10aa13fc35d5",
        "_uuid": "bd1f493a-c5eb-4821-938b-1fd4baf55549",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.673679Z",
          "iopub.status.busy": "2025-03-16T21:17:25.673386Z",
          "iopub.status.idle": "2025-03-16T21:17:25.693459Z",
          "shell.execute_reply": "2025-03-16T21:17:25.692644Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.673647Z"
        },
        "id": "cf0Jf_7UcuoN",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class MaskedAttentionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.head_size = embeddings_dims // no_of_heads\n",
        "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
        "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
        "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        batch, block_size, embd_dims = x.shape\n",
        "        k = self.keys(x)\n",
        "        q = self.query(x)\n",
        "        v = self.values(x)\n",
        "        if(use_flash_attebntion == False):\n",
        "            masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "            weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
        "            masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n",
        "            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "            weights_normalized = self.dropout(weights_normalized)\n",
        "            out = weights_normalized @ v\n",
        "            return out\n",
        "        else:\n",
        "            out = torch.nn.functional.scaled_dot_product_attention(q, k, v, dropout_p=dropout ,is_causal=True)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "_cell_guid": "aee629bd-84ad-4f0c-a0e7-9e3070e10081",
        "_uuid": "a252848c-a0b1-4c08-8a42-e2851e642a06",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.694740Z",
          "iopub.status.busy": "2025-03-16T21:17:25.694382Z",
          "iopub.status.idle": "2025-03-16T21:17:25.713823Z",
          "shell.execute_reply": "2025-03-16T21:17:25.712953Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.694708Z"
        },
        "id": "OUFERSL2u8LT",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class MaskedMHA(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([MaskedAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
        "\n",
        "    def forward(self, x):\n",
        "        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "        linear_layer = self.linear(concat)\n",
        "        out = self.dropout(linear_layer)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "_cell_guid": "76ee1dab-07cf-4ae4-ac9a-3c134b9dc41d",
        "_uuid": "0bdd11ba-b65a-4dbe-9b09-25d24c2b3ab6",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.714859Z",
          "iopub.status.busy": "2025-03-16T21:17:25.714607Z",
          "iopub.status.idle": "2025-03-16T21:17:25.736087Z",
          "shell.execute_reply": "2025-03-16T21:17:25.735469Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.714838Z"
        },
        "id": "oGGyyF4pjHyd",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Single Attention Head\n",
        "\n",
        "class CrossAttentionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.head_size = embeddings_dims // no_of_heads\n",
        "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
        "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
        "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "\n",
        "\n",
        "        batch, block_size, embd_dims = query.shape\n",
        "        q = self.query(query)\n",
        "        k = self.keys(key)\n",
        "        v = self.values(value)\n",
        "        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "        # weights = query @ torch.transpose(key, dim0=-2, dim1=-1) * (key.shape[-1] ** -0.5)\n",
        "        # if(mask != None):\n",
        "        #     mask = mask.unsqueeze(1)\n",
        "        #     masked_values = weights.masked_fill(mask == 0, float('-inf'))\n",
        "        #     weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "        #     # weights_normalized = self.dropout(weights_normalized)\n",
        "        #     out = weights_normalized @ value\n",
        "        #     out = self.dropout(out)\n",
        "        #     return out\n",
        "        # else:\n",
        "        #     weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "        #     # weights_normalized = self.dropout(weights_normalized)\n",
        "        #     out = weights_normalized @ value\n",
        "        #     out = self.dropout(out)\n",
        "        #     return out\n",
        "\n",
        "        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
        "        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n",
        "        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "        weights_normalized = self.dropout(weights_normalized)\n",
        "        out = weights_normalized @ v\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "_cell_guid": "bcde57b5-61a0-4d56-aa5a-5fbbc2f2a9bd",
        "_uuid": "af55eb4d-6d72-465f-8692-4777da91e56f",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.737123Z",
          "iopub.status.busy": "2025-03-16T21:17:25.736929Z",
          "iopub.status.idle": "2025-03-16T21:17:25.763686Z",
          "shell.execute_reply": "2025-03-16T21:17:25.762859Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.737106Z"
        },
        "id": "U5NmszzcjHyf",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Single Attention Head\n",
        "\n",
        "class FullAttentionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.head_size = embeddings_dims // no_of_heads\n",
        "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
        "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
        "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # batch, block_size, embd_dims = x.shape\n",
        "        k = self.keys(x)\n",
        "        q = self.query(x)\n",
        "        v = self.values(x)\n",
        "        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
        "        if(mask != None):\n",
        "            mask = mask.unsqueeze(1)\n",
        "            masked_values = weights.masked_fill(mask == 0, float('-inf'))\n",
        "            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "            # weights_normalized = self.dropout(weights_normalized)\n",
        "            out = weights_normalized @ v\n",
        "            out = self.dropout(out)\n",
        "            return out\n",
        "        else:\n",
        "            weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "            # weights_normalized = self.dropout(weights_normalized)\n",
        "            out = weights_normalized @ v\n",
        "            out = self.dropout(out)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "_cell_guid": "8099497c-1f19-4d53-8965-ae8f153335be",
        "_uuid": "50fee96b-7dae-4da2-951a-b06330293a3e",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.765002Z",
          "iopub.status.busy": "2025-03-16T21:17:25.764640Z",
          "iopub.status.idle": "2025-03-16T21:17:25.787092Z",
          "shell.execute_reply": "2025-03-16T21:17:25.786217Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.764968Z"
        },
        "id": "v_BB7r7kqmOc",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "class FullMHA(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([FullAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        concat = torch.cat([head(x, mask) for head in self.heads], dim=-1)\n",
        "        linear_layer = self.linear(concat)\n",
        "        out = self.dropout(linear_layer)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "_cell_guid": "06ee6670-5428-4e5a-867e-cdd98cddc2aa",
        "_uuid": "3627fa0f-bd35-4dab-9451-03a2b716732b",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.788020Z",
          "iopub.status.busy": "2025-03-16T21:17:25.787815Z",
          "iopub.status.idle": "2025-03-16T21:17:25.809259Z",
          "shell.execute_reply": "2025-03-16T21:17:25.808685Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.788001Z"
        },
        "id": "TTwRkBzcvE-_",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class CrossMHA(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([CrossAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False)\n",
        "\n",
        "    def forward(self, value, key, x, mask=None):\n",
        "        concat = torch.cat([head(x, key, value,  mask) for head in self.heads], dim=-1)\n",
        "        linear_layer = self.linear(concat)\n",
        "        out = self.dropout(linear_layer)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "_cell_guid": "2e095386-2ee5-4a3c-83bb-cad96cb26746",
        "_uuid": "2c290085-c1fe-4c64-9bab-baa448c3bae5",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.810295Z",
          "iopub.status.busy": "2025-03-16T21:17:25.810050Z",
          "iopub.status.idle": "2025-03-16T21:17:25.826116Z",
          "shell.execute_reply": "2025-03-16T21:17:25.825190Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.810261Z"
        },
        "id": "s9rJzO_XcuoO",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Decoder Block\n",
        "\n",
        "class TransformerDecoderBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        dropout = dropout,\n",
        "        # vocab_size = vocab_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cross = CrossMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
        "        self.masked = MaskedMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
        "        self.layer_norm1 = LayerNormalization(embeddings_dims)\n",
        "        self.layer_norm2 = LayerNormalization(embeddings_dims)\n",
        "        # self.layer_norm3 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
        "        self.layer_norm4 = LayerNormalization(embeddings_dims)\n",
        "        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n",
        "\n",
        "    def forward(self, key, value, x, mask=None):\n",
        "        x = self.layer_norm1(x + self.masked(x)) #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n",
        "        # print(x.shape)\n",
        "        x = self.layer_norm2(x + self.cross(value, key, x, mask)) #Very important step\n",
        "        # print(x.shape)\n",
        "        # x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n",
        "        x = self.layer_norm4(x + self.mlp_block(x)) #Very important step\n",
        "        # print(x.shape)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "_cell_guid": "63e5400a-b5d2-4ef7-8f30-b1bc0e233820",
        "_uuid": "05fd4f49-cc4b-474c-9a9c-3d5191eefa43",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.827199Z",
          "iopub.status.busy": "2025-03-16T21:17:25.826969Z",
          "iopub.status.idle": "2025-03-16T21:17:25.850583Z",
          "shell.execute_reply": "2025-03-16T21:17:25.849957Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.827178Z"
        },
        "id": "KGh8ujQJcuoO",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Decoder Block\n",
        "\n",
        "class DecoderModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        block_size = block_size,\n",
        "        dropout = dropout,\n",
        "        no_of_decoder_layers = no_of_decoder_layers,\n",
        "        # vocab_size = vocab_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n",
        "        # self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
        "        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n",
        "        self.decoder_layers = nn.ModuleList([TransformerDecoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n",
        "        self.apply(self._init_weights)\n",
        "        # self.positional_embeddings_tgt = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n",
        "        self.positional_embeddings_tgt = PositionEmbeddings()\n",
        "        # torch.nn.init.normal_(self.positional_embeddings_tgt, mean=0.0, std=0.02)\n",
        "\n",
        "        # out = self.decoder_layers(query, key, x)\n",
        "        # Loop through each decoder layer\n",
        "    def _init_weights(self, module):  #Weight Initialization\n",
        "            if isinstance(module, nn.Linear):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    torch.nn.init.zeros_(module.bias)\n",
        "            elif isinstance(module, nn.Embedding):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, key, value, x, mask):\n",
        "        # x = self.tgt_text_embds(x)\n",
        "        x = x + self.positional_embeddings_tgt(x)\n",
        "        # print(x.shape)\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "            x = decoder_layer(key, value, x, mask)\n",
        "        # x = self.layer_norm(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "_cell_guid": "5327372f-0db3-4ef1-a59c-1757b6edfc62",
        "_uuid": "1e94a41d-aaa3-4e74-a02f-fb0edbfa9118",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.854582Z",
          "iopub.status.busy": "2025-03-16T21:17:25.854371Z",
          "iopub.status.idle": "2025-03-16T21:17:25.876149Z",
          "shell.execute_reply": "2025-03-16T21:17:25.875339Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.854563Z"
        },
        "id": "A3SgKrC-jHyd",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "_cell_guid": "2a3683d1-303c-41a2-9cc6-b7e053fde34c",
        "_uuid": "3ecc13cd-e38a-4e1c-af9c-10f8e84b02d7",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.878065Z",
          "iopub.status.busy": "2025-03-16T21:17:25.877823Z",
          "iopub.status.idle": "2025-03-16T21:17:25.893369Z",
          "shell.execute_reply": "2025-03-16T21:17:25.892523Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.878033Z"
        },
        "id": "v6mbbO3yp-gh",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        dropout = dropout,\n",
        "        mask=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = FullMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
        "        self.layer_norm1 = LayerNormalization(embeddings_dims)\n",
        "        self.layer_norm2 = LayerNormalization(embeddings_dims)\n",
        "        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.layer_norm1(x + self.mha(x, mask))\n",
        "        x = self.layer_norm2(x + self.mlp_block(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "_cell_guid": "2fa82426-e551-497d-8247-051a55f74a3c",
        "_uuid": "39475274-a828-4151-9556-fa4bf30d4455",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.894660Z",
          "iopub.status.busy": "2025-03-16T21:17:25.894341Z",
          "iopub.status.idle": "2025-03-16T21:17:25.916685Z",
          "shell.execute_reply": "2025-03-16T21:17:25.915829Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.894605Z"
        },
        "id": "HxW0pvnV12Ms",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class EncoderModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        block_size = block_size,\n",
        "        dropout = dropout,\n",
        "        no_of_decoder_layers = no_of_decoder_layers,\n",
        "        # vocab_size = vocab_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # self.positional_embeddings_src = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=n_channels, out_channels=embeddings_dims, kernel_size=kernel_size, device=device, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=embeddings_dims, out_channels=embeddings_dims, kernel_size=kernel_size, device=device, padding=1)\n",
        "\n",
        "        self.positional_embeddings_src = PositionEmbeddings()\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([TransformerEncoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):  #Weight Initialization\n",
        "            if isinstance(module, nn.Linear):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    torch.nn.init.zeros_(module.bias)\n",
        "            elif isinstance(module, nn.Embedding):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = torch.nn.functional.gelu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.nn.functional.gelu(x)\n",
        "        # print(x.shape)\n",
        "        # x = self.src_text_embeds(x)\n",
        "        # print(self.positional_embeddings_src.shape)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        # print(x.shape)\n",
        "        # print(self.positional_embeddings_src(x).shape)\n",
        "        x = x + self.positional_embeddings_src(x)\n",
        "        # print(x)\n",
        "        # print(x.shape)\n",
        "        # Loop through each encoder layer\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            x = encoder_layer(x, mask)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "_cell_guid": "ad3a1595-5722-4fff-a54e-87e3bb755abe",
        "_uuid": "249cf674-9b8b-406a-920d-603c6c2f00ff",
        "id": "Qi3v6jczY3go",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "_cell_guid": "a6d4d773-0ed2-4059-ab2b-683692ce2c32",
        "_uuid": "6f0e32f9-14f2-4b65-a106-cab2051ad125",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.917942Z",
          "iopub.status.busy": "2025-03-16T21:17:25.917671Z",
          "iopub.status.idle": "2025-03-16T21:17:25.937565Z",
          "shell.execute_reply": "2025-03-16T21:17:25.936953Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.917913Z"
        },
        "id": "2UWijIFl2Ykd",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = EncoderModel()\n",
        "        self.decoder = DecoderModel()\n",
        "        # self.pos = PositionalEmbeddings()\n",
        "        self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n",
        "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
        "        # self.src_text_embeds = SrcTextEmbeddings(vocab_size=src_vocab_size, embeddings_dims=embeddings_dims)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, actual_labels=None):\n",
        "        # x = self.src_text_embeds(src)\n",
        "        x = self.encoder(src, src_mask)\n",
        "        y = self.tgt_text_embds(tgt)\n",
        "        # print(x.shape)\n",
        "        y = self.decoder(x, x, y, tgt_mask)\n",
        "        # print(y.shape)\n",
        "        if(use_liger):\n",
        "            linear = self.linear_layer(y)\n",
        "            res = LigerFusedLinearCrossEntropyLoss(linear.weight, actual_labels, y)\n",
        "            return res\n",
        "        else:\n",
        "            out = self.linear_layer(y)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "_cell_guid": "17dd187f-c195-44a0-990c-c6d17c90227e",
        "_uuid": "e407283d-b631-479c-9bae-014aab7a0a3d",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:25.938678Z",
          "iopub.status.busy": "2025-03-16T21:17:25.938378Z",
          "iopub.status.idle": "2025-03-16T21:17:26.442178Z",
          "shell.execute_reply": "2025-03-16T21:17:26.441341Z",
          "shell.execute_reply.started": "2025-03-16T21:17:25.938647Z"
        },
        "id": "ntIaQj1U3pFX",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Instantiating the model\n",
        "model = Transformer()\n",
        "# model = torch.compile(model)\n",
        "# model = model.to(device)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "_cell_guid": "4f4d8f86-6a6c-43fe-8a7f-06301998ac15",
        "_uuid": "3efcd10c-fbd4-4818-b23b-636503f4df30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:26.443631Z",
          "iopub.status.busy": "2025-03-16T21:17:26.443241Z",
          "iopub.status.idle": "2025-03-16T21:17:26.730652Z",
          "shell.execute_reply": "2025-03-16T21:17:26.729694Z",
          "shell.execute_reply.started": "2025-03-16T21:17:26.443574Z"
        },
        "id": "Y_T--TYbpsOq",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "d1233863-c0aa-46a6-cab0-86a7fde1ada8",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1220"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "_cell_guid": "130524f5-869f-4ea2-8cb7-5de2780ed66a",
        "_uuid": "3ecf1b70-4a77-4786-bdbd-df86011c7d31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:26.732102Z",
          "iopub.status.busy": "2025-03-16T21:17:26.731735Z",
          "iopub.status.idle": "2025-03-16T21:17:26.758778Z",
          "shell.execute_reply": "2025-03-16T21:17:26.757829Z",
          "shell.execute_reply.started": "2025-03-16T21:17:26.732063Z"
        },
        "id": "7wQoqS77psOr",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "f106c6a6-6286-452b-f792-8c7410939e32",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[40881, 40758, 39215,  ...,  4273, 33545, 12089],\n",
              "        [41156, 12515,  1242,  ..., 44457, 34477, 41097],\n",
              "        [13258, 45885, 48303,  ..., 42415,  7490, 39716],\n",
              "        ...,\n",
              "        [14931, 15291, 26114,  ..., 29419,  8344, 41207],\n",
              "        [26139, 37021, 31918,  ..., 32901, 26692, 38368],\n",
              "        [47027, 32866,  2893,  ...,  1025, 11696, 12860]], device='cuda:0')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n",
        "tgt_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "_cell_guid": "d92d3629-d59c-4361-9572-8e0075329808",
        "_uuid": "5061d499-36a9-427b-90ad-eead117d5a51",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:17:26.759979Z",
          "iopub.status.busy": "2025-03-16T21:17:26.759689Z",
          "iopub.status.idle": "2025-03-16T21:17:31.629859Z",
          "shell.execute_reply": "2025-03-16T21:17:31.628564Z",
          "shell.execute_reply.started": "2025-03-16T21:17:26.759955Z"
        },
        "id": "yOXtmG-lcuoO",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "spec, text = next(iter(train_dataloader))\n",
        "tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n",
        "spec = spec.to(device)\n",
        "texts = text.to(device)\n",
        "\n",
        "summary(model=model,\n",
        "        input_data=(spec, texts),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "_cell_guid": "97226398-cb33-48d6-9abc-f5a9c549b5c5",
        "_uuid": "ee98acba-6992-4b1e-8cc1-3eda3997ae5b",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:47.480394Z",
          "iopub.status.busy": "2025-03-16T21:18:47.480025Z",
          "iopub.status.idle": "2025-03-16T21:18:47.490347Z",
          "shell.execute_reply": "2025-03-16T21:18:47.489487Z",
          "shell.execute_reply.started": "2025-03-16T21:18:47.480363Z"
        },
        "id": "LH95cJEvcuoO",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Optimizer setup and scheduler steup\n",
        "# out = {\"Train\": None, \"val\": None}\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "_cell_guid": "53e031da-134a-4271-8879-b012f262ccc6",
        "_uuid": "7860931f-c816-4796-b4c5-265e3df9bf57",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:47.977592Z",
          "iopub.status.busy": "2025-03-16T21:18:47.977290Z",
          "iopub.status.idle": "2025-03-16T21:18:47.981528Z",
          "shell.execute_reply": "2025-03-16T21:18:47.980718Z",
          "shell.execute_reply.started": "2025-03-16T21:18:47.977569Z"
        },
        "id": "bbvONdUTWmvL",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "scaler = torch.amp.GradScaler(enabled=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "_cell_guid": "58095701-5ad6-4bd6-bc30-0b1422af2a93",
        "_uuid": "6d9f8456-d5da-49d1-8211-c97897782909",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:48.014114Z",
          "iopub.status.busy": "2025-03-16T21:18:48.013911Z",
          "iopub.status.idle": "2025-03-16T21:18:48.018021Z",
          "shell.execute_reply": "2025-03-16T21:18:48.017242Z",
          "shell.execute_reply.started": "2025-03-16T21:18:48.014096Z"
        },
        "id": "MdhqasdjpsOr",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def _save_snapshot(model, optimizer, scheduler, epoch, step):\n",
        "    snapshot = {\n",
        "        \"MODEL_STATE\": model.state_dict(),\n",
        "        \"OPTIMIZER_STATE\": optimizer.state_dict(),\n",
        "        # \"SCHEDULER_STATE\": scheduler.state_dict(),\n",
        "        \"EPOCHS_RUN\": epoch,\n",
        "        \"STEP_RUN\": step\n",
        "    }\n",
        "    torch.save(snapshot, f\"snapshot_{step}.pt\")\n",
        "    print(f\"Epoch: {epoch} | Step: {step} | Snapshot saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "_cell_guid": "6f951a8f-3f05-4b6a-9080-99a81e5925b0",
        "_uuid": "9f8791fb-3c63-4871-8402-fbfb2a649e89",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:48.045122Z",
          "iopub.status.busy": "2025-03-16T21:18:48.044918Z",
          "iopub.status.idle": "2025-03-16T21:18:48.048197Z",
          "shell.execute_reply": "2025-03-16T21:18:48.047524Z",
          "shell.execute_reply.started": "2025-03-16T21:18:48.045104Z"
        },
        "id": "wBo4MmRopsOr",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !pip install torchtriton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "_cell_guid": "2fc4d2f7-40d4-4733-8e32-65c38f198b5e",
        "_uuid": "5582f78b-b57d-484e-bfa5-66a2688a6e21",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:48.069834Z",
          "iopub.status.busy": "2025-03-16T21:18:48.069579Z",
          "iopub.status.idle": "2025-03-16T21:18:48.074196Z",
          "shell.execute_reply": "2025-03-16T21:18:48.073418Z",
          "shell.execute_reply.started": "2025-03-16T21:18:48.069814Z"
        },
        "id": "EpyoWzdxpsOr",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "save_chechpoint_iter = 50\n",
        "total_iters = 20000\n",
        "eval_iters = 50\n",
        "eval_check = 100\n",
        "warmup_iters = 2048\n",
        "min_lr = 0.1 * max_lr\n",
        "lr_decay_iters = 20000\n",
        "total_batch_size = 524288\n",
        "micro_batch_size = batch_size\n",
        "gradient_accumulation_steps = total_batch_size // (micro_batch_size * (block_size * torch.cuda.device_count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "_cell_guid": "20e917d1-9770-456a-99dd-5e9c33d4edda",
        "_uuid": "a0929ebe-c656-48ba-b479-e08113f3113e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:48.108479Z",
          "iopub.status.busy": "2025-03-16T21:18:48.108253Z",
          "iopub.status.idle": "2025-03-16T21:18:48.126877Z",
          "shell.execute_reply": "2025-03-16T21:18:48.126223Z",
          "shell.execute_reply.started": "2025-03-16T21:18:48.108459Z"
        },
        "id": "oATkWQfApsOs",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "7e06c1e1-5d5b-4870-9bf1-5edabb88e42b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaders ready both\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "world_size = torch.cuda.device_count()\n",
        "@torch.inference_mode()\n",
        "def estimate_loss(val_loader, val_iterator, device):\n",
        "    out = {}\n",
        "    # train_loader = prepare_dataset('train', ModelArgs.batch_size)\n",
        "\n",
        "    # val_loader_iterator = iter(val_loader)\n",
        "    loader = None\n",
        "    epoch_loss = None\n",
        "    epoch_losses = []\n",
        "    # print(\"Starting the eval...\")\n",
        "    for split in ['val']:\n",
        "        print(f\"Starting with {split} evaluation...\")\n",
        "        # losses = torch.zeros(ModelArgs.val_epochs)\n",
        "        # if(split == 'train'):\n",
        "        #         loader = train_loader\n",
        "        # if(split == 'val'):\n",
        "        #         loader = val_loader\n",
        "        for step in range(eval_check):\n",
        "            try:\n",
        "                batch = next(val_iterator)\n",
        "            except StopIteration:\n",
        "                val_loader_iterator = iter(val_loader)\n",
        "                X, x, y = next(val_loader_iterator)\n",
        "\n",
        "            # tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n",
        "            total_loss = 0\n",
        "            # loader.sampler.set_epoch(step)\n",
        "            total_batches = 0\n",
        "            # batch = next(val_loader_iterator)\n",
        "            # for batch in loader:  # Loop through DataLoader batches\n",
        "            # idx = batch['input_ids']\n",
        "            # targets = batch['labels']\n",
        "            spec = X.to(device)\n",
        "\n",
        "            idx = x.to(device)\n",
        "            targets = y.to(device)\n",
        "            with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "\n",
        "                logits = model(spec, idx)\n",
        "                batch_size, block_size, embeddings_dims = logits.shape\n",
        "                logits = logits.view(batch_size * block_size, embeddings_dims)  # Flatten tokens\n",
        "                targets = targets.view(batch_size * block_size)\n",
        "\n",
        "                loss = torch.nn.functional.cross_entropy(logits, targets, ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_batches += 1\n",
        "\n",
        "        # Compute mean loss for this epoch\n",
        "        epoch_loss = total_loss / total_batches if total_batches > 0 else 0.0\n",
        "        epoch_losses.append(epoch_loss)\n",
        "\n",
        "            # print(f\"Epoch {epoch + 1}/{ModelArgs.val_epochs}: Loss = {epoch_loss:.4f}\")\n",
        "\n",
        "        # Compute mean loss across all evaluation epochs\n",
        "        out[split] = sum(epoch_losses) / len(epoch_losses) if epoch_losses else 0.0\n",
        "        epoch_loss = None\n",
        "        epoch_losses = []\n",
        "\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "# model = model.to(rank)\n",
        "model.train()\n",
        "count = 0\n",
        "\n",
        "# train_dataloader = prepare_dataset('train', device, ModelArgs.batch_size)\n",
        "# val_loader= prepare_dataset('val', device, ModelArgs.batch_size)\n",
        "# for step in tqdm(range(total_iters)):\n",
        "# for epoch in range(ModelArgs.epochs):\n",
        "    # torch.cuda.synchronize()\n",
        "\n",
        "# train_dataloader.sampler.set_epoch(epoch)\n",
        "\n",
        "# val_loader.sampler.set_epoch(epoch)\n",
        "print(\"Loaders ready both\")\n",
        "epochs = epochs\n",
        "\n",
        "# train_step_iterator = range(len(train_dataloader))\n",
        "# if device == 0:  # Only create progress bar on rank 0\n",
        "#   train_step_iterator = tqdm(train_step_iterator, desc=\"Training Progress\", position=0, leave=True)\n",
        "\n",
        "    # Print progress on rank 0\n",
        "train_loader_length = 0\n",
        "train_data_iterator = iter(train_dataloader)\n",
        "val_data_iterator = iter(val_dataloader)\n",
        "token_count = 0\n",
        "if(device == 0):\n",
        "    train_loader_length = len(train_dataloader)\n",
        "    # print(\"Total batches: \", train_loader_length)\n",
        "# print(\"Length of : \", len(train_dataloader))\n",
        "# print(\"Length of val: \", len(val_loader))\n",
        "# for  step, batch in enumerate(train_dataloader):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "_cell_guid": "5fd44e9d-01f8-4e2b-9130-4640fdab7419",
        "_uuid": "c8abd50d-6173-4aeb-8219-b6396120af54",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:48.145768Z",
          "iopub.status.busy": "2025-03-16T21:18:48.145554Z",
          "iopub.status.idle": "2025-03-16T21:18:48.149258Z",
          "shell.execute_reply": "2025-03-16T21:18:48.148608Z",
          "shell.execute_reply.started": "2025-03-16T21:18:48.145750Z"
        },
        "id": "R9rFUrIlpsOs",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def find_unused_parameters(model):\n",
        "    unused = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.grad is None:\n",
        "            unused.append(name)\n",
        "    return unused"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "_cell_guid": "39ba72e2-ffe8-4acf-afa3-dbc3077e3e2a",
        "_uuid": "1cdf81be-4ae9-43f2-b3c5-304c73e13883",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:48.182998Z",
          "iopub.status.busy": "2025-03-16T21:18:48.182799Z",
          "iopub.status.idle": "2025-03-16T21:18:48.187182Z",
          "shell.execute_reply": "2025-03-16T21:18:48.186415Z",
          "shell.execute_reply.started": "2025-03-16T21:18:48.182979Z"
        },
        "id": "AMnlZeKTpsOt",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def get_lr(it):\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if it < warmup_iters:\n",
        "        return max_lr * (it + 1) / (warmup_iters + 1)\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if it > lr_decay_iters:\n",
        "        return min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
        "    return min_lr + coeff * (max_lr - min_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "_cell_guid": "317d13ff-dc6c-4965-adfe-d28c4bd6b40d",
        "_uuid": "5feb1c4e-332c-4b97-8952-4646e07467a6",
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:48.204188Z",
          "iopub.status.busy": "2025-03-16T21:18:48.203969Z",
          "iopub.status.idle": "2025-03-16T21:18:48.207464Z",
          "shell.execute_reply": "2025-03-16T21:18:48.206860Z",
          "shell.execute_reply.started": "2025-03-16T21:18:48.204168Z"
        },
        "id": "O7-thMpYpsOt",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44ced50a-b954-4b04-8bc2-25b7c2601b9c",
        "_uuid": "600fec50-d0e3-4593-a316-5c25e586c4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-03-16T21:18:48.265086Z",
          "iopub.status.busy": "2025-03-16T21:18:48.264869Z"
        },
        "id": "nPrSPPu8cuoO",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "27b849a0-ac60-4323-8183-bee0281e125e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250317_153549-bg6nilpi</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rentio/Whisper-From-Scratch/runs/bg6nilpi' target=\"_blank\">elated-durian-22</a></strong> to <a href='https://wandb.ai/rentio/Whisper-From-Scratch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rentio/Whisper-From-Scratch' target=\"_blank\">https://wandb.ai/rentio/Whisper-From-Scratch</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rentio/Whisper-From-Scratch/runs/bg6nilpi' target=\"_blank\">https://wandb.ai/rentio/Whisper-From-Scratch/runs/bg6nilpi</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Micro Batch :  0\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  10\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  20\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  30\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  40\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  50\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  60\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  70\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  80\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  90\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  100\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  110\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  120\n",
            "Step :  0 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/20000 [03:33<1184:04:50, 213.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.0315, device='cuda:0')\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Micro Batch :  0\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  10\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  20\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  30\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  40\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  50\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  60\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  70\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  80\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  90\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  100\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  110\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  120\n",
            "Step :  1 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 2/20000 [07:04<1177:06:20, 211.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.0287, device='cuda:0')\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Micro Batch :  0\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  10\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  20\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  30\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  40\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  50\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  60\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  70\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  80\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  90\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  100\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  110\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  120\n",
            "Step :  2 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 3/20000 [10:36<1178:52:47, 212.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.0208, device='cuda:0')\n",
            "Step :  3 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Micro Batch :  0\n",
            "Step :  3 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  10\n",
            "Step :  3 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  20\n",
            "Step :  3 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  30\n",
            "Step :  3 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  40\n",
            "Step :  3 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n",
            "Micro Batch :  50\n",
            "Step :  3 / 20000\n",
            "Total batches:  343\n",
            "Total gradient accumulation steps:  128\n",
            "Total tokens processed:  0\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "train_losses =  torch.zeros(len(train_dataloader))\n",
        "val_losses = torch.zeros(len(val_dataloader))\n",
        "wandb.init(\n",
        "    project='Whisper-From-Scratch'\n",
        ")\n",
        "step = 0\n",
        "if(use_torch_compile):\n",
        "    model = torch.compile(model)\n",
        "\n",
        "# loss_fn = LigerFusedLinearCrossEntropyLoss()\n",
        "for step in tqdm(range(total_iters)):\n",
        "        # print(\"Dataloader things: \", batch)\n",
        "        # print(\"Total batches: \", len(train_dataloader))\n",
        "\n",
        "\n",
        "        # if(device == 0):\n",
        "            # if(step % 100 == 0):\n",
        "        #     if(step == train_loader_length):\n",
        "        #       break\n",
        "        print(\"Step : \", step, \"/\", total_iters)\n",
        "        print('Total batches: ', len(train_dataloader))\n",
        "        print(\"Total gradient accumulation steps: \", gradient_accumulation_steps)\n",
        "                # print(\"Total tokens processed: \", token_count)\n",
        "\n",
        "        # all_gpus_avg_train_loss = None\n",
        "        # all_gpus_avg_val_loss = None\n",
        "        # every once in a while evaluate the loss on train and val sets\n",
        "        if (step  % eval_iters == 0 and step != 0) or step == total_iters - 1:\n",
        "            losses = estimate_loss( val_loader, val_data_iterator, 'cuda')\n",
        "            # avg_train_loss = losses['train']\n",
        "            avg_val_loss = losses['val']\n",
        "            # print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "            # if device == 0:  # Only print on main process\n",
        "            print(f\"[GPU {device}] | Step: {step} / {total_iters} | Val Loss: {losses['val']:.4f}\")\n",
        "            # print(f\"[GPU {device}] | Epoch {epoch}/{ModelArgs.epochs}| |Step: {step} | Train Loss: {losses['train']:.4f}\")\n",
        "                # print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "                # Log training loss more frequently\n",
        "                # Aggregate average loss across all GPUs\n",
        "            # avg_train_loss = torch.Tensor([losses['train']]).to(device)\n",
        "            avg_val_loss = torch.Tensor([losses['val']]).to(device)\n",
        "            # torch.distributed.reduce(avg_train_loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n",
        "            # torch.distributed.reduce(avg_val_loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n",
        "\n",
        "            # if device == 0:\n",
        "                # all_gpus_avg_train_loss = avg_train_loss / world_size\n",
        "                # print(f\"All_GPUs_Train_losses: {all_gpus_avg_train_loss.item():.4f}\")\n",
        "            all_gpus_avg_val_loss = avg_val_loss / world_size\n",
        "            print(f\"All_GPUs_Val_losses: {all_gpus_avg_val_loss.item():.4f}\")\n",
        "\n",
        "            # if device == 0:\n",
        "\n",
        "                # writer.add_scalar(\"All_GPUs_Train_losses\", all_gpus_avg_train_loss.item(), global_step=step)\n",
        "                # writer.add_scalar(\"All_GPUs_Val_losses\", all_gpus_avg_val_loss.item(), global_step=step)\n",
        "                # writer.add_scalar(\"training_step_loss\", losses['train'], global_step=step)\n",
        "                # writer.add_scalar(\"val_step_loss\", losses['val'], global_step=step)\n",
        "                # writer.add_scalar(\"GPU\", device, global_step=step)\n",
        "                # writer.add_scalar(\"Epoch\", epoch, global_step=step)\n",
        "\n",
        "            wandb.log({\n",
        "                    # \"Learning Rate\": optimizer.param_groups[0]['lr'],\n",
        "                    # \"All_GPUs_Train_losses\": all_gpus_avg_train_loss,\n",
        "                    \"All_GPUs_Val_losses\": all_gpus_avg_val_loss,\n",
        "                    # \"training_step_loss\": losses['train'],\n",
        "                    \"val_step_loss\": losses['val'],\n",
        "                    # \"Step\": step,\n",
        "                    # \"Epoch\": epoch\n",
        "                })\n",
        "\n",
        "\n",
        "\n",
        "        #Loading a checkpoint\n",
        "        # if(os.path.exists('snapshot.pt')):\n",
        "        #    model, optimizer =  _load_snapshot(model=model, optimizer=optimizer, epoch=epoch, step=step, snapshot_path='snapshot.pt')\n",
        "\n",
        "        # if(step % save_chechpoint_iter == 0 and device == 0 and step != 0):\n",
        "\n",
        "        #     _save_snapshot(epoch=epoch, model=model, optimizer=optimizer, step=step)\n",
        "\n",
        "        if step % save_chechpoint_iter == 0 and device == 0 and step != 0:\n",
        "            print(f\"Saving the model checkpoint for step: {step}\")\n",
        "            _save_snapshot(model, optimizer, None, None, step)\n",
        "\n",
        "        accumulated_loss = 0.0\n",
        "\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        for micro_step in range(gradient_accumulation_steps):\n",
        "            try:\n",
        "                spec, idx, y = next(train_data_iterator)\n",
        "            except StopIteration:\n",
        "                train_data_iterator = iter(train_dataloader)\n",
        "                spec, idx, y = next(train_data_iterator)\n",
        "            spec = spec.to(device)\n",
        "            y = y.to(device)\n",
        "            idx = idx.to(device)\n",
        "\n",
        "            # tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n",
        "            # print(batch)\n",
        "            # batch = next(train_data_iterator)\n",
        "            # print(batch)\n",
        "            # batch = {k: v.to(self.local_rank) for k, v in batch.items()}\n",
        "            # idx = batch['input_ids'].to(device)\n",
        "            # idx, targets = get_batch(split='train')\n",
        "            # print(f\"Starting the train step: {step}...\")\n",
        "            # for idx, targets in train_loader:\n",
        "            # idx, targets = next(iter(train_loader))\n",
        "\n",
        "            # print(\"Idx: \", idx)\n",
        "            # print(\"Targets: \", targets)\n",
        "\n",
        "            # idx = idx.to(device)\n",
        "            # print(\"Idx: \", idx)\n",
        "            # print(\"Targets: \", targets)\n",
        "            # targets = batch['labels'].to(device)\n",
        "            # token_count += len(idx)\n",
        "            with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "                logits = model(spec, idx)\n",
        "                batch_size, block_size, embeddings_dims = logits.shape\n",
        "                # print(logits.shape)\n",
        "                # print(targets)\n",
        "                logits = logits.view(batch_size*block_size, embeddings_dims)\n",
        "                # print(\"OK\")\n",
        "                targets = y.view(batch_size * block_size)\n",
        "                # print(\"OK2\")\n",
        "                if(use_liger == False):\n",
        "                    loss_fn\n",
        "                else:\n",
        "                    loss = nn.functional.cross_entropy(logits, targets, ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "                loss = loss / gradient_accumulation_steps #IDK why div is done here specifically? Maybe think of it in terms of a very big batch being processed and there is need for equal important of each mini batch for the overall big batch\n",
        "                accumulated_loss += loss.detach()\n",
        "\n",
        "            model.require_backward_grad_sync = (micro_step == gradient_accumulation_steps - 1) # so that we dont synchronize the gradient everytime across the GPU devices\n",
        "            scaler.scale(loss).backward()\n",
        "            # print(\"loss: \", loss.item())\n",
        "                # Check for unused parameters\n",
        "            unused_params = find_unused_parameters(model)\n",
        "            if unused_params:\n",
        "                print(f\"Unused parameters: {unused_params}\")\n",
        "        # break\n",
        "\n",
        "            # if(device == 0):\n",
        "            if(micro_step % 10 == 0):\n",
        "            #     if(step == train_loader_length):\n",
        "            #       break\n",
        "\n",
        "                    print(\"Micro Batch : \", micro_step)\n",
        "                    print(\"Step : \", step, \"/\", total_iters)\n",
        "                    print('Total batches: ', len(train_dataloader))\n",
        "                    print(\"Total gradient accumulation steps: \", gradient_accumulation_steps)\n",
        "                    print(\"Total tokens processed: \", token_count)\n",
        "            # count += 1\n",
        "\n",
        "        lr = get_lr(step)\n",
        "        for params in optimizer.param_groups:\n",
        "            params['lr'] = lr\n",
        "\n",
        "\n",
        "\n",
        "        # Compute gradient norms before clipping\n",
        "        if(clip != 0.0):\n",
        "            scaler.unscale_(optimizer) #To avoid underflow\n",
        "            total_norm_before = torch.norm(\n",
        "                torch.stack([torch.norm(p.grad.detach(), 2) for p in model.parameters()]), 2\n",
        "            )\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "            # Compute gradient norms after clipping\n",
        "            total_norm_after = torch.norm(\n",
        "                torch.stack([torch.norm(p.grad.detach(), 2) for p in model.parameters()]), 2\n",
        "            )\n",
        "\n",
        "            if(device  == 0 and step !=0):\n",
        "                print(f\"Gradient Norm Before Clipping: {total_norm_before.item():.4f}\")\n",
        "                print(f\"Gradient Norm After Clipping: {total_norm_after.item():.4f}\")\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # optimizer.step()\n",
        "        # new_scheduler.step()\n",
        "        print(accumulated_loss)\n",
        "        # torch.cuda.synchronize()\n",
        "        # torch.distributed.reduce(loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n",
        "        # if(device == 0):\n",
        "        wandb.log({\n",
        "                    \"Learning Rate\": lr,\n",
        "                    \"All_GPUs_Train_losses\": accumulated_loss.item(),\n",
        "                    # \"All_GPUs_Val_losses\": all_gpus_avg_val_loss,\n",
        "                    # \"training_step_loss\": losses['train'],\n",
        "                    # \"val_step_loss\": losses['val'],\n",
        "                    \"Step\": step,\n",
        "                    # \"Epoch\": epoch\n",
        "\n",
        "                })\n",
        "\n",
        "\n",
        "        # model.train()\n",
        "        # wandb.log({\n",
        "        #   \"Train Loss\": train_losses.mean(),\n",
        "        #   \"Val Loss\": val_losses.mean(),\n",
        "        #   # \"epoch\": epoch\n",
        "        # })\n",
        "        # print(\"Epoch: \", epoch, \"|\", \"Train Loss: \", train_losses.mean(),  \"|\", \"Val Loss: \", val_losses.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "92c4ae77-c006-43e9-a677-343c07e75e87",
        "_uuid": "8cf1c23a-fb45-45af-a00e-3219a7a750c8",
        "id": "UmELOJIEpsOt",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e23d9c5c-bfe8-4e86-8fd7-da9eb29e2901",
        "_uuid": "83764454-8200-4a10-9ab4-322effc15cb2",
        "id": "_X9rlI-ApsOt",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JTSt1DgpsOt",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux7EkLwtpsOt",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FLisl7UpsOt",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjYbJOoxpsOt",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzk_j9m_psOt",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nAHEP1rpsOu",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc8pcHgmpsOu",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cenj1I7dpsOu",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DRS6XCJpsOu",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNy8RUV9psOu",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "mt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
