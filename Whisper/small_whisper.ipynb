{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom pathlib import Path\nimport random\n\n# from tokenizers import Tokenizer\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"4b54e35b-02bb-44b4-adca-a297c3081d36","_cell_guid":"e4b2df23-1b2f-4ca2-9968-9bbd2972779d","trusted":true,"collapsed":false,"id":"Pw7f2ghccuoK","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-16T20:27:50.949124Z","iopub.execute_input":"2025-03-16T20:27:50.949322Z","iopub.status.idle":"2025-03-16T20:27:53.952701Z","shell.execute_reply.started":"2025-03-16T20:27:50.949302Z","shell.execute_reply":"2025-03-16T20:27:53.951790Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\nimport re\nHF_TOKEN = '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'\n\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", token=HF_TOKEN)\ntokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n\nSOT = '<|startoftranscript|>'\nEOT = '<|endoftranscript|>'\ntranscribe = '<|transcribe|>'\nprev = '<|prev|>'\n\nspecial_tokens_dict = {\n    'additional_special_tokens': [SOT, EOT, transcribe, prev]\n}\n\n\ntokenizer.add_special_tokens(special_tokens_dict)\n# model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n\n# tokenizer(\"hi\")","metadata":{"_uuid":"fe2c17e3-b1bf-4b93-8760-de26e849e84f","_cell_guid":"8e81d8cb-2c43-4550-a8f8-09815ff2a1ab","trusted":true,"collapsed":false,"id":"LwR5_uvTcuoL","outputId":"492fa6c9-a295-4ebb-e3b7-8c007fbf9055","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-16T20:27:53.954400Z","iopub.execute_input":"2025-03-16T20:27:53.954751Z","iopub.status.idle":"2025-03-16T20:27:56.417272Z","shell.execute_reply.started":"2025-03-16T20:27:53.954727Z","shell.execute_reply":"2025-03-16T20:27:56.416335Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"\n!pip install wandb\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"API_KEY\")\n\nwandb.login(key=secret_value_0)","metadata":{"_uuid":"234d59ef-e07b-4028-a613-ec9e72abfd67","_cell_guid":"32170d73-d4d4-431e-ad94-fa5d9addd61f","trusted":true,"collapsed":false,"id":"P3vCVc6OlXe2","outputId":"e0a26206-20aa-4bf4-98db-dd576e96b2d9","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-16T20:27:56.418752Z","iopub.execute_input":"2025-03-16T20:27:56.419235Z","iopub.status.idle":"2025-03-16T20:28:08.001610Z","shell.execute_reply.started":"2025-03-16T20:27:56.419209Z","shell.execute_reply":"2025-03-16T20:28:08.000672Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#Hyperparameters\nepochs=10\nblock_size = 64\nbatch_size = 64\n# src_vocab_size = None\ntgt_vocab_size = len(tokenizer)\nembeddings_dims = 512\nattn_dropout = 0.1\nno_of_heads = 8 #IMP needs to be thoroughly calculated\ndropout = 0.1\n# epochs = 3\nmax_lr = 6e-4\nno_of_decoder_layers = 8 #IMP needs to be thoroughly calculated\nattn_dropout = 0.1\nweight_decay_optim = 0.01\nlog_mel_features = 80\nkernel_size = 3\nstride = (2,10)\nsr = 16000\ndevice= 'cuda:0'\nSAMPLING_RATE=16000\nN_MELS = 80  # 80-channel Mel spectrogram\nWINDOW_DURATION = 0.025  # 25 milliseconds\nSTRIDE_DURATION = 0.010  # 10 milliseconds\nmax_t = 500\nn_channels = N_MELS\nclip = 1.0","metadata":{"_uuid":"4f155899-f57d-4c37-aa94-e56a969d0259","_cell_guid":"33ab1861-74f7-45f5-adb9-f986e5a7e036","trusted":true,"collapsed":false,"id":"D7AP219KJzTs","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-16T20:28:08.002697Z","iopub.execute_input":"2025-03-16T20:28:08.003275Z","iopub.status.idle":"2025-03-16T20:28:08.018779Z","shell.execute_reply.started":"2025-03-16T20:28:08.003246Z","shell.execute_reply":"2025-03-16T20:28:08.017823Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"torch.set_default_device(device)","metadata":{"_uuid":"92a80d68-b0eb-4f1d-b988-7f190e0b934a","_cell_guid":"5ac94789-1d5e-4ace-88f3-25b5413fb78b","trusted":true,"collapsed":false,"id":"TmPkI_UEpvor","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-16T20:28:08.020054Z","iopub.execute_input":"2025-03-16T20:28:08.020631Z","iopub.status.idle":"2025-03-16T20:28:08.043556Z","shell.execute_reply.started":"2025-03-16T20:28:08.020565Z","shell.execute_reply":"2025-03-16T20:28:08.042503Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n!pip install datasets\nfrom tabnanny import verbose\nfrom datasets import load_dataset\n\ngs = load_dataset(\"speechcolab/gigaspeech\", \"s\", token=HF_TOKEN, trust_remote_code=True) \n\n\nprint(gs)\n\n\naudio_input = gs['train'][0][\"audio\"] \ntranscription = gs[\"train\"][0][\"text\"]","metadata":{"_uuid":"e08f94e6-dae5-42f3-a285-c151086b8f1b","_cell_guid":"1777fa9a-7686-4b62-93c1-c31c2ccf73c1","trusted":true,"collapsed":false,"id":"IME1Ls95Y3gl","outputId":"ab87d390-48f4-43be-b421-aad103deacca","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-16T20:28:08.044805Z","iopub.execute_input":"2025-03-16T20:28:08.045189Z","iopub.status.idle":"2025-03-16T20:28:14.373089Z","shell.execute_reply.started":"2025-03-16T20:28:08.045149Z","shell.execute_reply":"2025-03-16T20:28:14.372056Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDatasetDict({\n    train: Dataset({\n        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n        num_rows: 230068\n    })\n    validation: Dataset({\n        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n        num_rows: 6750\n    })\n    test: Dataset({\n        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n        num_rows: 25619\n    })\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"MAX_DURATION_IN_SECONDS = 10\n\nimport librosa\nfrom tqdm import tqdm\ndef is_audio_length_in_range(input_length):\n    return input_length < MAX_DURATION_IN_SECONDS\n\ntrain_new_column = []\n\nfor x in tqdm(range(len(gs['train']))):\n    train_new_column.append(librosa.get_duration(path=gs['train'][x]['audio']['path']))\n\ngs_ = gs['train'].add_column(\"duration\", train_new_column)\n\n\ngs_ = gs_.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n\n\ntruncated_gs_train = gs_.remove_columns([\"duration\"])\n# truncated_gs\n\n\n\nval_new_column = []\n# new_column = [librosa.get_duration(path=x) ]]\nfor x in tqdm(range(len(gs['validation']))):\n    val_new_column.append(librosa.get_duration(path=gs['validation'][x]['audio']['path']))\n\ngs_ = gs['validation'].add_column(\"duration\", val_new_column)\n\n\ngs_ = gs_.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n\n\ntruncated_gs_val = gs_.remove_columns([\"duration\"])\n# truncated_gs","metadata":{"_uuid":"027b3fe3-8e01-40c4-99de-1a1b12d93453","_cell_guid":"0c018b51-6161-49d9-995e-21cf09d1391f","trusted":true,"collapsed":false,"id":"cRV1EOlVY3gm","outputId":"1052df52-a76c-4ee1-c4e7-cd495e3fb212","execution":{"iopub.status.busy":"2025-03-16T20:28:14.374239Z","iopub.execute_input":"2025-03-16T20:28:14.374940Z","iopub.status.idle":"2025-03-16T20:35:37.108931Z","shell.execute_reply.started":"2025-03-16T20:28:14.374907Z","shell.execute_reply":"2025-03-16T20:35:37.108126Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"100%|██████████| 230068/230068 [07:02<00:00, 545.17it/s]\n100%|██████████| 6750/6750 [00:20<00:00, 335.73it/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\nimport numpy as np\n\n\nn_fft = int(WINDOW_DURATION * MAX_DURATION_IN_SECONDS * SAMPLING_RATE)\nhop_length = int(STRIDE_DURATION * MAX_DURATION_IN_SECONDS * SAMPLING_RATE)\n\ntrain_outputs = []\ntrain_texts = []\nfor i in tqdm(range(len(truncated_gs_train))):\n  S = librosa.feature.melspectrogram(\n      y=truncated_gs_train[i]['audio']['array'],\n      sr=SAMPLING_RATE,\n      n_mels=N_MELS,\n      n_fft=n_fft,\n      hop_length=hop_length,\n      win_length=n_fft,\n      fmax=SAMPLING_RATE // 2\n  )\n\n\n  S_dB = librosa.power_to_db(S, ref=np.max)\n  train_outputs.append(S_dB)\n  train_texts.append(truncated_gs_train[i]['text'])\n\nval_outputs = []\nval_texts = []\nfor i in tqdm(range(len(truncated_gs_val))):\n  S = librosa.feature.melspectrogram(\n      y=truncated_gs_val[i]['audio']['array'],\n      sr=SAMPLING_RATE,\n      n_mels=N_MELS,\n      n_fft=n_fft,\n      hop_length=hop_length,\n      win_length=n_fft,\n      fmax=SAMPLING_RATE // 2\n  )\n\n\n  S_dB = librosa.power_to_db(S, ref=np.max)\n  val_outputs.append(S_dB)\n  val_texts.append(truncated_gs_val[i]['text'])","metadata":{"_uuid":"d988499f-ad5b-47cf-bd9e-257395584889","_cell_guid":"68c3295a-6eef-4874-acaf-73f9279fad98","trusted":true,"collapsed":false,"id":"6NZ9Hbp5q1to","outputId":"cf76473e-8044-4b1c-b1e3-a18861572149","execution":{"iopub.status.busy":"2025-03-16T20:35:37.111522Z","iopub.execute_input":"2025-03-16T20:35:37.111778Z","iopub.status.idle":"2025-03-16T21:17:23.216508Z","shell.execute_reply.started":"2025-03-16T20:35:37.111754Z","shell.execute_reply":"2025-03-16T21:17:23.215522Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"100%|██████████| 220942/220942 [40:27<00:00, 91.01it/s] \n  1%|▏         | 71/5447 [00:01<01:15, 70.84it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3408\n  warnings.warn(\n 26%|██▌       | 1394/5447 [00:20<00:58, 68.92it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2000\n  warnings.warn(\n 50%|█████     | 2726/5447 [00:39<00:39, 68.64it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2240\n  warnings.warn(\n 69%|██████▉   | 3782/5447 [00:54<00:21, 77.39it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3808\n  warnings.warn(\n 85%|████████▍ | 4624/5447 [01:06<00:11, 71.32it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3600\n  warnings.warn(\n100%|██████████| 5447/5447 [01:18<00:00, 69.52it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# import math\n# print(round(random.random(), 1))\nclass GigaSpeechDataset(Dataset):\n\n  def __init__(self, outputs, texts): \n\n    self.data = outputs\n    self.texts = texts\n    self.max_t = block_size\n\n  def __len__(self):\n    return len(self.data)\n\n\n  def pad_to_max_t(self, spectrogram, max_t):\n\n    n_mels, t = spectrogram.shape\n    if t < max_t:\n        # Pad with zeros\n        pad_width = ((0, 0), (0, max_t - t))\n        spectrogram = np.pad(spectrogram, pad_width, mode='constant')\n    else:\n      spectrogram = spectrogram[:, :max_t]\n\n    return spectrogram\n\n  def clean(self, desc):\n    # Use regex to remove anything between < and >\n    cleaned_text = re.sub(r'<[^>]*>', '', desc)\n    return cleaned_text\n\n  def __getitem__(self, idx):\n\n      SOT = '<|startoftranscript|>'\n      EOT = '<|endoftranscript|>'\n      transcribe = '<|transcribe|>'\n      # prev = '<|prev|>'\n      spectrogram = self.pad_to_max_t(self.data[idx], self.max_t)\n      # probs = round(random.random(),1)\n      spectrogram = torch.tensor(spectrogram, dtype=torch.float32)\n\n      # if(probs == 0.5):\n        # Normalize the spectrogram between -1 and 1\n      spectrogram_min = spectrogram.min()\n      spectrogram_max = spectrogram.max()\n      # spectrogram = spectrogram.unsqueeze(0)  # Shape: (1, n_mels, max_t)\n      # prev_text =\n      text = self.clean(self.texts[idx])\n\n      text = text.lower()\n      text = SOT  + 'en' + transcribe +  text + EOT\n      tokenized_text = tokenizer(text, truncation=True, padding='max_length', max_length=block_size, return_tensors='pt')\n      # print(tokenized_text.shape)\n\n      epsilon = 1e-8  # To avoid division by zero\n      spectrogram = 2 * ((spectrogram - spectrogram_min) / (spectrogram_max - spectrogram_min + epsilon)) - 1\n\n      # tokenized_win_prompt = tokenizer(text, max_length = ModelArgs.block_size, padding='max_length', truncation=True,  return_tensors=\"pt\").to(device)\n      tokenized_text['labels'] = tokenized_text['input_ids'].clone()\n      tokenized_text['labels'][: , :-1] = tokenized_text['input_ids'][: , 1:]\n      tokenized_text['labels'][: , -1] = tokenizer.eos_token_id \n\n      tokenized_text_x = tokenized_text['input_ids'].squeeze(0)\n      tokenized_text_y = tokenized_text['labels'].squeeze(0)\n      \n      # print(tokenized_text.shape)\n      return spectrogram, tokenized_text_x, tokenized_text_y","metadata":{"_uuid":"b456c1a6-6703-4809-a1fb-fc077a5dc8e3","_cell_guid":"db1f5e13-91c6-4d24-8d31-325796a8a0fd","trusted":true,"collapsed":false,"id":"z2aGf6_7xe9S","execution":{"iopub.status.busy":"2025-03-16T21:17:23.219057Z","iopub.execute_input":"2025-03-16T21:17:23.219755Z","iopub.status.idle":"2025-03-16T21:17:23.229394Z","shell.execute_reply.started":"2025-03-16T21:17:23.219721Z","shell.execute_reply":"2025-03-16T21:17:23.228433Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"torch.autograd.set_detect_anomaly(True)  # Add at the start of training","metadata":{"_uuid":"5ca81223-5c7e-43e5-83b2-7b00a3ecee7f","_cell_guid":"78e27c8d-e3cd-434c-b2c6-9d16b79eb5be","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:23.230437Z","iopub.execute_input":"2025-03-16T21:17:23.230758Z","iopub.status.idle":"2025-03-16T21:17:23.258809Z","shell.execute_reply.started":"2025-03-16T21:17:23.230731Z","shell.execute_reply":"2025-03-16T21:17:23.257804Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7887ebef2f80>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"\n\nshuffle = True\n\ntrain_dataset = GigaSpeechDataset(train_outputs, train_texts)\nval_dataset = GigaSpeechDataset(val_outputs, val_texts)\n\ngenerator = torch.Generator(device=device)\n\ntrain_dataloader = DataLoader(\n\n    train_dataset,\n    batch_size=batch_size,\n    generator=generator,\n    shuffle=shuffle,\n     drop_last=True,\n)\nval_dataloader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    generator=generator,\n    drop_last=True ,\n    shuffle=shuffle,\n)","metadata":{"_uuid":"8db84c70-d655-4b7c-8c00-9e195d240a7d","_cell_guid":"d26cf6eb-55b2-484c-bc9b-10952ea5c977","trusted":true,"collapsed":false,"id":"2tvMuBSOynPy","execution":{"iopub.status.busy":"2025-03-16T21:17:23.259908Z","iopub.execute_input":"2025-03-16T21:17:23.260278Z","iopub.status.idle":"2025-03-16T21:17:23.478760Z","shell.execute_reply.started":"2025-03-16T21:17:23.260242Z","shell.execute_reply":"2025-03-16T21:17:23.477736Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"next(iter(train_dataloader))","metadata":{"_uuid":"d681546c-459b-4cdf-b52d-256e7113beb7","_cell_guid":"b0074df8-52c7-45e7-99d2-7aeb8f646a6b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:23.479814Z","iopub.execute_input":"2025-03-16T21:17:23.480097Z","iopub.status.idle":"2025-03-16T21:17:25.574570Z","shell.execute_reply.started":"2025-03-16T21:17:23.480071Z","shell.execute_reply":"2025-03-16T21:17:25.573700Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[tensor([[[-0.6308, -0.5936, -0.1951,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.5304, -0.4495, -0.1550,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.4679, -0.3332,  0.2241,  ...,  1.0000,  1.0000,  1.0000],\n          ...,\n          [-1.0000, -0.8912, -0.2970,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -1.0000, -0.4235,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -1.0000, -0.4402,  ...,  1.0000,  1.0000,  1.0000]],\n \n         [[-0.1280, -0.0385,  0.1464,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.4492, -0.2401,  0.1058,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.5139, -0.2780,  0.3146,  ...,  1.0000,  1.0000,  1.0000],\n          ...,\n          [-1.0000, -1.0000, -0.6439,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -1.0000, -0.6567,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -1.0000, -0.9125,  ...,  1.0000,  1.0000,  1.0000]],\n \n         [[-0.2847, -0.2055, -0.0936,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.1869, -0.1504, -0.0317,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.1396, -0.0051,  0.0646,  ...,  1.0000,  1.0000,  1.0000],\n          ...,\n          [-1.0000, -1.0000, -0.9895,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -1.0000, -1.0000,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -1.0000, -1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n \n         ...,\n \n         [[ 0.1052, -0.1046,  0.0111,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.1178, -0.1320,  0.0529,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.1492,  0.2231,  0.5416,  ...,  1.0000,  1.0000,  1.0000],\n          ...,\n          [-0.8554, -1.0000, -0.6556,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.8801, -1.0000, -0.8046,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.9292, -1.0000, -0.9218,  ...,  1.0000,  1.0000,  1.0000]],\n \n         [[ 0.4733,  0.4843,  0.5110,  ...,  1.0000,  1.0000,  1.0000],\n          [ 0.1678,  0.2962,  0.2360,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.0977,  0.0471,  0.0858,  ...,  1.0000,  1.0000,  1.0000],\n          ...,\n          [-1.0000, -1.0000, -0.6226,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -1.0000, -0.8729,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -1.0000, -1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n \n         [[-0.4354, -0.4761, -0.0994,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.3909, -0.5456, -0.1636,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.0200,  0.0759,  0.1113,  ...,  1.0000,  1.0000,  1.0000],\n          ...,\n          [-0.9704, -0.7813, -0.3913,  ...,  1.0000,  1.0000,  1.0000],\n          [-0.9725, -0.8091, -0.4207,  ...,  1.0000,  1.0000,  1.0000],\n          [-1.0000, -0.9922, -0.5436,  ...,  1.0000,  1.0000,  1.0000]]],\n        device='cuda:0'),\n tensor([[50258,   268, 50260,  ..., 50257, 50257, 50257],\n         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n         ...,\n         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n         [50258,   268, 50260,  ..., 50257, 50257, 50257]], device='cuda:0'),\n tensor([[  268, 50260,   271,  ..., 50257, 50257, 50256],\n         [  268, 50260,   258,  ..., 50257, 50257, 50256],\n         [  268, 50260,  2197,  ..., 50257, 50257, 50256],\n         ...,\n         [  268, 50260, 35569,  ..., 50257, 50257, 50256],\n         [  268, 50260, 10197,  ..., 50257, 50257, 50256],\n         [  268, 50260,    73,  ..., 50257, 50257, 50256]], device='cuda:0')]"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"#Position embeddings\nclass PositionEmbeddings(nn.Module):\n    def __init__(\n        self,\n        embeddings_dims = embeddings_dims,\n        block_size = block_size\n    ):\n        super().__init__()\n\n        self.position_embeddings = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n        # nn.init.normal_(self.position_embeddings.weight.data, mean=0, std=0.02)\n\n    def forward(self, x):\n        return self.position_embeddings","metadata":{"_uuid":"25ee96a4-00b2-40a5-a8e4-10ea78a00481","_cell_guid":"a7c6dcaa-5a5d-4260-8696-ee827274edff","trusted":true,"collapsed":false,"id":"kzXk76ULY3gm","execution":{"iopub.status.busy":"2025-03-16T21:17:25.575422Z","iopub.execute_input":"2025-03-16T21:17:25.575666Z","iopub.status.idle":"2025-03-16T21:17:25.580222Z","shell.execute_reply.started":"2025-03-16T21:17:25.575643Z","shell.execute_reply":"2025-03-16T21:17:25.579208Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"pos = PositionEmbeddings()\nx = torch.randn(batch_size, block_size, embeddings_dims)\npos(x)","metadata":{"_uuid":"6c495fe4-d351-4477-be75-b575ea534db0","_cell_guid":"779e1bc7-798e-4e86-ad9e-0967b08dcab9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.580958Z","iopub.execute_input":"2025-03-16T21:17:25.581153Z","iopub.status.idle":"2025-03-16T21:17:25.631084Z","shell.execute_reply.started":"2025-03-16T21:17:25.581135Z","shell.execute_reply":"2025-03-16T21:17:25.630436Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Parameter containing:\ntensor([[[-0.1833,  1.0182,  0.6804,  ...,  0.9679,  0.1340,  0.0834],\n         [-0.3049,  0.2414,  0.4808,  ..., -1.5566, -0.5475,  0.2741],\n         [-1.1239,  0.7832, -1.0881,  ..., -1.0171,  0.0344, -0.6055],\n         ...,\n         [-1.2816, -1.1764,  1.5847,  ...,  2.2729, -0.5462, -1.1655],\n         [-0.2015, -0.9212,  1.6189,  ...,  0.1398,  1.1379,  1.0406],\n         [-0.0946,  1.5284,  1.0860,  ...,  0.8111, -1.0142,  0.8692]]],\n       device='cuda:0', requires_grad=True)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"\n\n# Text embeddings\nclass TgtTextEmbeddings(nn.Module):\n    def __init__(\n        self,\n        vocab_size = tgt_vocab_size,\n        embeddings_dims = embeddings_dims\n    ):\n        super().__init__()\n        self.embeddings_table = nn.Embedding(num_embeddings = tgt_vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n\n    def forward(self, x):\n        return self.embeddings_table(x)","metadata":{"_uuid":"8c520ea7-c368-4ce4-914c-2094cb5ed848","_cell_guid":"62818f89-119f-4059-8538-2feefb03e6a7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.631754Z","iopub.execute_input":"2025-03-16T21:17:25.631941Z","iopub.status.idle":"2025-03-16T21:17:25.636182Z","shell.execute_reply.started":"2025-03-16T21:17:25.631924Z","shell.execute_reply":"2025-03-16T21:17:25.635330Z"},"id":"R9CSiuD2jHyT","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\n\n\n#Layer Normalization\n\nclass LayerNormalization(nn.Module):\n    def __init__(\n        self,\n        embeddings_dims = embeddings_dims\n    ):\n        super().__init__()\n        self.norm = nn.LayerNorm(normalized_shape=embeddings_dims)\n    def forward(self, x):\n\n        return self.norm(x)","metadata":{"_uuid":"ae3226bb-4414-4840-8da7-73db14ad8271","_cell_guid":"0e795d31-2801-446a-807d-0ea3bebb6e3d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.637118Z","iopub.execute_input":"2025-03-16T21:17:25.637345Z","iopub.status.idle":"2025-03-16T21:17:25.653427Z","shell.execute_reply.started":"2025-03-16T21:17:25.637325Z","shell.execute_reply":"2025-03-16T21:17:25.652838Z"},"id":"REUDHWrWcuoN","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\n\n\n#FeedForward Neural Network\n\nclass MLPBlock(nn.Module):\n    def __init__(\n        self,\n        dropout = dropout,\n        embeddings_size = embeddings_dims,\n        # inner_dimensional_states: int = 3072\n    ):\n        super().__init__()\n\n        self.mlp = nn.Sequential(\n            nn.Linear(device=device, in_features=embeddings_size, out_features= 4 * embeddings_dims),\n            nn.GELU(),\n            nn.Linear(device=device, in_features= 4 * embeddings_dims, out_features=embeddings_size),\n            nn.Dropout(p = dropout)\n        )\n\n    def forward(self, x):\n        # mlp_weights_init = self.mlp.apply(weights_init)\n        return self.mlp(x)","metadata":{"_uuid":"70301094-ba8a-4078-a1ad-46dc8d357f6a","_cell_guid":"762624a5-8d63-403b-bc4e-039b16aba3f9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.654077Z","iopub.execute_input":"2025-03-16T21:17:25.654302Z","iopub.status.idle":"2025-03-16T21:17:25.672472Z","shell.execute_reply.started":"2025-03-16T21:17:25.654281Z","shell.execute_reply":"2025-03-16T21:17:25.671677Z"},"id":"lEe02cH9cuoN","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\n\nclass MaskedAttentionHead(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.head_size = embeddings_dims // no_of_heads\n        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n        self.dropout = nn.Dropout(p = attn_dropout)\n\n\n    def forward(self, x):\n        # print(x.shape)\n        batch, block_size, embd_dims = x.shape\n        k = self.keys(x)\n        q = self.query(x)\n        v = self.values(x)\n        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n        weights_normalized = self.dropout(weights_normalized)\n        out = weights_normalized @ v\n        return out","metadata":{"_uuid":"bd1f493a-c5eb-4821-938b-1fd4baf55549","_cell_guid":"50c3f233-f3ea-44cc-bccf-10aa13fc35d5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.673386Z","iopub.execute_input":"2025-03-16T21:17:25.673679Z","iopub.status.idle":"2025-03-16T21:17:25.693459Z","shell.execute_reply.started":"2025-03-16T21:17:25.673647Z","shell.execute_reply":"2025-03-16T21:17:25.692644Z"},"id":"cf0Jf_7UcuoN","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\n\n\nclass MaskedMHA(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.heads = nn.ModuleList([MaskedAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n        self.dropout = nn.Dropout(p = attn_dropout)\n        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n\n    def forward(self, x):\n        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n        linear_layer = self.linear(concat)\n        out = self.dropout(linear_layer)\n        return out","metadata":{"_uuid":"a252848c-a0b1-4c08-8a42-e2851e642a06","_cell_guid":"aee629bd-84ad-4f0c-a0e7-9e3070e10081","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.694382Z","iopub.execute_input":"2025-03-16T21:17:25.694740Z","iopub.status.idle":"2025-03-16T21:17:25.713823Z","shell.execute_reply.started":"2025-03-16T21:17:25.694708Z","shell.execute_reply":"2025-03-16T21:17:25.712953Z"},"id":"OUFERSL2u8LT","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\n#Single Attention Head\n\nclass CrossAttentionHead(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.head_size = embeddings_dims // no_of_heads\n        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n        self.dropout = nn.Dropout(p = attn_dropout)\n\n\n    def forward(self, query, key, value, mask=None):\n        \n       \n        batch, block_size, embd_dims = query.shape\n        q = self.query(query)\n        k = self.keys(key)\n        v = self.values(value)\n        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n        # weights = query @ torch.transpose(key, dim0=-2, dim1=-1) * (key.shape[-1] ** -0.5)\n        # if(mask != None):\n        #     mask = mask.unsqueeze(1)\n        #     masked_values = weights.masked_fill(mask == 0, float('-inf'))\n        #     weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n        #     # weights_normalized = self.dropout(weights_normalized)\n        #     out = weights_normalized @ value\n        #     out = self.dropout(out)\n        #     return out\n        # else:\n        #     weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n        #     # weights_normalized = self.dropout(weights_normalized)\n        #     out = weights_normalized @ value\n        #     out = self.dropout(out)\n        #     return out\n\n        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n        weights_normalized = self.dropout(weights_normalized)\n        out = weights_normalized @ v\n        return out","metadata":{"_uuid":"0bdd11ba-b65a-4dbe-9b09-25d24c2b3ab6","_cell_guid":"76ee1dab-07cf-4ae4-ac9a-3c134b9dc41d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.714607Z","iopub.execute_input":"2025-03-16T21:17:25.714859Z","iopub.status.idle":"2025-03-16T21:17:25.736087Z","shell.execute_reply.started":"2025-03-16T21:17:25.714838Z","shell.execute_reply":"2025-03-16T21:17:25.735469Z"},"id":"oGGyyF4pjHyd","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#Single Attention Head\n\nclass FullAttentionHead(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.head_size = embeddings_dims // no_of_heads\n        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n        self.dropout = nn.Dropout(p = attn_dropout)\n\n\n    def forward(self, x, mask=None):\n        # batch, block_size, embd_dims = x.shape\n        k = self.keys(x)\n        q = self.query(x)\n        v = self.values(x)\n        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n        if(mask != None):\n            mask = mask.unsqueeze(1)\n            masked_values = weights.masked_fill(mask == 0, float('-inf'))\n            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n            # weights_normalized = self.dropout(weights_normalized)\n            out = weights_normalized @ v\n            out = self.dropout(out)\n            return out\n        else:\n            weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n            # weights_normalized = self.dropout(weights_normalized)\n            out = weights_normalized @ v\n            out = self.dropout(out)\n            return out","metadata":{"_uuid":"af55eb4d-6d72-465f-8692-4777da91e56f","_cell_guid":"bcde57b5-61a0-4d56-aa5a-5fbbc2f2a9bd","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.736929Z","iopub.execute_input":"2025-03-16T21:17:25.737123Z","iopub.status.idle":"2025-03-16T21:17:25.763686Z","shell.execute_reply.started":"2025-03-16T21:17:25.737106Z","shell.execute_reply":"2025-03-16T21:17:25.762859Z"},"id":"U5NmszzcjHyf","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"\nclass FullMHA(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.heads = nn.ModuleList([FullAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n        self.dropout = nn.Dropout(p = attn_dropout)\n        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n\n    def forward(self, x, mask=None):\n        concat = torch.cat([head(x, mask) for head in self.heads], dim=-1)\n        linear_layer = self.linear(concat)\n        out = self.dropout(linear_layer)\n        return out","metadata":{"_uuid":"50fee96b-7dae-4da2-951a-b06330293a3e","_cell_guid":"8099497c-1f19-4d53-8965-ae8f153335be","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.764640Z","iopub.execute_input":"2025-03-16T21:17:25.765002Z","iopub.status.idle":"2025-03-16T21:17:25.787092Z","shell.execute_reply.started":"2025-03-16T21:17:25.764968Z","shell.execute_reply":"2025-03-16T21:17:25.786217Z"},"id":"v_BB7r7kqmOc","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\n\nclass CrossMHA(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.heads = nn.ModuleList([CrossAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n        self.dropout = nn.Dropout(p = attn_dropout)\n        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) \n\n    def forward(self, value, key, x, mask=None):\n        concat = torch.cat([head(x, key, value,  mask) for head in self.heads], dim=-1)\n        linear_layer = self.linear(concat)\n        out = self.dropout(linear_layer)\n        return out","metadata":{"_uuid":"3627fa0f-bd35-4dab-9451-03a2b716732b","_cell_guid":"06ee6670-5428-4e5a-867e-cdd98cddc2aa","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.787815Z","iopub.execute_input":"2025-03-16T21:17:25.788020Z","iopub.status.idle":"2025-03-16T21:17:25.809259Z","shell.execute_reply.started":"2025-03-16T21:17:25.788001Z","shell.execute_reply":"2025-03-16T21:17:25.808685Z"},"id":"TTwRkBzcvE-_","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Decoder Block\n\nclass TransformerDecoderBlock(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        dropout = dropout,\n        # vocab_size = vocab_size\n    ):\n        super().__init__()\n\n        self.cross = CrossMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n        self.masked = MaskedMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n        self.layer_norm1 = LayerNormalization(embeddings_dims)\n        self.layer_norm2 = LayerNormalization(embeddings_dims)\n        # self.layer_norm3 = LayerNormalization(embeddings_dims=embeddings_dims)\n        self.layer_norm4 = LayerNormalization(embeddings_dims)\n        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n\n    def forward(self, key, value, x, mask=None):\n        x = self.layer_norm1(x + self.masked(x)) #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n        # print(x.shape)\n        x = self.layer_norm2(x + self.cross(value, key, x, mask)) #Very important step\n        # print(x.shape)\n        # x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n        x = self.layer_norm4(x + self.mlp_block(x)) #Very important step\n        # print(x.shape)\n\n        return x","metadata":{"_uuid":"2c290085-c1fe-4c64-9bab-baa448c3bae5","_cell_guid":"2e095386-2ee5-4a3c-83bb-cad96cb26746","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.810050Z","iopub.execute_input":"2025-03-16T21:17:25.810295Z","iopub.status.idle":"2025-03-16T21:17:25.826116Z","shell.execute_reply.started":"2025-03-16T21:17:25.810261Z","shell.execute_reply":"2025-03-16T21:17:25.825190Z"},"id":"s9rJzO_XcuoO","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Decoder Block\n\nclass DecoderModel(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        block_size = block_size,\n        dropout = dropout,\n        no_of_decoder_layers = no_of_decoder_layers,\n        # vocab_size = vocab_size\n    ):\n        super().__init__()\n\n\n\n\n        # self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n        # self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n        self.decoder_layers = nn.ModuleList([TransformerDecoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n        self.apply(self._init_weights)\n        # self.positional_embeddings_tgt = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n        self.positional_embeddings_tgt = PositionEmbeddings()\n        # torch.nn.init.normal_(self.positional_embeddings_tgt, mean=0.0, std=0.02)\n\n        # out = self.decoder_layers(query, key, x)\n        # Loop through each decoder layer\n    def _init_weights(self, module):  #Weight Initialization\n            if isinstance(module, nn.Linear):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n                if module.bias is not None:\n                    torch.nn.init.zeros_(module.bias)\n            elif isinstance(module, nn.Embedding):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, key, value, x, mask):\n        # x = self.tgt_text_embds(x)\n        x = x + self.positional_embeddings_tgt(x)\n        # print(x.shape)\n        for decoder_layer in self.decoder_layers:\n            x = decoder_layer(key, value, x, mask)\n        # x = self.layer_norm(x)\n\n        return x","metadata":{"_uuid":"05fd4f49-cc4b-474c-9a9c-3d5191eefa43","_cell_guid":"63e5400a-b5d2-4ef7-8f30-b1bc0e233820","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.826969Z","iopub.execute_input":"2025-03-16T21:17:25.827199Z","iopub.status.idle":"2025-03-16T21:17:25.850583Z","shell.execute_reply.started":"2025-03-16T21:17:25.827178Z","shell.execute_reply":"2025-03-16T21:17:25.849957Z"},"id":"KGh8ujQJcuoO","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"\n#Encoder","metadata":{"_uuid":"1e94a41d-aaa3-4e74-a02f-fb0edbfa9118","_cell_guid":"5327372f-0db3-4ef1-a59c-1757b6edfc62","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.854371Z","iopub.execute_input":"2025-03-16T21:17:25.854582Z","iopub.status.idle":"2025-03-16T21:17:25.876149Z","shell.execute_reply.started":"2025-03-16T21:17:25.854563Z","shell.execute_reply":"2025-03-16T21:17:25.875339Z"},"id":"A3SgKrC-jHyd","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"\n\n\nclass TransformerEncoderBlock(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        dropout = dropout,\n        mask=None\n    ):\n        super().__init__()\n\n        self.mha = FullMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n        self.layer_norm1 = LayerNormalization(embeddings_dims)\n        self.layer_norm2 = LayerNormalization(embeddings_dims)\n        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n\n    def forward(self, x, mask=None):\n        x = self.layer_norm1(x + self.mha(x, mask))\n        x = self.layer_norm2(x + self.mlp_block(x))\n\n        return x","metadata":{"_uuid":"3ecc13cd-e38a-4e1c-af9c-10f8e84b02d7","_cell_guid":"2a3683d1-303c-41a2-9cc6-b7e053fde34c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.877823Z","iopub.execute_input":"2025-03-16T21:17:25.878065Z","iopub.status.idle":"2025-03-16T21:17:25.893369Z","shell.execute_reply.started":"2025-03-16T21:17:25.878033Z","shell.execute_reply":"2025-03-16T21:17:25.892523Z"},"id":"v6mbbO3yp-gh","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"\n\n\nclass EncoderModel(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        block_size = block_size,\n        dropout = dropout,\n        no_of_decoder_layers = no_of_decoder_layers,\n        # vocab_size = vocab_size\n    ):\n        super().__init__()\n\n\n        # self.positional_embeddings_src = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n\n        self.conv1 = nn.Conv1d(in_channels=n_channels, out_channels=embeddings_dims, kernel_size=kernel_size, device=device, padding=1)\n        self.conv2 = nn.Conv1d(in_channels=embeddings_dims, out_channels=embeddings_dims, kernel_size=kernel_size, device=device, padding=1)\n\n        self.positional_embeddings_src = PositionEmbeddings()\n\n        self.encoder_layers = nn.ModuleList([TransformerEncoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):  #Weight Initialization\n            if isinstance(module, nn.Linear):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n                if module.bias is not None:\n                    torch.nn.init.zeros_(module.bias)\n            elif isinstance(module, nn.Embedding):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, x, mask):\n\n        x = self.conv1(x)\n        x = torch.nn.functional.gelu(x)\n        x = self.conv2(x)\n        x = torch.nn.functional.gelu(x)\n        # print(x.shape)\n        # x = self.src_text_embeds(x)\n        # print(self.positional_embeddings_src.shape)\n        x = x.permute(0, 2, 1)\n        # print(x.shape)\n        # print(self.positional_embeddings_src(x).shape)\n        x = x + self.positional_embeddings_src(x)\n        # print(x)\n        # print(x.shape)\n        # Loop through each encoder layer\n        for encoder_layer in self.encoder_layers:\n            x = encoder_layer(x, mask)\n        return x","metadata":{"_uuid":"39475274-a828-4151-9556-fa4bf30d4455","_cell_guid":"2fa82426-e551-497d-8247-051a55f74a3c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.894341Z","iopub.execute_input":"2025-03-16T21:17:25.894660Z","iopub.status.idle":"2025-03-16T21:17:25.916685Z","shell.execute_reply.started":"2025-03-16T21:17:25.894605Z","shell.execute_reply":"2025-03-16T21:17:25.915829Z"},"id":"HxW0pvnV12Ms","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"","metadata":{"_uuid":"249cf674-9b8b-406a-920d-603c6c2f00ff","_cell_guid":"ad3a1595-5722-4fff-a54e-87e3bb755abe","trusted":true,"collapsed":false,"id":"Qi3v6jczY3go","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nclass Transformer(nn.Module):\n    def __init__(\n        self,\n\n    ):\n        super().__init__()\n\n        self.encoder = EncoderModel()\n        self.decoder = DecoderModel()\n        # self.pos = PositionalEmbeddings()\n        self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n        # self.src_text_embeds = SrcTextEmbeddings(vocab_size=src_vocab_size, embeddings_dims=embeddings_dims)\n\n    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n        # x = self.src_text_embeds(src)\n        x = self.encoder(src, src_mask)\n        y = self.tgt_text_embds(tgt)\n        # print(x.shape)\n        y = self.decoder(x, x, y, tgt_mask)\n        # print(y.shape)\n        out = self.linear_layer(y)\n        return out","metadata":{"_uuid":"6f0e32f9-14f2-4b65-a106-cab2051ad125","_cell_guid":"a6d4d773-0ed2-4059-ab2b-683692ce2c32","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.917671Z","iopub.execute_input":"2025-03-16T21:17:25.917942Z","iopub.status.idle":"2025-03-16T21:17:25.937565Z","shell.execute_reply.started":"2025-03-16T21:17:25.917913Z","shell.execute_reply":"2025-03-16T21:17:25.936953Z"},"id":"2UWijIFl2Ykd","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"#Instantiating the model\nmodel = Transformer()\n# model = torch.compile(model)\n# model = model.to(device)\nmodel = model.to(device)","metadata":{"_uuid":"e407283d-b631-479c-9bae-014aab7a0a3d","_cell_guid":"17dd187f-c195-44a0-990c-c6d17c90227e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:25.938378Z","iopub.execute_input":"2025-03-16T21:17:25.938678Z","iopub.status.idle":"2025-03-16T21:17:26.442178Z","shell.execute_reply.started":"2025-03-16T21:17:25.938647Z","shell.execute_reply":"2025-03-16T21:17:26.441341Z"},"id":"ntIaQj1U3pFX","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"_uuid":"3efcd10c-fbd4-4818-b23b-636503f4df30","_cell_guid":"4f4d8f86-6a6c-43fe-8a7f-06301998ac15","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:26.443241Z","iopub.execute_input":"2025-03-16T21:17:26.443631Z","iopub.status.idle":"2025-03-16T21:17:26.730652Z","shell.execute_reply.started":"2025-03-16T21:17:26.443574Z","shell.execute_reply":"2025-03-16T21:17:26.729694Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\ntgt_mask","metadata":{"_uuid":"3ecf1b70-4a77-4786-bdbd-df86011c7d31","_cell_guid":"130524f5-869f-4ea2-8cb7-5de2780ed66a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:26.731735Z","iopub.execute_input":"2025-03-16T21:17:26.732102Z","iopub.status.idle":"2025-03-16T21:17:26.758778Z","shell.execute_reply.started":"2025-03-16T21:17:26.732063Z","shell.execute_reply":"2025-03-16T21:17:26.757829Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"tensor([[19581, 42628, 44362,  ..., 31259, 30194, 26385],\n        [14440, 27165, 28905,  ..., 44917,  4816,  7300],\n        [43949, 14247, 43535,  ..., 26924, 41709,  3581],\n        ...,\n        [36012, 12941, 41426,  ..., 40712, 49571, 22076],\n        [23577, 17596, 16240,  ..., 49236, 30748, 46980],\n        [19953, 31215,   880,  ..., 36761, 22380, 22405]], device='cuda:0')"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"\n!pip install torchinfo\nfrom torchinfo import summary\n\nspec, text = next(iter(train_dataloader))\ntgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\nspec = spec.to(device)\ntexts = text.to(device)\n\nsummary(model=model,\n        input_data=(spec, texts),\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"_uuid":"5061d499-36a9-427b-90ad-eead117d5a51","_cell_guid":"d92d3629-d59c-4361-9572-8e0075329808","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:17:26.759689Z","iopub.execute_input":"2025-03-16T21:17:26.759979Z","iopub.status.idle":"2025-03-16T21:17:31.629859Z","shell.execute_reply.started":"2025-03-16T21:17:26.759955Z","shell.execute_reply":"2025-03-16T21:17:31.628564Z"},"id":"yOXtmG-lcuoO","outputId":"00697eb7-4384-4bca-82bf-100f45e5216f","jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-feaf0d775239>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchinfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"],"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error"}],"execution_count":33},{"cell_type":"code","source":"\n# # Optimizer setup and scheduler steup\n# out = {\"Train\": None, \"val\": None}\noptimizer = torch.optim.AdamW(model.parameters(), lr=max_lr)\n\nloss_fn = nn.CrossEntropyLoss()","metadata":{"_uuid":"ee98acba-6992-4b1e-8cc1-3eda3997ae5b","_cell_guid":"97226398-cb33-48d6-9abc-f5a9c549b5c5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:47.480025Z","iopub.execute_input":"2025-03-16T21:18:47.480394Z","iopub.status.idle":"2025-03-16T21:18:47.490347Z","shell.execute_reply.started":"2025-03-16T21:18:47.480363Z","shell.execute_reply":"2025-03-16T21:18:47.489487Z"},"id":"LH95cJEvcuoO","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"torch.set_float32_matmul_precision('high')\n\nscaler = torch.amp.GradScaler(enabled=True)","metadata":{"_uuid":"7860931f-c816-4796-b4c5-265e3df9bf57","_cell_guid":"53e031da-134a-4271-8879-b012f262ccc6","trusted":true,"collapsed":false,"id":"bbvONdUTWmvL","execution":{"iopub.status.busy":"2025-03-16T21:18:47.977290Z","iopub.execute_input":"2025-03-16T21:18:47.977592Z","iopub.status.idle":"2025-03-16T21:18:47.981528Z","shell.execute_reply.started":"2025-03-16T21:18:47.977569Z","shell.execute_reply":"2025-03-16T21:18:47.980718Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def _save_snapshot(model, optimizer, scheduler, epoch, step):\n    snapshot = {\n        \"MODEL_STATE\": model.state_dict(),\n        \"OPTIMIZER_STATE\": optimizer.state_dict(),\n        # \"SCHEDULER_STATE\": scheduler.state_dict(),  \n        \"EPOCHS_RUN\": epoch,\n        \"STEP_RUN\": step\n    }\n    torch.save(snapshot, f\"/kaggle/working/snapshot_{step}.pt\")\n    print(f\"Epoch: {epoch} | Step: {step} | Snapshot saved.\")","metadata":{"_uuid":"6d9f8456-d5da-49d1-8211-c97897782909","_cell_guid":"58095701-5ad6-4bd6-bc30-0b1422af2a93","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:48.013911Z","iopub.execute_input":"2025-03-16T21:18:48.014114Z","iopub.status.idle":"2025-03-16T21:18:48.018021Z","shell.execute_reply.started":"2025-03-16T21:18:48.014096Z","shell.execute_reply":"2025-03-16T21:18:48.017242Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# !pip install torchtriton","metadata":{"_uuid":"9f8791fb-3c63-4871-8402-fbfb2a649e89","_cell_guid":"6f951a8f-3f05-4b6a-9080-99a81e5925b0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:48.044918Z","iopub.execute_input":"2025-03-16T21:18:48.045122Z","iopub.status.idle":"2025-03-16T21:18:48.048197Z","shell.execute_reply.started":"2025-03-16T21:18:48.045104Z","shell.execute_reply":"2025-03-16T21:18:48.047524Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"save_chechpoint_iter = 50\ntotal_iters = 20000\neval_iters = 50\neval_check = 100\nwarmup_iters = 2048\nmin_lr = 0.1 * max_lr\nlr_decay_iters = 20000\ntotal_batch_size = 524288\nmicro_batch_size = batch_size\ngradient_accumulation_steps = total_batch_size // (micro_batch_size * (block_size * torch.cuda.device_count()))","metadata":{"_uuid":"5582f78b-b57d-484e-bfa5-66a2688a6e21","_cell_guid":"2fc4d2f7-40d4-4733-8e32-65c38f198b5e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:48.069579Z","iopub.execute_input":"2025-03-16T21:18:48.069834Z","iopub.status.idle":"2025-03-16T21:18:48.074196Z","shell.execute_reply.started":"2025-03-16T21:18:48.069814Z","shell.execute_reply":"2025-03-16T21:18:48.073418Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"model.eval()\nworld_size = torch.cuda.device_count()\n@torch.inference_mode()\ndef estimate_loss(val_loader, val_iterator, device):\n    out = {}\n    # train_loader = prepare_dataset('train', ModelArgs.batch_size)\n    \n    # val_loader_iterator = iter(val_loader)\n    loader = None\n    epoch_loss = None\n    epoch_losses = []\n    # print(\"Starting the eval...\")\n    for split in ['val']:\n        print(f\"Starting with {split} evaluation...\")\n        # losses = torch.zeros(ModelArgs.val_epochs)\n        # if(split == 'train'):\n        #         loader = train_loader\n        # if(split == 'val'):\n        #         loader = val_loader\n        for step in range(eval_check):  \n            try:\n                batch = next(val_iterator)\n            except StopIteration:\n                val_loader_iterator = iter(val_loader)\n                X, x, y = next(val_loader_iterator)\n                \n            # tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n            total_loss = 0  \n            # loader.sampler.set_epoch(step)\n            total_batches = 0 \n            # batch = next(val_loader_iterator)\n            # for batch in loader:  # Loop through DataLoader batches\n            # idx = batch['input_ids']\n            # targets = batch['labels']\n            spec = X.to(device)\n            \n            idx = x.to(device)\n            targets = y.to(device)\n            with torch.autocast(device_type=device, dtype=torch.float16):\n                \n                logits = model(spec, idx)\n                batch_size, block_size, embeddings_dims = logits.shape\n                logits = logits.view(batch_size * block_size, embeddings_dims)  # Flatten tokens\n                targets = targets.view(batch_size * block_size)\n\n                loss = F.cross_entropy(logits, targets, ignore_index=tokenizer.pad_token_id)\n\n                total_loss += loss.item()\n                total_batches += 1\n\n        # Compute mean loss for this epoch\n        epoch_loss = total_loss / total_batches if total_batches > 0 else 0.0\n        epoch_losses.append(epoch_loss)\n\n            # print(f\"Epoch {epoch + 1}/{ModelArgs.val_epochs}: Loss = {epoch_loss:.4f}\")\n\n        # Compute mean loss across all evaluation epochs\n        out[split] = sum(epoch_losses) / len(epoch_losses) if epoch_losses else 0.0\n        epoch_loss = None\n        epoch_losses = []\n\n    model.train()\n    return out\n\n# model = model.to(rank)\nmodel.train()\ncount = 0\n\n# train_dataloader = prepare_dataset('train', device, ModelArgs.batch_size)\n# val_loader= prepare_dataset('val', device, ModelArgs.batch_size)\n# for step in tqdm(range(total_iters)):\n# for epoch in range(ModelArgs.epochs):\n    # torch.cuda.synchronize() \n\n# train_dataloader.sampler.set_epoch(epoch)\n\n# val_loader.sampler.set_epoch(epoch)\nprint(\"Loaders ready both\")\nepochs = epochs\n\n# train_step_iterator = range(len(train_dataloader))\n# if device == 0:  # Only create progress bar on rank 0\n#   train_step_iterator = tqdm(train_step_iterator, desc=\"Training Progress\", position=0, leave=True)\n\n    # Print progress on rank 0\ntrain_loader_length = 0\ntrain_data_iterator = iter(train_dataloader)\nval_data_iterator = iter(val_dataloader)\ntoken_count = 0\nif(device == 0):\n    train_loader_length = len(train_dataloader)\n    # print(\"Total batches: \", train_loader_length)\n# print(\"Length of : \", len(train_dataloader))\n# print(\"Length of val: \", len(val_loader))\n# for  step, batch in enumerate(train_dataloader):","metadata":{"_uuid":"a0929ebe-c656-48ba-b479-e08113f3113e","_cell_guid":"20e917d1-9770-456a-99dd-5e9c33d4edda","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:48.108253Z","iopub.execute_input":"2025-03-16T21:18:48.108479Z","iopub.status.idle":"2025-03-16T21:18:48.126877Z","shell.execute_reply.started":"2025-03-16T21:18:48.108459Z","shell.execute_reply":"2025-03-16T21:18:48.126223Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Loaders ready both\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"def find_unused_parameters(model):\n    unused = []\n    for name, param in model.named_parameters():\n        if param.grad is None:\n            unused.append(name)\n    return unused","metadata":{"_uuid":"c8abd50d-6173-4aeb-8219-b6396120af54","_cell_guid":"5fd44e9d-01f8-4e2b-9130-4640fdab7419","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:48.145554Z","iopub.execute_input":"2025-03-16T21:18:48.145768Z","iopub.status.idle":"2025-03-16T21:18:48.149258Z","shell.execute_reply.started":"2025-03-16T21:18:48.145750Z","shell.execute_reply":"2025-03-16T21:18:48.148608Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def get_lr(it):\n    # 1) linear warmup for warmup_iters steps\n    if it < warmup_iters:\n        return max_lr * (it + 1) / (warmup_iters + 1)\n    # 2) if it > lr_decay_iters, return min learning rate\n    if it > lr_decay_iters:\n        return min_lr\n    # 3) in between, use cosine decay down to min learning rate\n    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n    assert 0 <= decay_ratio <= 1\n    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) \n    return min_lr + coeff * (max_lr - min_lr)","metadata":{"_uuid":"1cdf81be-4ae9-43f2-b3c5-304c73e13883","_cell_guid":"39ba72e2-ffe8-4acf-afa3-dbc3077e3e2a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:48.182799Z","iopub.execute_input":"2025-03-16T21:18:48.182998Z","iopub.status.idle":"2025-03-16T21:18:48.187182Z","shell.execute_reply.started":"2025-03-16T21:18:48.182979Z","shell.execute_reply":"2025-03-16T21:18:48.186415Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"#","metadata":{"_uuid":"5feb1c4e-332c-4b97-8952-4646e07467a6","_cell_guid":"317d13ff-dc6c-4965-adfe-d28c4bd6b40d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:48.203969Z","iopub.execute_input":"2025-03-16T21:18:48.204188Z","iopub.status.idle":"2025-03-16T21:18:48.207464Z","shell.execute_reply.started":"2025-03-16T21:18:48.204168Z","shell.execute_reply":"2025-03-16T21:18:48.206860Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"model.train()\ntrain_losses =  torch.zeros(len(train_dataloader))\nval_losses = torch.zeros(len(val_dataloader))\nwandb.init(\n    project='Whisper-From-Scratch'\n)\nstep = 0\nfor step in tqdm(range(total_iters)):\n        # print(\"Dataloader things: \", batch)\n        # print(\"Total batches: \", len(train_dataloader))\n        \n        \n        # if(device == 0):\n            # if(step % 100 == 0):\n        #     if(step == train_loader_length):\n        #       break\n        print(\"Step : \", step, \"/\", total_iters)\n        print('Total batches: ', len(train_dataloader))\n        print(\"Total gradient accumulation steps: \", gradient_accumulation_steps)\n                # print(\"Total tokens processed: \", token_count)\n                \n        # all_gpus_avg_train_loss = None\n        # all_gpus_avg_val_loss = None\n        # every once in a while evaluate the loss on train and val sets\n        if (step  % eval_iters == 0 and step != 0) or step == total_iters - 1:\n            losses = estimate_loss( val_loader, val_data_iterator, 'cuda')\n            # avg_train_loss = losses['train']\n            avg_val_loss = losses['val']\n            # print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n            # if device == 0:  # Only print on main process\n            print(f\"[GPU {device}] | Step: {step} / {total_iters} | Val Loss: {losses['val']:.4f}\")\n            # print(f\"[GPU {device}] | Epoch {epoch}/{ModelArgs.epochs}| |Step: {step} | Train Loss: {losses['train']:.4f}\")\n                # print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n                # Log training loss more frequently\n                # Aggregate average loss across all GPUs\n            # avg_train_loss = torch.Tensor([losses['train']]).to(device)\n            avg_val_loss = torch.Tensor([losses['val']]).to(device)\n            # torch.distributed.reduce(avg_train_loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n            # torch.distributed.reduce(avg_val_loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n            \n            # if device == 0:\n                # all_gpus_avg_train_loss = avg_train_loss / world_size\n                # print(f\"All_GPUs_Train_losses: {all_gpus_avg_train_loss.item():.4f}\")\n            all_gpus_avg_val_loss = avg_val_loss / world_size\n            print(f\"All_GPUs_Val_losses: {all_gpus_avg_val_loss.item():.4f}\")\n                \n            # if device == 0:\n        \n                # writer.add_scalar(\"All_GPUs_Train_losses\", all_gpus_avg_train_loss.item(), global_step=step)\n                # writer.add_scalar(\"All_GPUs_Val_losses\", all_gpus_avg_val_loss.item(), global_step=step)\n                # writer.add_scalar(\"training_step_loss\", losses['train'], global_step=step)\n                # writer.add_scalar(\"val_step_loss\", losses['val'], global_step=step)\n                # writer.add_scalar(\"GPU\", device, global_step=step)\n                # writer.add_scalar(\"Epoch\", epoch, global_step=step)\n                \n            wandb.log({\n                    # \"Learning Rate\": optimizer.param_groups[0]['lr'],\n                    # \"All_GPUs_Train_losses\": all_gpus_avg_train_loss,\n                    \"All_GPUs_Val_losses\": all_gpus_avg_val_loss,\n                    # \"training_step_loss\": losses['train'],\n                    \"val_step_loss\": losses['val'],\n                    # \"Step\": step,\n                    # \"Epoch\": epoch\n                })\n            \n            \n        \n        #Loading a checkpoint\n        # if(os.path.exists('snapshot.pt')):\n        #    model, optimizer =  _load_snapshot(model=model, optimizer=optimizer, epoch=epoch, step=step, snapshot_path='snapshot.pt')\n        \n        # if(step % save_chechpoint_iter == 0 and device == 0 and step != 0):\n            \n        #     _save_snapshot(epoch=epoch, model=model, optimizer=optimizer, step=step)\n\n        if step % save_chechpoint_iter == 0 and device == 0 and step != 0:\n            print(f\"Saving the model checkpoint for step: {step}\")\n            _save_snapshot(model, optimizer, None, None, step)\n        \n        accumulated_loss = 0.0\n        \n        \n        optimizer.zero_grad(set_to_none=True)\n        for micro_step in range(gradient_accumulation_steps):\n            try:\n                spec, idx, y = next(train_data_iterator)\n            except StopIteration:\n                train_data_iterator = iter(train_dataloader)\n                spec, idx, y = next(train_data_iterator)\n            spec = spec.to(device)\n            y = y.to(device)\n            idx = idx.to(device)\n            \n            # tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n            # print(batch)\n            # batch = next(train_data_iterator)\n            # print(batch)\n            # batch = {k: v.to(self.local_rank) for k, v in batch.items()}\n            # idx = batch['input_ids'].to(device)\n            # idx, targets = get_batch(split='train')\n            # print(f\"Starting the train step: {step}...\")\n            # for idx, targets in train_loader:\n            # idx, targets = next(iter(train_loader))\n            \n            # print(\"Idx: \", idx)\n            # print(\"Targets: \", targets)\n            \n            # idx = idx.to(device)\n            # print(\"Idx: \", idx)\n            # print(\"Targets: \", targets)\n            # targets = batch['labels'].to(device)\n            # token_count += len(idx)\n            with torch.autocast(device_type=device, dtype=torch.float16):\n                logits = model(spec, idx)\n                batch_size, block_size, embeddings_dims = logits.shape\n                # print(logits.shape)\n                # print(targets)\n                logits = logits.view(batch_size*block_size, embeddings_dims)\n                # print(\"OK\")\n                targets = y.view(batch_size * block_size)\n                # print(\"OK2\")\n                loss = nn.functional.cross_entropy(logits, targets, ignore_index=tokenizer.pad_token_id)\n                \n                loss = loss / gradient_accumulation_steps #IDK why div is done here specifically? Maybe think of it in terms of a very big batch being processed and there is need for equal important of each mini batch for the overall big batch\n                accumulated_loss += loss.detach()\n            \n            model.require_backward_grad_sync = (micro_step == gradient_accumulation_steps - 1) # so that we dont synchronize the gradient everytime across the GPU devices\n            scaler.scale(loss).backward()\n            # print(\"loss: \", loss.item())\n                # Check for unused parameters\n            unused_params = find_unused_parameters(model)\n            if unused_params:\n                print(f\"Unused parameters: {unused_params}\")\n        # break\n    \n            # if(device == 0):\n            if(micro_step % 10 == 0):\n            #     if(step == train_loader_length):\n            #       break\n                    \n                    print(\"Micro Batch : \", micro_step)\n                    print(\"Step : \", step, \"/\", total_iters)\n                    print('Total batches: ', len(train_dataloader))\n                    print(\"Total gradient accumulation steps: \", gradient_accumulation_steps)\n                    print(\"Total tokens processed: \", token_count)\n            # count += 1\n       \n        lr = get_lr(step)\n        for params in optimizer.param_groups:\n            params['lr'] = lr\n            \n        \n        \n        # Compute gradient norms before clipping\n        if(clip != 0.0):\n            scaler.unscale_(optimizer) #To avoid underflow\n            total_norm_before = torch.norm(\n                torch.stack([torch.norm(p.grad.detach(), 2) for p in model.parameters()]), 2\n            )\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n\n            # Compute gradient norms after clipping\n            total_norm_after = torch.norm(\n                torch.stack([torch.norm(p.grad.detach(), 2) for p in model.parameters()]), 2\n            )\n            \n            if(device  == 0 and step !=0):\n                print(f\"Gradient Norm Before Clipping: {total_norm_before.item():.4f}\")\n                print(f\"Gradient Norm After Clipping: {total_norm_after.item():.4f}\")\n\n        scaler.step(optimizer)\n        scaler.update()\n    \n        # optimizer.step()\n        # new_scheduler.step()\n        print(accumulated_loss)\n        # torch.cuda.synchronize() \n        # torch.distributed.reduce(loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n        # if(device == 0):\n        wandb.log({\n                    \"Learning Rate\": lr,\n                    \"All_GPUs_Train_losses\": accumulated_loss.item(),\n                    # \"All_GPUs_Val_losses\": all_gpus_avg_val_loss,\n                    # \"training_step_loss\": losses['train'],\n                    # \"val_step_loss\": losses['val'],\n                    \"Step\": step,\n                    # \"Epoch\": epoch \n                    \n                })\n\n\n        # model.train()\n        # wandb.log({\n        #   \"Train Loss\": train_losses.mean(),\n        #   \"Val Loss\": val_losses.mean(),\n        #   # \"epoch\": epoch\n        # })\n        # print(\"Epoch: \", epoch, \"|\", \"Train Loss: \", train_losses.mean(),  \"|\", \"Val Loss: \", val_losses.mean())","metadata":{"_uuid":"600fec50-d0e3-4593-a316-5c25e586c4f2","_cell_guid":"44ced50a-b954-4b04-8bc2-25b7c2601b9c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-16T21:18:48.264869Z","iopub.execute_input":"2025-03-16T21:18:48.265086Z"},"id":"nPrSPPu8cuoO","outputId":"7ba86e12-999d-4b31-9a2b-53d645357d06","jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250316_211848-ad957zr3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rentio/Whisper-From-Scratch/runs/ad957zr3' target=\"_blank\">worldly-flower-20</a></strong> to <a href='https://wandb.ai/rentio/Whisper-From-Scratch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rentio/Whisper-From-Scratch' target=\"_blank\">https://wandb.ai/rentio/Whisper-From-Scratch</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rentio/Whisper-From-Scratch/runs/ad957zr3' target=\"_blank\">https://wandb.ai/rentio/Whisper-From-Scratch/runs/ad957zr3</a>"},"metadata":{}},{"name":"stderr","text":"  0%|          | 0/20000 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Step :  0 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nMicro Batch :  0\nStep :  0 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\nMicro Batch :  10\nStep :  0 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\nMicro Batch :  20\nStep :  0 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\nMicro Batch :  30\nStep :  0 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\nMicro Batch :  40\nStep :  0 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\nMicro Batch :  50\nStep :  0 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\nMicro Batch :  60\nStep :  0 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/20000 [04:15<1420:58:58, 255.79s/it]","output_type":"stream"},{"name":"stdout","text":"tensor(11.0872, device='cuda:0')\nStep :  1 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nMicro Batch :  0\nStep :  1 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\nMicro Batch :  10\nStep :  1 / 20000\nTotal batches:  3452\nTotal gradient accumulation steps:  64\nTotal tokens processed:  0\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"device","metadata":{"_uuid":"8cf1c23a-fb45-45af-a00e-3219a7a750c8","_cell_guid":"92c4ae77-c006-43e9-a677-343c07e75e87","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"83764454-8200-4a10-9ab4-322effc15cb2","_cell_guid":"e23d9c5c-bfe8-4e86-8fd7-da9eb29e2901","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}