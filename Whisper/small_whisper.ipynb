{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"e4b2df23-1b2f-4ca2-9968-9bbd2972779d","_uuid":"4b54e35b-02bb-44b4-adca-a297c3081d36","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T20:27:50.949322Z","iopub.status.busy":"2025-03-16T20:27:50.949124Z","iopub.status.idle":"2025-03-16T20:27:53.952701Z","shell.execute_reply":"2025-03-16T20:27:53.951790Z","shell.execute_reply.started":"2025-03-16T20:27:50.949302Z"},"id":"Pw7f2ghccuoK","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from pathlib import Path\n","import random\n","\n","# from tokenizers import Tokenizer\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"8e81d8cb-2c43-4550-a8f8-09815ff2a1ab","_uuid":"fe2c17e3-b1bf-4b93-8760-de26e849e84f","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T20:27:53.954751Z","iopub.status.busy":"2025-03-16T20:27:53.954400Z","iopub.status.idle":"2025-03-16T20:27:56.417272Z","shell.execute_reply":"2025-03-16T20:27:56.416335Z","shell.execute_reply.started":"2025-03-16T20:27:53.954727Z"},"id":"LwR5_uvTcuoL","jupyter":{"outputs_hidden":false},"outputId":"492fa6c9-a295-4ebb-e3b7-8c007fbf9055","trusted":true},"outputs":[{"data":{"text/plain":["4"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\n","import re\n","HF_TOKEN = '...'\n","\n","from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", token=HF_TOKEN)\n","tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n","\n","SOT = '<|startoftranscript|>'\n","EOT = '<|endoftranscript|>'\n","transcribe = '<|transcribe|>'\n","prev = '<|prev|>'\n","\n","special_tokens_dict = {\n","    'additional_special_tokens': [SOT, EOT, transcribe, prev]\n","}\n","\n","\n","tokenizer.add_special_tokens(special_tokens_dict)\n","# model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n","\n","# tokenizer(\"hi\")"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"32170d73-d4d4-431e-ad94-fa5d9addd61f","_uuid":"234d59ef-e07b-4028-a613-ec9e72abfd67","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T20:27:56.419235Z","iopub.status.busy":"2025-03-16T20:27:56.418752Z","iopub.status.idle":"2025-03-16T20:28:08.001610Z","shell.execute_reply":"2025-03-16T20:28:08.000672Z","shell.execute_reply.started":"2025-03-16T20:27:56.419209Z"},"id":"P3vCVc6OlXe2","jupyter":{"outputs_hidden":false},"outputId":"e0a26206-20aa-4bf4-98db-dd576e96b2d9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n","Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["\n","!pip install wandb\n","import wandb\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"API_KEY\")\n","\n","wandb.login(key=secret_value_0)"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"33ab1861-74f7-45f5-adb9-f986e5a7e036","_uuid":"4f155899-f57d-4c37-aa94-e56a969d0259","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T20:28:08.003275Z","iopub.status.busy":"2025-03-16T20:28:08.002697Z","iopub.status.idle":"2025-03-16T20:28:08.018779Z","shell.execute_reply":"2025-03-16T20:28:08.017823Z","shell.execute_reply.started":"2025-03-16T20:28:08.003246Z"},"id":"D7AP219KJzTs","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#Hyperparameters\n","epochs=10\n","block_size = 64\n","batch_size = 64\n","# src_vocab_size = None\n","tgt_vocab_size = len(tokenizer)\n","embeddings_dims = 512\n","attn_dropout = 0.1\n","no_of_heads = 8 #IMP needs to be thoroughly calculated\n","dropout = 0.1\n","# epochs = 3\n","max_lr = 6e-4\n","no_of_decoder_layers = 8 #IMP needs to be thoroughly calculated\n","attn_dropout = 0.1\n","weight_decay_optim = 0.01\n","log_mel_features = 80\n","kernel_size = 3\n","stride = (2,10)\n","sr = 16000\n","device= 'cuda:0'\n","SAMPLING_RATE=16000\n","N_MELS = 80  # 80-channel Mel spectrogram\n","WINDOW_DURATION = 0.025  # 25 milliseconds\n","STRIDE_DURATION = 0.010  # 10 milliseconds\n","max_t = 500\n","n_channels = N_MELS\n","clip = 1.0"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"5ac94789-1d5e-4ace-88f3-25b5413fb78b","_uuid":"92a80d68-b0eb-4f1d-b988-7f190e0b934a","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T20:28:08.020631Z","iopub.status.busy":"2025-03-16T20:28:08.020054Z","iopub.status.idle":"2025-03-16T20:28:08.043556Z","shell.execute_reply":"2025-03-16T20:28:08.042503Z","shell.execute_reply.started":"2025-03-16T20:28:08.020565Z"},"id":"TmPkI_UEpvor","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["torch.set_default_device(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"1777fa9a-7686-4b62-93c1-c31c2ccf73c1","_uuid":"e08f94e6-dae5-42f3-a285-c151086b8f1b","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T20:28:08.045189Z","iopub.status.busy":"2025-03-16T20:28:08.044805Z","iopub.status.idle":"2025-03-16T20:28:14.373089Z","shell.execute_reply":"2025-03-16T20:28:14.372056Z","shell.execute_reply.started":"2025-03-16T20:28:08.045149Z"},"id":"IME1Ls95Y3gl","jupyter":{"outputs_hidden":false},"outputId":"ab87d390-48f4-43be-b421-aad103deacca","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n","DatasetDict({\n","    train: Dataset({\n","        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n","        num_rows: 230068\n","    })\n","    validation: Dataset({\n","        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n","        num_rows: 6750\n","    })\n","    test: Dataset({\n","        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n","        num_rows: 25619\n","    })\n","})\n"]}],"source":["\n","!pip install datasets\n","from tabnanny import verbose\n","from datasets import load_dataset\n","\n","gs = load_dataset(\"speechcolab/gigaspeech\", \"s\", token=HF_TOKEN, trust_remote_code=True) \n","\n","\n","print(gs)\n","\n","\n","audio_input = gs['train'][0][\"audio\"] \n","transcription = gs[\"train\"][0][\"text\"]"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"0c018b51-6161-49d9-995e-21cf09d1391f","_uuid":"027b3fe3-8e01-40c4-99de-1a1b12d93453","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T20:28:14.374940Z","iopub.status.busy":"2025-03-16T20:28:14.374239Z","iopub.status.idle":"2025-03-16T20:35:37.108931Z","shell.execute_reply":"2025-03-16T20:35:37.108126Z","shell.execute_reply.started":"2025-03-16T20:28:14.374907Z"},"id":"cRV1EOlVY3gm","jupyter":{"outputs_hidden":false},"outputId":"1052df52-a76c-4ee1-c4e7-cd495e3fb212","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 230068/230068 [07:02<00:00, 545.17it/s]\n","100%|██████████| 6750/6750 [00:20<00:00, 335.73it/s]\n"]}],"source":["MAX_DURATION_IN_SECONDS = 10\n","\n","import librosa\n","from tqdm import tqdm\n","def is_audio_length_in_range(input_length):\n","    return input_length < MAX_DURATION_IN_SECONDS\n","\n","train_new_column = []\n","\n","for x in tqdm(range(len(gs['train']))):\n","    train_new_column.append(librosa.get_duration(path=gs['train'][x]['audio']['path']))\n","\n","gs_ = gs['train'].add_column(\"duration\", train_new_column)\n","\n","\n","gs_ = gs_.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n","\n","\n","truncated_gs_train = gs_.remove_columns([\"duration\"])\n","# truncated_gs\n","\n","\n","\n","val_new_column = []\n","# new_column = [librosa.get_duration(path=x) ]]\n","for x in tqdm(range(len(gs['validation']))):\n","    val_new_column.append(librosa.get_duration(path=gs['validation'][x]['audio']['path']))\n","\n","gs_ = gs['validation'].add_column(\"duration\", val_new_column)\n","\n","\n","gs_ = gs_.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n","\n","\n","truncated_gs_val = gs_.remove_columns([\"duration\"])\n","# truncated_gs"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"68c3295a-6eef-4874-acaf-73f9279fad98","_uuid":"d988499f-ad5b-47cf-bd9e-257395584889","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T20:35:37.111778Z","iopub.status.busy":"2025-03-16T20:35:37.111522Z","iopub.status.idle":"2025-03-16T21:17:23.216508Z","shell.execute_reply":"2025-03-16T21:17:23.215522Z","shell.execute_reply.started":"2025-03-16T20:35:37.111754Z"},"id":"6NZ9Hbp5q1to","jupyter":{"outputs_hidden":false},"outputId":"cf76473e-8044-4b1c-b1e3-a18861572149","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 220942/220942 [40:27<00:00, 91.01it/s] \n","  1%|▏         | 71/5447 [00:01<01:15, 70.84it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3408\n","  warnings.warn(\n"," 26%|██▌       | 1394/5447 [00:20<00:58, 68.92it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2000\n","  warnings.warn(\n"," 50%|█████     | 2726/5447 [00:39<00:39, 68.64it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2240\n","  warnings.warn(\n"," 69%|██████▉   | 3782/5447 [00:54<00:21, 77.39it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3808\n","  warnings.warn(\n"," 85%|████████▍ | 4624/5447 [01:06<00:11, 71.32it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3600\n","  warnings.warn(\n","100%|██████████| 5447/5447 [01:18<00:00, 69.52it/s]\n"]}],"source":["\n","import numpy as np\n","\n","\n","n_fft = int(WINDOW_DURATION * MAX_DURATION_IN_SECONDS * SAMPLING_RATE)\n","hop_length = int(STRIDE_DURATION * MAX_DURATION_IN_SECONDS * SAMPLING_RATE)\n","\n","train_outputs = []\n","train_texts = []\n","for i in tqdm(range(len(truncated_gs_train))):\n","  S = librosa.feature.melspectrogram(\n","      y=truncated_gs_train[i]['audio']['array'],\n","      sr=SAMPLING_RATE,\n","      n_mels=N_MELS,\n","      n_fft=n_fft,\n","      hop_length=hop_length,\n","      win_length=n_fft,\n","      fmax=SAMPLING_RATE // 2\n","  )\n","\n","\n","  S_dB = librosa.power_to_db(S, ref=np.max)\n","  train_outputs.append(S_dB)\n","  train_texts.append(truncated_gs_train[i]['text'])\n","\n","val_outputs = []\n","val_texts = []\n","for i in tqdm(range(len(truncated_gs_val))):\n","  S = librosa.feature.melspectrogram(\n","      y=truncated_gs_val[i]['audio']['array'],\n","      sr=SAMPLING_RATE,\n","      n_mels=N_MELS,\n","      n_fft=n_fft,\n","      hop_length=hop_length,\n","      win_length=n_fft,\n","      fmax=SAMPLING_RATE // 2\n","  )\n","\n","\n","  S_dB = librosa.power_to_db(S, ref=np.max)\n","  val_outputs.append(S_dB)\n","  val_texts.append(truncated_gs_val[i]['text'])"]},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"db1f5e13-91c6-4d24-8d31-325796a8a0fd","_uuid":"b456c1a6-6703-4809-a1fb-fc077a5dc8e3","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:23.219755Z","iopub.status.busy":"2025-03-16T21:17:23.219057Z","iopub.status.idle":"2025-03-16T21:17:23.229394Z","shell.execute_reply":"2025-03-16T21:17:23.228433Z","shell.execute_reply.started":"2025-03-16T21:17:23.219721Z"},"id":"z2aGf6_7xe9S","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# import math\n","# print(round(random.random(), 1))\n","class GigaSpeechDataset(Dataset):\n","\n","  def __init__(self, outputs, texts): \n","\n","    self.data = outputs\n","    self.texts = texts\n","    self.max_t = block_size\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","\n","  def pad_to_max_t(self, spectrogram, max_t):\n","\n","    n_mels, t = spectrogram.shape\n","    if t < max_t:\n","        # Pad with zeros\n","        pad_width = ((0, 0), (0, max_t - t))\n","        spectrogram = np.pad(spectrogram, pad_width, mode='constant')\n","    else:\n","      spectrogram = spectrogram[:, :max_t]\n","\n","    return spectrogram\n","\n","  def clean(self, desc):\n","    # Use regex to remove anything between < and >\n","    cleaned_text = re.sub(r'<[^>]*>', '', desc)\n","    return cleaned_text\n","\n","  def __getitem__(self, idx):\n","\n","      SOT = '<|startoftranscript|>'\n","      EOT = '<|endoftranscript|>'\n","      transcribe = '<|transcribe|>'\n","      # prev = '<|prev|>'\n","      spectrogram = self.pad_to_max_t(self.data[idx], self.max_t)\n","      # probs = round(random.random(),1)\n","      spectrogram = torch.tensor(spectrogram, dtype=torch.float32)\n","\n","      # if(probs == 0.5):\n","        # Normalize the spectrogram between -1 and 1\n","      spectrogram_min = spectrogram.min()\n","      spectrogram_max = spectrogram.max()\n","      # spectrogram = spectrogram.unsqueeze(0)  # Shape: (1, n_mels, max_t)\n","      # prev_text =\n","      text = self.clean(self.texts[idx])\n","\n","      text = text.lower()\n","      text = SOT  + 'en' + transcribe +  text + EOT\n","      tokenized_text = tokenizer(text, truncation=True, padding='max_length', max_length=block_size, return_tensors='pt')\n","      # print(tokenized_text.shape)\n","\n","      epsilon = 1e-8  # To avoid division by zero\n","      spectrogram = 2 * ((spectrogram - spectrogram_min) / (spectrogram_max - spectrogram_min + epsilon)) - 1\n","\n","      # tokenized_win_prompt = tokenizer(text, max_length = ModelArgs.block_size, padding='max_length', truncation=True,  return_tensors=\"pt\").to(device)\n","      tokenized_text['labels'] = tokenized_text['input_ids'].clone()\n","      tokenized_text['labels'][: , :-1] = tokenized_text['input_ids'][: , 1:]\n","      tokenized_text['labels'][: , -1] = tokenizer.eos_token_id \n","\n","      tokenized_text_x = tokenized_text['input_ids'].squeeze(0)\n","      tokenized_text_y = tokenized_text['labels'].squeeze(0)\n","      \n","      # print(tokenized_text.shape)\n","      return spectrogram, tokenized_text_x, tokenized_text_y"]},{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"78e27c8d-e3cd-434c-b2c6-9d16b79eb5be","_uuid":"5ca81223-5c7e-43e5-83b2-7b00a3ecee7f","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:23.230758Z","iopub.status.busy":"2025-03-16T21:17:23.230437Z","iopub.status.idle":"2025-03-16T21:17:23.258809Z","shell.execute_reply":"2025-03-16T21:17:23.257804Z","shell.execute_reply.started":"2025-03-16T21:17:23.230731Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7887ebef2f80>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["torch.autograd.set_detect_anomaly(True)  # Add at the start of training"]},{"cell_type":"code","execution_count":11,"metadata":{"_cell_guid":"d26cf6eb-55b2-484c-bc9b-10952ea5c977","_uuid":"8db84c70-d655-4b7c-8c00-9e195d240a7d","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:23.260278Z","iopub.status.busy":"2025-03-16T21:17:23.259908Z","iopub.status.idle":"2025-03-16T21:17:23.478760Z","shell.execute_reply":"2025-03-16T21:17:23.477736Z","shell.execute_reply.started":"2025-03-16T21:17:23.260242Z"},"id":"2tvMuBSOynPy","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","shuffle = True\n","\n","train_dataset = GigaSpeechDataset(train_outputs, train_texts)\n","val_dataset = GigaSpeechDataset(val_outputs, val_texts)\n","\n","generator = torch.Generator(device=device)\n","\n","train_dataloader = DataLoader(\n","\n","    train_dataset,\n","    batch_size=batch_size,\n","    generator=generator,\n","    shuffle=shuffle,\n","     drop_last=True,\n",")\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    generator=generator,\n","    drop_last=True ,\n","    shuffle=shuffle,\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"_cell_guid":"b0074df8-52c7-45e7-99d2-7aeb8f646a6b","_uuid":"d681546c-459b-4cdf-b52d-256e7113beb7","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:23.480097Z","iopub.status.busy":"2025-03-16T21:17:23.479814Z","iopub.status.idle":"2025-03-16T21:17:25.574570Z","shell.execute_reply":"2025-03-16T21:17:25.573700Z","shell.execute_reply.started":"2025-03-16T21:17:23.480071Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["[tensor([[[-0.6308, -0.5936, -0.1951,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.5304, -0.4495, -0.1550,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.4679, -0.3332,  0.2241,  ...,  1.0000,  1.0000,  1.0000],\n","          ...,\n","          [-1.0000, -0.8912, -0.2970,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -1.0000, -0.4235,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -1.0000, -0.4402,  ...,  1.0000,  1.0000,  1.0000]],\n"," \n","         [[-0.1280, -0.0385,  0.1464,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.4492, -0.2401,  0.1058,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.5139, -0.2780,  0.3146,  ...,  1.0000,  1.0000,  1.0000],\n","          ...,\n","          [-1.0000, -1.0000, -0.6439,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -1.0000, -0.6567,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -1.0000, -0.9125,  ...,  1.0000,  1.0000,  1.0000]],\n"," \n","         [[-0.2847, -0.2055, -0.0936,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.1869, -0.1504, -0.0317,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.1396, -0.0051,  0.0646,  ...,  1.0000,  1.0000,  1.0000],\n","          ...,\n","          [-1.0000, -1.0000, -0.9895,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -1.0000, -1.0000,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -1.0000, -1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n"," \n","         ...,\n"," \n","         [[ 0.1052, -0.1046,  0.0111,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.1178, -0.1320,  0.0529,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.1492,  0.2231,  0.5416,  ...,  1.0000,  1.0000,  1.0000],\n","          ...,\n","          [-0.8554, -1.0000, -0.6556,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.8801, -1.0000, -0.8046,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.9292, -1.0000, -0.9218,  ...,  1.0000,  1.0000,  1.0000]],\n"," \n","         [[ 0.4733,  0.4843,  0.5110,  ...,  1.0000,  1.0000,  1.0000],\n","          [ 0.1678,  0.2962,  0.2360,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.0977,  0.0471,  0.0858,  ...,  1.0000,  1.0000,  1.0000],\n","          ...,\n","          [-1.0000, -1.0000, -0.6226,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -1.0000, -0.8729,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -1.0000, -1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n"," \n","         [[-0.4354, -0.4761, -0.0994,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.3909, -0.5456, -0.1636,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.0200,  0.0759,  0.1113,  ...,  1.0000,  1.0000,  1.0000],\n","          ...,\n","          [-0.9704, -0.7813, -0.3913,  ...,  1.0000,  1.0000,  1.0000],\n","          [-0.9725, -0.8091, -0.4207,  ...,  1.0000,  1.0000,  1.0000],\n","          [-1.0000, -0.9922, -0.5436,  ...,  1.0000,  1.0000,  1.0000]]],\n","        device='cuda:0'),\n"," tensor([[50258,   268, 50260,  ..., 50257, 50257, 50257],\n","         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n","         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n","         ...,\n","         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n","         [50258,   268, 50260,  ..., 50257, 50257, 50257],\n","         [50258,   268, 50260,  ..., 50257, 50257, 50257]], device='cuda:0'),\n"," tensor([[  268, 50260,   271,  ..., 50257, 50257, 50256],\n","         [  268, 50260,   258,  ..., 50257, 50257, 50256],\n","         [  268, 50260,  2197,  ..., 50257, 50257, 50256],\n","         ...,\n","         [  268, 50260, 35569,  ..., 50257, 50257, 50256],\n","         [  268, 50260, 10197,  ..., 50257, 50257, 50256],\n","         [  268, 50260,    73,  ..., 50257, 50257, 50256]], device='cuda:0')]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(train_dataloader))"]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"a7c6dcaa-5a5d-4260-8696-ee827274edff","_uuid":"25ee96a4-00b2-40a5-a8e4-10ea78a00481","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.575666Z","iopub.status.busy":"2025-03-16T21:17:25.575422Z","iopub.status.idle":"2025-03-16T21:17:25.580222Z","shell.execute_reply":"2025-03-16T21:17:25.579208Z","shell.execute_reply.started":"2025-03-16T21:17:25.575643Z"},"id":"kzXk76ULY3gm","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#Position embeddings\n","class PositionEmbeddings(nn.Module):\n","    def __init__(\n","        self,\n","        embeddings_dims = embeddings_dims,\n","        block_size = block_size\n","    ):\n","        super().__init__()\n","\n","        self.position_embeddings = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n","        # nn.init.normal_(self.position_embeddings.weight.data, mean=0, std=0.02)\n","\n","    def forward(self, x):\n","        return self.position_embeddings"]},{"cell_type":"code","execution_count":14,"metadata":{"_cell_guid":"779e1bc7-798e-4e86-ad9e-0967b08dcab9","_uuid":"6c495fe4-d351-4477-be75-b575ea534db0","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.581153Z","iopub.status.busy":"2025-03-16T21:17:25.580958Z","iopub.status.idle":"2025-03-16T21:17:25.631084Z","shell.execute_reply":"2025-03-16T21:17:25.630436Z","shell.execute_reply.started":"2025-03-16T21:17:25.581135Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["Parameter containing:\n","tensor([[[-0.1833,  1.0182,  0.6804,  ...,  0.9679,  0.1340,  0.0834],\n","         [-0.3049,  0.2414,  0.4808,  ..., -1.5566, -0.5475,  0.2741],\n","         [-1.1239,  0.7832, -1.0881,  ..., -1.0171,  0.0344, -0.6055],\n","         ...,\n","         [-1.2816, -1.1764,  1.5847,  ...,  2.2729, -0.5462, -1.1655],\n","         [-0.2015, -0.9212,  1.6189,  ...,  0.1398,  1.1379,  1.0406],\n","         [-0.0946,  1.5284,  1.0860,  ...,  0.8111, -1.0142,  0.8692]]],\n","       device='cuda:0', requires_grad=True)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["pos = PositionEmbeddings()\n","x = torch.randn(batch_size, block_size, embeddings_dims)\n","pos(x)"]},{"cell_type":"code","execution_count":15,"metadata":{"_cell_guid":"62818f89-119f-4059-8538-2feefb03e6a7","_uuid":"8c520ea7-c368-4ce4-914c-2094cb5ed848","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.631941Z","iopub.status.busy":"2025-03-16T21:17:25.631754Z","iopub.status.idle":"2025-03-16T21:17:25.636182Z","shell.execute_reply":"2025-03-16T21:17:25.635330Z","shell.execute_reply.started":"2025-03-16T21:17:25.631924Z"},"id":"R9CSiuD2jHyT","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","# Text embeddings\n","class TgtTextEmbeddings(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size = tgt_vocab_size,\n","        embeddings_dims = embeddings_dims\n","    ):\n","        super().__init__()\n","        self.embeddings_table = nn.Embedding(num_embeddings = tgt_vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n","        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n","\n","    def forward(self, x):\n","        return self.embeddings_table(x)"]},{"cell_type":"code","execution_count":16,"metadata":{"_cell_guid":"0e795d31-2801-446a-807d-0ea3bebb6e3d","_uuid":"ae3226bb-4414-4840-8da7-73db14ad8271","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.637345Z","iopub.status.busy":"2025-03-16T21:17:25.637118Z","iopub.status.idle":"2025-03-16T21:17:25.653427Z","shell.execute_reply":"2025-03-16T21:17:25.652838Z","shell.execute_reply.started":"2025-03-16T21:17:25.637325Z"},"id":"REUDHWrWcuoN","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","\n","#Layer Normalization\n","\n","class LayerNormalization(nn.Module):\n","    def __init__(\n","        self,\n","        embeddings_dims = embeddings_dims\n","    ):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(normalized_shape=embeddings_dims)\n","    def forward(self, x):\n","\n","        return self.norm(x)"]},{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"762624a5-8d63-403b-bc4e-039b16aba3f9","_uuid":"70301094-ba8a-4078-a1ad-46dc8d357f6a","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.654302Z","iopub.status.busy":"2025-03-16T21:17:25.654077Z","iopub.status.idle":"2025-03-16T21:17:25.672472Z","shell.execute_reply":"2025-03-16T21:17:25.671677Z","shell.execute_reply.started":"2025-03-16T21:17:25.654281Z"},"id":"lEe02cH9cuoN","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","\n","#FeedForward Neural Network\n","\n","class MLPBlock(nn.Module):\n","    def __init__(\n","        self,\n","        dropout = dropout,\n","        embeddings_size = embeddings_dims,\n","        # inner_dimensional_states: int = 3072\n","    ):\n","        super().__init__()\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(device=device, in_features=embeddings_size, out_features= 4 * embeddings_dims),\n","            nn.GELU(),\n","            nn.Linear(device=device, in_features= 4 * embeddings_dims, out_features=embeddings_size),\n","            nn.Dropout(p = dropout)\n","        )\n","\n","    def forward(self, x):\n","        # mlp_weights_init = self.mlp.apply(weights_init)\n","        return self.mlp(x)"]},{"cell_type":"code","execution_count":18,"metadata":{"_cell_guid":"50c3f233-f3ea-44cc-bccf-10aa13fc35d5","_uuid":"bd1f493a-c5eb-4821-938b-1fd4baf55549","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.673679Z","iopub.status.busy":"2025-03-16T21:17:25.673386Z","iopub.status.idle":"2025-03-16T21:17:25.693459Z","shell.execute_reply":"2025-03-16T21:17:25.692644Z","shell.execute_reply.started":"2025-03-16T21:17:25.673647Z"},"id":"cf0Jf_7UcuoN","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","class MaskedAttentionHead(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","    ):\n","        super().__init__()\n","        self.head_size = embeddings_dims // no_of_heads\n","        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n","        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n","        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n","        self.dropout = nn.Dropout(p = attn_dropout)\n","\n","\n","    def forward(self, x):\n","        # print(x.shape)\n","        batch, block_size, embd_dims = x.shape\n","        k = self.keys(x)\n","        q = self.query(x)\n","        v = self.values(x)\n","        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n","        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n","        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n","        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n","        weights_normalized = self.dropout(weights_normalized)\n","        out = weights_normalized @ v\n","        return out"]},{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"aee629bd-84ad-4f0c-a0e7-9e3070e10081","_uuid":"a252848c-a0b1-4c08-8a42-e2851e642a06","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.694740Z","iopub.status.busy":"2025-03-16T21:17:25.694382Z","iopub.status.idle":"2025-03-16T21:17:25.713823Z","shell.execute_reply":"2025-03-16T21:17:25.712953Z","shell.execute_reply.started":"2025-03-16T21:17:25.694708Z"},"id":"OUFERSL2u8LT","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","\n","class MaskedMHA(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","    ):\n","        super().__init__()\n","        self.heads = nn.ModuleList([MaskedAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n","        self.dropout = nn.Dropout(p = attn_dropout)\n","        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n","\n","    def forward(self, x):\n","        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n","        linear_layer = self.linear(concat)\n","        out = self.dropout(linear_layer)\n","        return out"]},{"cell_type":"code","execution_count":20,"metadata":{"_cell_guid":"76ee1dab-07cf-4ae4-ac9a-3c134b9dc41d","_uuid":"0bdd11ba-b65a-4dbe-9b09-25d24c2b3ab6","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.714859Z","iopub.status.busy":"2025-03-16T21:17:25.714607Z","iopub.status.idle":"2025-03-16T21:17:25.736087Z","shell.execute_reply":"2025-03-16T21:17:25.735469Z","shell.execute_reply.started":"2025-03-16T21:17:25.714838Z"},"id":"oGGyyF4pjHyd","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","#Single Attention Head\n","\n","class CrossAttentionHead(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","    ):\n","        super().__init__()\n","        self.head_size = embeddings_dims // no_of_heads\n","        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n","        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n","        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n","        self.dropout = nn.Dropout(p = attn_dropout)\n","\n","\n","    def forward(self, query, key, value, mask=None):\n","        \n","       \n","        batch, block_size, embd_dims = query.shape\n","        q = self.query(query)\n","        k = self.keys(key)\n","        v = self.values(value)\n","        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n","        # weights = query @ torch.transpose(key, dim0=-2, dim1=-1) * (key.shape[-1] ** -0.5)\n","        # if(mask != None):\n","        #     mask = mask.unsqueeze(1)\n","        #     masked_values = weights.masked_fill(mask == 0, float('-inf'))\n","        #     weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n","        #     # weights_normalized = self.dropout(weights_normalized)\n","        #     out = weights_normalized @ value\n","        #     out = self.dropout(out)\n","        #     return out\n","        # else:\n","        #     weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n","        #     # weights_normalized = self.dropout(weights_normalized)\n","        #     out = weights_normalized @ value\n","        #     out = self.dropout(out)\n","        #     return out\n","\n","        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n","        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n","        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n","        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n","        weights_normalized = self.dropout(weights_normalized)\n","        out = weights_normalized @ v\n","        return out"]},{"cell_type":"code","execution_count":21,"metadata":{"_cell_guid":"bcde57b5-61a0-4d56-aa5a-5fbbc2f2a9bd","_uuid":"af55eb4d-6d72-465f-8692-4777da91e56f","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.737123Z","iopub.status.busy":"2025-03-16T21:17:25.736929Z","iopub.status.idle":"2025-03-16T21:17:25.763686Z","shell.execute_reply":"2025-03-16T21:17:25.762859Z","shell.execute_reply.started":"2025-03-16T21:17:25.737106Z"},"id":"U5NmszzcjHyf","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#Single Attention Head\n","\n","class FullAttentionHead(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","    ):\n","        super().__init__()\n","        self.head_size = embeddings_dims // no_of_heads\n","        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n","        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n","        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n","        self.dropout = nn.Dropout(p = attn_dropout)\n","\n","\n","    def forward(self, x, mask=None):\n","        # batch, block_size, embd_dims = x.shape\n","        k = self.keys(x)\n","        q = self.query(x)\n","        v = self.values(x)\n","        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n","        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n","        if(mask != None):\n","            mask = mask.unsqueeze(1)\n","            masked_values = weights.masked_fill(mask == 0, float('-inf'))\n","            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n","            # weights_normalized = self.dropout(weights_normalized)\n","            out = weights_normalized @ v\n","            out = self.dropout(out)\n","            return out\n","        else:\n","            weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n","            # weights_normalized = self.dropout(weights_normalized)\n","            out = weights_normalized @ v\n","            out = self.dropout(out)\n","            return out"]},{"cell_type":"code","execution_count":22,"metadata":{"_cell_guid":"8099497c-1f19-4d53-8965-ae8f153335be","_uuid":"50fee96b-7dae-4da2-951a-b06330293a3e","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.765002Z","iopub.status.busy":"2025-03-16T21:17:25.764640Z","iopub.status.idle":"2025-03-16T21:17:25.787092Z","shell.execute_reply":"2025-03-16T21:17:25.786217Z","shell.execute_reply.started":"2025-03-16T21:17:25.764968Z"},"id":"v_BB7r7kqmOc","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","class FullMHA(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","    ):\n","        super().__init__()\n","        self.heads = nn.ModuleList([FullAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n","        self.dropout = nn.Dropout(p = attn_dropout)\n","        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n","\n","    def forward(self, x, mask=None):\n","        concat = torch.cat([head(x, mask) for head in self.heads], dim=-1)\n","        linear_layer = self.linear(concat)\n","        out = self.dropout(linear_layer)\n","        return out"]},{"cell_type":"code","execution_count":23,"metadata":{"_cell_guid":"06ee6670-5428-4e5a-867e-cdd98cddc2aa","_uuid":"3627fa0f-bd35-4dab-9451-03a2b716732b","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.788020Z","iopub.status.busy":"2025-03-16T21:17:25.787815Z","iopub.status.idle":"2025-03-16T21:17:25.809259Z","shell.execute_reply":"2025-03-16T21:17:25.808685Z","shell.execute_reply.started":"2025-03-16T21:17:25.788001Z"},"id":"TTwRkBzcvE-_","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","class CrossMHA(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","    ):\n","        super().__init__()\n","        self.heads = nn.ModuleList([CrossAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n","        self.dropout = nn.Dropout(p = attn_dropout)\n","        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) \n","\n","    def forward(self, value, key, x, mask=None):\n","        concat = torch.cat([head(x, key, value,  mask) for head in self.heads], dim=-1)\n","        linear_layer = self.linear(concat)\n","        out = self.dropout(linear_layer)\n","        return out"]},{"cell_type":"code","execution_count":24,"metadata":{"_cell_guid":"2e095386-2ee5-4a3c-83bb-cad96cb26746","_uuid":"2c290085-c1fe-4c64-9bab-baa448c3bae5","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.810295Z","iopub.status.busy":"2025-03-16T21:17:25.810050Z","iopub.status.idle":"2025-03-16T21:17:25.826116Z","shell.execute_reply":"2025-03-16T21:17:25.825190Z","shell.execute_reply.started":"2025-03-16T21:17:25.810261Z"},"id":"s9rJzO_XcuoO","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Decoder Block\n","\n","class TransformerDecoderBlock(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","        dropout = dropout,\n","        # vocab_size = vocab_size\n","    ):\n","        super().__init__()\n","\n","        self.cross = CrossMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n","        self.masked = MaskedMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n","        self.layer_norm1 = LayerNormalization(embeddings_dims)\n","        self.layer_norm2 = LayerNormalization(embeddings_dims)\n","        # self.layer_norm3 = LayerNormalization(embeddings_dims=embeddings_dims)\n","        self.layer_norm4 = LayerNormalization(embeddings_dims)\n","        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n","\n","    def forward(self, key, value, x, mask=None):\n","        x = self.layer_norm1(x + self.masked(x)) #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n","        # print(x.shape)\n","        x = self.layer_norm2(x + self.cross(value, key, x, mask)) #Very important step\n","        # print(x.shape)\n","        # x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n","        x = self.layer_norm4(x + self.mlp_block(x)) #Very important step\n","        # print(x.shape)\n","\n","        return x"]},{"cell_type":"code","execution_count":25,"metadata":{"_cell_guid":"63e5400a-b5d2-4ef7-8f30-b1bc0e233820","_uuid":"05fd4f49-cc4b-474c-9a9c-3d5191eefa43","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.827199Z","iopub.status.busy":"2025-03-16T21:17:25.826969Z","iopub.status.idle":"2025-03-16T21:17:25.850583Z","shell.execute_reply":"2025-03-16T21:17:25.849957Z","shell.execute_reply.started":"2025-03-16T21:17:25.827178Z"},"id":"KGh8ujQJcuoO","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Decoder Block\n","\n","class DecoderModel(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","        block_size = block_size,\n","        dropout = dropout,\n","        no_of_decoder_layers = no_of_decoder_layers,\n","        # vocab_size = vocab_size\n","    ):\n","        super().__init__()\n","\n","\n","\n","\n","        # self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n","        # self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n","        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n","        self.decoder_layers = nn.ModuleList([TransformerDecoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n","        self.apply(self._init_weights)\n","        # self.positional_embeddings_tgt = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n","        self.positional_embeddings_tgt = PositionEmbeddings()\n","        # torch.nn.init.normal_(self.positional_embeddings_tgt, mean=0.0, std=0.02)\n","\n","        # out = self.decoder_layers(query, key, x)\n","        # Loop through each decoder layer\n","    def _init_weights(self, module):  #Weight Initialization\n","            if isinstance(module, nn.Linear):\n","                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","                if module.bias is not None:\n","                    torch.nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.Embedding):\n","                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, key, value, x, mask):\n","        # x = self.tgt_text_embds(x)\n","        x = x + self.positional_embeddings_tgt(x)\n","        # print(x.shape)\n","        for decoder_layer in self.decoder_layers:\n","            x = decoder_layer(key, value, x, mask)\n","        # x = self.layer_norm(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":26,"metadata":{"_cell_guid":"5327372f-0db3-4ef1-a59c-1757b6edfc62","_uuid":"1e94a41d-aaa3-4e74-a02f-fb0edbfa9118","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.854582Z","iopub.status.busy":"2025-03-16T21:17:25.854371Z","iopub.status.idle":"2025-03-16T21:17:25.876149Z","shell.execute_reply":"2025-03-16T21:17:25.875339Z","shell.execute_reply.started":"2025-03-16T21:17:25.854563Z"},"id":"A3SgKrC-jHyd","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","#Encoder"]},{"cell_type":"code","execution_count":27,"metadata":{"_cell_guid":"2a3683d1-303c-41a2-9cc6-b7e053fde34c","_uuid":"3ecc13cd-e38a-4e1c-af9c-10f8e84b02d7","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.878065Z","iopub.status.busy":"2025-03-16T21:17:25.877823Z","iopub.status.idle":"2025-03-16T21:17:25.893369Z","shell.execute_reply":"2025-03-16T21:17:25.892523Z","shell.execute_reply.started":"2025-03-16T21:17:25.878033Z"},"id":"v6mbbO3yp-gh","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","\n","class TransformerEncoderBlock(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","        dropout = dropout,\n","        mask=None\n","    ):\n","        super().__init__()\n","\n","        self.mha = FullMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n","        self.layer_norm1 = LayerNormalization(embeddings_dims)\n","        self.layer_norm2 = LayerNormalization(embeddings_dims)\n","        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n","\n","    def forward(self, x, mask=None):\n","        x = self.layer_norm1(x + self.mha(x, mask))\n","        x = self.layer_norm2(x + self.mlp_block(x))\n","\n","        return x"]},{"cell_type":"code","execution_count":28,"metadata":{"_cell_guid":"2fa82426-e551-497d-8247-051a55f74a3c","_uuid":"39475274-a828-4151-9556-fa4bf30d4455","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.894660Z","iopub.status.busy":"2025-03-16T21:17:25.894341Z","iopub.status.idle":"2025-03-16T21:17:25.916685Z","shell.execute_reply":"2025-03-16T21:17:25.915829Z","shell.execute_reply.started":"2025-03-16T21:17:25.894605Z"},"id":"HxW0pvnV12Ms","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","\n","class EncoderModel(nn.Module):\n","    def __init__(\n","        self,\n","        attn_dropout = attn_dropout,\n","        embeddings_dims = embeddings_dims,\n","        no_of_heads = no_of_heads,\n","        block_size = block_size,\n","        dropout = dropout,\n","        no_of_decoder_layers = no_of_decoder_layers,\n","        # vocab_size = vocab_size\n","    ):\n","        super().__init__()\n","\n","\n","        # self.positional_embeddings_src = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n","\n","        self.conv1 = nn.Conv1d(in_channels=n_channels, out_channels=embeddings_dims, kernel_size=kernel_size, device=device, padding=1)\n","        self.conv2 = nn.Conv1d(in_channels=embeddings_dims, out_channels=embeddings_dims, kernel_size=kernel_size, device=device, padding=1)\n","\n","        self.positional_embeddings_src = PositionEmbeddings()\n","\n","        self.encoder_layers = nn.ModuleList([TransformerEncoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):  #Weight Initialization\n","            if isinstance(module, nn.Linear):\n","                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","                if module.bias is not None:\n","                    torch.nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.Embedding):\n","                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, x, mask):\n","\n","        x = self.conv1(x)\n","        x = torch.nn.functional.gelu(x)\n","        x = self.conv2(x)\n","        x = torch.nn.functional.gelu(x)\n","        # print(x.shape)\n","        # x = self.src_text_embeds(x)\n","        # print(self.positional_embeddings_src.shape)\n","        x = x.permute(0, 2, 1)\n","        # print(x.shape)\n","        # print(self.positional_embeddings_src(x).shape)\n","        x = x + self.positional_embeddings_src(x)\n","        # print(x)\n","        # print(x.shape)\n","        # Loop through each encoder layer\n","        for encoder_layer in self.encoder_layers:\n","            x = encoder_layer(x, mask)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad3a1595-5722-4fff-a54e-87e3bb755abe","_uuid":"249cf674-9b8b-406a-920d-603c6c2f00ff","collapsed":false,"id":"Qi3v6jczY3go","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":29,"metadata":{"_cell_guid":"a6d4d773-0ed2-4059-ab2b-683692ce2c32","_uuid":"6f0e32f9-14f2-4b65-a106-cab2051ad125","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.917942Z","iopub.status.busy":"2025-03-16T21:17:25.917671Z","iopub.status.idle":"2025-03-16T21:17:25.937565Z","shell.execute_reply":"2025-03-16T21:17:25.936953Z","shell.execute_reply.started":"2025-03-16T21:17:25.917913Z"},"id":"2UWijIFl2Ykd","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","class Transformer(nn.Module):\n","    def __init__(\n","        self,\n","\n","    ):\n","        super().__init__()\n","\n","        self.encoder = EncoderModel()\n","        self.decoder = DecoderModel()\n","        # self.pos = PositionalEmbeddings()\n","        self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n","        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n","        # self.src_text_embeds = SrcTextEmbeddings(vocab_size=src_vocab_size, embeddings_dims=embeddings_dims)\n","\n","    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n","        # x = self.src_text_embeds(src)\n","        x = self.encoder(src, src_mask)\n","        y = self.tgt_text_embds(tgt)\n","        # print(x.shape)\n","        y = self.decoder(x, x, y, tgt_mask)\n","        # print(y.shape)\n","        out = self.linear_layer(y)\n","        return out"]},{"cell_type":"code","execution_count":30,"metadata":{"_cell_guid":"17dd187f-c195-44a0-990c-c6d17c90227e","_uuid":"e407283d-b631-479c-9bae-014aab7a0a3d","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:25.938678Z","iopub.status.busy":"2025-03-16T21:17:25.938378Z","iopub.status.idle":"2025-03-16T21:17:26.442178Z","shell.execute_reply":"2025-03-16T21:17:26.441341Z","shell.execute_reply.started":"2025-03-16T21:17:25.938647Z"},"id":"ntIaQj1U3pFX","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#Instantiating the model\n","model = Transformer()\n","# model = torch.compile(model)\n","# model = model.to(device)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":31,"metadata":{"_cell_guid":"4f4d8f86-6a6c-43fe-8a7f-06301998ac15","_uuid":"3efcd10c-fbd4-4818-b23b-636503f4df30","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:26.443631Z","iopub.status.busy":"2025-03-16T21:17:26.443241Z","iopub.status.idle":"2025-03-16T21:17:26.730652Z","shell.execute_reply":"2025-03-16T21:17:26.729694Z","shell.execute_reply.started":"2025-03-16T21:17:26.443574Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":32,"metadata":{"_cell_guid":"130524f5-869f-4ea2-8cb7-5de2780ed66a","_uuid":"3ecf1b70-4a77-4786-bdbd-df86011c7d31","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:26.732102Z","iopub.status.busy":"2025-03-16T21:17:26.731735Z","iopub.status.idle":"2025-03-16T21:17:26.758778Z","shell.execute_reply":"2025-03-16T21:17:26.757829Z","shell.execute_reply.started":"2025-03-16T21:17:26.732063Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[19581, 42628, 44362,  ..., 31259, 30194, 26385],\n","        [14440, 27165, 28905,  ..., 44917,  4816,  7300],\n","        [43949, 14247, 43535,  ..., 26924, 41709,  3581],\n","        ...,\n","        [36012, 12941, 41426,  ..., 40712, 49571, 22076],\n","        [23577, 17596, 16240,  ..., 49236, 30748, 46980],\n","        [19953, 31215,   880,  ..., 36761, 22380, 22405]], device='cuda:0')"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n","tgt_mask"]},{"cell_type":"code","execution_count":33,"metadata":{"_cell_guid":"d92d3629-d59c-4361-9572-8e0075329808","_uuid":"5061d499-36a9-427b-90ad-eead117d5a51","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:17:26.759979Z","iopub.status.busy":"2025-03-16T21:17:26.759689Z","iopub.status.idle":"2025-03-16T21:17:31.629859Z","shell.execute_reply":"2025-03-16T21:17:31.628564Z","shell.execute_reply.started":"2025-03-16T21:17:26.759955Z"},"id":"yOXtmG-lcuoO","jupyter":{"outputs_hidden":false},"outputId":"00697eb7-4384-4bca-82bf-100f45e5216f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"]},{"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-feaf0d775239>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchinfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["\n","!pip install torchinfo\n","from torchinfo import summary\n","\n","spec, text = next(iter(train_dataloader))\n","tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n","spec = spec.to(device)\n","texts = text.to(device)\n","\n","summary(model=model,\n","        input_data=(spec, texts),\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"])"]},{"cell_type":"code","execution_count":34,"metadata":{"_cell_guid":"97226398-cb33-48d6-9abc-f5a9c549b5c5","_uuid":"ee98acba-6992-4b1e-8cc1-3eda3997ae5b","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:47.480394Z","iopub.status.busy":"2025-03-16T21:18:47.480025Z","iopub.status.idle":"2025-03-16T21:18:47.490347Z","shell.execute_reply":"2025-03-16T21:18:47.489487Z","shell.execute_reply.started":"2025-03-16T21:18:47.480363Z"},"id":"LH95cJEvcuoO","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","# # Optimizer setup and scheduler steup\n","# out = {\"Train\": None, \"val\": None}\n","optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr)\n","\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":35,"metadata":{"_cell_guid":"53e031da-134a-4271-8879-b012f262ccc6","_uuid":"7860931f-c816-4796-b4c5-265e3df9bf57","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:47.977592Z","iopub.status.busy":"2025-03-16T21:18:47.977290Z","iopub.status.idle":"2025-03-16T21:18:47.981528Z","shell.execute_reply":"2025-03-16T21:18:47.980718Z","shell.execute_reply.started":"2025-03-16T21:18:47.977569Z"},"id":"bbvONdUTWmvL","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["torch.set_float32_matmul_precision('high')\n","\n","scaler = torch.amp.GradScaler(enabled=True)"]},{"cell_type":"code","execution_count":36,"metadata":{"_cell_guid":"58095701-5ad6-4bd6-bc30-0b1422af2a93","_uuid":"6d9f8456-d5da-49d1-8211-c97897782909","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:48.014114Z","iopub.status.busy":"2025-03-16T21:18:48.013911Z","iopub.status.idle":"2025-03-16T21:18:48.018021Z","shell.execute_reply":"2025-03-16T21:18:48.017242Z","shell.execute_reply.started":"2025-03-16T21:18:48.014096Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def _save_snapshot(model, optimizer, scheduler, epoch, step):\n","    snapshot = {\n","        \"MODEL_STATE\": model.state_dict(),\n","        \"OPTIMIZER_STATE\": optimizer.state_dict(),\n","        # \"SCHEDULER_STATE\": scheduler.state_dict(),  \n","        \"EPOCHS_RUN\": epoch,\n","        \"STEP_RUN\": step\n","    }\n","    torch.save(snapshot, f\"/kaggle/working/snapshot_{step}.pt\")\n","    print(f\"Epoch: {epoch} | Step: {step} | Snapshot saved.\")"]},{"cell_type":"code","execution_count":37,"metadata":{"_cell_guid":"6f951a8f-3f05-4b6a-9080-99a81e5925b0","_uuid":"9f8791fb-3c63-4871-8402-fbfb2a649e89","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:48.045122Z","iopub.status.busy":"2025-03-16T21:18:48.044918Z","iopub.status.idle":"2025-03-16T21:18:48.048197Z","shell.execute_reply":"2025-03-16T21:18:48.047524Z","shell.execute_reply.started":"2025-03-16T21:18:48.045104Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# !pip install torchtriton"]},{"cell_type":"code","execution_count":38,"metadata":{"_cell_guid":"2fc4d2f7-40d4-4733-8e32-65c38f198b5e","_uuid":"5582f78b-b57d-484e-bfa5-66a2688a6e21","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:48.069834Z","iopub.status.busy":"2025-03-16T21:18:48.069579Z","iopub.status.idle":"2025-03-16T21:18:48.074196Z","shell.execute_reply":"2025-03-16T21:18:48.073418Z","shell.execute_reply.started":"2025-03-16T21:18:48.069814Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["save_chechpoint_iter = 50\n","total_iters = 20000\n","eval_iters = 50\n","eval_check = 100\n","warmup_iters = 2048\n","min_lr = 0.1 * max_lr\n","lr_decay_iters = 20000\n","total_batch_size = 524288\n","micro_batch_size = batch_size\n","gradient_accumulation_steps = total_batch_size // (micro_batch_size * (block_size * torch.cuda.device_count()))"]},{"cell_type":"code","execution_count":39,"metadata":{"_cell_guid":"20e917d1-9770-456a-99dd-5e9c33d4edda","_uuid":"a0929ebe-c656-48ba-b479-e08113f3113e","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:48.108479Z","iopub.status.busy":"2025-03-16T21:18:48.108253Z","iopub.status.idle":"2025-03-16T21:18:48.126877Z","shell.execute_reply":"2025-03-16T21:18:48.126223Z","shell.execute_reply.started":"2025-03-16T21:18:48.108459Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaders ready both\n"]}],"source":["model.eval()\n","world_size = torch.cuda.device_count()\n","@torch.inference_mode()\n","def estimate_loss(val_loader, val_iterator, device):\n","    out = {}\n","    # train_loader = prepare_dataset('train', ModelArgs.batch_size)\n","    \n","    # val_loader_iterator = iter(val_loader)\n","    loader = None\n","    epoch_loss = None\n","    epoch_losses = []\n","    # print(\"Starting the eval...\")\n","    for split in ['val']:\n","        print(f\"Starting with {split} evaluation...\")\n","        # losses = torch.zeros(ModelArgs.val_epochs)\n","        # if(split == 'train'):\n","        #         loader = train_loader\n","        # if(split == 'val'):\n","        #         loader = val_loader\n","        for step in range(eval_check):  \n","            try:\n","                batch = next(val_iterator)\n","            except StopIteration:\n","                val_loader_iterator = iter(val_loader)\n","                X, x, y = next(val_loader_iterator)\n","                \n","            # tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n","            total_loss = 0  \n","            # loader.sampler.set_epoch(step)\n","            total_batches = 0 \n","            # batch = next(val_loader_iterator)\n","            # for batch in loader:  # Loop through DataLoader batches\n","            # idx = batch['input_ids']\n","            # targets = batch['labels']\n","            spec = X.to(device)\n","            \n","            idx = x.to(device)\n","            targets = y.to(device)\n","            with torch.autocast(device_type=device, dtype=torch.float16):\n","                \n","                logits = model(spec, idx)\n","                batch_size, block_size, embeddings_dims = logits.shape\n","                logits = logits.view(batch_size * block_size, embeddings_dims)  # Flatten tokens\n","                targets = targets.view(batch_size * block_size)\n","\n","                loss = F.cross_entropy(logits, targets, ignore_index=tokenizer.pad_token_id)\n","\n","                total_loss += loss.item()\n","                total_batches += 1\n","\n","        # Compute mean loss for this epoch\n","        epoch_loss = total_loss / total_batches if total_batches > 0 else 0.0\n","        epoch_losses.append(epoch_loss)\n","\n","            # print(f\"Epoch {epoch + 1}/{ModelArgs.val_epochs}: Loss = {epoch_loss:.4f}\")\n","\n","        # Compute mean loss across all evaluation epochs\n","        out[split] = sum(epoch_losses) / len(epoch_losses) if epoch_losses else 0.0\n","        epoch_loss = None\n","        epoch_losses = []\n","\n","    model.train()\n","    return out\n","\n","# model = model.to(rank)\n","model.train()\n","count = 0\n","\n","# train_dataloader = prepare_dataset('train', device, ModelArgs.batch_size)\n","# val_loader= prepare_dataset('val', device, ModelArgs.batch_size)\n","# for step in tqdm(range(total_iters)):\n","# for epoch in range(ModelArgs.epochs):\n","    # torch.cuda.synchronize() \n","\n","# train_dataloader.sampler.set_epoch(epoch)\n","\n","# val_loader.sampler.set_epoch(epoch)\n","print(\"Loaders ready both\")\n","epochs = epochs\n","\n","# train_step_iterator = range(len(train_dataloader))\n","# if device == 0:  # Only create progress bar on rank 0\n","#   train_step_iterator = tqdm(train_step_iterator, desc=\"Training Progress\", position=0, leave=True)\n","\n","    # Print progress on rank 0\n","train_loader_length = 0\n","train_data_iterator = iter(train_dataloader)\n","val_data_iterator = iter(val_dataloader)\n","token_count = 0\n","if(device == 0):\n","    train_loader_length = len(train_dataloader)\n","    # print(\"Total batches: \", train_loader_length)\n","# print(\"Length of : \", len(train_dataloader))\n","# print(\"Length of val: \", len(val_loader))\n","# for  step, batch in enumerate(train_dataloader):"]},{"cell_type":"code","execution_count":40,"metadata":{"_cell_guid":"5fd44e9d-01f8-4e2b-9130-4640fdab7419","_uuid":"c8abd50d-6173-4aeb-8219-b6396120af54","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:48.145768Z","iopub.status.busy":"2025-03-16T21:18:48.145554Z","iopub.status.idle":"2025-03-16T21:18:48.149258Z","shell.execute_reply":"2025-03-16T21:18:48.148608Z","shell.execute_reply.started":"2025-03-16T21:18:48.145750Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def find_unused_parameters(model):\n","    unused = []\n","    for name, param in model.named_parameters():\n","        if param.grad is None:\n","            unused.append(name)\n","    return unused"]},{"cell_type":"code","execution_count":41,"metadata":{"_cell_guid":"39ba72e2-ffe8-4acf-afa3-dbc3077e3e2a","_uuid":"1cdf81be-4ae9-43f2-b3c5-304c73e13883","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:48.182998Z","iopub.status.busy":"2025-03-16T21:18:48.182799Z","iopub.status.idle":"2025-03-16T21:18:48.187182Z","shell.execute_reply":"2025-03-16T21:18:48.186415Z","shell.execute_reply.started":"2025-03-16T21:18:48.182979Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def get_lr(it):\n","    # 1) linear warmup for warmup_iters steps\n","    if it < warmup_iters:\n","        return max_lr * (it + 1) / (warmup_iters + 1)\n","    # 2) if it > lr_decay_iters, return min learning rate\n","    if it > lr_decay_iters:\n","        return min_lr\n","    # 3) in between, use cosine decay down to min learning rate\n","    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n","    assert 0 <= decay_ratio <= 1\n","    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) \n","    return min_lr + coeff * (max_lr - min_lr)"]},{"cell_type":"code","execution_count":42,"metadata":{"_cell_guid":"317d13ff-dc6c-4965-adfe-d28c4bd6b40d","_uuid":"5feb1c4e-332c-4b97-8952-4646e07467a6","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:48.204188Z","iopub.status.busy":"2025-03-16T21:18:48.203969Z","iopub.status.idle":"2025-03-16T21:18:48.207464Z","shell.execute_reply":"2025-03-16T21:18:48.206860Z","shell.execute_reply.started":"2025-03-16T21:18:48.204168Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44ced50a-b954-4b04-8bc2-25b7c2601b9c","_uuid":"600fec50-d0e3-4593-a316-5c25e586c4f2","collapsed":false,"execution":{"iopub.execute_input":"2025-03-16T21:18:48.265086Z","iopub.status.busy":"2025-03-16T21:18:48.264869Z"},"id":"nPrSPPu8cuoO","jupyter":{"outputs_hidden":false},"outputId":"7ba86e12-999d-4b31-9a2b-53d645357d06","trusted":true},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.19.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20250316_211848-ad957zr3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rentio/Whisper-From-Scratch/runs/ad957zr3' target=\"_blank\">worldly-flower-20</a></strong> to <a href='https://wandb.ai/rentio/Whisper-From-Scratch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rentio/Whisper-From-Scratch' target=\"_blank\">https://wandb.ai/rentio/Whisper-From-Scratch</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rentio/Whisper-From-Scratch/runs/ad957zr3' target=\"_blank\">https://wandb.ai/rentio/Whisper-From-Scratch/runs/ad957zr3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/20000 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Step :  0 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Micro Batch :  0\n","Step :  0 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n","Micro Batch :  10\n","Step :  0 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n","Micro Batch :  20\n","Step :  0 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n","Micro Batch :  30\n","Step :  0 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n","Micro Batch :  40\n","Step :  0 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n","Micro Batch :  50\n","Step :  0 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n","Micro Batch :  60\n","Step :  0 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 1/20000 [04:15<1420:58:58, 255.79s/it]"]},{"name":"stdout","output_type":"stream","text":["tensor(11.0872, device='cuda:0')\n","Step :  1 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Micro Batch :  0\n","Step :  1 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n","Micro Batch :  10\n","Step :  1 / 20000\n","Total batches:  3452\n","Total gradient accumulation steps:  64\n","Total tokens processed:  0\n"]}],"source":["model.train()\n","train_losses =  torch.zeros(len(train_dataloader))\n","val_losses = torch.zeros(len(val_dataloader))\n","wandb.init(\n","    project='Whisper-From-Scratch'\n",")\n","step = 0\n","for step in tqdm(range(total_iters)):\n","        # print(\"Dataloader things: \", batch)\n","        # print(\"Total batches: \", len(train_dataloader))\n","        \n","        \n","        # if(device == 0):\n","            # if(step % 100 == 0):\n","        #     if(step == train_loader_length):\n","        #       break\n","        print(\"Step : \", step, \"/\", total_iters)\n","        print('Total batches: ', len(train_dataloader))\n","        print(\"Total gradient accumulation steps: \", gradient_accumulation_steps)\n","                # print(\"Total tokens processed: \", token_count)\n","                \n","        # all_gpus_avg_train_loss = None\n","        # all_gpus_avg_val_loss = None\n","        # every once in a while evaluate the loss on train and val sets\n","        if (step  % eval_iters == 0 and step != 0) or step == total_iters - 1:\n","            losses = estimate_loss( val_loader, val_data_iterator, 'cuda')\n","            # avg_train_loss = losses['train']\n","            avg_val_loss = losses['val']\n","            # print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","            # if device == 0:  # Only print on main process\n","            print(f\"[GPU {device}] | Step: {step} / {total_iters} | Val Loss: {losses['val']:.4f}\")\n","            # print(f\"[GPU {device}] | Epoch {epoch}/{ModelArgs.epochs}| |Step: {step} | Train Loss: {losses['train']:.4f}\")\n","                # print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","                # Log training loss more frequently\n","                # Aggregate average loss across all GPUs\n","            # avg_train_loss = torch.Tensor([losses['train']]).to(device)\n","            avg_val_loss = torch.Tensor([losses['val']]).to(device)\n","            # torch.distributed.reduce(avg_train_loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n","            # torch.distributed.reduce(avg_val_loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n","            \n","            # if device == 0:\n","                # all_gpus_avg_train_loss = avg_train_loss / world_size\n","                # print(f\"All_GPUs_Train_losses: {all_gpus_avg_train_loss.item():.4f}\")\n","            all_gpus_avg_val_loss = avg_val_loss / world_size\n","            print(f\"All_GPUs_Val_losses: {all_gpus_avg_val_loss.item():.4f}\")\n","                \n","            # if device == 0:\n","        \n","                # writer.add_scalar(\"All_GPUs_Train_losses\", all_gpus_avg_train_loss.item(), global_step=step)\n","                # writer.add_scalar(\"All_GPUs_Val_losses\", all_gpus_avg_val_loss.item(), global_step=step)\n","                # writer.add_scalar(\"training_step_loss\", losses['train'], global_step=step)\n","                # writer.add_scalar(\"val_step_loss\", losses['val'], global_step=step)\n","                # writer.add_scalar(\"GPU\", device, global_step=step)\n","                # writer.add_scalar(\"Epoch\", epoch, global_step=step)\n","                \n","            wandb.log({\n","                    # \"Learning Rate\": optimizer.param_groups[0]['lr'],\n","                    # \"All_GPUs_Train_losses\": all_gpus_avg_train_loss,\n","                    \"All_GPUs_Val_losses\": all_gpus_avg_val_loss,\n","                    # \"training_step_loss\": losses['train'],\n","                    \"val_step_loss\": losses['val'],\n","                    # \"Step\": step,\n","                    # \"Epoch\": epoch\n","                })\n","            \n","            \n","        \n","        #Loading a checkpoint\n","        # if(os.path.exists('snapshot.pt')):\n","        #    model, optimizer =  _load_snapshot(model=model, optimizer=optimizer, epoch=epoch, step=step, snapshot_path='snapshot.pt')\n","        \n","        # if(step % save_chechpoint_iter == 0 and device == 0 and step != 0):\n","            \n","        #     _save_snapshot(epoch=epoch, model=model, optimizer=optimizer, step=step)\n","\n","        if step % save_chechpoint_iter == 0 and device == 0 and step != 0:\n","            print(f\"Saving the model checkpoint for step: {step}\")\n","            _save_snapshot(model, optimizer, None, None, step)\n","        \n","        accumulated_loss = 0.0\n","        \n","        \n","        optimizer.zero_grad(set_to_none=True)\n","        for micro_step in range(gradient_accumulation_steps):\n","            try:\n","                spec, idx, y = next(train_data_iterator)\n","            except StopIteration:\n","                train_data_iterator = iter(train_dataloader)\n","                spec, idx, y = next(train_data_iterator)\n","            spec = spec.to(device)\n","            y = y.to(device)\n","            idx = idx.to(device)\n","            \n","            # tgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n","            # print(batch)\n","            # batch = next(train_data_iterator)\n","            # print(batch)\n","            # batch = {k: v.to(self.local_rank) for k, v in batch.items()}\n","            # idx = batch['input_ids'].to(device)\n","            # idx, targets = get_batch(split='train')\n","            # print(f\"Starting the train step: {step}...\")\n","            # for idx, targets in train_loader:\n","            # idx, targets = next(iter(train_loader))\n","            \n","            # print(\"Idx: \", idx)\n","            # print(\"Targets: \", targets)\n","            \n","            # idx = idx.to(device)\n","            # print(\"Idx: \", idx)\n","            # print(\"Targets: \", targets)\n","            # targets = batch['labels'].to(device)\n","            # token_count += len(idx)\n","            with torch.autocast(device_type=device, dtype=torch.float16):\n","                logits = model(spec, idx)\n","                batch_size, block_size, embeddings_dims = logits.shape\n","                # print(logits.shape)\n","                # print(targets)\n","                logits = logits.view(batch_size*block_size, embeddings_dims)\n","                # print(\"OK\")\n","                targets = y.view(batch_size * block_size)\n","                # print(\"OK2\")\n","                loss = nn.functional.cross_entropy(logits, targets, ignore_index=tokenizer.pad_token_id)\n","                \n","                loss = loss / gradient_accumulation_steps #IDK why div is done here specifically? Maybe think of it in terms of a very big batch being processed and there is need for equal important of each mini batch for the overall big batch\n","                accumulated_loss += loss.detach()\n","            \n","            model.require_backward_grad_sync = (micro_step == gradient_accumulation_steps - 1) # so that we dont synchronize the gradient everytime across the GPU devices\n","            scaler.scale(loss).backward()\n","            # print(\"loss: \", loss.item())\n","                # Check for unused parameters\n","            unused_params = find_unused_parameters(model)\n","            if unused_params:\n","                print(f\"Unused parameters: {unused_params}\")\n","        # break\n","    \n","            # if(device == 0):\n","            if(micro_step % 10 == 0):\n","            #     if(step == train_loader_length):\n","            #       break\n","                    \n","                    print(\"Micro Batch : \", micro_step)\n","                    print(\"Step : \", step, \"/\", total_iters)\n","                    print('Total batches: ', len(train_dataloader))\n","                    print(\"Total gradient accumulation steps: \", gradient_accumulation_steps)\n","                    print(\"Total tokens processed: \", token_count)\n","            # count += 1\n","       \n","        lr = get_lr(step)\n","        for params in optimizer.param_groups:\n","            params['lr'] = lr\n","            \n","        \n","        \n","        # Compute gradient norms before clipping\n","        if(clip != 0.0):\n","            scaler.unscale_(optimizer) #To avoid underflow\n","            total_norm_before = torch.norm(\n","                torch.stack([torch.norm(p.grad.detach(), 2) for p in model.parameters()]), 2\n","            )\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n","\n","            # Compute gradient norms after clipping\n","            total_norm_after = torch.norm(\n","                torch.stack([torch.norm(p.grad.detach(), 2) for p in model.parameters()]), 2\n","            )\n","            \n","            if(device  == 0 and step !=0):\n","                print(f\"Gradient Norm Before Clipping: {total_norm_before.item():.4f}\")\n","                print(f\"Gradient Norm After Clipping: {total_norm_after.item():.4f}\")\n","\n","        scaler.step(optimizer)\n","        scaler.update()\n","    \n","        # optimizer.step()\n","        # new_scheduler.step()\n","        print(accumulated_loss)\n","        # torch.cuda.synchronize() \n","        # torch.distributed.reduce(loss, dst=0, op=torch.distributed.ReduceOp.SUM)\n","        # if(device == 0):\n","        wandb.log({\n","                    \"Learning Rate\": lr,\n","                    \"All_GPUs_Train_losses\": accumulated_loss.item(),\n","                    # \"All_GPUs_Val_losses\": all_gpus_avg_val_loss,\n","                    # \"training_step_loss\": losses['train'],\n","                    # \"val_step_loss\": losses['val'],\n","                    \"Step\": step,\n","                    # \"Epoch\": epoch \n","                    \n","                })\n","\n","\n","        # model.train()\n","        # wandb.log({\n","        #   \"Train Loss\": train_losses.mean(),\n","        #   \"Val Loss\": val_losses.mean(),\n","        #   # \"epoch\": epoch\n","        # })\n","        # print(\"Epoch: \", epoch, \"|\", \"Train Loss: \", train_losses.mean(),  \"|\", \"Val Loss: \", val_losses.mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92c4ae77-c006-43e9-a677-343c07e75e87","_uuid":"8cf1c23a-fb45-45af-a00e-3219a7a750c8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e23d9c5c-bfe8-4e86-8fd7-da9eb29e2901","_uuid":"83764454-8200-4a10-9ab4-322effc15cb2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
