{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:25.815754Z",
          "iopub.status.busy": "2024-12-30T23:41:25.815482Z",
          "iopub.status.idle": "2024-12-30T23:41:27.153981Z",
          "shell.execute_reply": "2024-12-30T23:41:27.153285Z",
          "shell.execute_reply.started": "2024-12-30T23:41:25.815732Z"
        },
        "id": "Pw7f2ghccuoK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "# from tokenizers import Tokenizer\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:27.513712Z",
          "iopub.status.busy": "2024-12-30T23:41:27.513428Z",
          "iopub.status.idle": "2024-12-30T23:41:27.517228Z",
          "shell.execute_reply": "2024-12-30T23:41:27.516268Z",
          "shell.execute_reply.started": "2024-12-30T23:41:27.513688Z"
        },
        "id": "LwR5_uvTcuoL",
        "outputId": "492fa6c9-a295-4ebb-e3b7-8c007fbf9055",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Data\n",
        "# from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# load_dotenv()\n",
        "\n",
        "HF_TOKEN = '...'\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", token=HF_TOKEN)\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "\n",
        "SOT = '<|startoftranscript|>'\n",
        "EOT = '<|endoftranscript|>'\n",
        "transcribe = '<|transcribe|>'\n",
        "prev = '<|prev|>'\n",
        "\n",
        "special_tokens_dict = {\n",
        "    'additional_special_tokens': [SOT, EOT, transcribe, prev]\n",
        "}\n",
        "\n",
        "# Update the tokenizer with the new special tokens\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "# tokenizer(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3vCVc6OlXe2",
        "outputId": "e0a26206-20aa-4bf4-98db-dd576e96b2d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install wandb\n",
        "import wandb\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:37.956230Z",
          "iopub.status.busy": "2024-12-30T23:41:37.955961Z",
          "iopub.status.idle": "2024-12-30T23:41:37.968761Z",
          "shell.execute_reply": "2024-12-30T23:41:37.967954Z",
          "shell.execute_reply.started": "2024-12-30T23:41:37.956179Z"
        },
        "id": "D7AP219KJzTs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "epochs=10\n",
        "block_size = 64\n",
        "batch_size = 64\n",
        "# src_vocab_size = None\n",
        "tgt_vocab_size = len(tokenizer)\n",
        "embeddings_dims = 384\n",
        "attn_dropout = 0.1\n",
        "no_of_heads = 6 #IMP needs to be thoroughly calculated\n",
        "dropout = 0.1\n",
        "# epochs = 3\n",
        "max_lr = 2e-4\n",
        "no_of_decoder_layers = 6 #IMP needs to be thoroughly calculated\n",
        "attn_dropout = 0.1\n",
        "weight_decay_optim = 0.01\n",
        "log_mel_features = 80\n",
        "kernel_size = 3\n",
        "stride = (2,10)\n",
        "sr = 16000\n",
        "device= 'cuda:0'\n",
        "SAMPLING_RATE=16000\n",
        "N_MELS = 80  # 80-channel Mel spectrogram\n",
        "WINDOW_DURATION = 0.025  # 25 milliseconds\n",
        "STRIDE_DURATION = 0.010  # 10 milliseconds\n",
        "max_t = 500\n",
        "n_channels = N_MELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TmPkI_UEpvor"
      },
      "outputs": [],
      "source": [
        "torch.set_default_device(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IME1Ls95Y3gl",
        "outputId": "ab87d390-48f4-43be-b421-aad103deacca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
            "        num_rows: 9389\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
            "        num_rows: 6750\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
            "        num_rows: 25619\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install datasets\n",
        "from tabnanny import verbose\n",
        "from datasets import load_dataset\n",
        "\n",
        "gs = load_dataset(\"speechcolab/gigaspeech\", \"xs\", token=HF_TOKEN, trust_remote_code=True) # Ensures only 'train' split of 'xs' is download)\n",
        "\n",
        "# see structure\n",
        "print(gs)\n",
        "\n",
        "# load audio sample on the fly\n",
        "audio_input = gs['train'][0][\"audio\"]  # first decoded audio sample\n",
        "transcription = gs[\"train\"][0][\"text\"]  # first transcription\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFlAHwhDlv-t",
        "outputId": "351a0b9e-f14e-41dd-e568-2c34f4e29ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'segment_id': 'YOU0000000315_S0000660',\n",
              " 'speaker': 'N/A',\n",
              " 'text': \"AS THEY'RE LEAVING <COMMA> CAN KASH PULL ZAHRA ASIDE REALLY QUICKLY <QUESTIONMARK>\",\n",
              " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/77906a935e2abb2d9cf4f707fdb5c12b788afa9bc712c39fef49bf186c19af8f/xs_chunks_0000/YOU0000000315_S0000660.wav',\n",
              "  'array': array([0.0005188 , 0.00085449, 0.00012207, ..., 0.00125122, 0.00076294,\n",
              "         0.00036621]),\n",
              "  'sampling_rate': 16000},\n",
              " 'begin_time': 2941.889892578125,\n",
              " 'end_time': 2945.070068359375,\n",
              " 'audio_id': 'YOU0000000315',\n",
              " 'title': 'Return to Vasselheim | Critical Role: VOX MACHINA | Episode 43',\n",
              " 'url': 'https://www.youtube.com/watch?v=zr2n1fLVasU',\n",
              " 'source': 2,\n",
              " 'category': 24,\n",
              " 'original_full_path': 'audio/youtube/P0004/YOU0000000315.opus'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gs['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRV1EOlVY3gm",
        "outputId": "1052df52-a76c-4ee1-c4e7-cd495e3fb212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25619/25619 [01:02<00:00, 409.32it/s]\n",
            "100%|██████████| 6750/6750 [00:11<00:00, 602.73it/s]\n"
          ]
        }
      ],
      "source": [
        "MAX_DURATION_IN_SECONDS = 10\n",
        "\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "def is_audio_length_in_range(input_length):\n",
        "    return input_length < MAX_DURATION_IN_SECONDS\n",
        "\n",
        "train_new_column = []\n",
        "# new_column = [librosa.get_duration(path=x) ]] #Because test data has more rows\n",
        "for x in tqdm(range(len(gs['test']))):\n",
        "    train_new_column.append(librosa.get_duration(path=gs['test'][x]['audio']['path']))\n",
        "\n",
        "gs_ = gs['test'].add_column(\"duration\", train_new_column)\n",
        "\n",
        "\n",
        "gs_ = gs_.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n",
        "\n",
        "\n",
        "truncated_gs_train = gs_.remove_columns([\"duration\"])\n",
        "# truncated_gs\n",
        "\n",
        "\n",
        "\n",
        "val_new_column = []\n",
        "# new_column = [librosa.get_duration(path=x) ]]\n",
        "for x in tqdm(range(len(gs['validation']))):\n",
        "    val_new_column.append(librosa.get_duration(path=gs['validation'][x]['audio']['path']))\n",
        "\n",
        "gs_ = gs['validation'].add_column(\"duration\", val_new_column)\n",
        "\n",
        "\n",
        "gs_ = gs_.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n",
        "\n",
        "\n",
        "truncated_gs_val = gs_.remove_columns([\"duration\"])\n",
        "# truncated_gs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NZ9Hbp5q1to",
        "outputId": "cf76473e-8044-4b1c-b1e3-a18861572149"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 41/22015 [00:00<04:35, 79.82it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1024\n",
            "  warnings.warn(\n",
            "  0%|          | 85/22015 [00:00<03:43, 97.96it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3840\n",
            "  warnings.warn(\n",
            "  2%|▏         | 349/22015 [00:03<03:47, 95.34it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3056\n",
            "  warnings.warn(\n",
            "  2%|▏         | 381/22015 [00:04<03:38, 99.18it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=992\n",
            "  warnings.warn(\n",
            "  2%|▏         | 393/22015 [00:04<03:35, 100.46it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=800\n",
            "  warnings.warn(\n",
            "  2%|▏         | 435/22015 [00:04<03:38, 98.99it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=720\n",
            "  warnings.warn(\n",
            "  2%|▏         | 445/22015 [00:04<03:49, 93.97it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=912\n",
            "  warnings.warn(\n",
            "  3%|▎         | 657/22015 [00:06<03:54, 90.99it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3600\n",
            "  warnings.warn(\n",
            "  3%|▎         | 760/22015 [00:08<04:02, 87.58it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=336\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3792\n",
            "  warnings.warn(\n",
            "  4%|▎         | 804/22015 [00:08<03:38, 97.00it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=432\n",
            "  warnings.warn(\n",
            "  4%|▍         | 836/22015 [00:08<03:34, 98.57it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=144\n",
            "  warnings.warn(\n",
            "  4%|▍         | 846/22015 [00:08<03:49, 92.30it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=864\n",
            "  warnings.warn(\n",
            "  4%|▍         | 947/22015 [00:10<06:11, 56.76it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=736\n",
            "  warnings.warn(\n",
            "  5%|▍         | 1069/22015 [00:12<03:36, 96.60it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=512\n",
            "  warnings.warn(\n",
            "  6%|▌         | 1306/22015 [00:15<03:51, 89.35it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=592\n",
            "  warnings.warn(\n",
            "  6%|▋         | 1376/22015 [00:16<03:50, 89.70it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=672\n",
            "  warnings.warn(\n",
            "  7%|▋         | 1510/22015 [00:17<03:46, 90.55it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=704\n",
            "  warnings.warn(\n",
            "  7%|▋         | 1650/22015 [00:19<03:35, 94.34it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=656\n",
            "  warnings.warn(\n",
            "  8%|▊         | 1767/22015 [00:20<03:32, 95.27it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=544\n",
            "  warnings.warn(\n",
            "  9%|▊         | 1922/22015 [00:21<03:27, 96.97it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2864\n",
            "  warnings.warn(\n",
            " 10%|▉         | 2154/22015 [00:25<03:55, 84.42it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=832\n",
            "  warnings.warn(\n",
            " 10%|█         | 2260/22015 [00:26<03:19, 99.08it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=240\n",
            "  warnings.warn(\n",
            " 11%|█▏        | 2493/22015 [00:29<03:16, 99.14it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=272\n",
            "  warnings.warn(\n",
            " 12%|█▏        | 2738/22015 [00:31<03:08, 102.18it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=528\n",
            "  warnings.warn(\n",
            " 13%|█▎        | 2760/22015 [00:31<03:16, 97.83it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=112\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=304\n",
            "  warnings.warn(\n",
            " 14%|█▍        | 3146/22015 [00:36<05:35, 56.32it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=640\n",
            "  warnings.warn(\n",
            " 15%|█▍        | 3271/22015 [00:38<04:36, 67.82it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=176\n",
            "  warnings.warn(\n",
            " 16%|█▌        | 3434/22015 [00:40<02:58, 103.95it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=608\n",
            "  warnings.warn(\n",
            " 16%|█▌        | 3490/22015 [00:40<02:57, 104.65it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1328\n",
            "  warnings.warn(\n",
            " 17%|█▋        | 3788/22015 [00:43<03:16, 92.94it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1920\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 3927/22015 [00:45<03:00, 100.28it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=128\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 3972/22015 [00:45<03:02, 98.95it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=288\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 3994/22015 [00:45<02:56, 102.03it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2208\n",
            "  warnings.warn(\n",
            " 19%|█▉        | 4246/22015 [00:48<02:54, 102.10it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2240\n",
            "  warnings.warn(\n",
            " 20%|█▉        | 4397/22015 [00:51<04:40, 62.77it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=320\n",
            "  warnings.warn(\n",
            " 20%|██        | 4418/22015 [00:51<05:05, 57.58it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1904\n",
            "  warnings.warn(\n",
            " 20%|██        | 4467/22015 [00:52<03:26, 84.94it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2704\n",
            "  warnings.warn(\n",
            " 20%|██        | 4477/22015 [00:52<03:19, 88.12it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1728\n",
            "  warnings.warn(\n",
            " 21%|██        | 4560/22015 [00:53<03:01, 96.00it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1120\n",
            "  warnings.warn(\n",
            " 21%|██▏       | 4682/22015 [00:54<03:00, 96.04it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=368\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 4859/22015 [00:56<02:53, 98.77it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3024\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 4915/22015 [00:56<02:47, 102.03it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3984\n",
            "  warnings.warn(\n",
            " 23%|██▎       | 5107/22015 [00:59<04:52, 57.86it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=400\n",
            "  warnings.warn(\n",
            " 24%|██▍       | 5234/22015 [01:01<03:32, 79.04it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=32\n",
            "  warnings.warn(\n",
            " 26%|██▌       | 5720/22015 [01:07<02:38, 102.87it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=208\n",
            "  warnings.warn(\n",
            " 26%|██▌       | 5753/22015 [01:08<02:46, 97.67it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1504\n",
            "  warnings.warn(\n",
            " 26%|██▋       | 5783/22015 [01:08<02:48, 96.17it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3808\n",
            "  warnings.warn(\n",
            " 28%|██▊       | 6192/22015 [01:13<02:45, 95.62it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1104\n",
            "  warnings.warn(\n",
            " 29%|██▉       | 6470/22015 [01:17<04:39, 55.70it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=448\n",
            "  warnings.warn(\n",
            " 29%|██▉       | 6487/22015 [01:17<03:54, 66.33it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1152\n",
            "  warnings.warn(\n",
            " 31%|███       | 6718/22015 [01:19<02:39, 95.68it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1840\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 7230/22015 [01:25<02:42, 90.91it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3200\n",
            "  warnings.warn(\n",
            " 34%|███▎      | 7403/22015 [01:27<02:21, 103.51it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=624\n",
            "  warnings.warn(\n",
            " 34%|███▍      | 7583/22015 [01:29<04:46, 50.32it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=560\n",
            "  warnings.warn(\n",
            " 36%|███▌      | 7838/22015 [01:33<02:26, 96.58it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=480\n",
            "  warnings.warn(\n",
            " 37%|███▋      | 8116/22015 [01:35<02:25, 95.57it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1088\n",
            "  warnings.warn(\n",
            " 37%|███▋      | 8139/22015 [01:36<02:17, 101.16it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=48\n",
            "  warnings.warn(\n",
            " 38%|███▊      | 8273/22015 [01:37<02:11, 104.61it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=688\n",
            "  warnings.warn(\n",
            " 41%|████▏     | 9098/22015 [01:47<02:13, 97.04it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=416\n",
            "  warnings.warn(\n",
            " 42%|████▏     | 9322/22015 [01:49<02:02, 103.50it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=464\n",
            "  warnings.warn(\n",
            " 43%|████▎     | 9521/22015 [01:51<02:09, 96.77it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1200\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 9686/22015 [01:53<02:13, 92.68it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1584\n",
            "  warnings.warn(\n",
            " 50%|█████     | 11065/22015 [02:10<02:51, 63.82it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3776\n",
            "  warnings.warn(\n",
            " 51%|█████     | 11192/22015 [02:11<01:49, 98.55it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2736\n",
            "  warnings.warn(\n",
            " 52%|█████▏    | 11379/22015 [02:13<01:53, 93.89it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=256\n",
            "  warnings.warn(\n",
            " 52%|█████▏    | 11529/22015 [02:15<01:50, 95.29it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1712\n",
            "  warnings.warn(\n",
            " 54%|█████▍    | 11995/22015 [02:20<01:37, 103.11it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3008\n",
            "  warnings.warn(\n",
            " 56%|█████▌    | 12284/22015 [02:24<01:46, 91.74it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=496\n",
            "  warnings.warn(\n",
            " 58%|█████▊    | 12723/22015 [02:29<01:36, 96.03it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=384\n",
            "  warnings.warn(\n",
            " 58%|█████▊    | 12800/22015 [02:29<01:30, 101.38it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=944\n",
            "  warnings.warn(\n",
            " 65%|██████▍   | 14246/22015 [02:46<01:19, 97.23it/s] /usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1008\n",
            "  warnings.warn(\n",
            " 65%|██████▍   | 14288/22015 [02:46<01:17, 100.30it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=352\n",
            "  warnings.warn(\n",
            " 66%|██████▌   | 14482/22015 [02:49<02:10, 57.69it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=960\n",
            "  warnings.warn(\n",
            " 66%|██████▌   | 14494/22015 [02:50<01:43, 72.71it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1040\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 14722/22015 [02:52<01:08, 105.71it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2192\n",
            "  warnings.warn(\n",
            " 72%|███████▏  | 15751/22015 [03:04<01:06, 94.15it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2560\n",
            "  warnings.warn(\n",
            " 73%|███████▎  | 16105/22015 [03:07<00:58, 100.88it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1248\n",
            "  warnings.warn(\n",
            " 73%|███████▎  | 16128/22015 [03:08<00:57, 102.32it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1072\n",
            "  warnings.warn(\n",
            " 75%|███████▌  | 16543/22015 [03:12<00:50, 107.54it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3216\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 17170/22015 [03:20<00:51, 94.99it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=0\n",
            "  warnings.warn(\n",
            " 81%|████████▏ | 17923/22015 [03:30<00:43, 93.94it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=784\n",
            "  warnings.warn(\n",
            " 82%|████████▏ | 18051/22015 [03:31<00:42, 93.97it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=160\n",
            "  warnings.warn(\n",
            " 86%|████████▌ | 18937/22015 [03:41<00:59, 52.14it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2976\n",
            "  warnings.warn(\n",
            " 87%|████████▋ | 19062/22015 [03:43<00:30, 96.30it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=1056\n",
            "  warnings.warn(\n",
            " 87%|████████▋ | 19254/22015 [03:45<00:27, 100.94it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=2000\n",
            "  warnings.warn(\n",
            " 88%|████████▊ | 19322/22015 [03:45<00:26, 100.01it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=752\n",
            "  warnings.warn(\n",
            " 90%|████████▉ | 19745/22015 [03:49<00:22, 101.05it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=80\n",
            "  warnings.warn(\n",
            " 93%|█████████▎| 20569/22015 [04:00<00:15, 94.90it/s]/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=4000 is too large for input signal of length=3408\n",
            "  warnings.warn(\n",
            "100%|██████████| 22015/22015 [04:16<00:00, 85.87it/s]\n",
            "100%|██████████| 5447/5447 [01:07<00:00, 80.72it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "n_fft = int(WINDOW_DURATION * MAX_DURATION_IN_SECONDS * SAMPLING_RATE)\n",
        "hop_length = int(STRIDE_DURATION * MAX_DURATION_IN_SECONDS * SAMPLING_RATE)\n",
        "\n",
        "train_outputs = []\n",
        "train_texts = []\n",
        "for i in tqdm(range(len(truncated_gs_train))):\n",
        "  S = librosa.feature.melspectrogram(\n",
        "      y=truncated_gs_train[i]['audio']['array'],\n",
        "      sr=SAMPLING_RATE,\n",
        "      n_mels=N_MELS,\n",
        "      n_fft=n_fft,\n",
        "      hop_length=hop_length,\n",
        "      win_length=n_fft,\n",
        "      fmax=SAMPLING_RATE // 2\n",
        "  )\n",
        "\n",
        "\n",
        "  S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "  train_outputs.append(S_dB)\n",
        "  train_texts.append(truncated_gs_train[i]['text'])\n",
        "\n",
        "val_outputs = []\n",
        "val_texts = []\n",
        "for i in tqdm(range(len(truncated_gs_val))):\n",
        "  S = librosa.feature.melspectrogram(\n",
        "      y=truncated_gs_val[i]['audio']['array'],\n",
        "      sr=SAMPLING_RATE,\n",
        "      n_mels=N_MELS,\n",
        "      n_fft=n_fft,\n",
        "      hop_length=hop_length,\n",
        "      win_length=n_fft,\n",
        "      fmax=SAMPLING_RATE // 2\n",
        "  )\n",
        "\n",
        "\n",
        "  S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "  val_outputs.append(S_dB)\n",
        "  val_texts.append(truncated_gs_val[i]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRJNMDQN7Ds8",
        "outputId": "7cab14a7-8044-45e5-8e3b-d87e5af66d2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(80, 99)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_outputs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHXqMLR48Wpp",
        "outputId": "5d5e9f3e-b42e-42e0-955b-bfd33f65383f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum t in the dataset: 100\n",
            "Average t (training): 46.40656179447964\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calculate the maximum t in the dataset\n",
        "max_t = max(spectrogram.shape[1] for spectrogram in train_outputs + val_outputs)\n",
        "print(f\"Maximum t in the dataset: {max_t}\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the average t for the training dataset\n",
        "train_t_lengths = [spectrogram.shape[1] for spectrogram in train_outputs + val_outputs]\n",
        "avg_t_train = np.mean(train_t_lengths)\n",
        "\n",
        "print(f\"Average t (training): {avg_t_train}\")\n",
        "# print(f\"Average t (validation): {avg_t_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apt0aGdiaR5e",
        "outputId": "2efa4ca4-450f-449d-9655-d6c79467a19c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AS THEY'RE LEAVING  CAN KASH PULL ZAHRA ASIDE REALLY QUICKLY \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Example text\n",
        "text = \"AS THEY'RE LEAVING <COMMA> CAN KASH PULL ZAHRA ASIDE REALLY QUICKLY <QUESTIONMARK>\"\n",
        "\n",
        "# Use regex to remove anything between < and >\n",
        "cleaned_text = re.sub(r'<[^>]*>', '', text)\n",
        "\n",
        "print(cleaned_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "PURLJRNB9V_s",
        "outputId": "c12ac580-ed0d-4029-c017-43757b0ec1a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ONE OF THEIR STANFORD PROFESSORS USED TO SAY <COMMA> WELL <COMMA> THE DIFFERENCE BETWEEN THE TWO OF THEM WAS THAT SERGEI WOULD JUST BURST INTO MY OFFICE WITHOUT ASKING <PERIOD> LARRY WOULD KNOCK AND THEN BURST IN <PERIOD>'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z2aGf6_7xe9S"
      },
      "outputs": [],
      "source": [
        "# import math\n",
        "# print(round(random.random(), 1))\n",
        "class GigaSpeechDataset(Dataset):\n",
        "\n",
        "  def __init__(self, outputs, texts):\n",
        "\n",
        "    self.data = outputs\n",
        "    self.texts = texts\n",
        "    self.max_t = block_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "\n",
        "  def pad_to_max_t(self, spectrogram, max_t):\n",
        "\n",
        "    n_mels, t = spectrogram.shape\n",
        "    if t < max_t:\n",
        "        # Pad with zeros\n",
        "        pad_width = ((0, 0), (0, max_t - t))\n",
        "        spectrogram = np.pad(spectrogram, pad_width, mode='constant')\n",
        "    else:\n",
        "      spectrogram = spectrogram[:, :max_t]\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "  def clean(self, desc):\n",
        "    # Use regex to remove anything between < and >\n",
        "    cleaned_text = re.sub(r'<[^>]*>', '', desc)\n",
        "    return cleaned_text\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "      SOT = '<|startoftranscript|>'\n",
        "      EOT = '<|endoftranscript|>'\n",
        "      transcribe = '<|transcribe|>'\n",
        "      # prev = '<|prev|>'\n",
        "      spectrogram = self.pad_to_max_t(self.data[idx], self.max_t)\n",
        "      # probs = round(random.random(),1)\n",
        "      spectrogram = torch.tensor(spectrogram, dtype=torch.float32)\n",
        "\n",
        "      # if(probs == 0.5):\n",
        "        # Normalize the spectrogram between -1 and 1\n",
        "      spectrogram_min = spectrogram.min()\n",
        "      spectrogram_max = spectrogram.max()\n",
        "      # spectrogram = spectrogram.unsqueeze(0)  # Shape: (1, n_mels, max_t)\n",
        "      # prev_text =\n",
        "      text = self.clean(self.texts[idx])\n",
        "\n",
        "      text = text.lower()\n",
        "      text = SOT  + 'en' + transcribe +  text + EOT\n",
        "      tokenized_text = tokenizer(text, truncation=True, padding='max_length', max_length=block_size, return_tensors='pt')['input_ids']\n",
        "      # print(tokenized_text.shape)\n",
        "\n",
        "      epsilon = 1e-8  # To avoid division by zero\n",
        "      spectrogram = 2 * ((spectrogram - spectrogram_min) / (spectrogram_max - spectrogram_min + epsilon)) - 1\n",
        "\n",
        "      tokenized_text = tokenized_text.squeeze(0)\n",
        "      # print(tokenized_text.shape)\n",
        "      return spectrogram, tokenized_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2tvMuBSOynPy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "shuffle = True\n",
        "\n",
        "train_dataset = GigaSpeechDataset(train_outputs, train_texts)\n",
        "val_dataset = GigaSpeechDataset(val_outputs, val_texts)\n",
        "\n",
        "generator = torch.Generator(device=device)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    generator=generator,\n",
        "    shuffle=shuffle,\n",
        "     drop_last=True,\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    generator=generator,\n",
        "    drop_last=True ,\n",
        "    shuffle=shuffle,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwZHkYst4Ink",
        "outputId": "45cc29ff-3af8-4a80-ba50-38772a4a2df4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 64])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "spec, texts = next(iter(train_dataloader))\n",
        "\n",
        "texts.shape\n",
        "# spec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpOc27ctr8iM",
        "outputId": "8a1a1259-53ed-4c11-e217-f386520a9cc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "len(S_dB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCdlgZpeY3gm",
        "outputId": "ee223675-6fbf-4a97-e66b-10dc75604010"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50262"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kzXk76ULY3gm"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "\n",
        "class PositionEmbeddings(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.d_model = embeddings_dims\n",
        "        self.i = torch.arange(0, embeddings_dims, dtype=torch.float32, device=device)\n",
        "        # self.pos = torch.arange(0, block_size, dtype=torch.float32)\n",
        "        self.exp = ((2 * self.i)) / self.d_model\n",
        "        self.theta = 10000 ** self.exp\n",
        "        # print(self.theta.shape)\n",
        "        self.x_reshaped = torch.randn(batch_size, block_size, embeddings_dims, device=device, dtype=torch.float32)\n",
        "\n",
        "        self.cos = torch.cos((self.i / self.theta))\n",
        "        self.sin = torch.sin((self.i / self.theta))\n",
        "\n",
        "        self.even = self.sin[::2]\n",
        "        self.odd = self.cos[1::2]\n",
        "\n",
        "        # self.block = torch.empty((odd.size(0) + even.size(0),), dtype=self.even.dtype)\n",
        "        self.x_reshaped[..., : , ::2] = self.even\n",
        "        self.x_reshaped[..., : , 1::2] = self.odd\n",
        "\n",
        "\n",
        "\n",
        "    def pe_for_inference(self, x):\n",
        "\n",
        "            batch_size, seq_len, embeddings_dims = x.shape\n",
        "\n",
        "            self.d_model = embeddings_dims\n",
        "            self.i = torch.arange(0, embeddings_dims, dtype=torch.float32)\n",
        "            # self.pos = torch.arange(0, block_size, dtype=torch.float32)\n",
        "            self.exp = ((2 * self.i)) / self.d_model\n",
        "            self.theta = 10000 ** self.exp\n",
        "            # print(self.theta.shape)\n",
        "            x_reshaped = x.view(batch_size, seq_len, embeddings_dims)\n",
        "\n",
        "            self.cos = torch.cos((self.i / self.theta))\n",
        "            self.sin = torch.sin((self.i / self.theta))\n",
        "\n",
        "            self.even = self.sin[::2]\n",
        "            self.odd = self.cos[1::2]\n",
        "\n",
        "            # self.block = torch.empty((odd.size(0) + even.size(0),), dtype=self.even.dtype)\n",
        "            x_reshaped[..., : , ::2] = self.even\n",
        "            x_reshaped[..., : , 1::2] = self.odd\n",
        "\n",
        "    def forward(self, x, inference=False):\n",
        "\n",
        "        if(inference):\n",
        "            x = self.pe_for_inference(x)\n",
        "            return x\n",
        "        else:\n",
        "            out = self.x_reshaped\n",
        "            return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qth0bzoGY3gm"
      },
      "outputs": [],
      "source": [
        "# c = torch.arange(0, block_size)\n",
        "# odd = c[1::2]\n",
        "# even = c[::2]\n",
        "# res = torch.empty((odd.size(0) + even.size(0),), dtype=odd.dtype)\n",
        "# res[::2] = even\n",
        "# res[1::2] = odd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.044041Z",
          "iopub.status.busy": "2024-12-30T23:41:38.043739Z",
          "iopub.status.idle": "2024-12-30T23:41:38.053157Z",
          "shell.execute_reply": "2024-12-30T23:41:38.052522Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.044011Z"
        },
        "id": "R9CSiuD2jHyT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Text embeddings\n",
        "class TgtTextEmbeddings(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size = tgt_vocab_size,\n",
        "        embeddings_dims = embeddings_dims\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embeddings_table = nn.Embedding(num_embeddings = tgt_vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n",
        "        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embeddings_table(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.069221Z",
          "iopub.status.busy": "2024-12-30T23:41:38.068924Z",
          "iopub.status.idle": "2024-12-30T23:41:38.079344Z",
          "shell.execute_reply": "2024-12-30T23:41:38.078634Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.069166Z"
        },
        "id": "REUDHWrWcuoN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "#Layer Normalization\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embeddings_dims = embeddings_dims\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(normalized_shape=embeddings_dims)\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.080590Z",
          "iopub.status.busy": "2024-12-30T23:41:38.080282Z",
          "iopub.status.idle": "2024-12-30T23:41:38.093224Z",
          "shell.execute_reply": "2024-12-30T23:41:38.092377Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.080556Z"
        },
        "id": "lEe02cH9cuoN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#FeedForward Neural Network\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dropout = dropout,\n",
        "        embeddings_size = embeddings_dims,\n",
        "        # inner_dimensional_states: int = 3072\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(device=device, in_features=embeddings_size, out_features= 4 * embeddings_dims),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(device=device, in_features= 4 * embeddings_dims, out_features=embeddings_size),\n",
        "            nn.Dropout(p = dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mlp_weights_init = self.mlp.apply(weights_init)\n",
        "        return self.mlp(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.094455Z",
          "iopub.status.busy": "2024-12-30T23:41:38.094129Z",
          "iopub.status.idle": "2024-12-30T23:41:38.107217Z",
          "shell.execute_reply": "2024-12-30T23:41:38.106611Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.094424Z"
        },
        "id": "cf0Jf_7UcuoN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class MaskedAttentionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.head_size = embeddings_dims // no_of_heads\n",
        "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
        "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
        "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        batch, block_size, embd_dims = x.shape\n",
        "        k = self.keys(x)\n",
        "        q = self.query(x)\n",
        "        v = self.values(x)\n",
        "        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
        "        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n",
        "        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "        weights_normalized = self.dropout(weights_normalized)\n",
        "        out = weights_normalized @ v\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.108386Z",
          "iopub.status.busy": "2024-12-30T23:41:38.108072Z",
          "iopub.status.idle": "2024-12-30T23:41:38.122997Z",
          "shell.execute_reply": "2024-12-30T23:41:38.122019Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.108365Z"
        },
        "id": "OUFERSL2u8LT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class MaskedMHA(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([MaskedAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
        "\n",
        "    def forward(self, x):\n",
        "        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "        linear_layer = self.linear(concat)\n",
        "        out = self.dropout(linear_layer)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.124170Z",
          "iopub.status.busy": "2024-12-30T23:41:38.123871Z",
          "iopub.status.idle": "2024-12-30T23:41:38.136893Z",
          "shell.execute_reply": "2024-12-30T23:41:38.136282Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.124133Z"
        },
        "id": "oGGyyF4pjHyd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Single Attention Head\n",
        "\n",
        "class CrossAttentionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.head_size = embeddings_dims // no_of_heads\n",
        "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
        "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
        "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        # batch, block_size, embd_dims = x.shape\n",
        "\n",
        "        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "        weights = query @ torch.transpose(key, dim0=-2, dim1=-1) * (key.shape[-1] ** -0.5)\n",
        "        if(mask != None):\n",
        "            mask = mask.unsqueeze(1)\n",
        "            masked_values = weights.masked_fill(mask == 0, float('-inf'))\n",
        "            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "            # weights_normalized = self.dropout(weights_normalized)\n",
        "            out = weights_normalized @ value\n",
        "            out = self.dropout(out)\n",
        "            return out\n",
        "        else:\n",
        "            weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "            # weights_normalized = self.dropout(weights_normalized)\n",
        "            out = weights_normalized @ value\n",
        "            out = self.dropout(out)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.138084Z",
          "iopub.status.busy": "2024-12-30T23:41:38.137820Z",
          "iopub.status.idle": "2024-12-30T23:41:38.151910Z",
          "shell.execute_reply": "2024-12-30T23:41:38.150743Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.138064Z"
        },
        "id": "U5NmszzcjHyf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Single Attention Head\n",
        "\n",
        "class FullAttentionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.head_size = embeddings_dims // no_of_heads\n",
        "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
        "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
        "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # batch, block_size, embd_dims = x.shape\n",
        "        k = self.keys(x)\n",
        "        q = self.query(x)\n",
        "        v = self.values(x)\n",
        "        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n",
        "        if(mask != None):\n",
        "            mask = mask.unsqueeze(1)\n",
        "            masked_values = weights.masked_fill(mask == 0, float('-inf'))\n",
        "            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "            # weights_normalized = self.dropout(weights_normalized)\n",
        "            out = weights_normalized @ v\n",
        "            out = self.dropout(out)\n",
        "            return out\n",
        "        else:\n",
        "            weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "            # weights_normalized = self.dropout(weights_normalized)\n",
        "            out = weights_normalized @ v\n",
        "            out = self.dropout(out)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.153253Z",
          "iopub.status.busy": "2024-12-30T23:41:38.152929Z",
          "iopub.status.idle": "2024-12-30T23:41:38.167755Z",
          "shell.execute_reply": "2024-12-30T23:41:38.166944Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.153220Z"
        },
        "id": "v_BB7r7kqmOc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "class FullMHA(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([FullAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        concat = torch.cat([head(x, mask) for head in self.heads], dim=-1)\n",
        "        linear_layer = self.linear(concat)\n",
        "        out = self.dropout(linear_layer)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.169064Z",
          "iopub.status.busy": "2024-12-30T23:41:38.168778Z",
          "iopub.status.idle": "2024-12-30T23:41:38.193706Z",
          "shell.execute_reply": "2024-12-30T23:41:38.192606Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.169035Z"
        },
        "id": "TTwRkBzcvE-_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class CrossMHA(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([CrossAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "        self.linear = nn.Linear(in_features=no_of_decoder_layers * embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n",
        "\n",
        "    def forward(self, query, key, x, mask=None):\n",
        "        concat = torch.cat([head(query, key, x,  mask) for head in self.heads], dim=-1)\n",
        "        linear_layer = self.linear(concat)\n",
        "        out = self.dropout(linear_layer)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.194950Z",
          "iopub.status.busy": "2024-12-30T23:41:38.194673Z",
          "iopub.status.idle": "2024-12-30T23:41:38.201695Z",
          "shell.execute_reply": "2024-12-30T23:41:38.200801Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.194926Z"
        },
        "id": "s9rJzO_XcuoO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Decoder Block\n",
        "\n",
        "class TransformerDecoderBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        dropout = dropout,\n",
        "        # vocab_size = vocab_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cross = CrossMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
        "        self.masked = MaskedMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
        "        self.layer_norm1 = LayerNormalization(embeddings_dims)\n",
        "        self.layer_norm2 = LayerNormalization(embeddings_dims)\n",
        "        # self.layer_norm3 = LayerNormalization(embeddings_dims=embeddings_dims)\n",
        "        self.layer_norm4 = LayerNormalization(embeddings_dims)\n",
        "        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n",
        "\n",
        "    def forward(self, key, value, x, mask=None):\n",
        "        x = self.layer_norm1(x + self.masked(x)) #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n",
        "        x = self.layer_norm2(x + self.cross(value, key, x, mask)) #Very important step\n",
        "        # x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n",
        "        x = self.layer_norm4(x + self.mlp_block(x)) #Very important step\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.206345Z",
          "iopub.status.busy": "2024-12-30T23:41:38.206020Z",
          "iopub.status.idle": "2024-12-30T23:41:38.223220Z",
          "shell.execute_reply": "2024-12-30T23:41:38.222390Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.206310Z"
        },
        "id": "KGh8ujQJcuoO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Decoder Block\n",
        "\n",
        "class DecoderModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        block_size = block_size,\n",
        "        dropout = dropout,\n",
        "        no_of_decoder_layers = no_of_decoder_layers,\n",
        "        # vocab_size = vocab_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n",
        "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
        "        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n",
        "        self.decoder_layers = nn.ModuleList([TransformerDecoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n",
        "        self.apply(self._init_weights)\n",
        "        # self.positional_embeddings_tgt = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n",
        "        self.positional_embeddings_tgt = PositionEmbeddings()\n",
        "        # torch.nn.init.normal_(self.positional_embeddings_tgt, mean=0.0, std=0.02)\n",
        "\n",
        "        # out = self.decoder_layers(query, key, x)\n",
        "        # Loop through each decoder layer\n",
        "    def _init_weights(self, module):  #Weight Initialization\n",
        "            if isinstance(module, nn.Linear):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    torch.nn.init.zeros_(module.bias)\n",
        "            elif isinstance(module, nn.Embedding):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, key, value, x, mask):\n",
        "        # x = self.tgt_text_embds(x)\n",
        "        x = x + self.positional_embeddings_tgt(x)\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "            x = decoder_layer(key, value, x, mask)\n",
        "        # x = self.layer_norm(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.224795Z",
          "iopub.status.busy": "2024-12-30T23:41:38.224514Z",
          "iopub.status.idle": "2024-12-30T23:41:38.237595Z",
          "shell.execute_reply": "2024-12-30T23:41:38.236768Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.224767Z"
        },
        "id": "A3SgKrC-jHyd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.238697Z",
          "iopub.status.busy": "2024-12-30T23:41:38.238404Z",
          "iopub.status.idle": "2024-12-30T23:41:38.247055Z",
          "shell.execute_reply": "2024-12-30T23:41:38.246135Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.238669Z"
        },
        "id": "v6mbbO3yp-gh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        dropout = dropout,\n",
        "        mask=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = FullMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
        "        self.layer_norm1 = LayerNormalization(embeddings_dims)\n",
        "        self.layer_norm2 = LayerNormalization(embeddings_dims)\n",
        "        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.layer_norm1(x + self.mha(x, mask))\n",
        "        x = self.layer_norm2(x + self.mlp_block(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.248257Z",
          "iopub.status.busy": "2024-12-30T23:41:38.247952Z",
          "iopub.status.idle": "2024-12-30T23:41:38.262347Z",
          "shell.execute_reply": "2024-12-30T23:41:38.261499Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.248229Z"
        },
        "id": "HxW0pvnV12Ms",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class EncoderModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        block_size = block_size,\n",
        "        dropout = dropout,\n",
        "        no_of_decoder_layers = no_of_decoder_layers,\n",
        "        # vocab_size = vocab_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # self.positional_embeddings_src = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=n_channels, out_channels=embeddings_dims, kernel_size=kernel_size, device=device, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=embeddings_dims, out_channels=embeddings_dims, kernel_size=kernel_size, device=device, padding=1)\n",
        "\n",
        "        self.positional_embeddings_src = PositionEmbeddings()\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([TransformerEncoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):  #Weight Initialization\n",
        "            if isinstance(module, nn.Linear):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    torch.nn.init.zeros_(module.bias)\n",
        "            elif isinstance(module, nn.Embedding):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = torch.nn.functional.gelu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.nn.functional.gelu(x)\n",
        "        # print(x.shape)\n",
        "        # x = self.src_text_embeds(x)\n",
        "        # print(self.positional_embeddings_src.shape)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        # print(x.shape)\n",
        "        # print(self.positional_embeddings_src(x).shape)\n",
        "        x = x + self.positional_embeddings_src(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # Loop through each encoder layer\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            x = encoder_layer(x, mask)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Qi3v6jczY3go"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.263631Z",
          "iopub.status.busy": "2024-12-30T23:41:38.263313Z",
          "iopub.status.idle": "2024-12-30T23:41:38.278543Z",
          "shell.execute_reply": "2024-12-30T23:41:38.277881Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.263563Z"
        },
        "id": "2UWijIFl2Ykd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = EncoderModel()\n",
        "        self.decoder = DecoderModel()\n",
        "        self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n",
        "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
        "        # self.src_text_embeds = SrcTextEmbeddings(vocab_size=src_vocab_size, embeddings_dims=embeddings_dims)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        # x = self.src_text_embeds(src)\n",
        "        x = self.encoder(src, src_mask)\n",
        "        y = self.tgt_text_embds(tgt)\n",
        "        y = self.decoder(x, x, y, None)\n",
        "        out = self.linear_layer(y)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.279371Z",
          "iopub.status.busy": "2024-12-30T23:41:38.279081Z",
          "iopub.status.idle": "2024-12-30T23:41:38.562125Z",
          "shell.execute_reply": "2024-12-30T23:41:38.561113Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.279345Z"
        },
        "id": "ntIaQj1U3pFX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Instantiating the model\n",
        "model = Transformer()\n",
        "model = torch.compile(model)\n",
        "# model = model.to(device)\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:38.571435Z",
          "iopub.status.busy": "2024-12-30T23:41:38.571114Z",
          "iopub.status.idle": "2024-12-30T23:41:42.449903Z",
          "shell.execute_reply": "2024-12-30T23:41:42.448944Z",
          "shell.execute_reply.started": "2024-12-30T23:41:38.571405Z"
        },
        "id": "yOXtmG-lcuoO",
        "outputId": "00697eb7-4384-4bca-82bf-100f45e5216f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0310 00:37:43.184000 23272 torch/_dynamo/convert_frame.py:844] [16/8] torch._dynamo hit config.cache_size_limit (8)\n",
            "W0310 00:37:43.184000 23272 torch/_dynamo/convert_frame.py:844] [16/8]    function: 'torch_dynamo_resume_in_forward_at_22' (<ipython-input-31-661d70b92d24>:22)\n",
            "W0310 00:37:43.184000 23272 torch/_dynamo/convert_frame.py:844] [16/8]    last reason: 16/0: ___check_obj_id(L['self']._modules['dropout'], 138831511853200)\n",
            "W0310 00:37:43.184000 23272 torch/_dynamo/convert_frame.py:844] [16/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0310 00:37:43.184000 23272 torch/_dynamo/convert_frame.py:844] [16/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "W0310 00:38:50.564000 23272 torch/_dynamo/convert_frame.py:844] [6/256] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0310 00:38:50.564000 23272 torch/_dynamo/convert_frame.py:844] [6/256]    function: 'hook' (/usr/local/lib/python3.11/dist-packages/torchinfo/torchinfo.py:592)\n",
            "W0310 00:38:50.564000 23272 torch/_dynamo/convert_frame.py:844] [6/256]    last reason: 6/0: tensor 'L['inputs'][0]' size mismatch at index 1. expected 80, actual 64\n",
            "W0310 00:38:50.564000 23272 torch/_dynamo/convert_frame.py:844] [6/256] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0310 00:38:50.564000 23272 torch/_dynamo/convert_frame.py:844] [6/256] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "W0310 00:39:04.086000 23272 torch/_dynamo/convert_frame.py:844] [35/8] torch._dynamo hit config.cache_size_limit (8)\n",
            "W0310 00:39:04.086000 23272 torch/_dynamo/convert_frame.py:844] [35/8]    function: 'torch_dynamo_resume_in_forward_at_21' (<ipython-input-28-a2a8b3401609>:21)\n",
            "W0310 00:39:04.086000 23272 torch/_dynamo/convert_frame.py:844] [35/8]    last reason: 35/0: ___check_obj_id(L['self']._modules['dropout'], 138831507518288)\n",
            "W0310 00:39:04.086000 23272 torch/_dynamo/convert_frame.py:844] [35/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0310 00:39:04.086000 23272 torch/_dynamo/convert_frame.py:844] [35/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "W0310 00:39:08.747000 23272 torch/_dynamo/convert_frame.py:844] [42/8] torch._dynamo hit config.cache_size_limit (8)\n",
            "W0310 00:39:08.747000 23272 torch/_dynamo/convert_frame.py:844] [42/8]    function: 'forward' (<ipython-input-30-7c7bc380f197>:18)\n",
            "W0310 00:39:08.747000 23272 torch/_dynamo/convert_frame.py:844] [42/8]    last reason: 42/0: ___check_obj_id(L['self']._modules['dropout'], 138831507507344)\n",
            "W0310 00:39:08.747000 23272 torch/_dynamo/convert_frame.py:844] [42/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0310 00:39:08.747000 23272 torch/_dynamo/convert_frame.py:844] [42/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type (var_name))                                           Input Shape          Output Shape         Param #              Trainable\n",
              "=================================================================================================================================================\n",
              "OptimizedModule (OptimizedModule)                                 [64, 80, 64]         [64, 64, 50262]      --                   True\n",
              "├─Transformer (_orig_mod)                                         [64, 80, 64]         [64, 64, 50262]      --                   True\n",
              "│    └─EncoderModel (encoder)                                     [64, 80, 64]         [64, 64, 384]        --                   True\n",
              "│    │    └─Conv1d (conv1)                                        [64, 80, 64]         [64, 384, 64]        92,544               True\n",
              "│    │    └─Conv1d (conv2)                                        [64, 384, 64]        [64, 384, 64]        442,752              True\n",
              "│    │    └─PositionEmbeddings (positional_embeddings_src)        [64, 64, 384]        [64, 64, 384]        --                   --\n",
              "│    │    └─ModuleList (encoder_layers)                           --                   --                   10,637,568           True\n",
              "│    └─TgtTextEmbeddings (tgt_text_embds)                         [64, 64]             [64, 64, 384]        --                   True\n",
              "│    │    └─Embedding (embeddings_table)                          [64, 64]             [64, 64, 384]        19,300,608           True\n",
              "│    └─DecoderModel (decoder)                                     [64, 64, 384]        [64, 64, 384]        38,601,216           True\n",
              "│    │    └─PositionEmbeddings (positional_embeddings_tgt)        [64, 64, 384]        [64, 64, 384]        --                   --\n",
              "│    │    └─ModuleList (decoder_layers)                           --                   --                   18,604,800           True\n",
              "│    └─Linear (linear_layer)                                      [64, 64, 384]        [64, 64, 50262]      19,300,608           True\n",
              "=================================================================================================================================================\n",
              "Total params: 106,980,096\n",
              "Trainable params: 106,980,096\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 6.36\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 1.34\n",
              "Forward/backward pass size (MB): 3496.67\n",
              "Params size (MB): 262.90\n",
              "Estimated Total Size (MB): 3760.92\n",
              "================================================================================================================================================="
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "spec, text = next(iter(train_dataloader))\n",
        "spec = spec.to(device)\n",
        "texts = text.to(device)\n",
        "\n",
        "summary(model=model,\n",
        "        input_data=(spec, texts),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:42.451139Z",
          "iopub.status.busy": "2024-12-30T23:41:42.450897Z",
          "iopub.status.idle": "2024-12-30T23:41:43.142042Z",
          "shell.execute_reply": "2024-12-30T23:41:43.141341Z",
          "shell.execute_reply.started": "2024-12-30T23:41:42.451116Z"
        },
        "id": "LH95cJEvcuoO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Optimizer setup and scheduler steup\n",
        "# out = {\"Train\": None, \"val\": None}\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bbvONdUTWmvL"
      },
      "outputs": [],
      "source": [
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "scaler = torch.amp.GradScaler(enabled=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "execution": {
          "iopub.execute_input": "2024-12-30T23:41:43.143397Z",
          "iopub.status.busy": "2024-12-30T23:41:43.142879Z",
          "iopub.status.idle": "2024-12-31T00:20:53.976987Z",
          "shell.execute_reply": "2024-12-31T00:20:53.976269Z",
          "shell.execute_reply.started": "2024-12-30T23:41:43.143371Z"
        },
        "id": "nPrSPPu8cuoO",
        "outputId": "7ba86e12-999d-4b31-9a2b-53d645357d06",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250310_003925-27la9tpm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rentio/Whisper-From-Scratch/runs/27la9tpm' target=\"_blank\">peach-fire-10</a></strong> to <a href='https://wandb.ai/rentio/Whisper-From-Scratch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rentio/Whisper-From-Scratch' target=\"_blank\">https://wandb.ai/rentio/Whisper-From-Scratch</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rentio/Whisper-From-Scratch/runs/27la9tpm' target=\"_blank\">https://wandb.ai/rentio/Whisper-From-Scratch/runs/27la9tpm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  0 | Train Loss:  tensor(6.2074, device='cuda:0') | Val Loss:  tensor(5.3821, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  1 | Train Loss:  tensor(3.2547, device='cuda:0') | Val Loss:  tensor(1.8244, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  2 | Train Loss:  tensor(0.9231, device='cuda:0') | Val Loss:  tensor(0.8662, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  3 | Train Loss:  tensor(0.4481, device='cuda:0') | Val Loss:  tensor(0.5454, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  4 | Train Loss:  tensor(0.2453, device='cuda:0') | Val Loss:  tensor(0.3914, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  5 | Train Loss:  tensor(0.1400, device='cuda:0') | Val Loss:  tensor(0.3194, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  6 | Train Loss:  tensor(0.0816, device='cuda:0') | Val Loss:  tensor(0.2759, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  7 | Train Loss:  tensor(0.0474, device='cuda:0') | Val Loss:  tensor(0.2496, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  8 | Train Loss:  tensor(0.0251, device='cuda:0') | Val Loss:  tensor(0.2313, device='cuda:0')\n",
            "Starting train...\n",
            "Starting val...\n",
            "Epoch:  9 | Train Loss:  tensor(0.0112, device='cuda:0') | Val Loss:  tensor(0.2244, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "train_losses =  torch.zeros(len(train_dataloader))\n",
        "val_losses = torch.zeros(len(val_dataloader))\n",
        "wandb.init(\n",
        "    project='Whisper-From-Scratch'\n",
        ")\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    count = 0\n",
        "    print(\"Starting train...\")\n",
        "\n",
        "    for X, y in train_dataloader:\n",
        "      with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        logits = model(X, y)\n",
        "        # print(logits.shape)\n",
        "\n",
        "        batch_size, block_size, vocab = logits.shape\n",
        "        # print(\"Va: \", vocab)\n",
        "        logits = logits.view(batch_size*block_size, vocab)\n",
        "        targets = y.view(batch_size * block_size)\n",
        "        # print(\"HiiiL \", en.shape)\n",
        "        # print(\"HiiiT \", logits.shape)\n",
        "        loss = nn.functional.cross_entropy(logits, targets, ignore_index=tokenizer.pad_token_id)\n",
        "        train_losses[count] = loss.item()\n",
        "        # print(\"Loss: \", loss.item())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      scaler.scale(loss).backward()\n",
        "      # loss.backward()\n",
        "      # optimizer.step()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "      count += 1\n",
        "        # print()\n",
        "        # print(count)\n",
        "\n",
        "\n",
        "    # count = 0\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print(\"Starting val...\")\n",
        "    for X, y in val_dataloader:\n",
        "\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        logits = model(X,y)\n",
        "        # print(logits.shape)\n",
        "        batch_size, block_size, vocab = logits.shape\n",
        "\n",
        "        logits = logits.view(batch_size*block_size, vocab)\n",
        "        # print(\"Va: \", vocab)\n",
        "        targets = y.view(batch_size * block_size)\n",
        "        loss = nn.functional.cross_entropy(logits, targets, ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "        # print(\"Loss: \", loss.item())\n",
        "        val_losses[count] = loss.item()\n",
        "\n",
        "        # optimizer.zero_grad()\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        count += 1\n",
        "\n",
        "\n",
        "    # print(\"eval\")\n",
        "    # print(\"Generating text...\")\n",
        "    # generated_text = topk_sampling(model, 'Ich fahre heute mit dem Rad zur Schule', de_tokenizer, device=ModelArgs.device, max_length=50, top_k=50, temperature=1.0)\n",
        "\n",
        "    # print(generated_text)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    wandb.log({\n",
        "      \"Train Loss\": train_losses.mean(),\n",
        "      \"Val Loss\": val_losses.mean(),\n",
        "      \"epoch\": epoch\n",
        "    })\n",
        "    print(\"Epoch: \", epoch, \"|\", \"Train Loss: \", train_losses.mean(),  \"|\", \"Val Loss: \", val_losses.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_4oLJprzmeHl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30823,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
