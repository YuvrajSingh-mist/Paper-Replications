/home/yuvrajsingh/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/_device.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return func(*args, **kwargs)
/home/yuvrajsingh/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/_device.py:106: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
Epoch:  0 | Step:  500 | Train Loss:  0.5740516185760498
Epoch:  0 | Step:  1 | Val Loss:  1.052208662033081
Epoch:  0 | Step:  2 | Val Loss:  0.998694121837616
Epoch:  0 | Step:  3 | Val Loss:  0.9415820837020874
Epoch:  0 | Step:  4 | Val Loss:  0.7433435916900635
Epoch:  0 | Step:  5 | Val Loss:  0.6139687895774841
Epoch:  0 | Step:  6 | Val Loss:  0.4671434164047241
Epoch:  0 | Step:  7 | Val Loss:  0.2710726857185364
Epoch:  0 | Step:  8 | Val Loss:  0.15589214861392975
Epoch:  0 | Step:  9 | Val Loss:  0.07059915363788605
Epoch:  0 | Step:  10 | Val Loss:  0.02683388441801071
Epoch:  0 | Step:  11 | Val Loss:  0.012249155901372433
Epoch:  0 | Step:  12 | Val Loss:  0.04729326814413071
Epoch:  0 | Step:  13 | Val Loss:  0.15579552948474884
Epoch:  0 | Step:  14 | Val Loss:  0.2734749913215637
Epoch:  0 | Step:  15 | Val Loss:  0.4172627329826355
Epoch:  0 | Step:  16 | Val Loss:  0.5368950963020325
Epoch:  0 | Step:  17 | Val Loss:  0.7465299963951111
Epoch:  0 | Step:  18 | Val Loss:  0.7921276092529297
Epoch:  0 | Step:  19 | Val Loss:  0.9188392162322998
Epoch:  0 | Step:  20 | Val Loss:  0.8971021175384521
Epoch:  0 | Step:  21 | Val Loss:  0.9018796682357788
Epoch:  0 | Step:  22 | Val Loss:  0.8250715732574463
Epoch:  0 | Step:  23 | Val Loss:  0.6492640376091003
Epoch:  0 | Step:  24 | Val Loss:  0.642625093460083
Epoch:  0 | Step:  25 | Val Loss:  0.4673182964324951
Epoch:  0 | Step:  26 | Val Loss:  0.28170686960220337
Epoch:  0 | Step:  27 | Val Loss:  0.13701295852661133
Epoch:  0 | Step:  28 | Val Loss:  0.11622552573680878
Epoch:  0 | Step:  29 | Val Loss:  0.02795255184173584
Epoch:  0 | Step:  30 | Val Loss:  0.01564505137503147
Epoch:  0 | Step:  31 | Val Loss:  0.05434064567089081
Epoch:  0 | Step:  32 | Val Loss:  0.11669699847698212
Epoch:  0 | Step:  33 | Val Loss:  0.26696011424064636
Epoch:  0 | Step:  34 | Val Loss:  0.45837271213531494
Epoch:  0 | Step:  35 | Val Loss:  0.5678950548171997
Epoch:  0 | Step:  36 | Val Loss:  0.7382039427757263
Epoch:  0 | Step:  37 | Val Loss:  0.9118748307228088
Epoch:  0 | Step:  38 | Val Loss:  1.0311079025268555
Epoch:  0 | Step:  39 | Val Loss:  1.0957304239273071
Epoch:  0 | Step:  40 | Val Loss:  1.134050965309143
Epoch:  0 | Step:  41 | Val Loss:  1.0836760997772217
Epoch:  0 | Step:  42 | Val Loss:  0.9315204620361328
Epoch:  0 | Step:  43 | Val Loss:  0.9095428586006165
Epoch:  0 | Step:  44 | Val Loss:  0.7862141728401184
Epoch:  0 | Step:  45 | Val Loss:  0.5489208698272705
Epoch:  0 | Step:  46 | Val Loss:  0.43090805411338806
Epoch:  0 | Step:  47 | Val Loss:  0.2606707215309143
Epoch:  0 | Step:  48 | Val Loss:  0.11731074750423431
Epoch:  0 | Step:  49 | Val Loss:  0.03627081215381622
Epoch:  0 | Step:  50 | Val Loss:  0.008643608540296555
Epoch:  0 | Step:  51 | Val Loss:  0.021722130477428436
Epoch:  0 | Step:  52 | Val Loss:  0.09039090573787689
Epoch:  0 | Step:  53 | Val Loss:  0.22380881011486053
Epoch:  0 | Step:  54 | Val Loss:  0.3510517477989197
Epoch:  0 | Step:  55 | Val Loss:  0.48076748847961426
Epoch:  0 | Step:  56 | Val Loss:  0.6118967533111572
Epoch:  0 | Step:  57 | Val Loss:  0.789087176322937
Epoch:  0 | Step:  58 | Val Loss:  0.8754292726516724
Epoch:  0 | Step:  59 | Val Loss:  0.8827643394470215
Epoch:  0 | Step:  60 | Val Loss:  0.9359421730041504
Epoch:  0 | Step:  61 | Val Loss:  0.9076521992683411
Epoch:  0 | Step:  62 | Val Loss:  0.7396911382675171
Epoch:  0 | Step:  63 | Val Loss:  0.7006801962852478
Epoch:  0 | Step:  64 | Val Loss:  0.5078518390655518
Epoch:  0 | Step:  65 | Val Loss:  0.3462042212486267
Epoch:  0 | Step:  66 | Val Loss:  0.2262771725654602
Epoch:  0 | Step:  67 | Val Loss:  0.10909318923950195
Epoch:  0 | Step:  68 | Val Loss:  0.04899197816848755
Epoch:  0 | Step:  69 | Val Loss:  0.0172684658318758
Epoch:  0 | Step:  70 | Val Loss:  0.030618149787187576
Epoch:  0 | Step:  71 | Val Loss:  0.0658777728676796
Epoch:  0 | Step:  72 | Val Loss:  0.1960911750793457
Epoch:  0 | Step:  73 | Val Loss:  0.32095766067504883
Epoch:  0 | Step:  74 | Val Loss:  0.50355464220047
Epoch:  0 | Step:  75 | Val Loss:  0.6280596852302551
Epoch:  0 | Step:  76 | Val Loss:  0.8034331202507019
Epoch:  0 | Step:  77 | Val Loss:  1.0159528255462646
Epoch:  0 | Step:  78 | Val Loss:  1.114867925643921
Epoch:  0 | Step:  79 | Val Loss:  1.0683774948120117
Epoch:  0 | Step:  80 | Val Loss:  1.1740286350250244
Epoch:  0 | Step:  81 | Val Loss:  1.0056794881820679
Epoch:  0 | Step:  82 | Val Loss:  0.9283908605575562
Epoch:  0 | Step:  83 | Val Loss:  0.8089184761047363
Epoch:  0 | Step:  84 | Val Loss:  0.6495344638824463
Epoch:  0 | Step:  85 | Val Loss:  0.4758129119873047
Epoch:  0 | Step:  86 | Val Loss:  0.2823389172554016
Epoch:  0 | Step:  87 | Val Loss:  0.2126375138759613
Epoch:  0 | Step:  88 | Val Loss:  0.04668663442134857
Epoch:  0 | Step:  89 | Val Loss:  0.019548974931240082
Epoch:  0 | Step:  90 | Val Loss:  0.011997835710644722
Epoch:  0 | Step:  91 | Val Loss:  0.05771984905004501
Epoch:  0 | Step:  92 | Val Loss:  0.14068815112113953
Epoch:  0 | Step:  93 | Val Loss:  0.2783580422401428
Epoch:  0 | Step:  94 | Val Loss:  0.4414423108100891
Epoch:  0 | Step:  95 | Val Loss:  0.5298286080360413
Epoch:  0 | Step:  96 | Val Loss:  0.678495466709137
Epoch:  0 | Step:  97 | Val Loss:  0.8590559959411621
Epoch:  0 | Step:  98 | Val Loss:  0.8636569976806641
Epoch:  0 | Step:  99 | Val Loss:  0.908862829208374
Epoch:  0 | Step:  100 | Val Loss:  0.8358803987503052
Epoch:  0 | Step:  101 | Val Loss:  0.8813352584838867
Epoch:  0 | Step:  102 | Val Loss:  0.7460324168205261
Epoch:  0 | Step:  103 | Val Loss:  0.6151188015937805
Epoch:  0 | Step:  104 | Val Loss:  0.42777103185653687
Epoch:  0 | Step:  105 | Val Loss:  0.29965224862098694
Epoch:  0 | Step:  106 | Val Loss:  0.17063766717910767
Epoch:  0 | Step:  107 | Val Loss:  0.07000041007995605
Epoch:  0 | Step:  108 | Val Loss:  0.031386829912662506
Epoch:  0 | Step:  109 | Val Loss:  0.009834222495555878
Epoch:  0 | Step:  110 | Val Loss:  0.04928620904684067
Epoch:  0 | Step:  111 | Val Loss:  0.14337652921676636
Epoch:  0 | Step:  112 | Val Loss:  0.293292373418808
Epoch:  0 | Step:  113 | Val Loss:  0.41421574354171753
Epoch:  0 | Step:  114 | Val Loss:  0.6133593916893005
Epoch:  0 | Step:  115 | Val Loss:  0.7633971571922302
Epoch:  0 | Step:  116 | Val Loss:  0.9514416456222534
Epoch:  0 | Step:  117 | Val Loss:  1.0003241300582886
Epoch:  0 | Step:  118 | Val Loss:  1.0004417896270752
Epoch:  0 | Step:  119 | Val Loss:  0.9975656270980835
Epoch:  0 | Step:  120 | Val Loss:  1.0944938659667969
Epoch:  0 | Step:  121 | Val Loss:  1.024501919746399
Epoch:  0 | Step:  122 | Val Loss:  0.7781962752342224
Epoch:  0 | Step:  123 | Val Loss:  0.6029442548751831
Epoch:  0 | Step:  124 | Val Loss:  0.5926554203033447
Epoch:  0 | Step:  125 | Val Loss:  0.38592350482940674
Epoch:  0 | Train Loss:  tensor(0.5390, device='cuda:0') | Val Loss:  tensor(0.5238, device='cuda:0')
/home/yuvrajsingh/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/_device.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return func(*args, **kwargs)
/home/yuvrajsingh/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/_device.py:106: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
Epoch:  1 | Step:  500 | Train Loss:  0.6356580853462219
Epoch:  1 | Step:  1 | Val Loss:  1.011858344078064
Epoch:  1 | Step:  2 | Val Loss:  0.9595073461532593
Epoch:  1 | Step:  3 | Val Loss:  0.9035947322845459
Epoch:  1 | Step:  4 | Val Loss:  0.709881067276001
Epoch:  1 | Step:  5 | Val Loss:  0.5834516286849976
Epoch:  1 | Step:  6 | Val Loss:  0.44057658314704895
Epoch:  1 | Step:  7 | Val Loss:  0.2512111961841583
Epoch:  1 | Step:  8 | Val Loss:  0.14098083972930908
Epoch:  1 | Step:  9 | Val Loss:  0.06115887314081192
Epoch:  1 | Step:  10 | Val Loss:  0.022825350984930992
Epoch:  1 | Step:  11 | Val Loss:  0.014455142430961132
Epoch:  1 | Step:  12 | Val Loss:  0.05482155829668045
Epoch:  1 | Step:  13 | Val Loss:  0.17084714770317078
Epoch:  1 | Step:  14 | Val Loss:  0.2938273549079895
Epoch:  1 | Step:  15 | Val Loss:  0.44257616996765137
Epoch:  1 | Step:  16 | Val Loss:  0.5655364394187927
Epoch:  1 | Step:  17 | Val Loss:  0.7800989151000977
Epoch:  1 | Step:  18 | Val Loss:  0.8266705274581909
Epoch:  1 | Step:  19 | Val Loss:  0.9561293125152588
Epoch:  1 | Step:  20 | Val Loss:  0.9339849948883057
Epoch:  1 | Step:  21 | Val Loss:  0.9387590885162354
Epoch:  1 | Step:  22 | Val Loss:  0.8604874610900879
Epoch:  1 | Step:  23 | Val Loss:  0.6807168126106262
Epoch:  1 | Step:  24 | Val Loss:  0.6737841963768005
Epoch:  1 | Step:  25 | Val Loss:  0.4940652847290039
Epoch:  1 | Step:  26 | Val Loss:  0.3024100661277771
Epoch:  1 | Step:  27 | Val Loss:  0.15126018226146698
Epoch:  1 | Step:  28 | Val Loss:  0.12890200316905975
Epoch:  1 | Step:  29 | Val Loss:  0.032884467393159866
Epoch:  1 | Step:  30 | Val Loss:  0.013467522338032722
Epoch:  1 | Step:  31 | Val Loss:  0.04662062227725983
Epoch:  1 | Step:  32 | Val Loss:  0.1044691875576973
Epoch:  1 | Step:  33 | Val Loss:  0.24739927053451538
Epoch:  1 | Step:  34 | Val Loss:  0.43224847316741943
Epoch:  1 | Step:  35 | Val Loss:  0.538803219795227
Epoch:  1 | Step:  36 | Val Loss:  0.7046545743942261
Epoch:  1 | Step:  37 | Val Loss:  0.8744879961013794
Epoch:  1 | Step:  38 | Val Loss:  0.9912029504776001
Epoch:  1 | Step:  39 | Val Loss:  1.0546668767929077
Epoch:  1 | Step:  40 | Val Loss:  1.0920706987380981
Epoch:  1 | Step:  41 | Val Loss:  1.0427864789962769
Epoch:  1 | Step:  42 | Val Loss:  0.8937520980834961
Epoch:  1 | Step:  43 | Val Loss:  0.8722250461578369
Epoch:  1 | Step:  44 | Val Loss:  0.7517492771148682
Epoch:  1 | Step:  45 | Val Loss:  0.5204188823699951
Epoch:  1 | Step:  46 | Val Loss:  0.40559592843055725
Epoch:  1 | Step:  47 | Val Loss:  0.2416602075099945
Epoch:  1 | Step:  48 | Val Loss:  0.10515022277832031
Epoch:  1 | Step:  49 | Val Loss:  0.030068350955843925
Epoch:  1 | Step:  50 | Val Loss:  0.009272117167711258
Epoch:  1 | Step:  51 | Val Loss:  0.02760637179017067
Epoch:  1 | Step:  52 | Val Loss:  0.10167933255434036
Epoch:  1 | Step:  53 | Val Loss:  0.2422625720500946
Epoch:  1 | Step:  54 | Val Loss:  0.37408000230789185
Epoch:  1 | Step:  55 | Val Loss:  0.5077172517776489
Epoch:  1 | Step:  56 | Val Loss:  0.6424481868743896
Epoch:  1 | Step:  57 | Val Loss:  0.8237003684043884
Epoch:  1 | Step:  58 | Val Loss:  0.9118313193321228
Epoch:  1 | Step:  59 | Val Loss:  0.9193443059921265
Epoch:  1 | Step:  60 | Val Loss:  0.9734963178634644
Epoch:  1 | Step:  61 | Val Loss:  0.9447011947631836
Epoch:  1 | Step:  62 | Val Loss:  0.7732857465744019
Epoch:  1 | Step:  63 | Val Loss:  0.7332688570022583
Epoch:  1 | Step:  64 | Val Loss:  0.5356398820877075
Epoch:  1 | Step:  65 | Val Loss:  0.3690887689590454
Epoch:  1 | Step:  66 | Val Loss:  0.24481512606143951
Epoch:  1 | Step:  67 | Val Loss:  0.1218748390674591
Epoch:  1 | Step:  68 | Val Loss:  0.056862782686948776
Epoch:  1 | Step:  69 | Val Loss:  0.02023681439459324
Epoch:  1 | Step:  70 | Val Loss:  0.02566204033792019
Epoch:  1 | Step:  71 | Val Loss:  0.05652734264731407
Epoch:  1 | Step:  72 | Val Loss:  0.1794462352991104
Epoch:  1 | Step:  73 | Val Loss:  0.29930025339126587
Epoch:  1 | Step:  74 | Val Loss:  0.47619473934173584
Epoch:  1 | Step:  75 | Val Loss:  0.5971921682357788
Epoch:  1 | Step:  76 | Val Loss:  0.7684078216552734
Epoch:  1 | Step:  77 | Val Loss:  0.9763429760932922
Epoch:  1 | Step:  78 | Val Loss:  1.0734515190124512
Epoch:  1 | Step:  79 | Val Loss:  1.0276776552200317
Epoch:  1 | Step:  80 | Val Loss:  1.1314550638198853
Epoch:  1 | Step:  81 | Val Loss:  0.9662318229675293
Epoch:  1 | Step:  82 | Val Loss:  0.8905901908874512
Epoch:  1 | Step:  83 | Val Loss:  0.773850679397583
Epoch:  1 | Step:  84 | Val Loss:  0.6180265545845032
Epoch:  1 | Step:  85 | Val Loss:  0.44924265146255493
Epoch:  1 | Step:  86 | Val Loss:  0.26198720932006836
Epoch:  1 | Step:  87 | Val Loss:  0.19519460201263428
Epoch:  1 | Step:  88 | Val Loss:  0.03919360786676407
Epoch:  1 | Step:  89 | Val Loss:  0.016240879893302917
Epoch:  1 | Step:  90 | Val Loss:  0.014382311142981052
Epoch:  1 | Step:  91 | Val Loss:  0.06641489267349243
Epoch:  1 | Step:  92 | Val Loss:  0.15473952889442444
Epoch:  1 | Step:  93 | Val Loss:  0.2990865111351013
Epoch:  1 | Step:  94 | Val Loss:  0.46737760305404663
Epoch:  1 | Step:  95 | Val Loss:  0.5581309795379639
Epoch:  1 | Step:  96 | Val Loss:  0.7105535268783569
Epoch:  1 | Step:  97 | Val Loss:  0.8948708772659302
Epoch:  1 | Step:  98 | Val Loss:  0.8996610641479492
Epoch:  1 | Step:  99 | Val Loss:  0.9458085298538208
Epoch:  1 | Step:  100 | Val Loss:  0.871364951133728
Epoch:  1 | Step:  101 | Val Loss:  0.9178038835525513
Epoch:  1 | Step:  102 | Val Loss:  0.7796929478645325
Epoch:  1 | Step:  103 | Val Loss:  0.645583987236023
Epoch:  1 | Step:  104 | Val Loss:  0.4531288743019104
Epoch:  1 | Step:  105 | Val Loss:  0.320788711309433
Epoch:  1 | Step:  106 | Val Loss:  0.1866971105337143
Epoch:  1 | Step:  107 | Val Loss:  0.07946471869945526
Epoch:  1 | Step:  108 | Val Loss:  0.03763408958911896
Epoch:  1 | Step:  109 | Val Loss:  0.009407036006450653
Epoch:  1 | Step:  110 | Val Loss:  0.041185323148965836
Epoch:  1 | Step:  111 | Val Loss:  0.12992557883262634
Epoch:  1 | Step:  112 | Val Loss:  0.27268660068511963
Epoch:  1 | Step:  113 | Val Loss:  0.3892909288406372
Epoch:  1 | Step:  114 | Val Loss:  0.5828678607940674
Epoch:  1 | Step:  115 | Val Loss:  0.7292967438697815
Epoch:  1 | Step:  116 | Val Loss:  0.913200855255127
Epoch:  1 | Step:  117 | Val Loss:  0.9610209465026855
Epoch:  1 | Step:  118 | Val Loss:  0.9611680507659912
Epoch:  1 | Step:  119 | Val Loss:  0.958283007144928
Epoch:  1 | Step:  120 | Val Loss:  1.0533936023712158
Epoch:  1 | Step:  121 | Val Loss:  0.9847197532653809
Epoch:  1 | Step:  122 | Val Loss:  0.7437777519226074
Epoch:  1 | Step:  123 | Val Loss:  0.5727832317352295
Epoch:  1 | Step:  124 | Val Loss:  0.5626693964004517
Epoch:  1 | Step:  125 | Val Loss:  0.36219334602355957
Epoch:  1 | Train Loss:  tensor(0.5140, device='cuda:0') | Val Loss:  tensor(0.5203, device='cuda:0')
Epoch:  2 | Step:  500 | Train Loss:  0.48008275032043457
Epoch:  2 | Step:  1 | Val Loss:  1.0004597902297974
Epoch:  2 | Step:  2 | Val Loss:  0.9484441876411438
Epoch:  2 | Step:  3 | Val Loss:  0.8928773403167725
Epoch:  2 | Step:  4 | Val Loss:  0.7004724740982056
Epoch:  2 | Step:  5 | Val Loss:  0.5748944878578186
Epoch:  2 | Step:  6 | Val Loss:  0.43315625190734863
Epoch:  2 | Step:  7 | Val Loss:  0.24571415781974792
Epoch:  2 | Step:  8 | Val Loss:  0.13690021634101868
Epoch:  2 | Step:  9 | Val Loss:  0.05863385275006294
Epoch:  2 | Step:  10 | Val Loss:  0.02183651551604271
Epoch:  2 | Step:  11 | Val Loss:  0.015212374739348888
Epoch:  2 | Step:  12 | Val Loss:  0.05706363171339035
Epoch:  2 | Step:  13 | Val Loss:  0.17516855895519257
Epoch:  2 | Step:  14 | Val Loss:  0.2995942234992981
Epoch:  2 | Step:  15 | Val Loss:  0.44968950748443604
Epoch:  2 | Step:  16 | Val Loss:  0.5735359191894531
Epoch:  2 | Step:  17 | Val Loss:  0.7894152998924255
Epoch:  2 | Step:  18 | Val Loss:  0.8362358808517456
Epoch:  2 | Step:  19 | Val Loss:  0.9664217233657837
Epoch:  2 | Step:  20 | Val Loss:  0.9441698789596558
Epoch:  2 | Step:  21 | Val Loss:  0.9489384889602661
Epoch:  2 | Step:  22 | Val Loss:  0.8702850341796875
Epoch:  2 | Step:  23 | Val Loss:  0.6894646883010864
Epoch:  2 | Step:  24 | Val Loss:  0.6824541091918945
Epoch:  2 | Step:  25 | Val Loss:  0.5015610456466675
Epoch:  2 | Step:  26 | Val Loss:  0.3082684874534607
Epoch:  2 | Step:  27 | Val Loss:  0.15535710752010345
Epoch:  2 | Step:  28 | Val Loss:  0.13256672024726868
Epoch:  2 | Step:  29 | Val Loss:  0.03440262749791145
Epoch:  2 | Step:  30 | Val Loss:  0.012994753196835518
Epoch:  2 | Step:  31 | Val Loss:  0.04458359628915787
Epoch:  2 | Step:  32 | Val Loss:  0.10115344822406769
Epoch:  2 | Step:  33 | Val Loss:  0.2419898360967636
Epoch:  2 | Step:  34 | Val Loss:  0.42495936155319214
Epoch:  2 | Step:  35 | Val Loss:  0.5306577682495117
Epoch:  2 | Step:  36 | Val Loss:  0.6952223777770996
Epoch:  2 | Step:  37 | Val Loss:  0.863947868347168
Epoch:  2 | Step:  38 | Val Loss:  0.9799296855926514
Epoch:  2 | Step:  39 | Val Loss:  1.0430623292922974
Epoch:  2 | Step:  40 | Val Loss:  1.0801972150802612
Epoch:  2 | Step:  41 | Val Loss:  1.0312302112579346
Epoch:  2 | Step:  42 | Val Loss:  0.8830983638763428
Epoch:  2 | Step:  43 | Val Loss:  0.8617033958435059
Epoch:  2 | Step:  44 | Val Loss:  0.7420498728752136
Epoch:  2 | Step:  45 | Val Loss:  0.5124421715736389
Epoch:  2 | Step:  46 | Val Loss:  0.39853811264038086
Epoch:  2 | Step:  47 | Val Loss:  0.23640742897987366
Epoch:  2 | Step:  48 | Val Loss:  0.10185246169567108
Epoch:  2 | Step:  49 | Val Loss:  0.028460128232836723
Epoch:  2 | Step:  50 | Val Loss:  0.00958762876689434
Epoch:  2 | Step:  51 | Val Loss:  0.029390571638941765
Epoch:  2 | Step:  52 | Val Loss:  0.10496333241462708
Epoch:  2 | Step:  53 | Val Loss:  0.2475150227546692
Epoch:  2 | Step:  54 | Val Loss:  0.3805725872516632
Epoch:  2 | Step:  55 | Val Loss:  0.5152692794799805
Epoch:  2 | Step:  56 | Val Loss:  0.650963306427002
Epoch:  2 | Step:  57 | Val Loss:  0.8332852721214294
Epoch:  2 | Step:  58 | Val Loss:  0.9218891263008118
Epoch:  2 | Step:  59 | Val Loss:  0.9294471740722656
Epoch:  2 | Step:  60 | Val Loss:  0.9838625192642212
Epoch:  2 | Step:  61 | Val Loss:  0.954919695854187
Epoch:  2 | Step:  62 | Val Loss:  0.7826043367385864
Epoch:  2 | Step:  63 | Val Loss:  0.7423185110092163
Epoch:  2 | Step:  64 | Val Loss:  0.5434104800224304
Epoch:  2 | Step:  65 | Val Loss:  0.37554073333740234
Epoch:  2 | Step:  66 | Val Loss:  0.2500869929790497
Epoch:  2 | Step:  67 | Val Loss:  0.12556850910186768
Epoch:  2 | Step:  68 | Val Loss:  0.059197887778282166
Epoch:  2 | Step:  69 | Val Loss:  0.021206915378570557
Epoch:  2 | Step:  70 | Val Loss:  0.024406418204307556
Epoch:  2 | Step:  71 | Val Loss:  0.05402790382504463
Epoch:  2 | Step:  72 | Val Loss:  0.17487236857414246
Epoch:  2 | Step:  73 | Val Loss:  0.29329144954681396
Epoch:  2 | Step:  74 | Val Loss:  0.4685482382774353
Epoch:  2 | Step:  75 | Val Loss:  0.5885351896286011
Epoch:  2 | Step:  76 | Val Loss:  0.7585484981536865
Epoch:  2 | Step:  77 | Val Loss:  0.9651578664779663
Epoch:  2 | Step:  78 | Val Loss:  1.0617436170578003
Epoch:  2 | Step:  79 | Val Loss:  1.016175627708435
Epoch:  2 | Step:  80 | Val Loss:  1.1194093227386475
Epoch:  2 | Step:  81 | Val Loss:  0.9550924301147461
Epoch:  2 | Step:  82 | Val Loss:  0.8799272775650024
Epoch:  2 | Step:  83 | Val Loss:  0.7639789581298828
Epoch:  2 | Step:  84 | Val Loss:  0.6091838479042053
Epoch:  2 | Step:  85 | Val Loss:  0.44182059168815613
Epoch:  2 | Step:  86 | Val Loss:  0.2563514709472656
Epoch:  2 | Step:  87 | Val Loss:  0.19039031863212585
Epoch:  2 | Step:  88 | Val Loss:  0.0372200608253479
Epoch:  2 | Step:  89 | Val Loss:  0.01544957235455513
Epoch:  2 | Step:  90 | Val Loss:  0.015189440920948982
Epoch:  2 | Step:  91 | Val Loss:  0.06898127496242523
Epoch:  2 | Step:  92 | Val Loss:  0.15878410637378693
Epoch:  2 | Step:  93 | Val Loss:  0.30495789647102356
Epoch:  2 | Step:  94 | Val Loss:  0.47465434670448303
Epoch:  2 | Step:  95 | Val Loss:  0.5660476684570312
Epoch:  2 | Step:  96 | Val Loss:  0.7194638252258301
Epoch:  2 | Step:  97 | Val Loss:  0.9047731757164001
Epoch:  2 | Step:  98 | Val Loss:  0.9096137881278992
Epoch:  2 | Step:  99 | Val Loss:  0.956000804901123
Epoch:  2 | Step:  100 | Val Loss:  0.8811829090118408
Epoch:  2 | Step:  101 | Val Loss:  0.9278791546821594
Epoch:  2 | Step:  102 | Val Loss:  0.7890294790267944
Epoch:  2 | Step:  103 | Val Loss:  0.6540682315826416
Epoch:  2 | Step:  104 | Val Loss:  0.4602503776550293
Epoch:  2 | Step:  105 | Val Loss:  0.3267654776573181
Epoch:  2 | Step:  106 | Val Loss:  0.19128993153572083
Epoch:  2 | Step:  107 | Val Loss:  0.08224170655012131
Epoch:  2 | Step:  108 | Val Loss:  0.039519667625427246
Epoch:  2 | Step:  109 | Val Loss:  0.009426092728972435
Epoch:  2 | Step:  110 | Val Loss:  0.03904101997613907
Epoch:  2 | Step:  111 | Val Loss:  0.12626177072525024
Epoch:  2 | Step:  112 | Val Loss:  0.2669796049594879
Epoch:  2 | Step:  113 | Val Loss:  0.38234418630599976
Epoch:  2 | Step:  114 | Val Loss:  0.5743188858032227
Epoch:  2 | Step:  115 | Val Loss:  0.7197073101997375
Epoch:  2 | Step:  116 | Val Loss:  0.9024116396903992
Epoch:  2 | Step:  117 | Val Loss:  0.949924111366272
Epoch:  2 | Step:  118 | Val Loss:  0.9500794410705566
Epoch:  2 | Step:  119 | Val Loss:  0.9471920728683472
Epoch:  2 | Step:  120 | Val Loss:  1.0417747497558594
Epoch:  2 | Step:  121 | Val Loss:  0.9734835624694824
Epoch:  2 | Step:  122 | Val Loss:  0.7340932488441467
Epoch:  2 | Step:  123 | Val Loss:  0.5643264055252075
Epoch:  2 | Step:  124 | Val Loss:  0.5542659759521484
Epoch:  2 | Step:  125 | Val Loss:  0.35558849573135376
Epoch:  2 | Train Loss:  tensor(0.5135, device='cuda:0') | Val Loss:  tensor(0.5193, device='cuda:0')
Epoch:  3 | Step:  500 | Train Loss:  0.558838427066803
Epoch:  3 | Step:  1 | Val Loss:  0.9947348833084106
Epoch:  3 | Step:  2 | Val Loss:  0.942894458770752
Epoch:  3 | Step:  3 | Val Loss:  0.8875085115432739
Epoch:  3 | Step:  4 | Val Loss:  0.6957982778549194
Epoch:  3 | Step:  5 | Val Loss:  0.5706710815429688
Epoch:  3 | Step:  6 | Val Loss:  0.42952144145965576
Epoch:  3 | Step:  7 | Val Loss:  0.24306026101112366
Epoch:  3 | Step:  8 | Val Loss:  0.13496047258377075
Epoch:  3 | Step:  9 | Val Loss:  0.05745645612478256
Epoch:  3 | Step:  10 | Val Loss:  0.021394124254584312
Epoch:  3 | Step:  11 | Val Loss:  0.015581264160573483
Epoch:  3 | Step:  12 | Val Loss:  0.058100394904613495
Epoch:  3 | Step:  13 | Val Loss:  0.17710062861442566
Epoch:  3 | Step:  14 | Val Loss:  0.3021090626716614
Epoch:  3 | Step:  15 | Val Loss:  0.452734112739563
Epoch:  3 | Step:  16 | Val Loss:  0.5768951177597046
Epoch:  3 | Step:  17 | Val Loss:  0.7932519912719727
Epoch:  3 | Step:  18 | Val Loss:  0.8401396870613098
Epoch:  3 | Step:  19 | Val Loss:  0.9705744385719299
Epoch:  3 | Step:  20 | Val Loss:  0.9482861757278442
Epoch:  3 | Step:  21 | Val Loss:  0.9530438184738159
Epoch:  3 | Step:  22 | Val Loss:  0.8742706775665283
Epoch:  3 | Step:  23 | Val Loss:  0.6930890083312988
Epoch:  3 | Step:  24 | Val Loss:  0.6860511302947998
Epoch:  3 | Step:  25 | Val Loss:  0.5047428011894226
Epoch:  3 | Step:  26 | Val Loss:  0.3108119070529938
Epoch:  3 | Step:  27 | Val Loss:  0.15718811750411987
Epoch:  3 | Step:  28 | Val Loss:  0.1342156082391739
Epoch:  3 | Step:  29 | Val Loss:  0.035114776343107224
Epoch:  3 | Step:  30 | Val Loss:  0.012795696035027504
Epoch:  3 | Step:  31 | Val Loss:  0.043642934411764145
Epoch:  3 | Step:  32 | Val Loss:  0.09959264099597931
Epoch:  3 | Step:  33 | Val Loss:  0.2393834888935089
Epoch:  3 | Step:  34 | Val Loss:  0.42140114307403564
Epoch:  3 | Step:  35 | Val Loss:  0.5266507863998413
Epoch:  3 | Step:  36 | Val Loss:  0.6905395984649658
Epoch:  3 | Step:  37 | Val Loss:  0.8586816191673279
Epoch:  3 | Step:  38 | Val Loss:  0.9742625951766968
Epoch:  3 | Step:  39 | Val Loss:  1.0372285842895508
Epoch:  3 | Step:  40 | Val Loss:  1.0742108821868896
Epoch:  3 | Step:  41 | Val Loss:  1.0254168510437012
Epoch:  3 | Step:  42 | Val Loss:  0.877764105796814
Epoch:  3 | Step:  43 | Val Loss:  0.8564434051513672
Epoch:  3 | Step:  44 | Val Loss:  0.7372190952301025
Epoch:  3 | Step:  45 | Val Loss:  0.5085200667381287
Epoch:  3 | Step:  46 | Val Loss:  0.39509421586990356
Epoch:  3 | Step:  47 | Val Loss:  0.23387809097766876
Epoch:  3 | Step:  48 | Val Loss:  0.10029780864715576
Epoch:  3 | Step:  49 | Val Loss:  0.027723748236894608
Epoch:  3 | Step:  50 | Val Loss:  0.009754358790814877
Epoch:  3 | Step:  51 | Val Loss:  0.030222998932003975
Epoch:  3 | Step:  52 | Val Loss:  0.10645422339439392
Epoch:  3 | Step:  53 | Val Loss:  0.24982911348342896
Epoch:  3 | Step:  54 | Val Loss:  0.3833720088005066
Epoch:  3 | Step:  55 | Val Loss:  0.5184757709503174
Epoch:  3 | Step:  56 | Val Loss:  0.6545197367668152
Epoch:  3 | Step:  57 | Val Loss:  0.837197482585907
Epoch:  3 | Step:  58 | Val Loss:  0.9259624481201172
Epoch:  3 | Step:  59 | Val Loss:  0.9335315823554993
Epoch:  3 | Step:  60 | Val Loss:  0.9880488514900208
Epoch:  3 | Step:  61 | Val Loss:  0.9590267539024353
Epoch:  3 | Step:  62 | Val Loss:  0.7864320874214172
Epoch:  3 | Step:  63 | Val Loss:  0.7460485100746155
Epoch:  3 | Step:  64 | Val Loss:  0.546684980392456
Epoch:  3 | Step:  65 | Val Loss:  0.37832075357437134
Epoch:  3 | Step:  66 | Val Loss:  0.25240179896354675
Epoch:  3 | Step:  67 | Val Loss:  0.12722963094711304
Epoch:  3 | Step:  68 | Val Loss:  0.06027146056294441
Epoch:  3 | Step:  69 | Val Loss:  0.021672004833817482
Epoch:  3 | Step:  70 | Val Loss:  0.023839082568883896
Epoch:  3 | Step:  71 | Val Loss:  0.052863165736198425
Epoch:  3 | Step:  72 | Val Loss:  0.17269010841846466
Epoch:  3 | Step:  73 | Val Loss:  0.2903841733932495
Epoch:  3 | Step:  74 | Val Loss:  0.46480095386505127
Epoch:  3 | Step:  75 | Val Loss:  0.5842623710632324
Epoch:  3 | Step:  76 | Val Loss:  0.753638744354248
Epoch:  3 | Step:  77 | Val Loss:  0.9595447182655334
Epoch:  3 | Step:  78 | Val Loss:  1.0558513402938843
Epoch:  3 | Step:  79 | Val Loss:  1.010389804840088
Epoch:  3 | Step:  80 | Val Loss:  1.1133298873901367
Epoch:  3 | Step:  81 | Val Loss:  0.9495004415512085
Epoch:  3 | Step:  82 | Val Loss:  0.874588668346405
Epoch:  3 | Step:  83 | Val Loss:  0.759061872959137
Epoch:  3 | Step:  84 | Val Loss:  0.604811429977417
Epoch:  3 | Step:  85 | Val Loss:  0.4381830096244812
Epoch:  3 | Step:  86 | Val Loss:  0.2536311149597168
Epoch:  3 | Step:  87 | Val Loss:  0.18808726966381073
Epoch:  3 | Step:  88 | Val Loss:  0.036308132112026215
Epoch:  3 | Step:  89 | Val Loss:  0.015100523829460144
Epoch:  3 | Step:  90 | Val Loss:  0.015580989420413971
Epoch:  3 | Step:  91 | Val Loss:  0.07016143202781677
Epoch:  3 | Step:  92 | Val Loss:  0.1605963110923767
Epoch:  3 | Step:  93 | Val Loss:  0.30751878023147583
Epoch:  3 | Step:  94 | Val Loss:  0.47775259613990784
Epoch:  3 | Step:  95 | Val Loss:  0.5693926811218262
Epoch:  3 | Step:  96 | Val Loss:  0.7231482267379761
Epoch:  3 | Step:  97 | Val Loss:  0.9087932109832764
Epoch:  3 | Step:  98 | Val Loss:  0.9136516451835632
Epoch:  3 | Step:  99 | Val Loss:  0.9601008892059326
Epoch:  3 | Step:  100 | Val Loss:  0.8851802945137024
Epoch:  3 | Step:  101 | Val Loss:  0.9319581985473633
Epoch:  3 | Step:  102 | Val Loss:  0.7928644418716431
Epoch:  3 | Step:  103 | Val Loss:  0.6575978994369507
Epoch:  3 | Step:  104 | Val Loss:  0.4632907509803772
Epoch:  3 | Step:  105 | Val Loss:  0.3293570280075073
Epoch:  3 | Step:  106 | Val Loss:  0.19332443177700043
Epoch:  3 | Step:  107 | Val Loss:  0.08350852131843567
Epoch:  3 | Step:  108 | Val Loss:  0.04039790853857994
Epoch:  3 | Step:  109 | Val Loss:  0.009455585852265358
Epoch:  3 | Step:  110 | Val Loss:  0.03805004805326462
Epoch:  3 | Step:  111 | Val Loss:  0.1245296448469162
Epoch:  3 | Step:  112 | Val Loss:  0.26422640681266785
Epoch:  3 | Step:  113 | Val Loss:  0.37895703315734863
Epoch:  3 | Step:  114 | Val Loss:  0.5701013803482056
Epoch:  3 | Step:  115 | Val Loss:  0.7149461507797241
Epoch:  3 | Step:  116 | Val Loss:  0.8970085978507996
Epoch:  3 | Step:  117 | Val Loss:  0.9443567991256714
Epoch:  3 | Step:  118 | Val Loss:  0.9445157051086426
Epoch:  3 | Step:  119 | Val Loss:  0.9416279792785645
Epoch:  3 | Step:  120 | Val Loss:  1.0359246730804443
Epoch:  3 | Step:  121 | Val Loss:  0.9678401947021484
Epoch:  3 | Step:  122 | Val Loss:  0.7292742729187012
Epoch:  3 | Step:  123 | Val Loss:  0.5601496696472168
Epoch:  3 | Step:  124 | Val Loss:  0.5501241683959961
Epoch:  3 | Step:  125 | Val Loss:  0.3523736596107483
Epoch:  3 | Train Loss:  tensor(0.5134, device='cuda:0') | Val Loss:  tensor(0.5186, device='cuda:0')
Epoch:  4 | Step:  500 | Train Loss:  0.5439928770065308
Epoch:  4 | Step:  1 | Val Loss:  0.9894447922706604
Epoch:  4 | Step:  2 | Val Loss:  0.9377661943435669
Epoch:  4 | Step:  3 | Val Loss:  0.8825472593307495
Epoch:  4 | Step:  4 | Val Loss:  0.6914775967597961
Epoch:  4 | Step:  5 | Val Loss:  0.5667662620544434
Epoch:  4 | Step:  6 | Val Loss:  0.4261617064476013
Epoch:  4 | Step:  7 | Val Loss:  0.24061048030853271
Epoch:  4 | Step:  8 | Val Loss:  0.13317397236824036
Epoch:  4 | Step:  9 | Val Loss:  0.05637786537408829
Epoch:  4 | Step:  10 | Val Loss:  0.020996853709220886
Epoch:  4 | Step:  11 | Val Loss:  0.015933020040392876
Epoch:  4 | Step:  12 | Val Loss:  0.059065110981464386
Epoch:  4 | Step:  13 | Val Loss:  0.17887817323207855
Epoch:  4 | Step:  14 | Val Loss:  0.3044048249721527
Epoch:  4 | Step:  15 | Val Loss:  0.45549631118774414
Epoch:  4 | Step:  16 | Val Loss:  0.5799217224121094
Epoch:  4 | Step:  17 | Val Loss:  0.7966824769973755
Epoch:  4 | Step:  18 | Val Loss:  0.8436174988746643
Epoch:  4 | Step:  19 | Val Loss:  0.9742566347122192
Epoch:  4 | Step:  20 | Val Loss:  0.9519389867782593
Epoch:  4 | Step:  21 | Val Loss:  0.9566832184791565
Epoch:  4 | Step:  22 | Val Loss:  0.8778171539306641
Epoch:  4 | Step:  23 | Val Loss:  0.6963378190994263
Epoch:  4 | Step:  24 | Val Loss:  0.6892770528793335
Epoch:  4 | Step:  25 | Val Loss:  0.5076207518577576
Epoch:  4 | Step:  26 | Val Loss:  0.3131304979324341
Epoch:  4 | Step:  27 | Val Loss:  0.15887290239334106
Epoch:  4 | Step:  28 | Val Loss:  0.13573595881462097
Epoch:  4 | Step:  29 | Val Loss:  0.03578171879053116
Epoch:  4 | Step:  30 | Val Loss:  0.012623487040400505
Epoch:  4 | Step:  31 | Val Loss:  0.04278406500816345
Epoch:  4 | Step:  32 | Val Loss:  0.0981583297252655
Epoch:  4 | Step:  33 | Val Loss:  0.23697805404663086
Epoch:  4 | Step:  34 | Val Loss:  0.41811254620552063
Epoch:  4 | Step:  35 | Val Loss:  0.5229465961456299
Epoch:  4 | Step:  36 | Val Loss:  0.6862103343009949
Epoch:  4 | Step:  37 | Val Loss:  0.8538137674331665
Epoch:  4 | Step:  38 | Val Loss:  0.9690268039703369
Epoch:  4 | Step:  39 | Val Loss:  1.0318386554718018
Epoch:  4 | Step:  40 | Val Loss:  1.0686813592910767
Epoch:  4 | Step:  41 | Val Loss:  1.0200462341308594
Epoch:  4 | Step:  42 | Val Loss:  0.8728345632553101
Epoch:  4 | Step:  43 | Val Loss:  0.8515818119049072
Epoch:  4 | Step:  44 | Val Loss:  0.7327540516853333
Epoch:  4 | Step:  45 | Val Loss:  0.5048946142196655
Epoch:  4 | Step:  46 | Val Loss:  0.39191150665283203
Epoch:  4 | Step:  47 | Val Loss:  0.2315444052219391
Epoch:  4 | Step:  48 | Val Loss:  0.09886914491653442
Epoch:  4 | Step:  49 | Val Loss:  0.02705414965748787
Epoch:  4 | Step:  50 | Val Loss:  0.009919960051774979
Epoch:  4 | Step:  51 | Val Loss:  0.031000616028904915
Epoch:  4 | Step:  52 | Val Loss:  0.1078326553106308
Epoch:  4 | Step:  53 | Val Loss:  0.2519485354423523
Epoch:  4 | Step:  54 | Val Loss:  0.3859178423881531
Epoch:  4 | Step:  55 | Val Loss:  0.5213761925697327
Epoch:  4 | Step:  56 | Val Loss:  0.6577178239822388
Epoch:  4 | Step:  57 | Val Loss:  0.8406832218170166
Epoch:  4 | Step:  58 | Val Loss:  0.9295800924301147
Epoch:  4 | Step:  59 | Val Loss:  0.9371564388275146
Epoch:  4 | Step:  60 | Val Loss:  0.9917622804641724
Epoch:  4 | Step:  61 | Val Loss:  0.9626621603965759
Epoch:  4 | Step:  62 | Val Loss:  0.7898516654968262
Epoch:  4 | Step:  63 | Val Loss:  0.7493851184844971
Epoch:  4 | Step:  64 | Val Loss:  0.5496389865875244
Epoch:  4 | Step:  65 | Val Loss:  0.3808484673500061
Epoch:  4 | Step:  66 | Val Loss:  0.2545197010040283
Epoch:  4 | Step:  67 | Val Loss:  0.1287611424922943
Epoch:  4 | Step:  68 | Val Loss:  0.061268873512744904
Epoch:  4 | Step:  69 | Val Loss:  0.022112105041742325
Epoch:  4 | Step:  70 | Val Loss:  0.023326193913817406
Epoch:  4 | Step:  71 | Val Loss:  0.051796287298202515
Epoch:  4 | Step:  72 | Val Loss:  0.17067861557006836
Epoch:  4 | Step:  73 | Val Loss:  0.28769931197166443
Epoch:  4 | Step:  74 | Val Loss:  0.46133720874786377
Epoch:  4 | Step:  75 | Val Loss:  0.5803117156028748
Epoch:  4 | Step:  76 | Val Loss:  0.7490999698638916
Epoch:  4 | Step:  77 | Val Loss:  0.9543578028678894
Epoch:  4 | Step:  78 | Val Loss:  1.050407886505127
Epoch:  4 | Step:  79 | Val Loss:  1.0050442218780518
Epoch:  4 | Step:  80 | Val Loss:  1.1077154874801636
Epoch:  4 | Step:  81 | Val Loss:  0.9443331360816956
Epoch:  4 | Step:  82 | Val Loss:  0.8696547746658325
Epoch:  4 | Step:  83 | Val Loss:  0.7545166015625
Epoch:  4 | Step:  84 | Val Loss:  0.6007688045501709
Epoch:  4 | Step:  85 | Val Loss:  0.43482106924057007
Epoch:  4 | Step:  86 | Val Loss:  0.2511197328567505
Epoch:  4 | Step:  87 | Val Loss:  0.18596334755420685
Epoch:  4 | Step:  88 | Val Loss:  0.03547573834657669
Epoch:  4 | Step:  89 | Val Loss:  0.014789612963795662
Epoch:  4 | Step:  90 | Val Loss:  0.015953583642840385
Epoch:  4 | Step:  91 | Val Loss:  0.07125727832317352
Epoch:  4 | Step:  92 | Val Loss:  0.16226479411125183
Epoch:  4 | Step:  93 | Val Loss:  0.3098567724227905
Epoch:  4 | Step:  94 | Val Loss:  0.4805580973625183
Epoch:  4 | Step:  95 | Val Loss:  0.5724132061004639
Epoch:  4 | Step:  96 | Val Loss:  0.7264482378959656
Epoch:  4 | Step:  97 | Val Loss:  0.9123663902282715
Epoch:  4 | Step:  98 | Val Loss:  0.917239785194397
Epoch:  4 | Step:  99 | Val Loss:  0.9637317061424255
Epoch:  4 | Step:  100 | Val Loss:  0.8887379169464111
Epoch:  4 | Step:  101 | Val Loss:  0.9355802536010742
Epoch:  4 | Step:  102 | Val Loss:  0.7962902784347534
Epoch:  4 | Step:  103 | Val Loss:  0.6607667207717896
Epoch:  4 | Step:  104 | Val Loss:  0.46604621410369873
Epoch:  4 | Step:  105 | Val Loss:  0.33171820640563965
Epoch:  4 | Step:  106 | Val Loss:  0.19519132375717163
Epoch:  4 | Step:  107 | Val Loss:  0.08468210697174072
Epoch:  4 | Step:  108 | Val Loss:  0.04121756553649902
Epoch:  4 | Step:  109 | Val Loss:  0.009494442492723465
Epoch:  4 | Step:  110 | Val Loss:  0.037144556641578674
Epoch:  4 | Step:  111 | Val Loss:  0.12293636798858643
Epoch:  4 | Step:  112 | Val Loss:  0.2616846561431885
Epoch:  4 | Step:  113 | Val Loss:  0.37582677602767944
Epoch:  4 | Step:  114 | Val Loss:  0.5662020444869995
Epoch:  4 | Step:  115 | Val Loss:  0.7105441093444824
Epoch:  4 | Step:  116 | Val Loss:  0.892015278339386
Epoch:  4 | Step:  117 | Val Loss:  0.9392120838165283
Epoch:  4 | Step:  118 | Val Loss:  0.9393745064735413
Epoch:  4 | Step:  119 | Val Loss:  0.936486005783081
Epoch:  4 | Step:  120 | Val Loss:  1.0305206775665283
Epoch:  4 | Step:  121 | Val Loss:  0.9626257419586182
Epoch:  4 | Step:  122 | Val Loss:  0.724819540977478
Epoch:  4 | Step:  123 | Val Loss:  0.5562883019447327
Epoch:  4 | Step:  124 | Val Loss:  0.5462948679924011
Epoch:  4 | Step:  125 | Val Loss:  0.3494035601615906
Epoch:  4 | Train Loss:  tensor(0.5133, device='cuda:0') | Val Loss:  tensor(0.5179, device='cuda:0')
