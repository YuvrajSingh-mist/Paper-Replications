{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter  \n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "    device = 'cuda'\n",
    "    batch_size = 1\n",
    "    lr = 0.0002\n",
    "    img_size = 128\n",
    "    no_of_channels = 3\n",
    "    kernel_size = (4,4)\n",
    "    stride = 2\n",
    "    # dropout = 0.5\n",
    "    padding = 1\n",
    "    lr_slope = 0.2\n",
    "    beta_1 = 0.5\n",
    "    beta_2 = 0.999\n",
    "    no_of_kernel = 64\n",
    "    lambda_gen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArgs.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)  #mean = 0, std = 0.02\n",
    "        \n",
    "    if classname.find('Conv2D') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)  #mean = 0, std = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=1, padding_mode='reflect', device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        \n",
    "        res = x + self.main(x)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.resnet_blocks = ResnetBlock()\n",
    "        \n",
    "        self.down = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels=ModelArgs.no_of_channels, out_channels=64, kernel_size=(7,7), stride=1, device=ModelArgs.device, padding=3),\n",
    "            nn.InstanceNorm2d(num_features=64, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=2, device=ModelArgs.device, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=128, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=2, device=ModelArgs.device),\n",
    "            nn.InstanceNorm2d(num_features=256, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=2, device=ModelArgs.device),\n",
    "            nn.InstanceNorm2d(num_features=128, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(3,3), stride=2, device=ModelArgs.device, output_padding=1),\n",
    "            nn.InstanceNorm2d(num_features=64, device=ModelArgs.device, affine=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=ModelArgs.no_of_channels, kernel_size=(7,7), stride=1, device=ModelArgs.device, padding_mode='reflect', padding=3),\n",
    "            nn.InstanceNorm2d(num_features=ModelArgs.no_of_channels, device=ModelArgs.device, affine=True),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "   \n",
    "        x = self.down(x)\n",
    "        x = self.resnet_blocks(x)\n",
    "        x = self.up(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (resnet_blocks): ResnetBlock(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (8): ReLU()\n",
      "      (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (10): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (13): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (14): ReLU()\n",
      "      (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (16): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (17): ReLU()\n",
      "      (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (19): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (20): ReLU()\n",
      "      (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (22): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (23): ReLU()\n",
      "      (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (25): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (26): ReLU()\n",
      "      (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (28): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (29): ReLU()\n",
      "      (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (31): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (32): ReLU()\n",
      "      (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (34): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (35): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (down): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (8): ReLU()\n",
      "  )\n",
      "  (up): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), output_padding=(1, 1))\n",
      "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
      "    (7): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (8): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Intializing the Discriminator instance\n",
    "Gen = Generator().to(ModelArgs.device)\n",
    "#Apply the wieght intilization function layer by layer\n",
    "Gen = Gen.apply(weights_init)\n",
    "#Printing the structure\n",
    "print(Gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "Generator (Generator)                    [1, 3, 128, 128]     [1, 3, 128, 128]     --                   True\n",
       "├─Sequential (down)                      [1, 3, 128, 128]     [1, 256, 31, 31]     --                   True\n",
       "│    └─Conv2d (0)                        [1, 3, 128, 128]     [1, 64, 128, 128]    9,472                True\n",
       "│    └─InstanceNorm2d (1)                [1, 64, 128, 128]    [1, 64, 128, 128]    128                  True\n",
       "│    └─ReLU (2)                          [1, 64, 128, 128]    [1, 64, 128, 128]    --                   --\n",
       "│    └─Conv2d (3)                        [1, 64, 128, 128]    [1, 128, 64, 64]     73,856               True\n",
       "│    └─InstanceNorm2d (4)                [1, 128, 64, 64]     [1, 128, 64, 64]     256                  True\n",
       "│    └─ReLU (5)                          [1, 128, 64, 64]     [1, 128, 64, 64]     --                   --\n",
       "│    └─Conv2d (6)                        [1, 128, 64, 64]     [1, 256, 31, 31]     295,168              True\n",
       "│    └─InstanceNorm2d (7)                [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    └─ReLU (8)                          [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "├─ResnetBlock (resnet_blocks)            [1, 256, 31, 31]     [1, 256, 31, 31]     --                   True\n",
       "│    └─Sequential (main)                 [1, 256, 31, 31]     [1, 256, 31, 31]     --                   True\n",
       "│    │    └─Conv2d (0)                   [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (1)           [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (2)                     [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (3)                   [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (4)           [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (5)                     [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (6)                   [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (7)           [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (8)                     [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (9)                   [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (10)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (11)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (12)                  [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (13)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (14)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (15)                  [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (16)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (17)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (18)                  [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (19)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (20)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (21)                  [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (22)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (23)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (24)                  [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (25)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (26)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (27)                  [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (28)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (29)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (30)                  [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (31)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (32)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "│    │    └─Conv2d (33)                  [1, 256, 31, 31]     [1, 256, 31, 31]     590,080              True\n",
       "│    │    └─InstanceNorm2d (34)          [1, 256, 31, 31]     [1, 256, 31, 31]     512                  True\n",
       "│    │    └─ReLU (35)                    [1, 256, 31, 31]     [1, 256, 31, 31]     --                   --\n",
       "├─Sequential (up)                        [1, 256, 31, 31]     [1, 3, 128, 128]     --                   True\n",
       "│    └─ConvTranspose2d (0)               [1, 256, 31, 31]     [1, 128, 63, 63]     295,040              True\n",
       "│    └─InstanceNorm2d (1)                [1, 128, 63, 63]     [1, 128, 63, 63]     256                  True\n",
       "│    └─ReLU (2)                          [1, 128, 63, 63]     [1, 128, 63, 63]     --                   --\n",
       "│    └─ConvTranspose2d (3)               [1, 128, 63, 63]     [1, 64, 128, 128]    73,792               True\n",
       "│    └─InstanceNorm2d (4)                [1, 64, 128, 128]    [1, 64, 128, 128]    128                  True\n",
       "│    └─ReLU (5)                          [1, 64, 128, 128]    [1, 64, 128, 128]    --                   --\n",
       "│    └─Conv2d (6)                        [1, 64, 128, 128]    [1, 3, 128, 128]     9,411                True\n",
       "│    └─InstanceNorm2d (7)                [1, 3, 128, 128]     [1, 3, 128, 128]     6                    True\n",
       "│    └─Tanh (8)                          [1, 3, 128, 128]     [1, 3, 128, 128]     --                   --\n",
       "========================================================================================================================\n",
       "Total params: 7,845,129\n",
       "Trainable params: 7,845,129\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 10.08\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 102.03\n",
       "Params size (MB): 31.38\n",
       "Estimated Total Size (MB): 133.61\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# images = torch.randn(64, 1, 64, 64)\n",
    "# labels = torch.randint(0, 10, (64,), dtype=torch.long)\n",
    "gen = Generator()\n",
    "summary(model=gen,\n",
    "        input_size=(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size),\n",
    "        # input_data=(images.to(ModelArgs.device), labels.to(ModelArgs.device)),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(ModelArgs.no_of_channels, 64, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding, padding_mode='reflect'),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "                \n",
    "            nn.Conv2d(64, 128, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding, padding_mode='reflect'),\n",
    "            nn.InstanceNorm2d(128, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "               \n",
    "            nn.Conv2d(128, 256, kernel_size=ModelArgs.kernel_size, stride=ModelArgs.stride, padding=ModelArgs.padding, padding_mode='reflect'),\n",
    "            nn.InstanceNorm2d(256, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "              \n",
    "            nn.Conv2d(256, 512, kernel_size=ModelArgs.kernel_size, stride=1, padding=ModelArgs.padding, padding_mode='reflect'),\n",
    "            nn.InstanceNorm2d(512, affine=True),\n",
    "            nn.LeakyReLU(negative_slope=ModelArgs.lr_slope),\n",
    "            \n",
    "            nn.Conv2d(512, 1, kernel_size=ModelArgs.kernel_size, stride=1, padding=ModelArgs.padding, padding_mode='reflect'),\n",
    "\n",
    "            # nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "        # print(x.shape)\n",
    "        # print(y.shape)\n",
    "        # res = torch.concat([x, y], dim=1)\n",
    "        return nn.functional.sigmoid(self.main(x))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchGAN(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Intializing the Discriminator instance\n",
    "patchgan = PatchGAN().to(ModelArgs.device)\n",
    "#Apply the wieght intilization function layer by layer\n",
    "patchgan = patchgan.apply(weights_init)\n",
    "#Printing the structure\n",
    "print(patchgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "PatchGAN (PatchGAN)                      [1, 3, 128, 128]     [1, 1, 14, 14]       --                   True\n",
       "├─Sequential (main)                      [1, 3, 128, 128]     [1, 1, 14, 14]       --                   True\n",
       "│    └─Conv2d (0)                        [1, 3, 128, 128]     [1, 64, 64, 64]      3,136                True\n",
       "│    └─LeakyReLU (1)                     [1, 64, 64, 64]      [1, 64, 64, 64]      --                   --\n",
       "│    └─Conv2d (2)                        [1, 64, 64, 64]      [1, 128, 32, 32]     131,200              True\n",
       "│    └─InstanceNorm2d (3)                [1, 128, 32, 32]     [1, 128, 32, 32]     256                  True\n",
       "│    └─LeakyReLU (4)                     [1, 128, 32, 32]     [1, 128, 32, 32]     --                   --\n",
       "│    └─Conv2d (5)                        [1, 128, 32, 32]     [1, 256, 16, 16]     524,544              True\n",
       "│    └─InstanceNorm2d (6)                [1, 256, 16, 16]     [1, 256, 16, 16]     512                  True\n",
       "│    └─LeakyReLU (7)                     [1, 256, 16, 16]     [1, 256, 16, 16]     --                   --\n",
       "│    └─Conv2d (8)                        [1, 256, 16, 16]     [1, 512, 15, 15]     2,097,664            True\n",
       "│    └─InstanceNorm2d (9)                [1, 512, 15, 15]     [1, 512, 15, 15]     1,024                True\n",
       "│    └─LeakyReLU (10)                    [1, 512, 15, 15]     [1, 512, 15, 15]     --                   --\n",
       "│    └─Conv2d (11)                       [1, 512, 15, 15]     [1, 1, 14, 14]       8,193                True\n",
       "========================================================================================================================\n",
       "Total params: 2,766,529\n",
       "Trainable params: 2,766,529\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 755.06\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 7.09\n",
       "Params size (MB): 11.07\n",
       "Estimated Total Size (MB): 18.35\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# images = torch.randn(64, 1, 64, 64)\n",
    "# labels = torch.randint(0, 10, (64,), dtype=torch.long)\n",
    "real_A = torch.randn(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size)\n",
    "# real_B = torch.randn(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size)\n",
    "patchgan = PatchGAN()\n",
    "summary(model=patchgan,\n",
    "        input_size=(ModelArgs.batch_size, ModelArgs.no_of_channels, ModelArgs.img_size, ModelArgs.img_size),\n",
    "        # input_data=(real_A),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "#Config\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "both_transform = A.Compose(\n",
    "    [A.Resize(width=ModelArgs.img_size, height=ModelArgs.img_size),], additional_targets={\"image0\": \"image\"},\n",
    ")\n",
    "\n",
    "transform_only_input = A.Compose(\n",
    "    [\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.ColorJitter(p=0.2),\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
    "        # A.ToFloat(max_value=ModelArgs.img_size),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_only_mask = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
    "        # A.ToFloat(max_value=ModelArgs.img_size),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Cityscapes2LabelsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir) -> None:\n",
    "        super().__init__()\n",
    "        self.train_path = root_dir\n",
    "        self.dir = os.listdir(self.train_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dir)\n",
    "    \n",
    "    def __getitem__(self, index):    \n",
    "        \n",
    "        current_img = self.dir[index]\n",
    "        img_path = os.path.join(self.train_path, current_img) \n",
    "        img = np.array(Image.open(img_path))\n",
    "        input = img[:, :256, :]\n",
    "        mask = img[:, 256:, :]\n",
    "        augmentataions = both_transform(image = input, image0 = mask)\n",
    "        input = augmentataions['image']\n",
    "        mask = augmentataions['image0']\n",
    "        \n",
    "        input_transformed = transform_only_input(image = input)['image']\n",
    "        mask_transformed = transform_only_mask(image = mask)['image']\n",
    "        \n",
    "        return input_transformed, mask_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataloaders\n",
    "dir = 'data/cityscapes/train'\n",
    "train = Cityscapes2LabelsDataset(dir)\n",
    "trainloader = DataLoader(train, batch_size=ModelArgs.batch_size, shuffle=True)\n",
    "val_dir = 'data/cityscapes/val'\n",
    "val = Cityscapes2LabelsDataset(val_dir)\n",
    "valloader = DataLoader(val, batch_size=ModelArgs.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib  import Path\n",
    "save_images = Path('generated_images/')\n",
    "# enc = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.95294124..0.91372555].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for X, y in trainloader:\n",
    "    imageX = X[0]\n",
    "    # imagey = y[0]\n",
    "\n",
    "    imageX = imageX.permute(1, 2, 0).numpy()\n",
    "    # imagey = imagey.permute(1, 2, 0).numpy()\n",
    "    # Plot the image\n",
    "    plt.imshow(imageX)\n",
    "    # plt.imshow(imagey)\n",
    "    plt.show()\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "generatorX = Generator().to(ModelArgs.device).apply(weights_init)\n",
    "discriminatorY = PatchGAN().to(ModelArgs.device).apply(weights_init)\n",
    "generatorY = Generator().to(ModelArgs.device).apply(weights_init)\n",
    "discriminatorX = PatchGAN().to(ModelArgs.device).apply(weights_init)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()  \n",
    "epochs = 200 \n",
    "\n",
    "generatorX.train()\n",
    "discriminatorX.train()\n",
    "generatorY.train()\n",
    "discriminatorY.train()\n",
    "\n",
    "optimizerG = torch.optim.Adam(itertools.chain(generatorX.parameters(), generatorY.parameters()), betas=(ModelArgs.beta_1, ModelArgs.beta_2), lr=ModelArgs.lr) #For discriminator\n",
    "optimizerD = torch.optim.Adam(itertools.chain(discriminatorY.parameters(), discriminatorX.parameters()), betas=(ModelArgs.beta_1, ModelArgs.beta_2), lr=ModelArgs.lr) #For generator\n",
    "\n",
    "\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "\n",
    "loss_g = []\n",
    "loss_d = []\n",
    "img_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLRScheduler:\n",
    "    def __init__(self, optimizers, total_epochs, lr_initial):\n",
    "        self.optimizers = optimizers\n",
    "        self.total_epochs = total_epochs\n",
    "        self.lr_initial = lr_initial\n",
    "\n",
    "    def step(self, epoch):\n",
    "        if epoch < 100:\n",
    "            lr = self.lr_initial\n",
    "        else:\n",
    "            decay = (self.lr_initial / 100) * (epoch - 100)\n",
    "            lr = max(0, self.lr_initial - decay)\n",
    "        \n",
    "        for optimizer in self.optimizers:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "scheduler = CustomLRScheduler([optimizerG, optimizerD], epochs, lr_initial=ModelArgs.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  0 Epoch:  0 Generator loss:  6.708699703216553 Discriminator loss:  0.5348831415176392\n",
      "saving the output\n",
      "Iterations:  200 Epoch:  0 Generator loss:  5.203976154327393 Discriminator loss:  0.2515261173248291\n",
      "Iterations:  400 Epoch:  0 Generator loss:  6.677587509155273 Discriminator loss:  0.0666915699839592\n",
      "saving the output\n",
      "Iterations:  600 Epoch:  0 Generator loss:  7.081015586853027 Discriminator loss:  0.17069436609745026\n",
      "Iterations:  800 Epoch:  0 Generator loss:  6.076804161071777 Discriminator loss:  0.25835809111595154\n",
      "Iterations:  1000 Epoch:  0 Generator loss:  7.259548187255859 Discriminator loss:  0.13021402060985565\n",
      "saving the output\n",
      "Iterations:  1200 Epoch:  0 Generator loss:  7.133435249328613 Discriminator loss:  0.11250948160886765\n",
      "Iterations:  1400 Epoch:  0 Generator loss:  4.916278839111328 Discriminator loss:  0.23098018765449524\n",
      "saving the output\n",
      "Iterations:  1600 Epoch:  0 Generator loss:  5.140400409698486 Discriminator loss:  0.09743780642747879\n",
      "Iterations:  1800 Epoch:  0 Generator loss:  5.326684474945068 Discriminator loss:  0.13973456621170044\n",
      "Iterations:  2000 Epoch:  0 Generator loss:  6.56304931640625 Discriminator loss:  0.24198579788208008\n",
      "saving the output\n",
      "Iterations:  2200 Epoch:  0 Generator loss:  5.071989059448242 Discriminator loss:  0.1137835830450058\n",
      "Iterations:  2400 Epoch:  0 Generator loss:  5.500655174255371 Discriminator loss:  0.232326477766037\n",
      "saving the output\n",
      "Iterations:  2600 Epoch:  0 Generator loss:  5.546324253082275 Discriminator loss:  0.02796889655292034\n",
      "Iterations:  2800 Epoch:  0 Generator loss:  6.562033176422119 Discriminator loss:  0.11661798506975174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [04:23<14:35:33, 263.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  3000 Epoch:  1 Generator loss:  6.0975189208984375 Discriminator loss:  0.11171866208314896\n",
      "saving the output\n",
      "Iterations:  3200 Epoch:  1 Generator loss:  6.1937079429626465 Discriminator loss:  0.03489059954881668\n",
      "Iterations:  3400 Epoch:  1 Generator loss:  5.815217018127441 Discriminator loss:  0.055435605347156525\n",
      "saving the output\n",
      "Iterations:  3600 Epoch:  1 Generator loss:  6.701831340789795 Discriminator loss:  0.11054302752017975\n",
      "Iterations:  3800 Epoch:  1 Generator loss:  5.090155124664307 Discriminator loss:  0.13664036989212036\n",
      "Iterations:  4000 Epoch:  1 Generator loss:  9.326272010803223 Discriminator loss:  0.2142733335494995\n",
      "saving the output\n",
      "Iterations:  4200 Epoch:  1 Generator loss:  7.50077486038208 Discriminator loss:  0.520683228969574\n",
      "Iterations:  4400 Epoch:  1 Generator loss:  7.051923751831055 Discriminator loss:  0.0616147480905056\n",
      "saving the output\n",
      "Iterations:  4600 Epoch:  1 Generator loss:  5.758209228515625 Discriminator loss:  0.11146757006645203\n",
      "Iterations:  4800 Epoch:  1 Generator loss:  5.712435722351074 Discriminator loss:  0.5123980045318604\n",
      "Iterations:  5000 Epoch:  1 Generator loss:  5.974294185638428 Discriminator loss:  0.16163671016693115\n",
      "saving the output\n",
      "Iterations:  5200 Epoch:  1 Generator loss:  6.411126136779785 Discriminator loss:  0.042629312723875046\n",
      "Iterations:  5400 Epoch:  1 Generator loss:  6.454018592834473 Discriminator loss:  0.22939041256904602\n",
      "saving the output\n",
      "Iterations:  5600 Epoch:  1 Generator loss:  4.655109882354736 Discriminator loss:  0.3215959668159485\n",
      "Iterations:  5800 Epoch:  1 Generator loss:  6.8764142990112305 Discriminator loss:  0.2439085692167282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [08:41<14:18:55, 260.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  6000 Epoch:  2 Generator loss:  5.744756698608398 Discriminator loss:  0.06274042278528214\n",
      "saving the output\n",
      "Iterations:  6200 Epoch:  2 Generator loss:  5.3473591804504395 Discriminator loss:  0.4946279227733612\n",
      "Iterations:  6400 Epoch:  2 Generator loss:  5.403684616088867 Discriminator loss:  0.4132544696331024\n",
      "saving the output\n",
      "Iterations:  6600 Epoch:  2 Generator loss:  7.198941230773926 Discriminator loss:  0.15593205392360687\n",
      "Iterations:  6800 Epoch:  2 Generator loss:  5.218955039978027 Discriminator loss:  0.2579195499420166\n",
      "Iterations:  7000 Epoch:  2 Generator loss:  5.382177829742432 Discriminator loss:  0.06357689946889877\n",
      "saving the output\n",
      "Iterations:  7200 Epoch:  2 Generator loss:  5.155367374420166 Discriminator loss:  0.29857945442199707\n",
      "Iterations:  7400 Epoch:  2 Generator loss:  5.255902290344238 Discriminator loss:  0.4199935793876648\n",
      "saving the output\n",
      "Iterations:  7600 Epoch:  2 Generator loss:  6.413141250610352 Discriminator loss:  0.2845469117164612\n",
      "Iterations:  7800 Epoch:  2 Generator loss:  5.683770179748535 Discriminator loss:  0.1405961662530899\n",
      "Iterations:  8000 Epoch:  2 Generator loss:  6.211178302764893 Discriminator loss:  0.2170657366514206\n",
      "saving the output\n",
      "Iterations:  8200 Epoch:  2 Generator loss:  4.763719081878662 Discriminator loss:  0.47856730222702026\n",
      "Iterations:  8400 Epoch:  2 Generator loss:  4.869994163513184 Discriminator loss:  0.0951055958867073\n",
      "saving the output\n",
      "Iterations:  8600 Epoch:  2 Generator loss:  3.9973607063293457 Discriminator loss:  0.2484540492296219\n",
      "Iterations:  8800 Epoch:  2 Generator loss:  5.525420665740967 Discriminator loss:  0.14276203513145447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [13:01<14:13:44, 260.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  9000 Epoch:  3 Generator loss:  6.281662464141846 Discriminator loss:  0.10827011615037918\n",
      "saving the output\n",
      "Iterations:  9200 Epoch:  3 Generator loss:  5.05148983001709 Discriminator loss:  0.016077890992164612\n",
      "Iterations:  9400 Epoch:  3 Generator loss:  4.107664108276367 Discriminator loss:  0.39933088421821594\n",
      "saving the output\n",
      "Iterations:  9600 Epoch:  3 Generator loss:  6.74880313873291 Discriminator loss:  0.05761769041419029\n",
      "Iterations:  9800 Epoch:  3 Generator loss:  4.775546073913574 Discriminator loss:  0.3415221571922302\n",
      "Iterations:  10000 Epoch:  3 Generator loss:  6.20522403717041 Discriminator loss:  0.12782111763954163\n",
      "saving the output\n",
      "Iterations:  10200 Epoch:  3 Generator loss:  5.792580604553223 Discriminator loss:  0.11137313395738602\n",
      "Iterations:  10400 Epoch:  3 Generator loss:  6.924965858459473 Discriminator loss:  0.022540302947163582\n",
      "saving the output\n",
      "Iterations:  10600 Epoch:  3 Generator loss:  4.39582633972168 Discriminator loss:  0.1604507714509964\n",
      "Iterations:  10800 Epoch:  3 Generator loss:  5.436263561248779 Discriminator loss:  0.0796244889497757\n",
      "Iterations:  11000 Epoch:  3 Generator loss:  4.640592575073242 Discriminator loss:  0.2032727748155594\n",
      "saving the output\n",
      "Iterations:  11200 Epoch:  3 Generator loss:  7.266680717468262 Discriminator loss:  0.15344293415546417\n",
      "Iterations:  11400 Epoch:  3 Generator loss:  5.716246604919434 Discriminator loss:  0.1690431833267212\n",
      "saving the output\n",
      "Iterations:  11600 Epoch:  3 Generator loss:  5.798016548156738 Discriminator loss:  0.02732902765274048\n",
      "Iterations:  11800 Epoch:  3 Generator loss:  5.645393371582031 Discriminator loss:  0.27256205677986145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [17:22<14:10:28, 260.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  12000 Epoch:  4 Generator loss:  6.820244789123535 Discriminator loss:  0.01838233880698681\n",
      "saving the output\n",
      "Iterations:  12200 Epoch:  4 Generator loss:  6.3041582107543945 Discriminator loss:  0.13052543997764587\n",
      "Iterations:  12400 Epoch:  4 Generator loss:  4.549004554748535 Discriminator loss:  0.12488727271556854\n",
      "saving the output\n",
      "Iterations:  12600 Epoch:  4 Generator loss:  4.933528900146484 Discriminator loss:  0.03652666136622429\n",
      "Iterations:  12800 Epoch:  4 Generator loss:  4.687222003936768 Discriminator loss:  0.3113665282726288\n",
      "Iterations:  13000 Epoch:  4 Generator loss:  7.224271297454834 Discriminator loss:  0.07314250618219376\n",
      "saving the output\n",
      "Iterations:  13200 Epoch:  4 Generator loss:  4.205132484436035 Discriminator loss:  0.45997554063796997\n",
      "Iterations:  13400 Epoch:  4 Generator loss:  4.42527437210083 Discriminator loss:  0.1481349617242813\n",
      "saving the output\n",
      "Iterations:  13600 Epoch:  4 Generator loss:  4.655445098876953 Discriminator loss:  0.02022615633904934\n",
      "Iterations:  13800 Epoch:  4 Generator loss:  4.905010223388672 Discriminator loss:  0.05635913461446762\n",
      "Iterations:  14000 Epoch:  4 Generator loss:  6.2892961502075195 Discriminator loss:  0.1455511748790741\n",
      "saving the output\n",
      "Iterations:  14200 Epoch:  4 Generator loss:  5.129703044891357 Discriminator loss:  0.3749983310699463\n",
      "Iterations:  14400 Epoch:  4 Generator loss:  3.9449939727783203 Discriminator loss:  0.2663773000240326\n",
      "saving the output\n",
      "Iterations:  14600 Epoch:  4 Generator loss:  5.800536632537842 Discriminator loss:  0.2472071647644043\n",
      "Iterations:  14800 Epoch:  4 Generator loss:  6.829200744628906 Discriminator loss:  0.02613310143351555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [21:43<14:06:46, 260.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  15000 Epoch:  5 Generator loss:  5.247339248657227 Discriminator loss:  0.1404014378786087\n",
      "saving the output\n",
      "Iterations:  15200 Epoch:  5 Generator loss:  4.586800575256348 Discriminator loss:  0.1789705604314804\n",
      "Iterations:  15400 Epoch:  5 Generator loss:  6.146969795227051 Discriminator loss:  0.061508625745773315\n",
      "saving the output\n",
      "Iterations:  15600 Epoch:  5 Generator loss:  6.017836570739746 Discriminator loss:  0.09889509528875351\n",
      "Iterations:  15800 Epoch:  5 Generator loss:  4.95614767074585 Discriminator loss:  0.016653407365083694\n",
      "Iterations:  16000 Epoch:  5 Generator loss:  4.579340934753418 Discriminator loss:  0.23462547361850739\n",
      "saving the output\n",
      "Iterations:  16200 Epoch:  5 Generator loss:  6.364041328430176 Discriminator loss:  0.02177181839942932\n",
      "Iterations:  16400 Epoch:  5 Generator loss:  4.310430526733398 Discriminator loss:  0.2032785564661026\n",
      "saving the output\n",
      "Iterations:  16600 Epoch:  5 Generator loss:  4.360827922821045 Discriminator loss:  0.18802510201931\n",
      "Iterations:  16800 Epoch:  5 Generator loss:  3.952817916870117 Discriminator loss:  0.3938400447368622\n",
      "Iterations:  17000 Epoch:  5 Generator loss:  6.6947784423828125 Discriminator loss:  0.0352010540664196\n",
      "saving the output\n",
      "Iterations:  17200 Epoch:  5 Generator loss:  6.716538906097412 Discriminator loss:  0.1124473512172699\n",
      "Iterations:  17400 Epoch:  5 Generator loss:  5.26287841796875 Discriminator loss:  0.13063403964042664\n",
      "saving the output\n",
      "Iterations:  17600 Epoch:  5 Generator loss:  5.272334575653076 Discriminator loss:  0.42913350462913513\n",
      "Iterations:  17800 Epoch:  5 Generator loss:  4.745471954345703 Discriminator loss:  0.034312352538108826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [26:04<14:02:56, 260.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  18000 Epoch:  6 Generator loss:  4.345767498016357 Discriminator loss:  0.03944769874215126\n",
      "saving the output\n",
      "Iterations:  18200 Epoch:  6 Generator loss:  5.767243385314941 Discriminator loss:  0.04540200158953667\n",
      "Iterations:  18400 Epoch:  6 Generator loss:  5.212712287902832 Discriminator loss:  0.412686288356781\n",
      "saving the output\n",
      "Iterations:  18600 Epoch:  6 Generator loss:  4.921520709991455 Discriminator loss:  0.1621008962392807\n",
      "Iterations:  18800 Epoch:  6 Generator loss:  5.760316848754883 Discriminator loss:  0.007096417248249054\n",
      "Iterations:  19000 Epoch:  6 Generator loss:  5.1759419441223145 Discriminator loss:  0.11471185088157654\n",
      "saving the output\n",
      "Iterations:  19200 Epoch:  6 Generator loss:  6.058907508850098 Discriminator loss:  0.2811061143875122\n",
      "Iterations:  19400 Epoch:  6 Generator loss:  5.112576007843018 Discriminator loss:  0.003025298472493887\n",
      "saving the output\n",
      "Iterations:  19600 Epoch:  6 Generator loss:  6.220129013061523 Discriminator loss:  0.032603733241558075\n",
      "Iterations:  19800 Epoch:  6 Generator loss:  4.3143630027771 Discriminator loss:  0.11454899609088898\n",
      "Iterations:  20000 Epoch:  6 Generator loss:  3.983193874359131 Discriminator loss:  0.40284016728401184\n",
      "saving the output\n",
      "Iterations:  20200 Epoch:  6 Generator loss:  5.553868293762207 Discriminator loss:  0.25788596272468567\n",
      "Iterations:  20400 Epoch:  6 Generator loss:  5.58027458190918 Discriminator loss:  0.005224838852882385\n",
      "saving the output\n",
      "Iterations:  20600 Epoch:  6 Generator loss:  5.040213584899902 Discriminator loss:  0.0008643338805995882\n",
      "Iterations:  20800 Epoch:  6 Generator loss:  3.9997425079345703 Discriminator loss:  0.34653329849243164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [30:25<13:59:34, 261.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  21000 Epoch:  7 Generator loss:  4.699504852294922 Discriminator loss:  0.02288646809756756\n",
      "saving the output\n",
      "Iterations:  21200 Epoch:  7 Generator loss:  8.11343002319336 Discriminator loss:  0.0023937998339533806\n",
      "Iterations:  21400 Epoch:  7 Generator loss:  6.3018107414245605 Discriminator loss:  0.005048543214797974\n",
      "saving the output\n",
      "Iterations:  21600 Epoch:  7 Generator loss:  5.505552768707275 Discriminator loss:  0.19376900792121887\n",
      "Iterations:  21800 Epoch:  7 Generator loss:  5.702380180358887 Discriminator loss:  0.04062590375542641\n",
      "Iterations:  22000 Epoch:  7 Generator loss:  5.240809440612793 Discriminator loss:  0.014265637844800949\n",
      "saving the output\n",
      "Iterations:  22200 Epoch:  7 Generator loss:  5.3186869621276855 Discriminator loss:  0.02303050085902214\n",
      "Iterations:  22400 Epoch:  7 Generator loss:  4.326444149017334 Discriminator loss:  0.17606347799301147\n",
      "saving the output\n",
      "Iterations:  22600 Epoch:  7 Generator loss:  5.6157755851745605 Discriminator loss:  9.556577424518764e-05\n",
      "Iterations:  22800 Epoch:  7 Generator loss:  5.745244026184082 Discriminator loss:  0.00023012334713712335\n",
      "Iterations:  23000 Epoch:  7 Generator loss:  5.068177223205566 Discriminator loss:  0.014075610786676407\n",
      "saving the output\n",
      "Iterations:  23200 Epoch:  7 Generator loss:  6.459122657775879 Discriminator loss:  0.17710216343402863\n",
      "Iterations:  23400 Epoch:  7 Generator loss:  5.344947814941406 Discriminator loss:  0.0030980294104665518\n",
      "saving the output\n",
      "Iterations:  23600 Epoch:  7 Generator loss:  5.65870475769043 Discriminator loss:  0.028331857174634933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [34:44<13:53:18, 260.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  23800 Epoch:  8 Generator loss:  4.359940528869629 Discriminator loss:  0.023425936698913574\n",
      "Iterations:  24000 Epoch:  8 Generator loss:  5.276801586151123 Discriminator loss:  0.0005441265529952943\n",
      "saving the output\n",
      "Iterations:  24200 Epoch:  8 Generator loss:  6.398956298828125 Discriminator loss:  0.01063800323754549\n",
      "Iterations:  24400 Epoch:  8 Generator loss:  5.653749942779541 Discriminator loss:  0.02690901979804039\n",
      "saving the output\n",
      "Iterations:  24600 Epoch:  8 Generator loss:  5.28125 Discriminator loss:  9.260952356271446e-05\n",
      "Iterations:  24800 Epoch:  8 Generator loss:  3.847710609436035 Discriminator loss:  0.04283488169312477\n",
      "Iterations:  25000 Epoch:  8 Generator loss:  4.753458023071289 Discriminator loss:  2.5059955078177154e-05\n",
      "saving the output\n",
      "Iterations:  25200 Epoch:  8 Generator loss:  4.616961479187012 Discriminator loss:  0.0038702532183378935\n",
      "Iterations:  25400 Epoch:  8 Generator loss:  6.429450035095215 Discriminator loss:  0.0018830427434295416\n",
      "saving the output\n",
      "Iterations:  25600 Epoch:  8 Generator loss:  5.0348711013793945 Discriminator loss:  0.002519553527235985\n",
      "Iterations:  25800 Epoch:  8 Generator loss:  6.8445515632629395 Discriminator loss:  0.001767725800164044\n",
      "Iterations:  26000 Epoch:  8 Generator loss:  6.336627960205078 Discriminator loss:  0.0001111537276301533\n",
      "saving the output\n",
      "Iterations:  26200 Epoch:  8 Generator loss:  5.436614036560059 Discriminator loss:  0.009648187085986137\n",
      "Iterations:  26400 Epoch:  8 Generator loss:  4.870113372802734 Discriminator loss:  0.00033978698775172234\n",
      "saving the output\n",
      "Iterations:  26600 Epoch:  8 Generator loss:  5.996065616607666 Discriminator loss:  3.9458824176108465e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [39:06<13:50:27, 260.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  26800 Epoch:  9 Generator loss:  7.896202087402344 Discriminator loss:  0.00690286373719573\n",
      "Iterations:  27000 Epoch:  9 Generator loss:  4.978006362915039 Discriminator loss:  0.2436208575963974\n",
      "saving the output\n",
      "Iterations:  27200 Epoch:  9 Generator loss:  5.530712127685547 Discriminator loss:  0.00010854944412130862\n",
      "Iterations:  27400 Epoch:  9 Generator loss:  5.897121906280518 Discriminator loss:  7.672323408769444e-05\n",
      "saving the output\n",
      "Iterations:  27600 Epoch:  9 Generator loss:  5.168020248413086 Discriminator loss:  0.00010309709614375606\n",
      "Iterations:  27800 Epoch:  9 Generator loss:  5.309312343597412 Discriminator loss:  1.401092049491126e-06\n",
      "Iterations:  28000 Epoch:  9 Generator loss:  6.119907855987549 Discriminator loss:  1.1468866887298645e-06\n",
      "saving the output\n",
      "Iterations:  28200 Epoch:  9 Generator loss:  5.335239887237549 Discriminator loss:  0.0005214441334828734\n",
      "Iterations:  28400 Epoch:  9 Generator loss:  5.424972057342529 Discriminator loss:  0.0013042932841926813\n",
      "saving the output\n",
      "Iterations:  28600 Epoch:  9 Generator loss:  4.659703254699707 Discriminator loss:  0.005619312636554241\n",
      "Iterations:  28800 Epoch:  9 Generator loss:  6.6113972663879395 Discriminator loss:  0.0003393547667656094\n",
      "Iterations:  29000 Epoch:  9 Generator loss:  4.201496124267578 Discriminator loss:  0.04132959619164467\n",
      "saving the output\n",
      "Iterations:  29200 Epoch:  9 Generator loss:  8.482168197631836 Discriminator loss:  0.17615419626235962\n",
      "Iterations:  29400 Epoch:  9 Generator loss:  3.514183521270752 Discriminator loss:  0.31679174304008484\n",
      "saving the output\n",
      "Iterations:  29600 Epoch:  9 Generator loss:  5.765345096588135 Discriminator loss:  0.050569333136081696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [43:28<13:46:56, 261.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  29800 Epoch:  10 Generator loss:  6.232028007507324 Discriminator loss:  0.01991034485399723\n",
      "Iterations:  30000 Epoch:  10 Generator loss:  5.703459739685059 Discriminator loss:  0.36139416694641113\n",
      "saving the output\n",
      "Iterations:  30200 Epoch:  10 Generator loss:  5.505306720733643 Discriminator loss:  0.1534269005060196\n",
      "Iterations:  30400 Epoch:  10 Generator loss:  4.283215045928955 Discriminator loss:  0.26844149827957153\n",
      "saving the output\n",
      "Iterations:  30600 Epoch:  10 Generator loss:  4.232552528381348 Discriminator loss:  0.3427964746952057\n",
      "Iterations:  30800 Epoch:  10 Generator loss:  4.472243309020996 Discriminator loss:  0.25669345259666443\n",
      "Iterations:  31000 Epoch:  10 Generator loss:  4.853731155395508 Discriminator loss:  0.36696675419807434\n",
      "saving the output\n",
      "Iterations:  31200 Epoch:  10 Generator loss:  5.3507256507873535 Discriminator loss:  0.01954314112663269\n",
      "Iterations:  31400 Epoch:  10 Generator loss:  4.404268264770508 Discriminator loss:  0.03100927360355854\n",
      "saving the output\n",
      "Iterations:  31600 Epoch:  10 Generator loss:  4.49100399017334 Discriminator loss:  0.31807148456573486\n",
      "Iterations:  31800 Epoch:  10 Generator loss:  4.522097110748291 Discriminator loss:  0.0005342988297343254\n",
      "Iterations:  32000 Epoch:  10 Generator loss:  5.4051008224487305 Discriminator loss:  0.017175810411572456\n",
      "saving the output\n",
      "Iterations:  32200 Epoch:  10 Generator loss:  5.731663227081299 Discriminator loss:  0.03902077674865723\n",
      "Iterations:  32400 Epoch:  10 Generator loss:  5.679891586303711 Discriminator loss:  0.0020061342511326075\n",
      "saving the output\n",
      "Iterations:  32600 Epoch:  10 Generator loss:  4.354477882385254 Discriminator loss:  0.047195471823215485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [47:53<13:46:02, 262.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  32800 Epoch:  11 Generator loss:  5.783968925476074 Discriminator loss:  0.37752965092658997\n",
      "Iterations:  33000 Epoch:  11 Generator loss:  4.687539577484131 Discriminator loss:  0.023117348551750183\n",
      "saving the output\n",
      "Iterations:  33200 Epoch:  11 Generator loss:  4.671928882598877 Discriminator loss:  0.004135406110435724\n",
      "Iterations:  33400 Epoch:  11 Generator loss:  6.200268268585205 Discriminator loss:  0.14843495190143585\n",
      "saving the output\n",
      "Iterations:  33600 Epoch:  11 Generator loss:  4.0218186378479 Discriminator loss:  0.2562597393989563\n",
      "Iterations:  33800 Epoch:  11 Generator loss:  4.672245979309082 Discriminator loss:  0.2943207323551178\n",
      "Iterations:  34000 Epoch:  11 Generator loss:  4.333047389984131 Discriminator loss:  0.0077803367748856544\n",
      "saving the output\n",
      "Iterations:  34200 Epoch:  11 Generator loss:  4.370416641235352 Discriminator loss:  0.2699934244155884\n",
      "Iterations:  34400 Epoch:  11 Generator loss:  4.354297637939453 Discriminator loss:  0.049839507788419724\n",
      "saving the output\n",
      "Iterations:  34600 Epoch:  11 Generator loss:  4.161713600158691 Discriminator loss:  0.06101830303668976\n",
      "Iterations:  34800 Epoch:  11 Generator loss:  4.143298625946045 Discriminator loss:  0.11627247184515\n",
      "Iterations:  35000 Epoch:  11 Generator loss:  5.801022529602051 Discriminator loss:  0.13347259163856506\n",
      "saving the output\n",
      "Iterations:  35200 Epoch:  11 Generator loss:  4.582735061645508 Discriminator loss:  0.004931719042360783\n",
      "Iterations:  35400 Epoch:  11 Generator loss:  5.378167629241943 Discriminator loss:  0.012412261217832565\n",
      "saving the output\n",
      "Iterations:  35600 Epoch:  11 Generator loss:  5.606217384338379 Discriminator loss:  0.028272075578570366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [52:11<13:38:06, 261.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  35800 Epoch:  12 Generator loss:  4.897019863128662 Discriminator loss:  0.0005224412307143211\n",
      "Iterations:  36000 Epoch:  12 Generator loss:  6.6838603019714355 Discriminator loss:  0.043168507516384125\n",
      "saving the output\n",
      "Iterations:  36200 Epoch:  12 Generator loss:  5.687010765075684 Discriminator loss:  0.0202175285667181\n",
      "Iterations:  36400 Epoch:  12 Generator loss:  5.678041458129883 Discriminator loss:  0.006086232140660286\n",
      "saving the output\n",
      "Iterations:  36600 Epoch:  12 Generator loss:  4.1939005851745605 Discriminator loss:  0.271390438079834\n",
      "Iterations:  36800 Epoch:  12 Generator loss:  5.655967712402344 Discriminator loss:  0.0009284982224926353\n",
      "Iterations:  37000 Epoch:  12 Generator loss:  4.923242568969727 Discriminator loss:  0.010931129567325115\n",
      "saving the output\n",
      "Iterations:  37200 Epoch:  12 Generator loss:  4.370917320251465 Discriminator loss:  0.5576494932174683\n",
      "Iterations:  37400 Epoch:  12 Generator loss:  5.364428997039795 Discriminator loss:  0.09883452206850052\n",
      "saving the output\n",
      "Iterations:  37600 Epoch:  12 Generator loss:  4.854045867919922 Discriminator loss:  0.3196110427379608\n",
      "Iterations:  37800 Epoch:  12 Generator loss:  3.7123279571533203 Discriminator loss:  0.42039501667022705\n",
      "Iterations:  38000 Epoch:  12 Generator loss:  5.072547912597656 Discriminator loss:  0.02073698863387108\n",
      "saving the output\n",
      "Iterations:  38200 Epoch:  12 Generator loss:  4.309852600097656 Discriminator loss:  0.023893915116786957\n",
      "Iterations:  38400 Epoch:  12 Generator loss:  5.329590797424316 Discriminator loss:  0.038460928946733475\n",
      "saving the output\n",
      "Iterations:  38600 Epoch:  12 Generator loss:  4.530515670776367 Discriminator loss:  0.2664354741573334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [56:34<13:34:51, 261.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  38800 Epoch:  13 Generator loss:  4.4771528244018555 Discriminator loss:  0.010197225026786327\n",
      "Iterations:  39000 Epoch:  13 Generator loss:  5.552740097045898 Discriminator loss:  0.008986513130366802\n",
      "saving the output\n",
      "Iterations:  39200 Epoch:  13 Generator loss:  5.970076560974121 Discriminator loss:  0.005620461888611317\n",
      "Iterations:  39400 Epoch:  13 Generator loss:  4.457176685333252 Discriminator loss:  0.03424521163105965\n",
      "saving the output\n",
      "Iterations:  39600 Epoch:  13 Generator loss:  4.001874923706055 Discriminator loss:  0.007389607839286327\n",
      "Iterations:  39800 Epoch:  13 Generator loss:  4.73789119720459 Discriminator loss:  0.3447951078414917\n",
      "Iterations:  40000 Epoch:  13 Generator loss:  5.227724075317383 Discriminator loss:  0.03765265271067619\n",
      "saving the output\n",
      "Iterations:  40200 Epoch:  13 Generator loss:  5.807317733764648 Discriminator loss:  0.012874052859842777\n",
      "Iterations:  40400 Epoch:  13 Generator loss:  6.392054557800293 Discriminator loss:  0.013608814217150211\n",
      "saving the output\n",
      "Iterations:  40600 Epoch:  13 Generator loss:  4.921158790588379 Discriminator loss:  0.002453178633004427\n",
      "Iterations:  40800 Epoch:  13 Generator loss:  5.254696369171143 Discriminator loss:  0.17688541114330292\n",
      "Iterations:  41000 Epoch:  13 Generator loss:  6.624886512756348 Discriminator loss:  0.07294373959302902\n",
      "saving the output\n",
      "Iterations:  41200 Epoch:  13 Generator loss:  7.269460678100586 Discriminator loss:  0.02068820595741272\n",
      "Iterations:  41400 Epoch:  13 Generator loss:  4.285943031311035 Discriminator loss:  0.1749376803636551\n",
      "saving the output\n",
      "Iterations:  41600 Epoch:  13 Generator loss:  5.954143524169922 Discriminator loss:  0.032714635133743286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [1:00:55<13:30:23, 261.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  41800 Epoch:  14 Generator loss:  5.938471794128418 Discriminator loss:  0.17135748267173767\n",
      "Iterations:  42000 Epoch:  14 Generator loss:  5.578055381774902 Discriminator loss:  0.09661553055047989\n",
      "saving the output\n",
      "Iterations:  42200 Epoch:  14 Generator loss:  6.481186866760254 Discriminator loss:  0.029261216521263123\n",
      "Iterations:  42400 Epoch:  14 Generator loss:  5.258734703063965 Discriminator loss:  0.07876349240541458\n",
      "saving the output\n",
      "Iterations:  42600 Epoch:  14 Generator loss:  4.644342422485352 Discriminator loss:  0.3020419776439667\n",
      "Iterations:  42800 Epoch:  14 Generator loss:  4.436752796173096 Discriminator loss:  0.2825729548931122\n",
      "Iterations:  43000 Epoch:  14 Generator loss:  5.5708417892456055 Discriminator loss:  0.05654267594218254\n",
      "saving the output\n",
      "Iterations:  43200 Epoch:  14 Generator loss:  4.758979797363281 Discriminator loss:  0.19468405842781067\n",
      "Iterations:  43400 Epoch:  14 Generator loss:  5.3468217849731445 Discriminator loss:  0.08843205124139786\n",
      "saving the output\n",
      "Iterations:  43600 Epoch:  14 Generator loss:  5.670845985412598 Discriminator loss:  0.16880109906196594\n",
      "Iterations:  43800 Epoch:  14 Generator loss:  5.410323143005371 Discriminator loss:  0.2434632033109665\n",
      "Iterations:  44000 Epoch:  14 Generator loss:  5.17354679107666 Discriminator loss:  0.0009376928210258484\n",
      "saving the output\n",
      "Iterations:  44200 Epoch:  14 Generator loss:  5.1131110191345215 Discriminator loss:  0.02772781252861023\n",
      "Iterations:  44400 Epoch:  14 Generator loss:  4.293155193328857 Discriminator loss:  0.1152862161397934\n",
      "saving the output\n",
      "Iterations:  44600 Epoch:  14 Generator loss:  5.519239902496338 Discriminator loss:  0.12823407351970673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [1:05:16<13:26:00, 261.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  44800 Epoch:  15 Generator loss:  6.4676513671875 Discriminator loss:  0.18139666318893433\n",
      "Iterations:  45000 Epoch:  15 Generator loss:  4.827067852020264 Discriminator loss:  0.3243553936481476\n",
      "saving the output\n",
      "Iterations:  45200 Epoch:  15 Generator loss:  5.822416305541992 Discriminator loss:  0.21971693634986877\n",
      "Iterations:  45400 Epoch:  15 Generator loss:  5.465339183807373 Discriminator loss:  0.3246728181838989\n",
      "saving the output\n",
      "Iterations:  45600 Epoch:  15 Generator loss:  4.676181793212891 Discriminator loss:  0.0032649117056280375\n",
      "Iterations:  45800 Epoch:  15 Generator loss:  6.779277801513672 Discriminator loss:  0.017386505380272865\n",
      "Iterations:  46000 Epoch:  15 Generator loss:  4.834181308746338 Discriminator loss:  0.19342170655727386\n",
      "saving the output\n",
      "Iterations:  46200 Epoch:  15 Generator loss:  3.893209457397461 Discriminator loss:  0.2646956145763397\n",
      "Iterations:  46400 Epoch:  15 Generator loss:  6.275901794433594 Discriminator loss:  0.1194196566939354\n",
      "saving the output\n",
      "Iterations:  46600 Epoch:  15 Generator loss:  4.565095901489258 Discriminator loss:  0.020085999742150307\n",
      "Iterations:  46800 Epoch:  15 Generator loss:  5.675858497619629 Discriminator loss:  0.16378945112228394\n",
      "Iterations:  47000 Epoch:  15 Generator loss:  4.74929666519165 Discriminator loss:  0.006056312937289476\n",
      "saving the output\n",
      "Iterations:  47200 Epoch:  15 Generator loss:  7.067922592163086 Discriminator loss:  0.047894999384880066\n",
      "Iterations:  47400 Epoch:  15 Generator loss:  8.172237396240234 Discriminator loss:  0.03659175708889961\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [1:09:39<13:22:44, 261.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  47600 Epoch:  16 Generator loss:  4.826265335083008 Discriminator loss:  0.3087726831436157\n",
      "Iterations:  47800 Epoch:  16 Generator loss:  3.689225196838379 Discriminator loss:  0.07027096301317215\n",
      "Iterations:  48000 Epoch:  16 Generator loss:  4.5363359451293945 Discriminator loss:  0.022855164483189583\n",
      "saving the output\n",
      "Iterations:  48200 Epoch:  16 Generator loss:  4.754981517791748 Discriminator loss:  0.17957577109336853\n",
      "Iterations:  48400 Epoch:  16 Generator loss:  5.821348667144775 Discriminator loss:  0.06069493666291237\n",
      "saving the output\n",
      "Iterations:  48600 Epoch:  16 Generator loss:  4.051423072814941 Discriminator loss:  0.32006269693374634\n",
      "Iterations:  48800 Epoch:  16 Generator loss:  6.804332733154297 Discriminator loss:  0.023886272683739662\n",
      "Iterations:  49000 Epoch:  16 Generator loss:  5.247375965118408 Discriminator loss:  0.040916819125413895\n",
      "saving the output\n",
      "Iterations:  49200 Epoch:  16 Generator loss:  4.216968059539795 Discriminator loss:  0.04678996652364731\n",
      "Iterations:  49400 Epoch:  16 Generator loss:  5.395621299743652 Discriminator loss:  0.15273010730743408\n",
      "saving the output\n",
      "Iterations:  49600 Epoch:  16 Generator loss:  3.719172477722168 Discriminator loss:  0.38282501697540283\n",
      "Iterations:  49800 Epoch:  16 Generator loss:  5.49395227432251 Discriminator loss:  0.012978279031813145\n",
      "Iterations:  50000 Epoch:  16 Generator loss:  7.178021430969238 Discriminator loss:  0.14227600395679474\n",
      "saving the output\n",
      "Iterations:  50200 Epoch:  16 Generator loss:  5.2214250564575195 Discriminator loss:  0.026653429493308067\n",
      "Iterations:  50400 Epoch:  16 Generator loss:  6.029865264892578 Discriminator loss:  0.005266111344099045\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [1:14:01<13:18:49, 261.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  50600 Epoch:  17 Generator loss:  5.438179016113281 Discriminator loss:  0.1446305513381958\n",
      "Iterations:  50800 Epoch:  17 Generator loss:  6.1327619552612305 Discriminator loss:  0.06842456012964249\n",
      "Iterations:  51000 Epoch:  17 Generator loss:  4.765753746032715 Discriminator loss:  0.21722328662872314\n",
      "saving the output\n",
      "Iterations:  51200 Epoch:  17 Generator loss:  6.137217998504639 Discriminator loss:  0.25223636627197266\n",
      "Iterations:  51400 Epoch:  17 Generator loss:  5.899862289428711 Discriminator loss:  0.12081612646579742\n",
      "saving the output\n",
      "Iterations:  51600 Epoch:  17 Generator loss:  4.917133331298828 Discriminator loss:  0.018540935590863228\n",
      "Iterations:  51800 Epoch:  17 Generator loss:  5.279425621032715 Discriminator loss:  0.019214913249015808\n",
      "Iterations:  52000 Epoch:  17 Generator loss:  5.205204010009766 Discriminator loss:  0.09198809415102005\n",
      "saving the output\n",
      "Iterations:  52200 Epoch:  17 Generator loss:  4.1646223068237305 Discriminator loss:  0.24139709770679474\n",
      "Iterations:  52400 Epoch:  17 Generator loss:  4.735517978668213 Discriminator loss:  0.0029017385095357895\n",
      "saving the output\n",
      "Iterations:  52600 Epoch:  17 Generator loss:  4.259502410888672 Discriminator loss:  0.023605599999427795\n",
      "Iterations:  52800 Epoch:  17 Generator loss:  4.860513210296631 Discriminator loss:  0.07541541010141373\n",
      "Iterations:  53000 Epoch:  17 Generator loss:  4.790311813354492 Discriminator loss:  0.0007805817294865847\n",
      "saving the output\n",
      "Iterations:  53200 Epoch:  17 Generator loss:  9.013582229614258 Discriminator loss:  0.0003285317507106811\n",
      "Iterations:  53400 Epoch:  17 Generator loss:  4.928235054016113 Discriminator loss:  0.010403734631836414\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [1:18:24<13:15:12, 262.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  53600 Epoch:  18 Generator loss:  4.85172700881958 Discriminator loss:  0.01262199692428112\n",
      "Iterations:  53800 Epoch:  18 Generator loss:  4.063826560974121 Discriminator loss:  0.28281110525131226\n",
      "Iterations:  54000 Epoch:  18 Generator loss:  4.970468521118164 Discriminator loss:  0.012656992301344872\n",
      "saving the output\n",
      "Iterations:  54200 Epoch:  18 Generator loss:  5.261064052581787 Discriminator loss:  0.056462012231349945\n",
      "Iterations:  54400 Epoch:  18 Generator loss:  4.980021953582764 Discriminator loss:  0.00011680804163916036\n",
      "saving the output\n",
      "Iterations:  54600 Epoch:  18 Generator loss:  5.640429973602295 Discriminator loss:  0.35297706723213196\n",
      "Iterations:  54800 Epoch:  18 Generator loss:  6.2031731605529785 Discriminator loss:  0.0020623337477445602\n",
      "Iterations:  55000 Epoch:  18 Generator loss:  5.839032173156738 Discriminator loss:  0.018553949892520905\n",
      "saving the output\n",
      "Iterations:  55200 Epoch:  18 Generator loss:  4.547971248626709 Discriminator loss:  0.0023705577477812767\n",
      "Iterations:  55400 Epoch:  18 Generator loss:  4.369579792022705 Discriminator loss:  0.3720744550228119\n",
      "saving the output\n",
      "Iterations:  55600 Epoch:  18 Generator loss:  6.291831970214844 Discriminator loss:  0.005361414514482021\n",
      "Iterations:  55800 Epoch:  18 Generator loss:  6.24777889251709 Discriminator loss:  0.2539370059967041\n",
      "Iterations:  56000 Epoch:  18 Generator loss:  6.061918258666992 Discriminator loss:  0.06924404203891754\n",
      "saving the output\n",
      "Iterations:  56200 Epoch:  18 Generator loss:  4.780856609344482 Discriminator loss:  0.00046684444532729685\n",
      "Iterations:  56400 Epoch:  18 Generator loss:  6.385894298553467 Discriminator loss:  0.005388238001614809\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [1:22:45<13:09:47, 261.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  56600 Epoch:  19 Generator loss:  4.928674221038818 Discriminator loss:  0.0033988477662205696\n",
      "Iterations:  56800 Epoch:  19 Generator loss:  5.805076599121094 Discriminator loss:  0.36387762427330017\n",
      "Iterations:  57000 Epoch:  19 Generator loss:  6.208641529083252 Discriminator loss:  0.0488341748714447\n",
      "saving the output\n",
      "Iterations:  57200 Epoch:  19 Generator loss:  5.441584587097168 Discriminator loss:  0.011662401258945465\n",
      "Iterations:  57400 Epoch:  19 Generator loss:  4.398116111755371 Discriminator loss:  0.33272409439086914\n",
      "saving the output\n",
      "Iterations:  57600 Epoch:  19 Generator loss:  4.563220977783203 Discriminator loss:  0.11863573640584946\n",
      "Iterations:  57800 Epoch:  19 Generator loss:  4.594087600708008 Discriminator loss:  0.18366403877735138\n",
      "Iterations:  58000 Epoch:  19 Generator loss:  5.52425479888916 Discriminator loss:  0.006055793724954128\n",
      "saving the output\n",
      "Iterations:  58200 Epoch:  19 Generator loss:  5.472982883453369 Discriminator loss:  0.003116220934316516\n",
      "Iterations:  58400 Epoch:  19 Generator loss:  3.9033281803131104 Discriminator loss:  0.05670420452952385\n",
      "saving the output\n",
      "Iterations:  58600 Epoch:  19 Generator loss:  6.158075332641602 Discriminator loss:  0.07692231982946396\n",
      "Iterations:  58800 Epoch:  19 Generator loss:  4.430228233337402 Discriminator loss:  0.24213822185993195\n",
      "Iterations:  59000 Epoch:  19 Generator loss:  4.827119827270508 Discriminator loss:  0.001797054777853191\n",
      "saving the output\n",
      "Iterations:  59200 Epoch:  19 Generator loss:  5.387883186340332 Discriminator loss:  8.671812247484922e-05\n",
      "Iterations:  59400 Epoch:  19 Generator loss:  5.053770542144775 Discriminator loss:  0.0006649469141848385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [1:27:08<13:07:03, 262.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  59600 Epoch:  20 Generator loss:  6.814333915710449 Discriminator loss:  0.2749975025653839\n",
      "Iterations:  59800 Epoch:  20 Generator loss:  4.964714050292969 Discriminator loss:  0.012381670996546745\n",
      "Iterations:  60000 Epoch:  20 Generator loss:  5.131712913513184 Discriminator loss:  0.07269949465990067\n",
      "saving the output\n",
      "Iterations:  60200 Epoch:  20 Generator loss:  4.96057653427124 Discriminator loss:  0.15989884734153748\n",
      "Iterations:  60400 Epoch:  20 Generator loss:  5.1419782638549805 Discriminator loss:  0.4872038960456848\n",
      "saving the output\n",
      "Iterations:  60600 Epoch:  20 Generator loss:  5.800551414489746 Discriminator loss:  0.007711526472121477\n",
      "Iterations:  60800 Epoch:  20 Generator loss:  6.502164840698242 Discriminator loss:  0.02310751937329769\n",
      "Iterations:  61000 Epoch:  20 Generator loss:  5.493851661682129 Discriminator loss:  0.0001172177362604998\n",
      "saving the output\n",
      "Iterations:  61200 Epoch:  20 Generator loss:  4.380703926086426 Discriminator loss:  0.000780184636823833\n",
      "Iterations:  61400 Epoch:  20 Generator loss:  3.894301414489746 Discriminator loss:  0.4608912169933319\n",
      "saving the output\n",
      "Iterations:  61600 Epoch:  20 Generator loss:  4.863929748535156 Discriminator loss:  0.020266778767108917\n",
      "Iterations:  61800 Epoch:  20 Generator loss:  4.937681674957275 Discriminator loss:  0.043501488864421844\n",
      "Iterations:  62000 Epoch:  20 Generator loss:  5.042826175689697 Discriminator loss:  0.0018743394175544381\n",
      "saving the output\n",
      "Iterations:  62200 Epoch:  20 Generator loss:  4.546685218811035 Discriminator loss:  0.30810320377349854\n",
      "Iterations:  62400 Epoch:  20 Generator loss:  3.6683435440063477 Discriminator loss:  0.105850450694561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [1:31:32<13:03:46, 262.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  62600 Epoch:  21 Generator loss:  4.961390972137451 Discriminator loss:  0.010418296791613102\n",
      "Iterations:  62800 Epoch:  21 Generator loss:  5.606437683105469 Discriminator loss:  0.009186245501041412\n",
      "Iterations:  63000 Epoch:  21 Generator loss:  4.510037422180176 Discriminator loss:  0.015772776678204536\n",
      "saving the output\n",
      "Iterations:  63200 Epoch:  21 Generator loss:  4.424904823303223 Discriminator loss:  0.05596138909459114\n",
      "Iterations:  63400 Epoch:  21 Generator loss:  5.411887168884277 Discriminator loss:  0.11810289323329926\n",
      "saving the output\n",
      "Iterations:  63600 Epoch:  21 Generator loss:  6.205061912536621 Discriminator loss:  0.008973483927547932\n",
      "Iterations:  63800 Epoch:  21 Generator loss:  5.7750630378723145 Discriminator loss:  0.19117256999015808\n",
      "Iterations:  64000 Epoch:  21 Generator loss:  4.300204277038574 Discriminator loss:  0.13792340457439423\n",
      "saving the output\n",
      "Iterations:  64200 Epoch:  21 Generator loss:  4.755207538604736 Discriminator loss:  0.025223374366760254\n",
      "Iterations:  64400 Epoch:  21 Generator loss:  4.808484077453613 Discriminator loss:  0.0008066618465818465\n",
      "saving the output\n",
      "Iterations:  64600 Epoch:  21 Generator loss:  4.9731621742248535 Discriminator loss:  0.023004954680800438\n",
      "Iterations:  64800 Epoch:  21 Generator loss:  3.9596176147460938 Discriminator loss:  0.21928396821022034\n",
      "Iterations:  65000 Epoch:  21 Generator loss:  6.022991180419922 Discriminator loss:  0.05608408525586128\n",
      "saving the output\n",
      "Iterations:  65200 Epoch:  21 Generator loss:  4.320409774780273 Discriminator loss:  0.002419549971818924\n",
      "Iterations:  65400 Epoch:  21 Generator loss:  4.05763053894043 Discriminator loss:  0.1845245212316513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [1:35:53<12:57:57, 262.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  65600 Epoch:  22 Generator loss:  5.6321611404418945 Discriminator loss:  0.015303950756788254\n",
      "Iterations:  65800 Epoch:  22 Generator loss:  4.381168842315674 Discriminator loss:  0.031027812510728836\n",
      "Iterations:  66000 Epoch:  22 Generator loss:  5.371054172515869 Discriminator loss:  0.0005803672247566283\n",
      "saving the output\n",
      "Iterations:  66200 Epoch:  22 Generator loss:  3.4883971214294434 Discriminator loss:  0.20615215599536896\n",
      "Iterations:  66400 Epoch:  22 Generator loss:  4.833785533905029 Discriminator loss:  0.04009350761771202\n",
      "saving the output\n",
      "Iterations:  66600 Epoch:  22 Generator loss:  6.034636974334717 Discriminator loss:  0.3623753786087036\n",
      "Iterations:  66800 Epoch:  22 Generator loss:  5.236799716949463 Discriminator loss:  0.03693097457289696\n",
      "Iterations:  67000 Epoch:  22 Generator loss:  4.819069862365723 Discriminator loss:  0.005298915319144726\n",
      "saving the output\n",
      "Iterations:  67200 Epoch:  22 Generator loss:  4.410893440246582 Discriminator loss:  0.3456744849681854\n",
      "Iterations:  67400 Epoch:  22 Generator loss:  4.63815975189209 Discriminator loss:  0.0014185485197231174\n",
      "saving the output\n",
      "Iterations:  67600 Epoch:  22 Generator loss:  4.674991130828857 Discriminator loss:  0.012494965456426144\n",
      "Iterations:  67800 Epoch:  22 Generator loss:  3.9781546592712402 Discriminator loss:  0.31597164273262024\n",
      "Iterations:  68000 Epoch:  22 Generator loss:  4.730952739715576 Discriminator loss:  2.1274729078868404e-05\n",
      "saving the output\n",
      "Iterations:  68200 Epoch:  22 Generator loss:  6.210151195526123 Discriminator loss:  0.0024866354651749134\n",
      "Iterations:  68400 Epoch:  22 Generator loss:  4.771337509155273 Discriminator loss:  0.0015949661610648036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [1:40:13<12:51:30, 261.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  68600 Epoch:  23 Generator loss:  3.688498020172119 Discriminator loss:  0.03775421157479286\n",
      "Iterations:  68800 Epoch:  23 Generator loss:  7.173735618591309 Discriminator loss:  0.10018739849328995\n",
      "Iterations:  69000 Epoch:  23 Generator loss:  4.663750171661377 Discriminator loss:  0.015479104593396187\n",
      "saving the output\n",
      "Iterations:  69200 Epoch:  23 Generator loss:  4.933374881744385 Discriminator loss:  1.4815675967838615e-05\n",
      "Iterations:  69400 Epoch:  23 Generator loss:  5.240438461303711 Discriminator loss:  0.3154400885105133\n",
      "saving the output\n",
      "Iterations:  69600 Epoch:  23 Generator loss:  4.333023548126221 Discriminator loss:  0.2737322449684143\n",
      "Iterations:  69800 Epoch:  23 Generator loss:  4.84531307220459 Discriminator loss:  0.06233351305127144\n",
      "Iterations:  70000 Epoch:  23 Generator loss:  4.534336090087891 Discriminator loss:  0.2748080790042877\n",
      "saving the output\n",
      "Iterations:  70200 Epoch:  23 Generator loss:  4.862748146057129 Discriminator loss:  0.0800810307264328\n",
      "Iterations:  70400 Epoch:  23 Generator loss:  6.910735130310059 Discriminator loss:  0.011752203106880188\n",
      "saving the output\n",
      "Iterations:  70600 Epoch:  23 Generator loss:  5.568394660949707 Discriminator loss:  0.0033379755914211273\n",
      "Iterations:  70800 Epoch:  23 Generator loss:  6.349022388458252 Discriminator loss:  0.005862507503479719\n",
      "Iterations:  71000 Epoch:  23 Generator loss:  5.035966873168945 Discriminator loss:  0.01055310107767582\n",
      "saving the output\n",
      "Iterations:  71200 Epoch:  23 Generator loss:  4.501187324523926 Discriminator loss:  0.0019236825173720717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [1:44:31<12:44:23, 260.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  71400 Epoch:  24 Generator loss:  4.569181442260742 Discriminator loss:  0.019211139529943466\n",
      "saving the output\n",
      "Iterations:  71600 Epoch:  24 Generator loss:  4.9744720458984375 Discriminator loss:  0.04398343339562416\n",
      "Iterations:  71800 Epoch:  24 Generator loss:  5.173403739929199 Discriminator loss:  6.0924532590433955e-05\n",
      "Iterations:  72000 Epoch:  24 Generator loss:  3.588599920272827 Discriminator loss:  0.11885285377502441\n",
      "saving the output\n",
      "Iterations:  72200 Epoch:  24 Generator loss:  5.236461639404297 Discriminator loss:  0.0569976270198822\n",
      "Iterations:  72400 Epoch:  24 Generator loss:  4.393337249755859 Discriminator loss:  0.011493663303554058\n",
      "saving the output\n",
      "Iterations:  72600 Epoch:  24 Generator loss:  4.885525703430176 Discriminator loss:  0.02824530191719532\n",
      "Iterations:  72800 Epoch:  24 Generator loss:  4.034145832061768 Discriminator loss:  0.08679676055908203\n",
      "Iterations:  73000 Epoch:  24 Generator loss:  4.076969623565674 Discriminator loss:  0.002491382183507085\n",
      "saving the output\n",
      "Iterations:  73200 Epoch:  24 Generator loss:  5.023099422454834 Discriminator loss:  2.679170574992895e-05\n",
      "Iterations:  73400 Epoch:  24 Generator loss:  4.7197675704956055 Discriminator loss:  0.0012032185913994908\n",
      "saving the output\n",
      "Iterations:  73600 Epoch:  24 Generator loss:  4.7107954025268555 Discriminator loss:  0.045514170080423355\n",
      "Iterations:  73800 Epoch:  24 Generator loss:  4.979913711547852 Discriminator loss:  5.8521651226328686e-05\n",
      "Iterations:  74000 Epoch:  24 Generator loss:  4.276313304901123 Discriminator loss:  0.00010770006338134408\n",
      "saving the output\n",
      "Iterations:  74200 Epoch:  24 Generator loss:  4.129518508911133 Discriminator loss:  0.04580467566847801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [1:48:52<12:40:18, 260.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  74400 Epoch:  25 Generator loss:  4.502988338470459 Discriminator loss:  0.2495540827512741\n",
      "saving the output\n",
      "Iterations:  74600 Epoch:  25 Generator loss:  5.325099468231201 Discriminator loss:  0.2664666771888733\n",
      "Iterations:  74800 Epoch:  25 Generator loss:  6.788956642150879 Discriminator loss:  6.48907371214591e-06\n",
      "Iterations:  75000 Epoch:  25 Generator loss:  5.26971435546875 Discriminator loss:  0.017627401277422905\n",
      "saving the output\n",
      "Iterations:  75200 Epoch:  25 Generator loss:  4.770585060119629 Discriminator loss:  0.23480910062789917\n",
      "Iterations:  75400 Epoch:  25 Generator loss:  5.3263139724731445 Discriminator loss:  0.013234439305961132\n",
      "saving the output\n",
      "Iterations:  75600 Epoch:  25 Generator loss:  5.732395172119141 Discriminator loss:  0.002583148656412959\n",
      "Iterations:  75800 Epoch:  25 Generator loss:  5.261772155761719 Discriminator loss:  0.003603206481784582\n",
      "Iterations:  76000 Epoch:  25 Generator loss:  3.802104949951172 Discriminator loss:  0.0007170793251134455\n",
      "saving the output\n",
      "Iterations:  76200 Epoch:  25 Generator loss:  4.882394790649414 Discriminator loss:  0.009975944645702839\n",
      "Iterations:  76400 Epoch:  25 Generator loss:  4.421314239501953 Discriminator loss:  0.15238292515277863\n",
      "saving the output\n",
      "Iterations:  76600 Epoch:  25 Generator loss:  5.444525718688965 Discriminator loss:  0.03200739249587059\n",
      "Iterations:  76800 Epoch:  25 Generator loss:  4.721151828765869 Discriminator loss:  0.0019446726655587554\n",
      "Iterations:  77000 Epoch:  25 Generator loss:  5.389248847961426 Discriminator loss:  0.015588290989398956\n",
      "saving the output\n",
      "Iterations:  77200 Epoch:  25 Generator loss:  5.420478820800781 Discriminator loss:  2.5252679733966943e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [1:53:13<12:35:46, 260.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  77400 Epoch:  26 Generator loss:  4.843560218811035 Discriminator loss:  0.04173876345157623\n",
      "saving the output\n",
      "Iterations:  77600 Epoch:  26 Generator loss:  5.294904708862305 Discriminator loss:  0.12390733510255814\n",
      "Iterations:  77800 Epoch:  26 Generator loss:  4.488085746765137 Discriminator loss:  0.008960102684795856\n",
      "Iterations:  78000 Epoch:  26 Generator loss:  5.059422969818115 Discriminator loss:  0.0012182217324152589\n",
      "saving the output\n",
      "Iterations:  78200 Epoch:  26 Generator loss:  4.365337371826172 Discriminator loss:  0.002034625271335244\n",
      "Iterations:  78400 Epoch:  26 Generator loss:  4.862937927246094 Discriminator loss:  0.0025234248023480177\n",
      "saving the output\n",
      "Iterations:  78600 Epoch:  26 Generator loss:  4.869572639465332 Discriminator loss:  0.06227266788482666\n",
      "Iterations:  78800 Epoch:  26 Generator loss:  4.403558731079102 Discriminator loss:  0.01729450561106205\n",
      "Iterations:  79000 Epoch:  26 Generator loss:  5.729500770568848 Discriminator loss:  0.09580157697200775\n",
      "saving the output\n",
      "Iterations:  79200 Epoch:  26 Generator loss:  5.758195877075195 Discriminator loss:  0.13143162429332733\n",
      "Iterations:  79400 Epoch:  26 Generator loss:  5.823654651641846 Discriminator loss:  0.00017345609376206994\n",
      "saving the output\n",
      "Iterations:  79600 Epoch:  26 Generator loss:  3.8950726985931396 Discriminator loss:  0.013385551050305367\n",
      "Iterations:  79800 Epoch:  26 Generator loss:  4.444334983825684 Discriminator loss:  0.14046749472618103\n",
      "Iterations:  80000 Epoch:  26 Generator loss:  5.865425109863281 Discriminator loss:  0.00022820057347416878\n",
      "saving the output\n",
      "Iterations:  80200 Epoch:  26 Generator loss:  4.582771301269531 Discriminator loss:  0.013490625657141209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [1:57:34<12:32:19, 260.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  80400 Epoch:  27 Generator loss:  5.171204566955566 Discriminator loss:  0.002603495493531227\n",
      "saving the output\n",
      "Iterations:  80600 Epoch:  27 Generator loss:  4.330756187438965 Discriminator loss:  0.0016588162397965789\n",
      "Iterations:  80800 Epoch:  27 Generator loss:  6.30449104309082 Discriminator loss:  0.1357412189245224\n",
      "Iterations:  81000 Epoch:  27 Generator loss:  4.9388556480407715 Discriminator loss:  0.019457751885056496\n",
      "saving the output\n",
      "Iterations:  81200 Epoch:  27 Generator loss:  4.343408584594727 Discriminator loss:  0.006707302760332823\n",
      "Iterations:  81400 Epoch:  27 Generator loss:  4.387594223022461 Discriminator loss:  0.0019395718118175864\n",
      "saving the output\n",
      "Iterations:  81600 Epoch:  27 Generator loss:  5.169225215911865 Discriminator loss:  0.017890166491270065\n",
      "Iterations:  81800 Epoch:  27 Generator loss:  6.983119964599609 Discriminator loss:  0.008322794921696186\n",
      "Iterations:  82000 Epoch:  27 Generator loss:  4.498047828674316 Discriminator loss:  0.016937488690018654\n",
      "saving the output\n",
      "Iterations:  82200 Epoch:  27 Generator loss:  4.494351863861084 Discriminator loss:  0.1933135688304901\n",
      "Iterations:  82400 Epoch:  27 Generator loss:  4.08802604675293 Discriminator loss:  0.014399121515452862\n",
      "saving the output\n",
      "Iterations:  82600 Epoch:  27 Generator loss:  4.940573215484619 Discriminator loss:  0.0029473616741597652\n",
      "Iterations:  82800 Epoch:  27 Generator loss:  4.633543968200684 Discriminator loss:  0.07873151451349258\n",
      "Iterations:  83000 Epoch:  27 Generator loss:  4.9145827293396 Discriminator loss:  0.0020023209508508444\n",
      "saving the output\n",
      "Iterations:  83200 Epoch:  27 Generator loss:  6.019430160522461 Discriminator loss:  6.08509435551241e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [2:01:54<12:27:07, 260.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  83400 Epoch:  28 Generator loss:  4.804938316345215 Discriminator loss:  2.0718980522360653e-05\n",
      "saving the output\n",
      "Iterations:  83600 Epoch:  28 Generator loss:  4.270359039306641 Discriminator loss:  0.09013344347476959\n",
      "Iterations:  83800 Epoch:  28 Generator loss:  4.577478408813477 Discriminator loss:  0.0007134320912882686\n",
      "Iterations:  84000 Epoch:  28 Generator loss:  3.982635021209717 Discriminator loss:  0.13718636333942413\n",
      "saving the output\n",
      "Iterations:  84200 Epoch:  28 Generator loss:  5.812682628631592 Discriminator loss:  0.19658523797988892\n",
      "Iterations:  84400 Epoch:  28 Generator loss:  5.853260040283203 Discriminator loss:  0.004072754643857479\n",
      "saving the output\n",
      "Iterations:  84600 Epoch:  28 Generator loss:  4.315593719482422 Discriminator loss:  0.0007543344981968403\n",
      "Iterations:  84800 Epoch:  28 Generator loss:  5.932297229766846 Discriminator loss:  0.0024696311447769403\n",
      "Iterations:  85000 Epoch:  28 Generator loss:  5.502531051635742 Discriminator loss:  0.021764051169157028\n",
      "saving the output\n",
      "Iterations:  85200 Epoch:  28 Generator loss:  4.962255477905273 Discriminator loss:  8.633866855234373e-06\n",
      "Iterations:  85400 Epoch:  28 Generator loss:  5.732687950134277 Discriminator loss:  2.4290704914164962e-06\n",
      "saving the output\n",
      "Iterations:  85600 Epoch:  28 Generator loss:  3.8106729984283447 Discriminator loss:  0.03932655602693558\n",
      "Iterations:  85800 Epoch:  28 Generator loss:  5.499814987182617 Discriminator loss:  1.5624917068635114e-05\n",
      "Iterations:  86000 Epoch:  28 Generator loss:  3.9021573066711426 Discriminator loss:  0.01989990659058094\n",
      "saving the output\n",
      "Iterations:  86200 Epoch:  28 Generator loss:  4.968255996704102 Discriminator loss:  0.023041684180498123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [2:06:13<12:20:55, 259.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  86400 Epoch:  29 Generator loss:  5.3051557540893555 Discriminator loss:  0.013330847024917603\n",
      "saving the output\n",
      "Iterations:  86600 Epoch:  29 Generator loss:  5.7707109451293945 Discriminator loss:  0.00011506959708640352\n",
      "Iterations:  86800 Epoch:  29 Generator loss:  4.264538764953613 Discriminator loss:  0.12168882042169571\n",
      "Iterations:  87000 Epoch:  29 Generator loss:  4.605865955352783 Discriminator loss:  4.325343525124481e-06\n",
      "saving the output\n",
      "Iterations:  87200 Epoch:  29 Generator loss:  4.392685890197754 Discriminator loss:  0.009185412898659706\n",
      "Iterations:  87400 Epoch:  29 Generator loss:  5.490301132202148 Discriminator loss:  0.3445051610469818\n",
      "saving the output\n",
      "Iterations:  87600 Epoch:  29 Generator loss:  3.9191694259643555 Discriminator loss:  0.3968394696712494\n",
      "Iterations:  87800 Epoch:  29 Generator loss:  3.8845674991607666 Discriminator loss:  0.23384582996368408\n",
      "Iterations:  88000 Epoch:  29 Generator loss:  4.251105785369873 Discriminator loss:  8.229723789554555e-06\n",
      "saving the output\n",
      "Iterations:  88200 Epoch:  29 Generator loss:  4.351644515991211 Discriminator loss:  0.00010465068771736696\n",
      "Iterations:  88400 Epoch:  29 Generator loss:  4.895226955413818 Discriminator loss:  0.13835789263248444\n",
      "saving the output\n",
      "Iterations:  88600 Epoch:  29 Generator loss:  4.518002033233643 Discriminator loss:  0.02551056444644928\n",
      "Iterations:  88800 Epoch:  29 Generator loss:  5.971254825592041 Discriminator loss:  0.13838811218738556\n",
      "Iterations:  89000 Epoch:  29 Generator loss:  5.563994407653809 Discriminator loss:  0.0005907460581511259\n",
      "saving the output\n",
      "Iterations:  89200 Epoch:  29 Generator loss:  6.5501627922058105 Discriminator loss:  0.02418680116534233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [2:10:32<12:16:14, 259.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  89400 Epoch:  30 Generator loss:  4.284398078918457 Discriminator loss:  0.01334866601973772\n",
      "saving the output\n",
      "Iterations:  89600 Epoch:  30 Generator loss:  6.347168922424316 Discriminator loss:  0.09909588098526001\n",
      "Iterations:  89800 Epoch:  30 Generator loss:  4.014559268951416 Discriminator loss:  0.05246182158589363\n",
      "Iterations:  90000 Epoch:  30 Generator loss:  7.570320129394531 Discriminator loss:  0.0019961372017860413\n",
      "saving the output\n",
      "Iterations:  90200 Epoch:  30 Generator loss:  5.445584774017334 Discriminator loss:  0.009355314075946808\n",
      "Iterations:  90400 Epoch:  30 Generator loss:  4.467931747436523 Discriminator loss:  0.009744658134877682\n",
      "saving the output\n",
      "Iterations:  90600 Epoch:  30 Generator loss:  5.887650489807129 Discriminator loss:  0.08396585285663605\n",
      "Iterations:  90800 Epoch:  30 Generator loss:  3.7198591232299805 Discriminator loss:  0.00791761465370655\n",
      "Iterations:  91000 Epoch:  30 Generator loss:  4.438211441040039 Discriminator loss:  0.00012009553029201925\n",
      "saving the output\n",
      "Iterations:  91200 Epoch:  30 Generator loss:  3.5990757942199707 Discriminator loss:  0.23196394741535187\n",
      "Iterations:  91400 Epoch:  30 Generator loss:  4.746006488800049 Discriminator loss:  0.03952613100409508\n",
      "saving the output\n",
      "Iterations:  91600 Epoch:  30 Generator loss:  4.968165874481201 Discriminator loss:  8.171575245796703e-06\n",
      "Iterations:  91800 Epoch:  30 Generator loss:  4.564303398132324 Discriminator loss:  0.00319278659299016\n",
      "Iterations:  92000 Epoch:  30 Generator loss:  3.9020285606384277 Discriminator loss:  0.012819784693419933\n",
      "saving the output\n",
      "Iterations:  92200 Epoch:  30 Generator loss:  5.250649929046631 Discriminator loss:  1.7384125385433435e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [2:14:54<12:13:10, 260.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  92400 Epoch:  31 Generator loss:  4.716283321380615 Discriminator loss:  1.6439693126812926e-06\n",
      "saving the output\n",
      "Iterations:  92600 Epoch:  31 Generator loss:  5.417392253875732 Discriminator loss:  0.0008009609882719815\n",
      "Iterations:  92800 Epoch:  31 Generator loss:  4.248573303222656 Discriminator loss:  4.887696559308097e-05\n",
      "Iterations:  93000 Epoch:  31 Generator loss:  5.196683883666992 Discriminator loss:  0.0009352645138278604\n",
      "saving the output\n",
      "Iterations:  93200 Epoch:  31 Generator loss:  3.8755087852478027 Discriminator loss:  0.016712814569473267\n",
      "Iterations:  93400 Epoch:  31 Generator loss:  4.140861511230469 Discriminator loss:  0.028684526681900024\n",
      "saving the output\n",
      "Iterations:  93600 Epoch:  31 Generator loss:  4.881054878234863 Discriminator loss:  4.735269249067642e-05\n",
      "Iterations:  93800 Epoch:  31 Generator loss:  4.332176208496094 Discriminator loss:  0.27607300877571106\n",
      "Iterations:  94000 Epoch:  31 Generator loss:  5.854682922363281 Discriminator loss:  3.8628288166364655e-05\n",
      "saving the output\n",
      "Iterations:  94200 Epoch:  31 Generator loss:  5.141661643981934 Discriminator loss:  0.03619595989584923\n",
      "Iterations:  94400 Epoch:  31 Generator loss:  3.8163046836853027 Discriminator loss:  0.3023340106010437\n",
      "saving the output\n",
      "Iterations:  94600 Epoch:  31 Generator loss:  4.841780662536621 Discriminator loss:  0.010137133300304413\n",
      "Iterations:  94800 Epoch:  31 Generator loss:  4.322812080383301 Discriminator loss:  0.1410512924194336\n",
      "Iterations:  95000 Epoch:  31 Generator loss:  5.535933494567871 Discriminator loss:  3.0359447009686846e-06\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [2:19:14<12:09:02, 260.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  95200 Epoch:  32 Generator loss:  4.734750270843506 Discriminator loss:  0.0001503606472397223\n",
      "Iterations:  95400 Epoch:  32 Generator loss:  4.966439247131348 Discriminator loss:  0.00012096612772438675\n",
      "saving the output\n",
      "Iterations:  95600 Epoch:  32 Generator loss:  3.917633056640625 Discriminator loss:  0.2270679920911789\n",
      "Iterations:  95800 Epoch:  32 Generator loss:  5.038099765777588 Discriminator loss:  0.019503973424434662\n",
      "Iterations:  96000 Epoch:  32 Generator loss:  5.419334411621094 Discriminator loss:  3.4320397389819846e-05\n",
      "saving the output\n",
      "Iterations:  96200 Epoch:  32 Generator loss:  6.524899482727051 Discriminator loss:  0.0017012341413646936\n",
      "Iterations:  96400 Epoch:  32 Generator loss:  5.946712493896484 Discriminator loss:  6.67680950527938e-08\n",
      "saving the output\n",
      "Iterations:  96600 Epoch:  32 Generator loss:  3.566089630126953 Discriminator loss:  0.2699694037437439\n",
      "Iterations:  96800 Epoch:  32 Generator loss:  3.894975423812866 Discriminator loss:  0.2897018790245056\n",
      "Iterations:  97000 Epoch:  32 Generator loss:  4.34094762802124 Discriminator loss:  0.3315601348876953\n",
      "saving the output\n",
      "Iterations:  97200 Epoch:  32 Generator loss:  5.348758697509766 Discriminator loss:  0.0013861339539289474\n",
      "Iterations:  97400 Epoch:  32 Generator loss:  4.025158405303955 Discriminator loss:  0.13479284942150116\n",
      "saving the output\n",
      "Iterations:  97600 Epoch:  32 Generator loss:  4.460085868835449 Discriminator loss:  0.0005933379288762808\n",
      "Iterations:  97800 Epoch:  32 Generator loss:  4.5830159187316895 Discriminator loss:  0.0006598999607376754\n",
      "Iterations:  98000 Epoch:  32 Generator loss:  5.221355438232422 Discriminator loss:  0.008513681590557098\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [2:23:37<12:07:01, 261.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  98200 Epoch:  33 Generator loss:  6.822818756103516 Discriminator loss:  0.00044784953934140503\n",
      "Iterations:  98400 Epoch:  33 Generator loss:  4.646620273590088 Discriminator loss:  2.3123575374484062e-06\n",
      "saving the output\n",
      "Iterations:  98600 Epoch:  33 Generator loss:  4.115879535675049 Discriminator loss:  0.14912360906600952\n",
      "Iterations:  98800 Epoch:  33 Generator loss:  4.622164726257324 Discriminator loss:  0.014623482711613178\n",
      "Iterations:  99000 Epoch:  33 Generator loss:  5.080951690673828 Discriminator loss:  4.167634870100301e-06\n",
      "saving the output\n",
      "Iterations:  99200 Epoch:  33 Generator loss:  5.019740104675293 Discriminator loss:  0.06460480391979218\n",
      "Iterations:  99400 Epoch:  33 Generator loss:  4.4471540451049805 Discriminator loss:  0.0015298818470910192\n",
      "saving the output\n",
      "Iterations:  99600 Epoch:  33 Generator loss:  4.132106304168701 Discriminator loss:  0.09577997028827667\n",
      "Iterations:  99800 Epoch:  33 Generator loss:  5.838994026184082 Discriminator loss:  0.0065606338903307915\n",
      "Iterations:  100000 Epoch:  33 Generator loss:  7.514300346374512 Discriminator loss:  0.027938976883888245\n",
      "saving the output\n",
      "Iterations:  100200 Epoch:  33 Generator loss:  6.998795509338379 Discriminator loss:  9.238535130862147e-05\n",
      "Iterations:  100400 Epoch:  33 Generator loss:  5.731407165527344 Discriminator loss:  0.03391602262854576\n",
      "saving the output\n",
      "Iterations:  100600 Epoch:  33 Generator loss:  5.0576019287109375 Discriminator loss:  0.0034403533209115267\n",
      "Iterations:  100800 Epoch:  33 Generator loss:  4.861701011657715 Discriminator loss:  4.010957582067931e-06\n",
      "Iterations:  101000 Epoch:  33 Generator loss:  4.167229652404785 Discriminator loss:  0.02031777799129486\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [2:27:58<12:02:07, 261.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  101200 Epoch:  34 Generator loss:  4.6447649002075195 Discriminator loss:  0.03753240779042244\n",
      "Iterations:  101400 Epoch:  34 Generator loss:  4.903022766113281 Discriminator loss:  0.00013169529847800732\n",
      "saving the output\n",
      "Iterations:  101600 Epoch:  34 Generator loss:  4.960912227630615 Discriminator loss:  0.04807519540190697\n",
      "Iterations:  101800 Epoch:  34 Generator loss:  5.41047477722168 Discriminator loss:  0.07501029968261719\n",
      "Iterations:  102000 Epoch:  34 Generator loss:  4.365299224853516 Discriminator loss:  0.1280950903892517\n",
      "saving the output\n",
      "Iterations:  102200 Epoch:  34 Generator loss:  5.0223493576049805 Discriminator loss:  0.00018387963064014912\n",
      "Iterations:  102400 Epoch:  34 Generator loss:  4.579227924346924 Discriminator loss:  0.08166296035051346\n",
      "saving the output\n",
      "Iterations:  102600 Epoch:  34 Generator loss:  5.0336503982543945 Discriminator loss:  3.2000691135181114e-05\n",
      "Iterations:  102800 Epoch:  34 Generator loss:  4.2114081382751465 Discriminator loss:  0.02046946808695793\n",
      "Iterations:  103000 Epoch:  34 Generator loss:  4.5871477127075195 Discriminator loss:  0.34714898467063904\n",
      "saving the output\n",
      "Iterations:  103200 Epoch:  34 Generator loss:  3.7752060890197754 Discriminator loss:  0.30334770679473877\n",
      "Iterations:  103400 Epoch:  34 Generator loss:  4.919331073760986 Discriminator loss:  0.04547443985939026\n",
      "saving the output\n",
      "Iterations:  103600 Epoch:  34 Generator loss:  3.740832805633545 Discriminator loss:  2.0958616005373187e-05\n",
      "Iterations:  103800 Epoch:  34 Generator loss:  3.9130632877349854 Discriminator loss:  0.005885242484509945\n",
      "Iterations:  104000 Epoch:  34 Generator loss:  5.072155952453613 Discriminator loss:  0.002686690306290984\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [2:32:22<12:00:39, 262.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  104200 Epoch:  35 Generator loss:  4.665493965148926 Discriminator loss:  0.0062941028736531734\n",
      "Iterations:  104400 Epoch:  35 Generator loss:  3.646028757095337 Discriminator loss:  0.4885101318359375\n",
      "saving the output\n",
      "Iterations:  104600 Epoch:  35 Generator loss:  4.093690872192383 Discriminator loss:  0.010335446335375309\n",
      "Iterations:  104800 Epoch:  35 Generator loss:  5.077071189880371 Discriminator loss:  0.16968506574630737\n",
      "Iterations:  105000 Epoch:  35 Generator loss:  6.223197937011719 Discriminator loss:  0.004023210145533085\n",
      "saving the output\n",
      "Iterations:  105200 Epoch:  35 Generator loss:  4.955379962921143 Discriminator loss:  1.8917569832410663e-05\n",
      "Iterations:  105400 Epoch:  35 Generator loss:  4.374248027801514 Discriminator loss:  0.1314145177602768\n",
      "saving the output\n",
      "Iterations:  105600 Epoch:  35 Generator loss:  3.8073110580444336 Discriminator loss:  0.002483923453837633\n",
      "Iterations:  105800 Epoch:  35 Generator loss:  5.152857780456543 Discriminator loss:  0.0029328723903745413\n",
      "Iterations:  106000 Epoch:  35 Generator loss:  4.969300270080566 Discriminator loss:  0.16734744608402252\n",
      "saving the output\n",
      "Iterations:  106200 Epoch:  35 Generator loss:  5.095649719238281 Discriminator loss:  0.0028592331800609827\n",
      "Iterations:  106400 Epoch:  35 Generator loss:  4.079325199127197 Discriminator loss:  0.2942964434623718\n",
      "saving the output\n",
      "Iterations:  106600 Epoch:  35 Generator loss:  5.902970314025879 Discriminator loss:  0.0018502172315493226\n",
      "Iterations:  106800 Epoch:  35 Generator loss:  6.193504333496094 Discriminator loss:  0.017042074352502823\n",
      "Iterations:  107000 Epoch:  35 Generator loss:  5.578951358795166 Discriminator loss:  0.1422235667705536\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [2:36:43<11:55:27, 261.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  107200 Epoch:  36 Generator loss:  3.8799614906311035 Discriminator loss:  0.0004153826739639044\n",
      "Iterations:  107400 Epoch:  36 Generator loss:  4.70259952545166 Discriminator loss:  0.02016768604516983\n",
      "saving the output\n",
      "Iterations:  107600 Epoch:  36 Generator loss:  4.519055366516113 Discriminator loss:  0.004926280118525028\n",
      "Iterations:  107800 Epoch:  36 Generator loss:  4.6998090744018555 Discriminator loss:  0.3163670003414154\n",
      "Iterations:  108000 Epoch:  36 Generator loss:  5.386414527893066 Discriminator loss:  0.00549964839592576\n",
      "saving the output\n",
      "Iterations:  108200 Epoch:  36 Generator loss:  4.861152648925781 Discriminator loss:  5.0509130232967436e-05\n",
      "Iterations:  108400 Epoch:  36 Generator loss:  4.232658863067627 Discriminator loss:  0.0540119931101799\n",
      "saving the output\n",
      "Iterations:  108600 Epoch:  36 Generator loss:  6.2394700050354 Discriminator loss:  1.5863176940911217e-06\n",
      "Iterations:  108800 Epoch:  36 Generator loss:  4.907695770263672 Discriminator loss:  0.026671629399061203\n",
      "Iterations:  109000 Epoch:  36 Generator loss:  5.023359298706055 Discriminator loss:  0.007125765550881624\n",
      "saving the output\n",
      "Iterations:  109200 Epoch:  36 Generator loss:  5.653380393981934 Discriminator loss:  0.20114077627658844\n",
      "Iterations:  109400 Epoch:  36 Generator loss:  3.8767199516296387 Discriminator loss:  0.2445615530014038\n",
      "saving the output\n",
      "Iterations:  109600 Epoch:  36 Generator loss:  5.814176559448242 Discriminator loss:  0.04886922612786293\n",
      "Iterations:  109800 Epoch:  36 Generator loss:  5.0942792892456055 Discriminator loss:  0.009246678091585636\n",
      "Iterations:  110000 Epoch:  36 Generator loss:  4.142391204833984 Discriminator loss:  0.038015078753232956\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [2:41:06<11:51:55, 262.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  110200 Epoch:  37 Generator loss:  5.596868515014648 Discriminator loss:  0.000258127402048558\n",
      "Iterations:  110400 Epoch:  37 Generator loss:  4.242091178894043 Discriminator loss:  1.1080892363679595e-06\n",
      "saving the output\n",
      "Iterations:  110600 Epoch:  37 Generator loss:  4.4659423828125 Discriminator loss:  0.013115817680954933\n",
      "Iterations:  110800 Epoch:  37 Generator loss:  5.0646162033081055 Discriminator loss:  4.247505955845554e-07\n",
      "Iterations:  111000 Epoch:  37 Generator loss:  4.258739471435547 Discriminator loss:  0.0013185079442337155\n",
      "saving the output\n",
      "Iterations:  111200 Epoch:  37 Generator loss:  4.9951252937316895 Discriminator loss:  0.017055023461580276\n",
      "Iterations:  111400 Epoch:  37 Generator loss:  3.8018267154693604 Discriminator loss:  0.15710844099521637\n",
      "saving the output\n",
      "Iterations:  111600 Epoch:  37 Generator loss:  4.689589500427246 Discriminator loss:  0.0052809640765190125\n",
      "Iterations:  111800 Epoch:  37 Generator loss:  4.639805793762207 Discriminator loss:  0.09294634312391281\n",
      "Iterations:  112000 Epoch:  37 Generator loss:  4.937491416931152 Discriminator loss:  4.4150083340355195e-06\n",
      "saving the output\n",
      "Iterations:  112200 Epoch:  37 Generator loss:  5.5811920166015625 Discriminator loss:  0.013044488616287708\n",
      "Iterations:  112400 Epoch:  37 Generator loss:  5.300261974334717 Discriminator loss:  2.059555981759331e-06\n",
      "saving the output\n",
      "Iterations:  112600 Epoch:  37 Generator loss:  4.741071701049805 Discriminator loss:  0.011701555922627449\n",
      "Iterations:  112800 Epoch:  37 Generator loss:  3.8663995265960693 Discriminator loss:  0.11008147150278091\n",
      "Iterations:  113000 Epoch:  37 Generator loss:  5.740751266479492 Discriminator loss:  0.023382335901260376\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [2:45:30<11:48:56, 262.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  113200 Epoch:  38 Generator loss:  4.19423770904541 Discriminator loss:  0.1271255612373352\n",
      "Iterations:  113400 Epoch:  38 Generator loss:  3.9145383834838867 Discriminator loss:  0.23742987215518951\n",
      "saving the output\n",
      "Iterations:  113600 Epoch:  38 Generator loss:  4.461584091186523 Discriminator loss:  0.045647770166397095\n",
      "Iterations:  113800 Epoch:  38 Generator loss:  5.690598487854004 Discriminator loss:  0.007962492294609547\n",
      "Iterations:  114000 Epoch:  38 Generator loss:  4.1619181632995605 Discriminator loss:  0.0014854766195639968\n",
      "saving the output\n",
      "Iterations:  114200 Epoch:  38 Generator loss:  5.443861484527588 Discriminator loss:  8.314076694659889e-06\n",
      "Iterations:  114400 Epoch:  38 Generator loss:  4.08986234664917 Discriminator loss:  0.002891211537644267\n",
      "saving the output\n",
      "Iterations:  114600 Epoch:  38 Generator loss:  5.862020492553711 Discriminator loss:  2.6458346837898716e-06\n",
      "Iterations:  114800 Epoch:  38 Generator loss:  4.632561683654785 Discriminator loss:  0.0047500645741820335\n",
      "Iterations:  115000 Epoch:  38 Generator loss:  4.333268165588379 Discriminator loss:  0.0009907804196700454\n",
      "saving the output\n",
      "Iterations:  115200 Epoch:  38 Generator loss:  5.22515869140625 Discriminator loss:  0.09993153065443039\n",
      "Iterations:  115400 Epoch:  38 Generator loss:  5.153725624084473 Discriminator loss:  0.009204164147377014\n",
      "saving the output\n",
      "Iterations:  115600 Epoch:  38 Generator loss:  5.736550331115723 Discriminator loss:  2.1033538359915838e-05\n",
      "Iterations:  115800 Epoch:  38 Generator loss:  5.349944114685059 Discriminator loss:  4.9154887165059336e-06\n",
      "Iterations:  116000 Epoch:  38 Generator loss:  5.851222991943359 Discriminator loss:  1.7191140955219453e-07\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [2:49:54<11:45:23, 262.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  116200 Epoch:  39 Generator loss:  4.759963035583496 Discriminator loss:  0.00012918080028612167\n",
      "Iterations:  116400 Epoch:  39 Generator loss:  4.151192665100098 Discriminator loss:  0.005297223571687937\n",
      "saving the output\n",
      "Iterations:  116600 Epoch:  39 Generator loss:  4.302864074707031 Discriminator loss:  0.004233366809785366\n",
      "Iterations:  116800 Epoch:  39 Generator loss:  4.062743186950684 Discriminator loss:  0.0008701288606971502\n",
      "Iterations:  117000 Epoch:  39 Generator loss:  5.032651424407959 Discriminator loss:  0.0001874958397820592\n",
      "saving the output\n",
      "Iterations:  117200 Epoch:  39 Generator loss:  5.097090244293213 Discriminator loss:  5.825138941872865e-06\n",
      "Iterations:  117400 Epoch:  39 Generator loss:  4.776325702667236 Discriminator loss:  0.11519545316696167\n",
      "saving the output\n",
      "Iterations:  117600 Epoch:  39 Generator loss:  6.548666000366211 Discriminator loss:  0.03848179802298546\n",
      "Iterations:  117800 Epoch:  39 Generator loss:  5.554893493652344 Discriminator loss:  7.345336143771419e-06\n",
      "Iterations:  118000 Epoch:  39 Generator loss:  4.457947731018066 Discriminator loss:  1.6163730833795853e-05\n",
      "saving the output\n",
      "Iterations:  118200 Epoch:  39 Generator loss:  5.437630653381348 Discriminator loss:  0.0024905477184802294\n",
      "Iterations:  118400 Epoch:  39 Generator loss:  5.42513370513916 Discriminator loss:  0.006259735208004713\n",
      "saving the output\n",
      "Iterations:  118600 Epoch:  39 Generator loss:  4.124361991882324 Discriminator loss:  0.008228057995438576\n",
      "Iterations:  118800 Epoch:  39 Generator loss:  5.685214042663574 Discriminator loss:  0.002151273423805833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [2:54:12<11:37:44, 261.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  119000 Epoch:  40 Generator loss:  5.2971062660217285 Discriminator loss:  0.03203211724758148\n",
      "saving the output\n",
      "Iterations:  119200 Epoch:  40 Generator loss:  3.8267340660095215 Discriminator loss:  0.3521243631839752\n",
      "Iterations:  119400 Epoch:  40 Generator loss:  4.48207950592041 Discriminator loss:  0.001088725053705275\n",
      "saving the output\n",
      "Iterations:  119600 Epoch:  40 Generator loss:  4.507671356201172 Discriminator loss:  0.003790686372667551\n",
      "Iterations:  119800 Epoch:  40 Generator loss:  4.351734638214111 Discriminator loss:  0.033420342952013016\n",
      "Iterations:  120000 Epoch:  40 Generator loss:  4.668154239654541 Discriminator loss:  0.04014727473258972\n",
      "saving the output\n",
      "Iterations:  120200 Epoch:  40 Generator loss:  5.039709091186523 Discriminator loss:  0.004310933407396078\n",
      "Iterations:  120400 Epoch:  40 Generator loss:  4.65974235534668 Discriminator loss:  0.00016698738909326494\n",
      "saving the output\n",
      "Iterations:  120600 Epoch:  40 Generator loss:  7.162728309631348 Discriminator loss:  2.3882421373855323e-06\n",
      "Iterations:  120800 Epoch:  40 Generator loss:  4.600763320922852 Discriminator loss:  0.004578248597681522\n",
      "Iterations:  121000 Epoch:  40 Generator loss:  4.465376853942871 Discriminator loss:  0.02258964627981186\n",
      "saving the output\n",
      "Iterations:  121200 Epoch:  40 Generator loss:  4.229864120483398 Discriminator loss:  0.03797765448689461\n",
      "Iterations:  121400 Epoch:  40 Generator loss:  4.157286643981934 Discriminator loss:  0.16981752216815948\n",
      "saving the output\n",
      "Iterations:  121600 Epoch:  40 Generator loss:  6.388765335083008 Discriminator loss:  0.0002215650019934401\n",
      "Iterations:  121800 Epoch:  40 Generator loss:  3.608668327331543 Discriminator loss:  0.02721182443201542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [2:58:30<11:30:22, 260.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  122000 Epoch:  41 Generator loss:  3.9665040969848633 Discriminator loss:  4.6510017455148045e-06\n",
      "saving the output\n",
      "Iterations:  122200 Epoch:  41 Generator loss:  3.681130886077881 Discriminator loss:  0.18391089141368866\n",
      "Iterations:  122400 Epoch:  41 Generator loss:  4.1003875732421875 Discriminator loss:  0.09080953150987625\n",
      "saving the output\n",
      "Iterations:  122600 Epoch:  41 Generator loss:  4.271581649780273 Discriminator loss:  0.01753004640340805\n",
      "Iterations:  122800 Epoch:  41 Generator loss:  4.304430961608887 Discriminator loss:  0.03805776312947273\n",
      "Iterations:  123000 Epoch:  41 Generator loss:  4.97610330581665 Discriminator loss:  0.33393752574920654\n",
      "saving the output\n",
      "Iterations:  123200 Epoch:  41 Generator loss:  5.064848899841309 Discriminator loss:  9.060886441147886e-06\n",
      "Iterations:  123400 Epoch:  41 Generator loss:  4.203376293182373 Discriminator loss:  0.012622766196727753\n",
      "saving the output\n",
      "Iterations:  123600 Epoch:  41 Generator loss:  4.322793483734131 Discriminator loss:  0.012862940318882465\n",
      "Iterations:  123800 Epoch:  41 Generator loss:  4.0229997634887695 Discriminator loss:  5.601351631412399e-07\n",
      "Iterations:  124000 Epoch:  41 Generator loss:  6.304208278656006 Discriminator loss:  0.006234372965991497\n",
      "saving the output\n",
      "Iterations:  124200 Epoch:  41 Generator loss:  4.420866012573242 Discriminator loss:  0.20472626388072968\n",
      "Iterations:  124400 Epoch:  41 Generator loss:  4.417590618133545 Discriminator loss:  0.0031142407096922398\n",
      "saving the output\n",
      "Iterations:  124600 Epoch:  41 Generator loss:  5.396391868591309 Discriminator loss:  1.6497121180236718e-07\n",
      "Iterations:  124800 Epoch:  41 Generator loss:  5.002339839935303 Discriminator loss:  4.013485522591509e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [3:02:53<11:27:31, 261.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  125000 Epoch:  42 Generator loss:  4.410964012145996 Discriminator loss:  5.126416726852767e-05\n",
      "saving the output\n",
      "Iterations:  125200 Epoch:  42 Generator loss:  4.19826602935791 Discriminator loss:  0.01646517403423786\n",
      "Iterations:  125400 Epoch:  42 Generator loss:  4.0945329666137695 Discriminator loss:  0.0002633399562910199\n",
      "saving the output\n",
      "Iterations:  125600 Epoch:  42 Generator loss:  5.051968574523926 Discriminator loss:  0.004566974472254515\n",
      "Iterations:  125800 Epoch:  42 Generator loss:  4.2367658615112305 Discriminator loss:  0.0039880224503576756\n",
      "Iterations:  126000 Epoch:  42 Generator loss:  4.641110420227051 Discriminator loss:  0.03682496026158333\n",
      "saving the output\n",
      "Iterations:  126200 Epoch:  42 Generator loss:  4.488870620727539 Discriminator loss:  0.054489489644765854\n",
      "Iterations:  126400 Epoch:  42 Generator loss:  4.466133117675781 Discriminator loss:  0.02433042973279953\n",
      "saving the output\n",
      "Iterations:  126600 Epoch:  42 Generator loss:  4.644099712371826 Discriminator loss:  8.598779572821513e-07\n",
      "Iterations:  126800 Epoch:  42 Generator loss:  4.078793048858643 Discriminator loss:  2.2793017251387937e-06\n",
      "Iterations:  127000 Epoch:  42 Generator loss:  4.598430633544922 Discriminator loss:  0.00025655244826339185\n",
      "saving the output\n",
      "Iterations:  127200 Epoch:  42 Generator loss:  4.683455467224121 Discriminator loss:  0.04898913949728012\n",
      "Iterations:  127400 Epoch:  42 Generator loss:  4.125888824462891 Discriminator loss:  4.597898441716097e-05\n",
      "saving the output\n",
      "Iterations:  127600 Epoch:  42 Generator loss:  4.539244174957275 Discriminator loss:  0.009293069131672382\n",
      "Iterations:  127800 Epoch:  42 Generator loss:  4.226273536682129 Discriminator loss:  0.016827557235956192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [3:07:11<11:21:14, 260.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  128000 Epoch:  43 Generator loss:  4.7922821044921875 Discriminator loss:  0.012446762062609196\n",
      "saving the output\n",
      "Iterations:  128200 Epoch:  43 Generator loss:  5.232397079467773 Discriminator loss:  5.341532300917606e-07\n",
      "Iterations:  128400 Epoch:  43 Generator loss:  4.613498687744141 Discriminator loss:  0.06662434339523315\n",
      "saving the output\n",
      "Iterations:  128600 Epoch:  43 Generator loss:  4.556630611419678 Discriminator loss:  2.341194203836494e-06\n",
      "Iterations:  128800 Epoch:  43 Generator loss:  4.167014122009277 Discriminator loss:  0.0048395786434412\n",
      "Iterations:  129000 Epoch:  43 Generator loss:  5.482532978057861 Discriminator loss:  6.453392984440143e-07\n",
      "saving the output\n",
      "Iterations:  129200 Epoch:  43 Generator loss:  4.348027229309082 Discriminator loss:  0.021378738805651665\n",
      "Iterations:  129400 Epoch:  43 Generator loss:  4.6895952224731445 Discriminator loss:  0.0018603914650157094\n",
      "saving the output\n",
      "Iterations:  129600 Epoch:  43 Generator loss:  4.116541862487793 Discriminator loss:  0.19277088344097137\n",
      "Iterations:  129800 Epoch:  43 Generator loss:  5.037100791931152 Discriminator loss:  0.014725557528436184\n",
      "Iterations:  130000 Epoch:  43 Generator loss:  4.737199306488037 Discriminator loss:  0.001943951821886003\n",
      "saving the output\n",
      "Iterations:  130200 Epoch:  43 Generator loss:  4.3969621658325195 Discriminator loss:  3.5213861337979324e-06\n",
      "Iterations:  130400 Epoch:  43 Generator loss:  3.998734951019287 Discriminator loss:  0.031492963433265686\n",
      "saving the output\n",
      "Iterations:  130600 Epoch:  43 Generator loss:  5.704713821411133 Discriminator loss:  3.075055587942188e-08\n",
      "Iterations:  130800 Epoch:  43 Generator loss:  5.238393783569336 Discriminator loss:  0.0004023766960017383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [3:11:33<11:17:44, 260.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  131000 Epoch:  44 Generator loss:  4.4244160652160645 Discriminator loss:  0.003144868416711688\n",
      "saving the output\n",
      "Iterations:  131200 Epoch:  44 Generator loss:  5.145641326904297 Discriminator loss:  2.950305315607693e-06\n",
      "Iterations:  131400 Epoch:  44 Generator loss:  6.071677207946777 Discriminator loss:  0.00038249933277256787\n",
      "saving the output\n",
      "Iterations:  131600 Epoch:  44 Generator loss:  4.603791236877441 Discriminator loss:  0.01908194273710251\n",
      "Iterations:  131800 Epoch:  44 Generator loss:  5.726531028747559 Discriminator loss:  1.745752706483472e-05\n",
      "Iterations:  132000 Epoch:  44 Generator loss:  5.053154945373535 Discriminator loss:  0.03426603227853775\n",
      "saving the output\n",
      "Iterations:  132200 Epoch:  44 Generator loss:  4.0388407707214355 Discriminator loss:  0.059958841651678085\n",
      "Iterations:  132400 Epoch:  44 Generator loss:  4.290902614593506 Discriminator loss:  7.859768811613321e-05\n",
      "saving the output\n",
      "Iterations:  132600 Epoch:  44 Generator loss:  3.976362705230713 Discriminator loss:  0.07680258899927139\n",
      "Iterations:  132800 Epoch:  44 Generator loss:  4.741521835327148 Discriminator loss:  4.4889110206725036e-09\n",
      "Iterations:  133000 Epoch:  44 Generator loss:  4.7607316970825195 Discriminator loss:  0.02807740867137909\n",
      "saving the output\n",
      "Iterations:  133200 Epoch:  44 Generator loss:  3.6938133239746094 Discriminator loss:  0.22091268002986908\n",
      "Iterations:  133400 Epoch:  44 Generator loss:  4.515395164489746 Discriminator loss:  0.0014532608911395073\n",
      "saving the output\n",
      "Iterations:  133600 Epoch:  44 Generator loss:  4.127729415893555 Discriminator loss:  0.00012711458839476109\n",
      "Iterations:  133800 Epoch:  44 Generator loss:  4.66619873046875 Discriminator loss:  1.760372833814472e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [3:15:54<11:13:51, 260.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  134000 Epoch:  45 Generator loss:  4.919179439544678 Discriminator loss:  0.00016826468345243484\n",
      "saving the output\n",
      "Iterations:  134200 Epoch:  45 Generator loss:  4.710710525512695 Discriminator loss:  0.0006796953966841102\n",
      "Iterations:  134400 Epoch:  45 Generator loss:  4.334932327270508 Discriminator loss:  0.02372404746711254\n",
      "saving the output\n",
      "Iterations:  134600 Epoch:  45 Generator loss:  4.5033369064331055 Discriminator loss:  0.00023081230756361037\n",
      "Iterations:  134800 Epoch:  45 Generator loss:  4.777728080749512 Discriminator loss:  3.720851282196236e-06\n",
      "Iterations:  135000 Epoch:  45 Generator loss:  5.172826766967773 Discriminator loss:  1.914297172334045e-06\n",
      "saving the output\n",
      "Iterations:  135200 Epoch:  45 Generator loss:  4.353947639465332 Discriminator loss:  0.0004780916206073016\n",
      "Iterations:  135400 Epoch:  45 Generator loss:  4.442426681518555 Discriminator loss:  0.05508851632475853\n",
      "saving the output\n",
      "Iterations:  135600 Epoch:  45 Generator loss:  4.940301895141602 Discriminator loss:  0.03185758739709854\n",
      "Iterations:  135800 Epoch:  45 Generator loss:  6.145036697387695 Discriminator loss:  2.459144639033184e-07\n",
      "Iterations:  136000 Epoch:  45 Generator loss:  3.8973145484924316 Discriminator loss:  0.02534458041191101\n",
      "saving the output\n",
      "Iterations:  136200 Epoch:  45 Generator loss:  4.462469100952148 Discriminator loss:  0.008673438802361488\n",
      "Iterations:  136400 Epoch:  45 Generator loss:  4.442395210266113 Discriminator loss:  0.021256383508443832\n",
      "saving the output\n",
      "Iterations:  136600 Epoch:  45 Generator loss:  4.333902359008789 Discriminator loss:  0.00010601343819871545\n",
      "Iterations:  136800 Epoch:  45 Generator loss:  5.168978691101074 Discriminator loss:  0.00032760738395154476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [3:20:14<11:08:39, 260.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  137000 Epoch:  46 Generator loss:  4.345291614532471 Discriminator loss:  1.4843445228507335e-07\n",
      "saving the output\n",
      "Iterations:  137200 Epoch:  46 Generator loss:  4.932792663574219 Discriminator loss:  8.303736365178338e-09\n",
      "Iterations:  137400 Epoch:  46 Generator loss:  5.098241806030273 Discriminator loss:  0.0022257063537836075\n",
      "saving the output\n",
      "Iterations:  137600 Epoch:  46 Generator loss:  5.134792327880859 Discriminator loss:  0.0007527433917857707\n",
      "Iterations:  137800 Epoch:  46 Generator loss:  4.334344863891602 Discriminator loss:  4.241697752149776e-06\n",
      "Iterations:  138000 Epoch:  46 Generator loss:  4.3192243576049805 Discriminator loss:  0.058471329510211945\n",
      "saving the output\n",
      "Iterations:  138200 Epoch:  46 Generator loss:  3.688141345977783 Discriminator loss:  0.10165276378393173\n",
      "Iterations:  138400 Epoch:  46 Generator loss:  4.243043899536133 Discriminator loss:  0.00014665805792901665\n",
      "saving the output\n",
      "Iterations:  138600 Epoch:  46 Generator loss:  4.053573131561279 Discriminator loss:  0.0007145203999243677\n",
      "Iterations:  138800 Epoch:  46 Generator loss:  3.7926502227783203 Discriminator loss:  0.3012863099575043\n",
      "Iterations:  139000 Epoch:  46 Generator loss:  5.165816307067871 Discriminator loss:  0.00913270004093647\n",
      "saving the output\n",
      "Iterations:  139200 Epoch:  46 Generator loss:  4.048269748687744 Discriminator loss:  4.1659279759187484e-07\n",
      "Iterations:  139400 Epoch:  46 Generator loss:  4.110039710998535 Discriminator loss:  0.0003168366092722863\n",
      "saving the output\n",
      "Iterations:  139600 Epoch:  46 Generator loss:  5.0785369873046875 Discriminator loss:  2.139516830368393e-08\n",
      "Iterations:  139800 Epoch:  46 Generator loss:  4.389003753662109 Discriminator loss:  0.0010016007581725717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [3:24:34<11:04:17, 260.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  140000 Epoch:  47 Generator loss:  5.569880485534668 Discriminator loss:  0.0015562339685857296\n",
      "saving the output\n",
      "Iterations:  140200 Epoch:  47 Generator loss:  5.110592842102051 Discriminator loss:  0.0012484525796025991\n",
      "Iterations:  140400 Epoch:  47 Generator loss:  4.670625686645508 Discriminator loss:  0.10758468508720398\n",
      "saving the output\n",
      "Iterations:  140600 Epoch:  47 Generator loss:  4.151769638061523 Discriminator loss:  2.5790575818973593e-05\n",
      "Iterations:  140800 Epoch:  47 Generator loss:  4.973577499389648 Discriminator loss:  0.07619697600603104\n",
      "Iterations:  141000 Epoch:  47 Generator loss:  4.913677215576172 Discriminator loss:  0.0033218516036868095\n",
      "saving the output\n",
      "Iterations:  141200 Epoch:  47 Generator loss:  4.242356300354004 Discriminator loss:  0.0445890873670578\n",
      "Iterations:  141400 Epoch:  47 Generator loss:  5.047231197357178 Discriminator loss:  7.304188809342804e-09\n",
      "saving the output\n",
      "Iterations:  141600 Epoch:  47 Generator loss:  4.334132194519043 Discriminator loss:  0.10741626471281052\n",
      "Iterations:  141800 Epoch:  47 Generator loss:  4.003955841064453 Discriminator loss:  7.624985755683156e-06\n",
      "Iterations:  142000 Epoch:  47 Generator loss:  4.605891704559326 Discriminator loss:  0.057032208889722824\n",
      "saving the output\n",
      "Iterations:  142200 Epoch:  47 Generator loss:  4.632634162902832 Discriminator loss:  0.03917766734957695\n",
      "Iterations:  142400 Epoch:  47 Generator loss:  4.1339111328125 Discriminator loss:  1.8874781744671054e-05\n",
      "saving the output\n",
      "Iterations:  142600 Epoch:  47 Generator loss:  4.301548004150391 Discriminator loss:  0.04306516423821449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [3:29:01<11:04:31, 262.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  142800 Epoch:  48 Generator loss:  5.049167633056641 Discriminator loss:  0.07941398024559021\n",
      "Iterations:  143000 Epoch:  48 Generator loss:  5.635438919067383 Discriminator loss:  0.06969192624092102\n",
      "saving the output\n",
      "Iterations:  143200 Epoch:  48 Generator loss:  5.298023223876953 Discriminator loss:  0.00632992759346962\n",
      "Iterations:  143400 Epoch:  48 Generator loss:  3.9758050441741943 Discriminator loss:  9.099487215280533e-05\n",
      "saving the output\n",
      "Iterations:  143600 Epoch:  48 Generator loss:  4.338068962097168 Discriminator loss:  0.014271458610892296\n",
      "Iterations:  143800 Epoch:  48 Generator loss:  4.698088645935059 Discriminator loss:  0.003106497460976243\n",
      "Iterations:  144000 Epoch:  48 Generator loss:  4.52482271194458 Discriminator loss:  0.0010034688748419285\n",
      "saving the output\n",
      "Iterations:  144200 Epoch:  48 Generator loss:  3.804399013519287 Discriminator loss:  4.382731333407719e-07\n",
      "Iterations:  144400 Epoch:  48 Generator loss:  4.382807731628418 Discriminator loss:  0.0009615470189601183\n",
      "saving the output\n",
      "Iterations:  144600 Epoch:  48 Generator loss:  5.028018951416016 Discriminator loss:  7.726747019987101e-10\n",
      "Iterations:  144800 Epoch:  48 Generator loss:  5.036426544189453 Discriminator loss:  9.602522769991406e-12\n",
      "Iterations:  145000 Epoch:  48 Generator loss:  4.274728298187256 Discriminator loss:  0.0004177006776444614\n",
      "saving the output\n",
      "Iterations:  145200 Epoch:  48 Generator loss:  4.84891414642334 Discriminator loss:  0.0019028913229703903\n",
      "Iterations:  145400 Epoch:  48 Generator loss:  4.074728965759277 Discriminator loss:  0.000967085943557322\n",
      "saving the output\n",
      "Iterations:  145600 Epoch:  48 Generator loss:  3.99550199508667 Discriminator loss:  0.0018994335550814867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [3:33:21<10:58:32, 261.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  145800 Epoch:  49 Generator loss:  4.915835380554199 Discriminator loss:  3.389701305422932e-06\n",
      "Iterations:  146000 Epoch:  49 Generator loss:  4.439243316650391 Discriminator loss:  0.016720417886972427\n",
      "saving the output\n",
      "Iterations:  146200 Epoch:  49 Generator loss:  4.003556251525879 Discriminator loss:  0.014750955626368523\n",
      "Iterations:  146400 Epoch:  49 Generator loss:  4.552509307861328 Discriminator loss:  0.018298456445336342\n",
      "saving the output\n",
      "Iterations:  146600 Epoch:  49 Generator loss:  4.607446670532227 Discriminator loss:  0.06486969441175461\n",
      "Iterations:  146800 Epoch:  49 Generator loss:  4.19871711730957 Discriminator loss:  0.009525716304779053\n",
      "Iterations:  147000 Epoch:  49 Generator loss:  5.049135684967041 Discriminator loss:  0.005931397899985313\n",
      "saving the output\n",
      "Iterations:  147200 Epoch:  49 Generator loss:  3.790593147277832 Discriminator loss:  0.0007729000644758344\n",
      "Iterations:  147400 Epoch:  49 Generator loss:  4.489721298217773 Discriminator loss:  3.0723008421773557e-06\n",
      "saving the output\n",
      "Iterations:  147600 Epoch:  49 Generator loss:  4.5042524337768555 Discriminator loss:  0.018344691023230553\n",
      "Iterations:  147800 Epoch:  49 Generator loss:  5.377020835876465 Discriminator loss:  0.006306088995188475\n",
      "Iterations:  148000 Epoch:  49 Generator loss:  4.425376892089844 Discriminator loss:  9.58168925535574e-07\n",
      "saving the output\n",
      "Iterations:  148200 Epoch:  49 Generator loss:  3.864157199859619 Discriminator loss:  0.0001950317237060517\n",
      "Iterations:  148400 Epoch:  49 Generator loss:  4.074533462524414 Discriminator loss:  5.388058639255178e-07\n",
      "saving the output\n",
      "Iterations:  148600 Epoch:  49 Generator loss:  4.286280632019043 Discriminator loss:  0.0001577491930220276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [3:37:42<10:53:45, 261.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  148800 Epoch:  50 Generator loss:  4.224055767059326 Discriminator loss:  0.013460151851177216\n",
      "Iterations:  149000 Epoch:  50 Generator loss:  5.167863845825195 Discriminator loss:  0.14010298252105713\n",
      "saving the output\n",
      "Iterations:  149200 Epoch:  50 Generator loss:  4.718136787414551 Discriminator loss:  3.18183424496965e-07\n",
      "Iterations:  149400 Epoch:  50 Generator loss:  4.469343662261963 Discriminator loss:  0.10737792402505875\n",
      "saving the output\n",
      "Iterations:  149600 Epoch:  50 Generator loss:  4.4354705810546875 Discriminator loss:  0.002694618422538042\n",
      "Iterations:  149800 Epoch:  50 Generator loss:  5.257829666137695 Discriminator loss:  4.7792502300580963e-05\n",
      "Iterations:  150000 Epoch:  50 Generator loss:  4.383111953735352 Discriminator loss:  0.0362999364733696\n",
      "saving the output\n",
      "Iterations:  150200 Epoch:  50 Generator loss:  4.2834930419921875 Discriminator loss:  0.04459209740161896\n",
      "Iterations:  150400 Epoch:  50 Generator loss:  5.126441955566406 Discriminator loss:  5.60610885713686e-07\n",
      "saving the output\n",
      "Iterations:  150600 Epoch:  50 Generator loss:  4.130476474761963 Discriminator loss:  0.0002677800366654992\n",
      "Iterations:  150800 Epoch:  50 Generator loss:  4.258745193481445 Discriminator loss:  0.022695258259773254\n",
      "Iterations:  151000 Epoch:  50 Generator loss:  3.6649227142333984 Discriminator loss:  0.001748019945807755\n",
      "saving the output\n",
      "Iterations:  151200 Epoch:  50 Generator loss:  4.347807884216309 Discriminator loss:  6.306929208221845e-06\n",
      "Iterations:  151400 Epoch:  50 Generator loss:  3.826539993286133 Discriminator loss:  7.029466360108927e-05\n",
      "saving the output\n",
      "Iterations:  151600 Epoch:  50 Generator loss:  3.94884991645813 Discriminator loss:  0.18205514550209045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [3:42:02<10:48:12, 261.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  151800 Epoch:  51 Generator loss:  4.394070625305176 Discriminator loss:  0.003800047328695655\n",
      "Iterations:  152000 Epoch:  51 Generator loss:  5.083282470703125 Discriminator loss:  1.2234084856288518e-09\n",
      "saving the output\n",
      "Iterations:  152200 Epoch:  51 Generator loss:  4.404094696044922 Discriminator loss:  0.00024339844821952283\n",
      "Iterations:  152400 Epoch:  51 Generator loss:  4.344025135040283 Discriminator loss:  7.924278122573014e-08\n",
      "saving the output\n",
      "Iterations:  152600 Epoch:  51 Generator loss:  4.8912835121154785 Discriminator loss:  0.02579909935593605\n",
      "Iterations:  152800 Epoch:  51 Generator loss:  4.411806106567383 Discriminator loss:  8.627383067505434e-06\n",
      "Iterations:  153000 Epoch:  51 Generator loss:  4.444905757904053 Discriminator loss:  0.04807165265083313\n",
      "saving the output\n",
      "Iterations:  153200 Epoch:  51 Generator loss:  4.751287460327148 Discriminator loss:  9.729592242990748e-09\n",
      "Iterations:  153400 Epoch:  51 Generator loss:  4.032275199890137 Discriminator loss:  0.07709900289773941\n",
      "saving the output\n",
      "Iterations:  153600 Epoch:  51 Generator loss:  4.280984878540039 Discriminator loss:  9.39940036914777e-07\n",
      "Iterations:  153800 Epoch:  51 Generator loss:  5.039159774780273 Discriminator loss:  0.009681956842541695\n",
      "Iterations:  154000 Epoch:  51 Generator loss:  4.235636234283447 Discriminator loss:  6.388391682321526e-08\n",
      "saving the output\n",
      "Iterations:  154200 Epoch:  51 Generator loss:  4.224836349487305 Discriminator loss:  0.05055364593863487\n",
      "Iterations:  154400 Epoch:  51 Generator loss:  4.240832805633545 Discriminator loss:  0.08538663387298584\n",
      "saving the output\n",
      "Iterations:  154600 Epoch:  51 Generator loss:  4.968327522277832 Discriminator loss:  0.0001603267010068521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [3:46:17<10:39:28, 259.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  154800 Epoch:  52 Generator loss:  5.51845645904541 Discriminator loss:  2.2225599138891994e-08\n",
      "Iterations:  155000 Epoch:  52 Generator loss:  4.304089546203613 Discriminator loss:  1.3877017590591123e-11\n",
      "saving the output\n",
      "Iterations:  155200 Epoch:  52 Generator loss:  4.620515823364258 Discriminator loss:  0.1437942087650299\n",
      "Iterations:  155400 Epoch:  52 Generator loss:  5.118136882781982 Discriminator loss:  0.0003287970321252942\n",
      "saving the output\n",
      "Iterations:  155600 Epoch:  52 Generator loss:  4.169803619384766 Discriminator loss:  0.0012995314318686724\n",
      "Iterations:  155800 Epoch:  52 Generator loss:  3.987238883972168 Discriminator loss:  8.746971029427453e-12\n",
      "Iterations:  156000 Epoch:  52 Generator loss:  4.1386566162109375 Discriminator loss:  4.239536792738363e-07\n",
      "saving the output\n",
      "Iterations:  156200 Epoch:  52 Generator loss:  5.819701194763184 Discriminator loss:  0.08044975250959396\n",
      "Iterations:  156400 Epoch:  52 Generator loss:  3.7967755794525146 Discriminator loss:  0.002568951342254877\n",
      "saving the output\n",
      "Iterations:  156600 Epoch:  52 Generator loss:  3.206496238708496 Discriminator loss:  0.24569271504878998\n",
      "Iterations:  156800 Epoch:  52 Generator loss:  4.105171203613281 Discriminator loss:  0.005271757487207651\n",
      "Iterations:  157000 Epoch:  52 Generator loss:  5.6580810546875 Discriminator loss:  2.8179704258946003e-06\n",
      "saving the output\n",
      "Iterations:  157200 Epoch:  52 Generator loss:  4.379482746124268 Discriminator loss:  0.0016766784247010946\n",
      "Iterations:  157400 Epoch:  52 Generator loss:  4.655694961547852 Discriminator loss:  2.7972935967568446e-08\n",
      "saving the output\n",
      "Iterations:  157600 Epoch:  52 Generator loss:  4.932659149169922 Discriminator loss:  2.7670513103039696e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [3:50:41<10:38:20, 260.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  157800 Epoch:  53 Generator loss:  4.574811935424805 Discriminator loss:  8.35209092997502e-08\n",
      "Iterations:  158000 Epoch:  53 Generator loss:  4.761634826660156 Discriminator loss:  0.03787310793995857\n",
      "saving the output\n",
      "Iterations:  158200 Epoch:  53 Generator loss:  5.127126216888428 Discriminator loss:  0.12285204976797104\n",
      "Iterations:  158400 Epoch:  53 Generator loss:  4.29404354095459 Discriminator loss:  9.161594221041014e-07\n",
      "saving the output\n",
      "Iterations:  158600 Epoch:  53 Generator loss:  4.289509296417236 Discriminator loss:  2.8660085718001937e-06\n",
      "Iterations:  158800 Epoch:  53 Generator loss:  3.7936909198760986 Discriminator loss:  1.1062816156481858e-05\n",
      "Iterations:  159000 Epoch:  53 Generator loss:  4.151898384094238 Discriminator loss:  1.0546596058702562e-06\n",
      "saving the output\n",
      "Iterations:  159200 Epoch:  53 Generator loss:  4.214496612548828 Discriminator loss:  0.1378629505634308\n",
      "Iterations:  159400 Epoch:  53 Generator loss:  4.670600891113281 Discriminator loss:  0.014353970997035503\n",
      "saving the output\n",
      "Iterations:  159600 Epoch:  53 Generator loss:  5.5053181648254395 Discriminator loss:  0.00011770847049774602\n",
      "Iterations:  159800 Epoch:  53 Generator loss:  4.410983085632324 Discriminator loss:  0.0019304701127111912\n",
      "Iterations:  160000 Epoch:  53 Generator loss:  6.4191484451293945 Discriminator loss:  7.281716534635052e-06\n",
      "saving the output\n",
      "Iterations:  160200 Epoch:  53 Generator loss:  4.080923080444336 Discriminator loss:  3.1919096272758907e-06\n",
      "Iterations:  160400 Epoch:  53 Generator loss:  3.9286179542541504 Discriminator loss:  1.9483222786220722e-05\n",
      "saving the output\n",
      "Iterations:  160600 Epoch:  53 Generator loss:  5.511964321136475 Discriminator loss:  6.28039470029762e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [3:55:01<10:33:33, 260.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  160800 Epoch:  54 Generator loss:  4.076416969299316 Discriminator loss:  5.728542419092264e-06\n",
      "Iterations:  161000 Epoch:  54 Generator loss:  3.932006359100342 Discriminator loss:  0.0001354510895907879\n",
      "saving the output\n",
      "Iterations:  161200 Epoch:  54 Generator loss:  4.6409101486206055 Discriminator loss:  0.005196720361709595\n",
      "Iterations:  161400 Epoch:  54 Generator loss:  4.210173606872559 Discriminator loss:  0.005498963408172131\n",
      "saving the output\n",
      "Iterations:  161600 Epoch:  54 Generator loss:  3.992208242416382 Discriminator loss:  1.6443833317225653e-07\n",
      "Iterations:  161800 Epoch:  54 Generator loss:  4.920906066894531 Discriminator loss:  4.5755658817370204e-08\n",
      "Iterations:  162000 Epoch:  54 Generator loss:  4.240375518798828 Discriminator loss:  0.0033687478862702847\n",
      "saving the output\n",
      "Iterations:  162200 Epoch:  54 Generator loss:  4.325733661651611 Discriminator loss:  0.00027669817791320384\n",
      "Iterations:  162400 Epoch:  54 Generator loss:  5.217706680297852 Discriminator loss:  2.889227523894533e-08\n",
      "saving the output\n",
      "Iterations:  162600 Epoch:  54 Generator loss:  4.1860432624816895 Discriminator loss:  0.09388357400894165\n",
      "Iterations:  162800 Epoch:  54 Generator loss:  4.032583713531494 Discriminator loss:  0.013864535838365555\n",
      "Iterations:  163000 Epoch:  54 Generator loss:  5.577298164367676 Discriminator loss:  0.0008729285909794271\n",
      "saving the output\n",
      "Iterations:  163200 Epoch:  54 Generator loss:  3.7708873748779297 Discriminator loss:  0.14281588792800903\n",
      "Iterations:  163400 Epoch:  54 Generator loss:  3.611083507537842 Discriminator loss:  0.05306057259440422\n",
      "saving the output\n",
      "Iterations:  163600 Epoch:  54 Generator loss:  4.481664180755615 Discriminator loss:  0.0019695376977324486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [3:59:23<10:30:53, 261.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  163800 Epoch:  55 Generator loss:  4.230298042297363 Discriminator loss:  1.761747626005672e-06\n",
      "Iterations:  164000 Epoch:  55 Generator loss:  4.118847370147705 Discriminator loss:  0.000191560568055138\n",
      "saving the output\n",
      "Iterations:  164200 Epoch:  55 Generator loss:  3.979762077331543 Discriminator loss:  0.0020808670669794083\n",
      "Iterations:  164400 Epoch:  55 Generator loss:  4.6515727043151855 Discriminator loss:  0.012951859273016453\n",
      "saving the output\n",
      "Iterations:  164600 Epoch:  55 Generator loss:  4.3702287673950195 Discriminator loss:  0.2742955684661865\n",
      "Iterations:  164800 Epoch:  55 Generator loss:  3.9690299034118652 Discriminator loss:  0.017586365342140198\n",
      "Iterations:  165000 Epoch:  55 Generator loss:  4.069073677062988 Discriminator loss:  0.05002535507082939\n",
      "saving the output\n",
      "Iterations:  165200 Epoch:  55 Generator loss:  3.911141872406006 Discriminator loss:  0.13669569790363312\n",
      "Iterations:  165400 Epoch:  55 Generator loss:  4.145988941192627 Discriminator loss:  0.008165334351360798\n",
      "saving the output\n",
      "Iterations:  165600 Epoch:  55 Generator loss:  3.9845852851867676 Discriminator loss:  0.005803616251796484\n",
      "Iterations:  165800 Epoch:  55 Generator loss:  3.903378486633301 Discriminator loss:  0.0002919206744991243\n",
      "Iterations:  166000 Epoch:  55 Generator loss:  3.8882670402526855 Discriminator loss:  0.2994801700115204\n",
      "saving the output\n",
      "Iterations:  166200 Epoch:  55 Generator loss:  3.8664844036102295 Discriminator loss:  0.0022117553744465113\n",
      "Iterations:  166400 Epoch:  55 Generator loss:  4.788514137268066 Discriminator loss:  0.00019700064149219543\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [4:03:45<10:26:47, 261.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  166600 Epoch:  56 Generator loss:  4.003961086273193 Discriminator loss:  1.3258406397653744e-05\n",
      "Iterations:  166800 Epoch:  56 Generator loss:  4.9217424392700195 Discriminator loss:  3.69967061430998e-08\n",
      "Iterations:  167000 Epoch:  56 Generator loss:  4.087794303894043 Discriminator loss:  0.02683006227016449\n",
      "saving the output\n",
      "Iterations:  167200 Epoch:  56 Generator loss:  4.031026840209961 Discriminator loss:  0.013280374929308891\n",
      "Iterations:  167400 Epoch:  56 Generator loss:  3.784256935119629 Discriminator loss:  0.0011817894410341978\n",
      "saving the output\n",
      "Iterations:  167600 Epoch:  56 Generator loss:  4.5256195068359375 Discriminator loss:  8.007453544678356e-08\n",
      "Iterations:  167800 Epoch:  56 Generator loss:  3.7336678504943848 Discriminator loss:  3.633686418424986e-08\n",
      "Iterations:  168000 Epoch:  56 Generator loss:  4.545327186584473 Discriminator loss:  0.3053601086139679\n",
      "saving the output\n",
      "Iterations:  168200 Epoch:  56 Generator loss:  3.599888324737549 Discriminator loss:  0.12787768244743347\n",
      "Iterations:  168400 Epoch:  56 Generator loss:  4.855856418609619 Discriminator loss:  0.0004917035112157464\n",
      "saving the output\n",
      "Iterations:  168600 Epoch:  56 Generator loss:  4.71088981628418 Discriminator loss:  0.03132176771759987\n",
      "Iterations:  168800 Epoch:  56 Generator loss:  4.7218170166015625 Discriminator loss:  1.1438187064172212e-09\n",
      "Iterations:  169000 Epoch:  56 Generator loss:  4.870857238769531 Discriminator loss:  6.669791108304679e-11\n",
      "saving the output\n",
      "Iterations:  169200 Epoch:  56 Generator loss:  3.977487325668335 Discriminator loss:  0.00041095222695730627\n",
      "Iterations:  169400 Epoch:  56 Generator loss:  4.4497480392456055 Discriminator loss:  7.342610479099676e-05\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [4:08:04<10:21:16, 260.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  169600 Epoch:  57 Generator loss:  4.326339244842529 Discriminator loss:  0.22087974846363068\n",
      "Iterations:  169800 Epoch:  57 Generator loss:  3.798135280609131 Discriminator loss:  0.014100675471127033\n",
      "Iterations:  170000 Epoch:  57 Generator loss:  4.492542743682861 Discriminator loss:  0.0006835961248725653\n",
      "saving the output\n",
      "Iterations:  170200 Epoch:  57 Generator loss:  3.963829517364502 Discriminator loss:  1.09982011053944e-05\n",
      "Iterations:  170400 Epoch:  57 Generator loss:  3.7599945068359375 Discriminator loss:  5.12904480274301e-05\n",
      "saving the output\n",
      "Iterations:  170600 Epoch:  57 Generator loss:  4.0427751541137695 Discriminator loss:  2.640652851937375e-08\n",
      "Iterations:  170800 Epoch:  57 Generator loss:  4.907341957092285 Discriminator loss:  4.918267182407732e-11\n",
      "Iterations:  171000 Epoch:  57 Generator loss:  3.7201454639434814 Discriminator loss:  0.017033541575074196\n",
      "saving the output\n",
      "Iterations:  171200 Epoch:  57 Generator loss:  4.393045902252197 Discriminator loss:  6.282958597836341e-10\n",
      "Iterations:  171400 Epoch:  57 Generator loss:  4.30696964263916 Discriminator loss:  0.0007861714693717659\n",
      "saving the output\n",
      "Iterations:  171600 Epoch:  57 Generator loss:  3.652273416519165 Discriminator loss:  0.053005319088697433\n",
      "Iterations:  171800 Epoch:  57 Generator loss:  3.762789726257324 Discriminator loss:  2.635925788752047e-08\n",
      "Iterations:  172000 Epoch:  57 Generator loss:  4.128345489501953 Discriminator loss:  3.05099347315263e-05\n",
      "saving the output\n",
      "Iterations:  172200 Epoch:  57 Generator loss:  4.428983688354492 Discriminator loss:  3.9254580030956276e-08\n",
      "Iterations:  172400 Epoch:  57 Generator loss:  4.892557621002197 Discriminator loss:  0.0404253788292408\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [4:12:27<10:18:28, 261.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  172600 Epoch:  58 Generator loss:  4.100440979003906 Discriminator loss:  4.116775016882457e-05\n",
      "Iterations:  172800 Epoch:  58 Generator loss:  3.890392541885376 Discriminator loss:  0.005261153448373079\n",
      "Iterations:  173000 Epoch:  58 Generator loss:  5.752161979675293 Discriminator loss:  3.929478225472849e-06\n",
      "saving the output\n",
      "Iterations:  173200 Epoch:  58 Generator loss:  4.598384857177734 Discriminator loss:  6.935348210390657e-05\n",
      "Iterations:  173400 Epoch:  58 Generator loss:  4.090553283691406 Discriminator loss:  0.007724469527602196\n",
      "saving the output\n",
      "Iterations:  173600 Epoch:  58 Generator loss:  4.021161079406738 Discriminator loss:  0.10957273840904236\n",
      "Iterations:  173800 Epoch:  58 Generator loss:  3.8524298667907715 Discriminator loss:  0.00037394685205072165\n",
      "Iterations:  174000 Epoch:  58 Generator loss:  4.726283073425293 Discriminator loss:  3.041516194457472e-08\n",
      "saving the output\n",
      "Iterations:  174200 Epoch:  58 Generator loss:  4.753026485443115 Discriminator loss:  4.100987280253321e-05\n",
      "Iterations:  174400 Epoch:  58 Generator loss:  4.359007835388184 Discriminator loss:  2.6913916371995583e-05\n",
      "saving the output\n",
      "Iterations:  174600 Epoch:  58 Generator loss:  5.501773357391357 Discriminator loss:  9.26608038298582e-07\n",
      "Iterations:  174800 Epoch:  58 Generator loss:  5.100842475891113 Discriminator loss:  6.427015170062944e-11\n",
      "Iterations:  175000 Epoch:  58 Generator loss:  4.587095260620117 Discriminator loss:  4.2933839816683417e-10\n",
      "saving the output\n",
      "Iterations:  175200 Epoch:  58 Generator loss:  4.12428092956543 Discriminator loss:  0.01619851402938366\n",
      "Iterations:  175400 Epoch:  58 Generator loss:  5.527052879333496 Discriminator loss:  0.030228760093450546\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [4:16:45<10:11:53, 260.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  175600 Epoch:  59 Generator loss:  4.020601749420166 Discriminator loss:  0.000974674301687628\n",
      "Iterations:  175800 Epoch:  59 Generator loss:  4.651933670043945 Discriminator loss:  0.00020511265029199421\n",
      "Iterations:  176000 Epoch:  59 Generator loss:  4.255785942077637 Discriminator loss:  3.041071616749491e-09\n",
      "saving the output\n",
      "Iterations:  176200 Epoch:  59 Generator loss:  4.971766471862793 Discriminator loss:  2.1154313799343072e-05\n",
      "Iterations:  176400 Epoch:  59 Generator loss:  4.253856658935547 Discriminator loss:  0.002506051678210497\n",
      "saving the output\n",
      "Iterations:  176600 Epoch:  59 Generator loss:  5.970670700073242 Discriminator loss:  8.772277482194113e-08\n",
      "Iterations:  176800 Epoch:  59 Generator loss:  4.345054626464844 Discriminator loss:  2.707235147170195e-08\n",
      "Iterations:  177000 Epoch:  59 Generator loss:  3.8635363578796387 Discriminator loss:  0.00020459512597881258\n",
      "saving the output\n",
      "Iterations:  177200 Epoch:  59 Generator loss:  4.361655235290527 Discriminator loss:  0.00017057612421922386\n",
      "Iterations:  177400 Epoch:  59 Generator loss:  3.56211519241333 Discriminator loss:  0.005154888611286879\n",
      "saving the output\n",
      "Iterations:  177600 Epoch:  59 Generator loss:  4.864895820617676 Discriminator loss:  0.03246307373046875\n",
      "Iterations:  177800 Epoch:  59 Generator loss:  4.379297256469727 Discriminator loss:  5.0785526894969735e-09\n",
      "Iterations:  178000 Epoch:  59 Generator loss:  4.153443336486816 Discriminator loss:  0.002564025577157736\n",
      "saving the output\n",
      "Iterations:  178200 Epoch:  59 Generator loss:  5.711020469665527 Discriminator loss:  1.3157361536286771e-05\n",
      "Iterations:  178400 Epoch:  59 Generator loss:  4.721907138824463 Discriminator loss:  1.6821101098685176e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [4:21:06<10:08:11, 260.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  178600 Epoch:  60 Generator loss:  4.908444404602051 Discriminator loss:  2.368230234139901e-08\n",
      "Iterations:  178800 Epoch:  60 Generator loss:  4.409642219543457 Discriminator loss:  3.0347135179908946e-05\n",
      "Iterations:  179000 Epoch:  60 Generator loss:  4.2778167724609375 Discriminator loss:  0.00015866935427766293\n",
      "saving the output\n",
      "Iterations:  179200 Epoch:  60 Generator loss:  3.9591596126556396 Discriminator loss:  4.439993404048437e-07\n",
      "Iterations:  179400 Epoch:  60 Generator loss:  3.769317150115967 Discriminator loss:  0.0684967190027237\n",
      "saving the output\n",
      "Iterations:  179600 Epoch:  60 Generator loss:  3.819336414337158 Discriminator loss:  0.015466313809156418\n",
      "Iterations:  179800 Epoch:  60 Generator loss:  5.433245658874512 Discriminator loss:  8.518624916575845e-09\n",
      "Iterations:  180000 Epoch:  60 Generator loss:  4.7040815353393555 Discriminator loss:  0.0016460091574117541\n",
      "saving the output\n",
      "Iterations:  180200 Epoch:  60 Generator loss:  4.432896614074707 Discriminator loss:  1.0836672572622774e-06\n",
      "Iterations:  180400 Epoch:  60 Generator loss:  4.4443135261535645 Discriminator loss:  9.737402706377907e-07\n",
      "saving the output\n",
      "Iterations:  180600 Epoch:  60 Generator loss:  5.730615615844727 Discriminator loss:  1.6786614764896512e-07\n",
      "Iterations:  180800 Epoch:  60 Generator loss:  4.813532829284668 Discriminator loss:  2.682576814549975e-05\n",
      "Iterations:  181000 Epoch:  60 Generator loss:  3.949321746826172 Discriminator loss:  0.0047253151424229145\n",
      "saving the output\n",
      "Iterations:  181200 Epoch:  60 Generator loss:  5.045851707458496 Discriminator loss:  0.0005316698807291687\n",
      "Iterations:  181400 Epoch:  60 Generator loss:  3.4993553161621094 Discriminator loss:  0.18483035266399384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [4:25:25<10:02:04, 259.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  181600 Epoch:  61 Generator loss:  3.8624558448791504 Discriminator loss:  5.3213752835290506e-05\n",
      "Iterations:  181800 Epoch:  61 Generator loss:  4.628801345825195 Discriminator loss:  0.0034847420174628496\n",
      "Iterations:  182000 Epoch:  61 Generator loss:  3.9863030910491943 Discriminator loss:  0.00786676350980997\n",
      "saving the output\n",
      "Iterations:  182200 Epoch:  61 Generator loss:  3.970747947692871 Discriminator loss:  0.03802596032619476\n",
      "Iterations:  182400 Epoch:  61 Generator loss:  4.840551853179932 Discriminator loss:  0.0011952186468988657\n",
      "saving the output\n",
      "Iterations:  182600 Epoch:  61 Generator loss:  5.014643669128418 Discriminator loss:  3.079782686654653e-07\n",
      "Iterations:  182800 Epoch:  61 Generator loss:  5.293542385101318 Discriminator loss:  2.704359303606907e-06\n",
      "Iterations:  183000 Epoch:  61 Generator loss:  3.795738697052002 Discriminator loss:  4.755057858574219e-08\n",
      "saving the output\n",
      "Iterations:  183200 Epoch:  61 Generator loss:  3.4580564498901367 Discriminator loss:  0.04462937265634537\n",
      "Iterations:  183400 Epoch:  61 Generator loss:  4.194770336151123 Discriminator loss:  8.446397470329714e-10\n",
      "saving the output\n",
      "Iterations:  183600 Epoch:  61 Generator loss:  4.09694242477417 Discriminator loss:  0.0057694450952112675\n",
      "Iterations:  183800 Epoch:  61 Generator loss:  3.939535617828369 Discriminator loss:  8.746471280574042e-07\n",
      "Iterations:  184000 Epoch:  61 Generator loss:  3.9626896381378174 Discriminator loss:  0.00010668651520973071\n",
      "saving the output\n",
      "Iterations:  184200 Epoch:  61 Generator loss:  4.1418843269348145 Discriminator loss:  0.06315421313047409\n",
      "Iterations:  184400 Epoch:  61 Generator loss:  3.9858546257019043 Discriminator loss:  0.13682274520397186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [4:29:45<9:57:50, 259.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  184600 Epoch:  62 Generator loss:  4.3116960525512695 Discriminator loss:  1.9357676350750808e-08\n",
      "Iterations:  184800 Epoch:  62 Generator loss:  3.6860849857330322 Discriminator loss:  0.2285740226507187\n",
      "Iterations:  185000 Epoch:  62 Generator loss:  4.514885425567627 Discriminator loss:  4.8322050361093716e-08\n",
      "saving the output\n",
      "Iterations:  185200 Epoch:  62 Generator loss:  3.8748104572296143 Discriminator loss:  0.07074093073606491\n",
      "Iterations:  185400 Epoch:  62 Generator loss:  3.9420080184936523 Discriminator loss:  6.394913487639542e-09\n",
      "saving the output\n",
      "Iterations:  185600 Epoch:  62 Generator loss:  4.131948471069336 Discriminator loss:  0.17864686250686646\n",
      "Iterations:  185800 Epoch:  62 Generator loss:  3.8773984909057617 Discriminator loss:  0.0021116002462804317\n",
      "Iterations:  186000 Epoch:  62 Generator loss:  4.185266494750977 Discriminator loss:  7.298857962467764e-09\n",
      "saving the output\n",
      "Iterations:  186200 Epoch:  62 Generator loss:  4.252893447875977 Discriminator loss:  1.7092984805344713e-09\n",
      "Iterations:  186400 Epoch:  62 Generator loss:  4.137873649597168 Discriminator loss:  1.8314357808080217e-09\n",
      "saving the output\n",
      "Iterations:  186600 Epoch:  62 Generator loss:  4.207817554473877 Discriminator loss:  1.6570875231991522e-06\n",
      "Iterations:  186800 Epoch:  62 Generator loss:  4.1912126541137695 Discriminator loss:  0.0024322541430592537\n",
      "Iterations:  187000 Epoch:  62 Generator loss:  3.5993812084198 Discriminator loss:  0.1406792551279068\n",
      "saving the output\n",
      "Iterations:  187200 Epoch:  62 Generator loss:  5.2825927734375 Discriminator loss:  3.0282456009445013e-06\n",
      "Iterations:  187400 Epoch:  62 Generator loss:  3.5980992317199707 Discriminator loss:  3.0633905225840863e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [4:34:04<9:53:15, 259.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  187600 Epoch:  63 Generator loss:  3.990755081176758 Discriminator loss:  2.4555276922910707e-07\n",
      "Iterations:  187800 Epoch:  63 Generator loss:  5.4349164962768555 Discriminator loss:  9.495610356680118e-06\n",
      "Iterations:  188000 Epoch:  63 Generator loss:  4.104657173156738 Discriminator loss:  0.24354876577854156\n",
      "saving the output\n",
      "Iterations:  188200 Epoch:  63 Generator loss:  3.9779367446899414 Discriminator loss:  4.826657686862745e-07\n",
      "Iterations:  188400 Epoch:  63 Generator loss:  3.688122272491455 Discriminator loss:  8.929749128583353e-06\n",
      "saving the output\n",
      "Iterations:  188600 Epoch:  63 Generator loss:  4.96405029296875 Discriminator loss:  0.07003210484981537\n",
      "Iterations:  188800 Epoch:  63 Generator loss:  4.040151119232178 Discriminator loss:  0.0016923709772527218\n",
      "Iterations:  189000 Epoch:  63 Generator loss:  4.689698219299316 Discriminator loss:  0.0009193102596327662\n",
      "saving the output\n",
      "Iterations:  189200 Epoch:  63 Generator loss:  4.432314872741699 Discriminator loss:  6.829003915088602e-14\n",
      "Iterations:  189400 Epoch:  63 Generator loss:  5.135324478149414 Discriminator loss:  1.0582870402231492e-07\n",
      "saving the output\n",
      "Iterations:  189600 Epoch:  63 Generator loss:  4.069843769073486 Discriminator loss:  1.365861407975899e-05\n",
      "Iterations:  189800 Epoch:  63 Generator loss:  4.100985527038574 Discriminator loss:  0.0014649805380031466\n",
      "Iterations:  190000 Epoch:  63 Generator loss:  5.041097640991211 Discriminator loss:  9.861499095618897e-14\n",
      "saving the output\n",
      "Iterations:  190200 Epoch:  63 Generator loss:  4.505286693572998 Discriminator loss:  0.04803457483649254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [4:38:22<9:47:51, 259.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  190400 Epoch:  64 Generator loss:  5.144837856292725 Discriminator loss:  3.685516891671625e-10\n",
      "saving the output\n",
      "Iterations:  190600 Epoch:  64 Generator loss:  4.353007793426514 Discriminator loss:  6.990844014787001e-11\n",
      "Iterations:  190800 Epoch:  64 Generator loss:  4.518466949462891 Discriminator loss:  0.00014090781041886657\n",
      "Iterations:  191000 Epoch:  64 Generator loss:  4.509159088134766 Discriminator loss:  0.011838559992611408\n",
      "saving the output\n",
      "Iterations:  191200 Epoch:  64 Generator loss:  4.590672969818115 Discriminator loss:  0.07506418228149414\n",
      "Iterations:  191400 Epoch:  64 Generator loss:  5.468560218811035 Discriminator loss:  0.00010545863915467635\n",
      "saving the output\n",
      "Iterations:  191600 Epoch:  64 Generator loss:  5.292108535766602 Discriminator loss:  9.456690577280824e-07\n",
      "Iterations:  191800 Epoch:  64 Generator loss:  5.4933624267578125 Discriminator loss:  1.713985758877712e-10\n",
      "Iterations:  192000 Epoch:  64 Generator loss:  3.8951549530029297 Discriminator loss:  4.203539916147747e-08\n",
      "saving the output\n",
      "Iterations:  192200 Epoch:  64 Generator loss:  3.989518642425537 Discriminator loss:  3.276925172185363e-13\n",
      "Iterations:  192400 Epoch:  64 Generator loss:  3.9925537109375 Discriminator loss:  0.010456016287207603\n",
      "saving the output\n",
      "Iterations:  192600 Epoch:  64 Generator loss:  3.89383864402771 Discriminator loss:  0.0017248416552320123\n",
      "Iterations:  192800 Epoch:  64 Generator loss:  4.1014933586120605 Discriminator loss:  0.00015152842388488352\n",
      "Iterations:  193000 Epoch:  64 Generator loss:  3.279419422149658 Discriminator loss:  0.0010865350486710668\n",
      "saving the output\n",
      "Iterations:  193200 Epoch:  64 Generator loss:  3.8358237743377686 Discriminator loss:  0.001009510364383459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [4:42:43<9:44:25, 259.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  193400 Epoch:  65 Generator loss:  4.07762336730957 Discriminator loss:  0.030961357057094574\n",
      "saving the output\n",
      "Iterations:  193600 Epoch:  65 Generator loss:  3.8456218242645264 Discriminator loss:  8.51495158826765e-08\n",
      "Iterations:  193800 Epoch:  65 Generator loss:  3.8508336544036865 Discriminator loss:  4.518560217547929e-06\n",
      "Iterations:  194000 Epoch:  65 Generator loss:  3.795504331588745 Discriminator loss:  0.020719939842820168\n",
      "saving the output\n",
      "Iterations:  194200 Epoch:  65 Generator loss:  5.060971260070801 Discriminator loss:  0.020664382725954056\n",
      "Iterations:  194400 Epoch:  65 Generator loss:  4.001448631286621 Discriminator loss:  0.0007495046593248844\n",
      "saving the output\n",
      "Iterations:  194600 Epoch:  65 Generator loss:  4.046119689941406 Discriminator loss:  2.26495818628214e-11\n",
      "Iterations:  194800 Epoch:  65 Generator loss:  4.906710624694824 Discriminator loss:  0.00048178393626585603\n",
      "Iterations:  195000 Epoch:  65 Generator loss:  4.840545654296875 Discriminator loss:  0.002502704504877329\n",
      "saving the output\n",
      "Iterations:  195200 Epoch:  65 Generator loss:  4.975880146026611 Discriminator loss:  9.866144523584808e-08\n",
      "Iterations:  195400 Epoch:  65 Generator loss:  4.428208351135254 Discriminator loss:  0.00023511674953624606\n",
      "saving the output\n",
      "Iterations:  195600 Epoch:  65 Generator loss:  3.687504529953003 Discriminator loss:  0.2933393716812134\n",
      "Iterations:  195800 Epoch:  65 Generator loss:  4.31118631362915 Discriminator loss:  1.4215386680282993e-13\n",
      "Iterations:  196000 Epoch:  65 Generator loss:  4.105440139770508 Discriminator loss:  1.8732959006229066e-07\n",
      "saving the output\n",
      "Iterations:  196200 Epoch:  65 Generator loss:  4.991206169128418 Discriminator loss:  1.220648804256541e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [4:47:02<9:39:47, 259.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  196400 Epoch:  66 Generator loss:  4.664032936096191 Discriminator loss:  4.373282180836213e-09\n",
      "saving the output\n",
      "Iterations:  196600 Epoch:  66 Generator loss:  4.779994487762451 Discriminator loss:  0.00012159429752500728\n",
      "Iterations:  196800 Epoch:  66 Generator loss:  4.6157426834106445 Discriminator loss:  4.143228943576105e-05\n",
      "Iterations:  197000 Epoch:  66 Generator loss:  4.1768798828125 Discriminator loss:  7.821233105609338e-10\n",
      "saving the output\n",
      "Iterations:  197200 Epoch:  66 Generator loss:  3.781588554382324 Discriminator loss:  0.0025702258571982384\n",
      "Iterations:  197400 Epoch:  66 Generator loss:  4.2502546310424805 Discriminator loss:  1.3433597984002787e-11\n",
      "saving the output\n",
      "Iterations:  197600 Epoch:  66 Generator loss:  5.068133354187012 Discriminator loss:  4.465543679543771e-05\n",
      "Iterations:  197800 Epoch:  66 Generator loss:  3.6006383895874023 Discriminator loss:  2.2084514057496563e-05\n",
      "Iterations:  198000 Epoch:  66 Generator loss:  4.590516090393066 Discriminator loss:  9.070512396736063e-11\n",
      "saving the output\n",
      "Iterations:  198200 Epoch:  66 Generator loss:  4.11058235168457 Discriminator loss:  0.00028418240253813565\n",
      "Iterations:  198400 Epoch:  66 Generator loss:  4.075962066650391 Discriminator loss:  2.207844318036223e-06\n",
      "saving the output\n",
      "Iterations:  198600 Epoch:  66 Generator loss:  4.758081436157227 Discriminator loss:  0.004928205162286758\n",
      "Iterations:  198800 Epoch:  66 Generator loss:  3.8831987380981445 Discriminator loss:  2.2139532518394844e-07\n",
      "Iterations:  199000 Epoch:  66 Generator loss:  4.400585174560547 Discriminator loss:  6.085838499814145e-10\n",
      "saving the output\n",
      "Iterations:  199200 Epoch:  66 Generator loss:  4.716259002685547 Discriminator loss:  5.548876289007687e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [4:51:23<9:36:14, 259.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  199400 Epoch:  67 Generator loss:  4.363008975982666 Discriminator loss:  6.08237127330824e-10\n",
      "saving the output\n",
      "Iterations:  199600 Epoch:  67 Generator loss:  4.145794868469238 Discriminator loss:  2.2377309505827725e-05\n",
      "Iterations:  199800 Epoch:  67 Generator loss:  4.749929428100586 Discriminator loss:  1.0057796373530437e-07\n",
      "Iterations:  200000 Epoch:  67 Generator loss:  4.345223903656006 Discriminator loss:  4.3811181349440176e-09\n",
      "saving the output\n",
      "Iterations:  200200 Epoch:  67 Generator loss:  4.6967644691467285 Discriminator loss:  8.695190345520132e-09\n",
      "Iterations:  200400 Epoch:  67 Generator loss:  3.9994773864746094 Discriminator loss:  0.10077151656150818\n",
      "saving the output\n",
      "Iterations:  200600 Epoch:  67 Generator loss:  3.7908594608306885 Discriminator loss:  2.7187078899260086e-07\n",
      "Iterations:  200800 Epoch:  67 Generator loss:  4.320672512054443 Discriminator loss:  5.483672893547009e-08\n",
      "Iterations:  201000 Epoch:  67 Generator loss:  5.1039934158325195 Discriminator loss:  1.9213654918383977e-14\n",
      "saving the output\n",
      "Iterations:  201200 Epoch:  67 Generator loss:  3.3455867767333984 Discriminator loss:  0.05096371844410896\n",
      "Iterations:  201400 Epoch:  67 Generator loss:  4.522643566131592 Discriminator loss:  2.4311363686080334e-11\n",
      "saving the output\n",
      "Iterations:  201600 Epoch:  67 Generator loss:  4.430936336517334 Discriminator loss:  1.767786130812965e-07\n",
      "Iterations:  201800 Epoch:  67 Generator loss:  3.9617605209350586 Discriminator loss:  1.3767820217225335e-10\n",
      "Iterations:  202000 Epoch:  67 Generator loss:  4.347521781921387 Discriminator loss:  4.865716718427393e-09\n",
      "saving the output\n",
      "Iterations:  202200 Epoch:  67 Generator loss:  3.8547308444976807 Discriminator loss:  6.09149508612461e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [4:55:45<9:32:54, 260.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  202400 Epoch:  68 Generator loss:  3.71630859375 Discriminator loss:  0.02693432755768299\n",
      "saving the output\n",
      "Iterations:  202600 Epoch:  68 Generator loss:  4.361148834228516 Discriminator loss:  0.06323042511940002\n",
      "Iterations:  202800 Epoch:  68 Generator loss:  3.4162118434906006 Discriminator loss:  3.278863687228295e-06\n",
      "Iterations:  203000 Epoch:  68 Generator loss:  4.713931083679199 Discriminator loss:  9.67054916145571e-08\n",
      "saving the output\n",
      "Iterations:  203200 Epoch:  68 Generator loss:  4.829317569732666 Discriminator loss:  0.0046228449791669846\n",
      "Iterations:  203400 Epoch:  68 Generator loss:  4.441037178039551 Discriminator loss:  1.8247098276802376e-09\n",
      "saving the output\n",
      "Iterations:  203600 Epoch:  68 Generator loss:  5.022481918334961 Discriminator loss:  0.0002043119166046381\n",
      "Iterations:  203800 Epoch:  68 Generator loss:  5.659569263458252 Discriminator loss:  1.8151280528400093e-05\n",
      "Iterations:  204000 Epoch:  68 Generator loss:  4.502058029174805 Discriminator loss:  0.0059022982604801655\n",
      "saving the output\n",
      "Iterations:  204200 Epoch:  68 Generator loss:  4.003195285797119 Discriminator loss:  0.003942788112908602\n",
      "Iterations:  204400 Epoch:  68 Generator loss:  3.812053918838501 Discriminator loss:  0.0008134993258863688\n",
      "saving the output\n",
      "Iterations:  204600 Epoch:  68 Generator loss:  4.821685791015625 Discriminator loss:  2.311277853550564e-07\n",
      "Iterations:  204800 Epoch:  68 Generator loss:  3.8121886253356934 Discriminator loss:  1.160976052978508e-14\n",
      "Iterations:  205000 Epoch:  68 Generator loss:  3.886767625808716 Discriminator loss:  4.731213994091377e-05\n",
      "saving the output\n",
      "Iterations:  205200 Epoch:  68 Generator loss:  3.776188850402832 Discriminator loss:  3.214869481737992e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [5:00:05<9:28:45, 260.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  205400 Epoch:  69 Generator loss:  4.643893241882324 Discriminator loss:  4.414537215780001e-06\n",
      "saving the output\n",
      "Iterations:  205600 Epoch:  69 Generator loss:  4.310474395751953 Discriminator loss:  3.05475800210786e-09\n",
      "Iterations:  205800 Epoch:  69 Generator loss:  4.483677387237549 Discriminator loss:  9.174220394925214e-06\n",
      "Iterations:  206000 Epoch:  69 Generator loss:  5.221699237823486 Discriminator loss:  1.0266259664604149e-07\n",
      "saving the output\n",
      "Iterations:  206200 Epoch:  69 Generator loss:  4.291876792907715 Discriminator loss:  0.008486584760248661\n",
      "Iterations:  206400 Epoch:  69 Generator loss:  4.320556640625 Discriminator loss:  6.093735738232908e-09\n",
      "saving the output\n",
      "Iterations:  206600 Epoch:  69 Generator loss:  4.727165222167969 Discriminator loss:  8.586682270106394e-06\n",
      "Iterations:  206800 Epoch:  69 Generator loss:  3.923006296157837 Discriminator loss:  9.952393753565048e-08\n",
      "Iterations:  207000 Epoch:  69 Generator loss:  4.093695163726807 Discriminator loss:  0.01890750043094158\n",
      "saving the output\n",
      "Iterations:  207200 Epoch:  69 Generator loss:  4.353067874908447 Discriminator loss:  0.0005438441876322031\n",
      "Iterations:  207400 Epoch:  69 Generator loss:  3.7770180702209473 Discriminator loss:  1.7212499869856401e-07\n",
      "saving the output\n",
      "Iterations:  207600 Epoch:  69 Generator loss:  4.838543891906738 Discriminator loss:  1.9494696967825575e-09\n",
      "Iterations:  207800 Epoch:  69 Generator loss:  3.978107452392578 Discriminator loss:  8.212948188202063e-08\n",
      "Iterations:  208000 Epoch:  69 Generator loss:  3.769735336303711 Discriminator loss:  0.012015832588076591\n",
      "saving the output\n",
      "Iterations:  208200 Epoch:  69 Generator loss:  4.131955146789551 Discriminator loss:  2.4790146824216208e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [5:04:27<9:24:58, 260.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  208400 Epoch:  70 Generator loss:  3.4790396690368652 Discriminator loss:  0.08045496046543121\n",
      "saving the output\n",
      "Iterations:  208600 Epoch:  70 Generator loss:  4.0385332107543945 Discriminator loss:  0.09387049078941345\n",
      "Iterations:  208800 Epoch:  70 Generator loss:  5.572602272033691 Discriminator loss:  1.9792862460121796e-08\n",
      "Iterations:  209000 Epoch:  70 Generator loss:  4.609230041503906 Discriminator loss:  1.1148920009418362e-07\n",
      "saving the output\n",
      "Iterations:  209200 Epoch:  70 Generator loss:  3.499577045440674 Discriminator loss:  4.5074491936247796e-05\n",
      "Iterations:  209400 Epoch:  70 Generator loss:  4.499337196350098 Discriminator loss:  0.2099519670009613\n",
      "saving the output\n",
      "Iterations:  209600 Epoch:  70 Generator loss:  3.9168620109558105 Discriminator loss:  1.7143729280633124e-07\n",
      "Iterations:  209800 Epoch:  70 Generator loss:  3.4275567531585693 Discriminator loss:  3.871261924359715e-06\n",
      "Iterations:  210000 Epoch:  70 Generator loss:  4.009180068969727 Discriminator loss:  3.970195550095923e-08\n",
      "saving the output\n",
      "Iterations:  210200 Epoch:  70 Generator loss:  4.27115535736084 Discriminator loss:  0.00015707904822193086\n",
      "Iterations:  210400 Epoch:  70 Generator loss:  4.084229469299316 Discriminator loss:  1.383742613825234e-07\n",
      "saving the output\n",
      "Iterations:  210600 Epoch:  70 Generator loss:  4.622105598449707 Discriminator loss:  0.0009156846790574491\n",
      "Iterations:  210800 Epoch:  70 Generator loss:  4.235302448272705 Discriminator loss:  6.527270670630969e-06\n",
      "Iterations:  211000 Epoch:  70 Generator loss:  4.059383392333984 Discriminator loss:  0.3299865126609802\n",
      "saving the output\n",
      "Iterations:  211200 Epoch:  70 Generator loss:  4.620291709899902 Discriminator loss:  6.315718781291224e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [5:08:47<9:20:06, 260.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  211400 Epoch:  71 Generator loss:  3.668907880783081 Discriminator loss:  1.6239115211647004e-05\n",
      "saving the output\n",
      "Iterations:  211600 Epoch:  71 Generator loss:  6.113598823547363 Discriminator loss:  0.0069145988672971725\n",
      "Iterations:  211800 Epoch:  71 Generator loss:  4.408524990081787 Discriminator loss:  0.004025579895824194\n",
      "Iterations:  212000 Epoch:  71 Generator loss:  3.997586250305176 Discriminator loss:  0.0008915440994314849\n",
      "saving the output\n",
      "Iterations:  212200 Epoch:  71 Generator loss:  4.656116962432861 Discriminator loss:  1.2664900239656163e-09\n",
      "Iterations:  212400 Epoch:  71 Generator loss:  3.7396554946899414 Discriminator loss:  0.20140810310840607\n",
      "saving the output\n",
      "Iterations:  212600 Epoch:  71 Generator loss:  4.297906875610352 Discriminator loss:  8.632550512095716e-14\n",
      "Iterations:  212800 Epoch:  71 Generator loss:  3.518456220626831 Discriminator loss:  2.17251836147625e-05\n",
      "Iterations:  213000 Epoch:  71 Generator loss:  4.168794631958008 Discriminator loss:  4.471226340563295e-12\n",
      "saving the output\n",
      "Iterations:  213200 Epoch:  71 Generator loss:  4.742916584014893 Discriminator loss:  1.8267946044758787e-09\n",
      "Iterations:  213400 Epoch:  71 Generator loss:  3.4098849296569824 Discriminator loss:  0.10103005170822144\n",
      "saving the output\n",
      "Iterations:  213600 Epoch:  71 Generator loss:  4.374096870422363 Discriminator loss:  0.17695733904838562\n",
      "Iterations:  213800 Epoch:  71 Generator loss:  4.729976654052734 Discriminator loss:  7.361203557820772e-08\n",
      "Iterations:  214000 Epoch:  71 Generator loss:  4.004480361938477 Discriminator loss:  0.03458999842405319\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [5:13:08<9:16:23, 260.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  214200 Epoch:  72 Generator loss:  4.024886131286621 Discriminator loss:  0.003509691683575511\n",
      "Iterations:  214400 Epoch:  72 Generator loss:  4.294051170349121 Discriminator loss:  5.249262903816998e-05\n",
      "saving the output\n",
      "Iterations:  214600 Epoch:  72 Generator loss:  3.831939697265625 Discriminator loss:  0.3221127688884735\n",
      "Iterations:  214800 Epoch:  72 Generator loss:  4.20817756652832 Discriminator loss:  2.402685481683875e-07\n",
      "Iterations:  215000 Epoch:  72 Generator loss:  4.09293794631958 Discriminator loss:  1.8246660848930674e-09\n",
      "saving the output\n",
      "Iterations:  215200 Epoch:  72 Generator loss:  4.224365234375 Discriminator loss:  6.690723530766718e-09\n",
      "Iterations:  215400 Epoch:  72 Generator loss:  4.1486897468566895 Discriminator loss:  1.4112846308256266e-11\n",
      "saving the output\n",
      "Iterations:  215600 Epoch:  72 Generator loss:  4.228105545043945 Discriminator loss:  0.003744010580703616\n",
      "Iterations:  215800 Epoch:  72 Generator loss:  4.028921127319336 Discriminator loss:  0.004933573305606842\n",
      "Iterations:  216000 Epoch:  72 Generator loss:  4.261819839477539 Discriminator loss:  6.858542622723007e-10\n",
      "saving the output\n",
      "Iterations:  216200 Epoch:  72 Generator loss:  4.184649467468262 Discriminator loss:  4.0609737794738976e-08\n",
      "Iterations:  216400 Epoch:  72 Generator loss:  4.830378532409668 Discriminator loss:  1.0495561042489499e-07\n",
      "saving the output\n",
      "Iterations:  216600 Epoch:  72 Generator loss:  4.177518844604492 Discriminator loss:  2.995924478454981e-05\n",
      "Iterations:  216800 Epoch:  72 Generator loss:  4.546627998352051 Discriminator loss:  1.2164766971523022e-09\n",
      "Iterations:  217000 Epoch:  72 Generator loss:  5.070869445800781 Discriminator loss:  0.011272726580500603\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [5:17:27<9:10:51, 260.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  217200 Epoch:  73 Generator loss:  5.3541669845581055 Discriminator loss:  5.080745424379529e-08\n",
      "Iterations:  217400 Epoch:  73 Generator loss:  4.353549003601074 Discriminator loss:  0.02766931802034378\n",
      "saving the output\n",
      "Iterations:  217600 Epoch:  73 Generator loss:  4.944590091705322 Discriminator loss:  0.07335224002599716\n",
      "Iterations:  217800 Epoch:  73 Generator loss:  3.766883134841919 Discriminator loss:  0.00011195008846698329\n",
      "Iterations:  218000 Epoch:  73 Generator loss:  5.034396648406982 Discriminator loss:  2.8919191663590027e-07\n",
      "saving the output\n",
      "Iterations:  218200 Epoch:  73 Generator loss:  5.7910966873168945 Discriminator loss:  4.9074205810129e-10\n",
      "Iterations:  218400 Epoch:  73 Generator loss:  3.815260887145996 Discriminator loss:  0.03579873591661453\n",
      "saving the output\n",
      "Iterations:  218600 Epoch:  73 Generator loss:  4.344491004943848 Discriminator loss:  4.810074460692704e-05\n",
      "Iterations:  218800 Epoch:  73 Generator loss:  3.937967300415039 Discriminator loss:  5.310108826961368e-05\n",
      "Iterations:  219000 Epoch:  73 Generator loss:  3.4551568031311035 Discriminator loss:  7.047320593756012e-08\n",
      "saving the output\n",
      "Iterations:  219200 Epoch:  73 Generator loss:  3.7696893215179443 Discriminator loss:  1.0357339306210633e-05\n",
      "Iterations:  219400 Epoch:  73 Generator loss:  4.562739372253418 Discriminator loss:  2.3926440357788497e-15\n",
      "saving the output\n",
      "Iterations:  219600 Epoch:  73 Generator loss:  4.853479862213135 Discriminator loss:  0.00016576513007748872\n",
      "Iterations:  219800 Epoch:  73 Generator loss:  4.400552749633789 Discriminator loss:  7.840308740014734e-07\n",
      "Iterations:  220000 Epoch:  73 Generator loss:  4.36668062210083 Discriminator loss:  5.659684120473685e-06\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74/200 [5:21:46<9:05:33, 259.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  220200 Epoch:  74 Generator loss:  4.484421730041504 Discriminator loss:  6.690326959102322e-09\n",
      "Iterations:  220400 Epoch:  74 Generator loss:  4.337428569793701 Discriminator loss:  0.060560792684555054\n",
      "saving the output\n",
      "Iterations:  220600 Epoch:  74 Generator loss:  4.78057861328125 Discriminator loss:  1.6422953663663975e-08\n",
      "Iterations:  220800 Epoch:  74 Generator loss:  4.25277042388916 Discriminator loss:  0.00022511297720484436\n",
      "Iterations:  221000 Epoch:  74 Generator loss:  3.7977776527404785 Discriminator loss:  1.6422267989923967e-08\n",
      "saving the output\n",
      "Iterations:  221200 Epoch:  74 Generator loss:  3.683685541152954 Discriminator loss:  3.9826825171118685e-10\n",
      "Iterations:  221400 Epoch:  74 Generator loss:  3.895474672317505 Discriminator loss:  2.404835140623618e-05\n",
      "saving the output\n",
      "Iterations:  221600 Epoch:  74 Generator loss:  4.3232340812683105 Discriminator loss:  0.002428859006613493\n",
      "Iterations:  221800 Epoch:  74 Generator loss:  4.8397626876831055 Discriminator loss:  4.105860114123061e-07\n",
      "Iterations:  222000 Epoch:  74 Generator loss:  4.410177230834961 Discriminator loss:  5.392567989370711e-11\n",
      "saving the output\n",
      "Iterations:  222200 Epoch:  74 Generator loss:  4.2406134605407715 Discriminator loss:  5.086879806270872e-09\n",
      "Iterations:  222400 Epoch:  74 Generator loss:  4.272006988525391 Discriminator loss:  2.0386627497259724e-08\n",
      "saving the output\n",
      "Iterations:  222600 Epoch:  74 Generator loss:  4.359012603759766 Discriminator loss:  6.084228676428438e-10\n",
      "Iterations:  222800 Epoch:  74 Generator loss:  5.376759052276611 Discriminator loss:  2.8224820880495827e-07\n",
      "Iterations:  223000 Epoch:  74 Generator loss:  4.009129524230957 Discriminator loss:  2.1030949937994592e-05\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [5:26:03<8:59:39, 259.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  223200 Epoch:  75 Generator loss:  4.9489898681640625 Discriminator loss:  0.0023535690270364285\n",
      "Iterations:  223400 Epoch:  75 Generator loss:  4.983838081359863 Discriminator loss:  3.803083745879121e-05\n",
      "saving the output\n",
      "Iterations:  223600 Epoch:  75 Generator loss:  4.122123718261719 Discriminator loss:  1.3684739030850324e-07\n",
      "Iterations:  223800 Epoch:  75 Generator loss:  4.123343467712402 Discriminator loss:  3.1554442218861833e-12\n",
      "Iterations:  224000 Epoch:  75 Generator loss:  3.61008882522583 Discriminator loss:  5.464451078296406e-07\n",
      "saving the output\n",
      "Iterations:  224200 Epoch:  75 Generator loss:  4.703003883361816 Discriminator loss:  0.0020684399642050266\n",
      "Iterations:  224400 Epoch:  75 Generator loss:  3.8899049758911133 Discriminator loss:  0.456063449382782\n",
      "saving the output\n",
      "Iterations:  224600 Epoch:  75 Generator loss:  4.564975261688232 Discriminator loss:  0.0019811152014881372\n",
      "Iterations:  224800 Epoch:  75 Generator loss:  4.610543251037598 Discriminator loss:  2.599492290755734e-06\n",
      "Iterations:  225000 Epoch:  75 Generator loss:  3.8319759368896484 Discriminator loss:  0.08682086318731308\n",
      "saving the output\n",
      "Iterations:  225200 Epoch:  75 Generator loss:  4.800307273864746 Discriminator loss:  1.4437289337365655e-06\n",
      "Iterations:  225400 Epoch:  75 Generator loss:  5.173893928527832 Discriminator loss:  3.0212947876862017e-06\n",
      "saving the output\n",
      "Iterations:  225600 Epoch:  75 Generator loss:  4.001265525817871 Discriminator loss:  0.0009599504410289228\n",
      "Iterations:  225800 Epoch:  75 Generator loss:  3.963303804397583 Discriminator loss:  0.02115953527390957\n",
      "Iterations:  226000 Epoch:  75 Generator loss:  4.135694980621338 Discriminator loss:  3.1639922326576198e-06\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [5:30:21<8:54:50, 258.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  226200 Epoch:  76 Generator loss:  3.9671895503997803 Discriminator loss:  9.695010636315282e-13\n",
      "Iterations:  226400 Epoch:  76 Generator loss:  4.321291923522949 Discriminator loss:  8.646743481222074e-07\n",
      "saving the output\n",
      "Iterations:  226600 Epoch:  76 Generator loss:  3.914979934692383 Discriminator loss:  4.708771683681334e-08\n",
      "Iterations:  226800 Epoch:  76 Generator loss:  4.813889503479004 Discriminator loss:  1.4459436314950835e-08\n",
      "Iterations:  227000 Epoch:  76 Generator loss:  4.25132942199707 Discriminator loss:  1.4995825949881691e-05\n",
      "saving the output\n",
      "Iterations:  227200 Epoch:  76 Generator loss:  4.465004920959473 Discriminator loss:  2.5936171255125373e-07\n",
      "Iterations:  227400 Epoch:  76 Generator loss:  4.104284286499023 Discriminator loss:  6.172500843781847e-10\n",
      "saving the output\n",
      "Iterations:  227600 Epoch:  76 Generator loss:  4.194467544555664 Discriminator loss:  0.3023975193500519\n",
      "Iterations:  227800 Epoch:  76 Generator loss:  4.965129852294922 Discriminator loss:  1.1875307594916285e-12\n",
      "Iterations:  228000 Epoch:  76 Generator loss:  4.044489860534668 Discriminator loss:  7.45278748581768e-06\n",
      "saving the output\n",
      "Iterations:  228200 Epoch:  76 Generator loss:  4.229527473449707 Discriminator loss:  0.00627613440155983\n",
      "Iterations:  228400 Epoch:  76 Generator loss:  3.791393518447876 Discriminator loss:  2.498709079645778e-07\n",
      "saving the output\n",
      "Iterations:  228600 Epoch:  76 Generator loss:  3.8604235649108887 Discriminator loss:  4.381015372700858e-08\n",
      "Iterations:  228800 Epoch:  76 Generator loss:  4.115165710449219 Discriminator loss:  3.9807250377943415e-12\n",
      "Iterations:  229000 Epoch:  76 Generator loss:  4.326462268829346 Discriminator loss:  0.018558580428361893\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/200 [5:34:39<8:49:58, 258.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  229200 Epoch:  77 Generator loss:  3.73575496673584 Discriminator loss:  1.8250017053134115e-09\n",
      "Iterations:  229400 Epoch:  77 Generator loss:  3.6701579093933105 Discriminator loss:  1.2129806236771401e-05\n",
      "saving the output\n",
      "Iterations:  229600 Epoch:  77 Generator loss:  5.440316200256348 Discriminator loss:  0.02134532295167446\n",
      "Iterations:  229800 Epoch:  77 Generator loss:  4.433577537536621 Discriminator loss:  7.294313486561066e-10\n",
      "Iterations:  230000 Epoch:  77 Generator loss:  3.9920270442962646 Discriminator loss:  2.484540573277627e-06\n",
      "saving the output\n",
      "Iterations:  230200 Epoch:  77 Generator loss:  3.3451950550079346 Discriminator loss:  0.11267183721065521\n",
      "Iterations:  230400 Epoch:  77 Generator loss:  4.045549392700195 Discriminator loss:  1.1014117262675427e-06\n",
      "saving the output\n",
      "Iterations:  230600 Epoch:  77 Generator loss:  3.864835500717163 Discriminator loss:  1.5446725228684954e-05\n",
      "Iterations:  230800 Epoch:  77 Generator loss:  4.265484809875488 Discriminator loss:  1.814282835077563e-09\n",
      "Iterations:  231000 Epoch:  77 Generator loss:  4.127154350280762 Discriminator loss:  7.609437489008997e-06\n",
      "saving the output\n",
      "Iterations:  231200 Epoch:  77 Generator loss:  4.525230407714844 Discriminator loss:  6.151831648260053e-12\n",
      "Iterations:  231400 Epoch:  77 Generator loss:  3.8748531341552734 Discriminator loss:  3.582367071430781e-06\n",
      "saving the output\n",
      "Iterations:  231600 Epoch:  77 Generator loss:  5.522204399108887 Discriminator loss:  3.44615500580403e-07\n",
      "Iterations:  231800 Epoch:  77 Generator loss:  4.07298469543457 Discriminator loss:  0.004151825327426195\n",
      "Iterations:  232000 Epoch:  77 Generator loss:  4.215578079223633 Discriminator loss:  8.917612831282895e-06\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78/200 [5:39:00<8:46:54, 259.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  232200 Epoch:  78 Generator loss:  4.272939205169678 Discriminator loss:  0.026969492435455322\n",
      "Iterations:  232400 Epoch:  78 Generator loss:  4.42306661605835 Discriminator loss:  6.845421921752859e-06\n",
      "saving the output\n",
      "Iterations:  232600 Epoch:  78 Generator loss:  4.017282962799072 Discriminator loss:  2.9498832532226515e-07\n",
      "Iterations:  232800 Epoch:  78 Generator loss:  3.6991465091705322 Discriminator loss:  3.549828875293315e-07\n",
      "Iterations:  233000 Epoch:  78 Generator loss:  4.1349873542785645 Discriminator loss:  8.424128168371681e-07\n",
      "saving the output\n",
      "Iterations:  233200 Epoch:  78 Generator loss:  3.9159388542175293 Discriminator loss:  4.500760439896112e-07\n",
      "Iterations:  233400 Epoch:  78 Generator loss:  3.6625876426696777 Discriminator loss:  1.1868695537486929e-07\n",
      "saving the output\n",
      "Iterations:  233600 Epoch:  78 Generator loss:  3.605665445327759 Discriminator loss:  2.3000465887434984e-07\n",
      "Iterations:  233800 Epoch:  78 Generator loss:  4.673996448516846 Discriminator loss:  0.0001242160942638293\n",
      "Iterations:  234000 Epoch:  78 Generator loss:  4.225805759429932 Discriminator loss:  5.048498152859793e-08\n",
      "saving the output\n",
      "Iterations:  234200 Epoch:  78 Generator loss:  4.286258220672607 Discriminator loss:  0.003224952844902873\n",
      "Iterations:  234400 Epoch:  78 Generator loss:  4.036275863647461 Discriminator loss:  2.775873326754663e-06\n",
      "saving the output\n",
      "Iterations:  234600 Epoch:  78 Generator loss:  4.1814069747924805 Discriminator loss:  0.0005878193769603968\n",
      "Iterations:  234800 Epoch:  78 Generator loss:  3.7812576293945312 Discriminator loss:  1.3138742360752076e-07\n",
      "Iterations:  235000 Epoch:  78 Generator loss:  4.082242965698242 Discriminator loss:  0.002556030871346593\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [5:43:20<8:43:21, 259.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  235200 Epoch:  79 Generator loss:  4.0716352462768555 Discriminator loss:  3.2423242828372167e-06\n",
      "Iterations:  235400 Epoch:  79 Generator loss:  3.997530937194824 Discriminator loss:  4.364864469863505e-09\n",
      "saving the output\n",
      "Iterations:  235600 Epoch:  79 Generator loss:  4.5899176597595215 Discriminator loss:  4.6238493922601265e-08\n",
      "Iterations:  235800 Epoch:  79 Generator loss:  5.277758598327637 Discriminator loss:  1.2783660796600316e-09\n",
      "Iterations:  236000 Epoch:  79 Generator loss:  6.170239448547363 Discriminator loss:  6.022012399853338e-08\n",
      "saving the output\n",
      "Iterations:  236200 Epoch:  79 Generator loss:  4.224306583404541 Discriminator loss:  1.1776456858569873e-06\n",
      "Iterations:  236400 Epoch:  79 Generator loss:  3.5548458099365234 Discriminator loss:  1.13911000880762e-05\n",
      "saving the output\n",
      "Iterations:  236600 Epoch:  79 Generator loss:  4.378551483154297 Discriminator loss:  2.457869907601662e-09\n",
      "Iterations:  236800 Epoch:  79 Generator loss:  4.365720272064209 Discriminator loss:  7.118618668755516e-06\n",
      "Iterations:  237000 Epoch:  79 Generator loss:  4.641420841217041 Discriminator loss:  1.2172626240314344e-09\n",
      "saving the output\n",
      "Iterations:  237200 Epoch:  79 Generator loss:  3.7813241481781006 Discriminator loss:  5.093383492749126e-10\n",
      "Iterations:  237400 Epoch:  79 Generator loss:  3.386593818664551 Discriminator loss:  3.517969844324398e-07\n",
      "saving the output\n",
      "Iterations:  237600 Epoch:  79 Generator loss:  4.829366683959961 Discriminator loss:  0.00017195539840031415\n",
      "Iterations:  237800 Epoch:  79 Generator loss:  3.830462694168091 Discriminator loss:  2.955986246888642e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [5:47:33<8:34:52, 257.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  238000 Epoch:  80 Generator loss:  4.493854522705078 Discriminator loss:  5.184315650386129e-12\n",
      "saving the output\n",
      "Iterations:  238200 Epoch:  80 Generator loss:  4.37272310256958 Discriminator loss:  3.880437304815132e-07\n",
      "Iterations:  238400 Epoch:  80 Generator loss:  4.089081764221191 Discriminator loss:  2.433817147817763e-09\n",
      "saving the output\n",
      "Iterations:  238600 Epoch:  80 Generator loss:  3.958983898162842 Discriminator loss:  0.029249513521790504\n",
      "Iterations:  238800 Epoch:  80 Generator loss:  3.8819243907928467 Discriminator loss:  0.006486942060291767\n",
      "Iterations:  239000 Epoch:  80 Generator loss:  4.572658538818359 Discriminator loss:  2.0270194056593027e-07\n",
      "saving the output\n",
      "Iterations:  239200 Epoch:  80 Generator loss:  4.046543598175049 Discriminator loss:  5.30981196789071e-07\n",
      "Iterations:  239400 Epoch:  80 Generator loss:  5.146055698394775 Discriminator loss:  0.00031290811602957547\n",
      "saving the output\n",
      "Iterations:  239600 Epoch:  80 Generator loss:  5.46926212310791 Discriminator loss:  5.480353593156906e-08\n",
      "Iterations:  239800 Epoch:  80 Generator loss:  5.64021110534668 Discriminator loss:  5.711341145797633e-06\n",
      "Iterations:  240000 Epoch:  80 Generator loss:  4.2326741218566895 Discriminator loss:  1.42059798236005e-05\n",
      "saving the output\n",
      "Iterations:  240200 Epoch:  80 Generator loss:  4.136609077453613 Discriminator loss:  3.448468888223033e-08\n",
      "Iterations:  240400 Epoch:  80 Generator loss:  4.29050350189209 Discriminator loss:  3.244172930294553e-08\n",
      "saving the output\n",
      "Iterations:  240600 Epoch:  80 Generator loss:  4.877577304840088 Discriminator loss:  6.872796348034171e-06\n",
      "Iterations:  240800 Epoch:  80 Generator loss:  3.6570522785186768 Discriminator loss:  7.814855013110744e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [5:51:54<8:32:56, 258.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  241000 Epoch:  81 Generator loss:  4.229825019836426 Discriminator loss:  1.0947876916134192e-07\n",
      "saving the output\n",
      "Iterations:  241200 Epoch:  81 Generator loss:  4.374878883361816 Discriminator loss:  2.5788202151488804e-07\n",
      "Iterations:  241400 Epoch:  81 Generator loss:  4.569502353668213 Discriminator loss:  6.151251730202034e-10\n",
      "saving the output\n",
      "Iterations:  241600 Epoch:  81 Generator loss:  3.6563258171081543 Discriminator loss:  0.027798539027571678\n",
      "Iterations:  241800 Epoch:  81 Generator loss:  4.252730369567871 Discriminator loss:  2.4328764780534584e-08\n",
      "Iterations:  242000 Epoch:  81 Generator loss:  3.851543664932251 Discriminator loss:  3.285073102432534e-09\n",
      "saving the output\n",
      "Iterations:  242200 Epoch:  81 Generator loss:  3.7758917808532715 Discriminator loss:  2.6271629316454437e-10\n",
      "Iterations:  242400 Epoch:  81 Generator loss:  4.1793951988220215 Discriminator loss:  3.2782656944618793e-07\n",
      "saving the output\n",
      "Iterations:  242600 Epoch:  81 Generator loss:  3.5192699432373047 Discriminator loss:  8.432767262256391e-10\n",
      "Iterations:  242800 Epoch:  81 Generator loss:  4.054699420928955 Discriminator loss:  0.1253201961517334\n",
      "Iterations:  243000 Epoch:  81 Generator loss:  3.7957398891448975 Discriminator loss:  0.0006815937231294811\n",
      "saving the output\n",
      "Iterations:  243200 Epoch:  81 Generator loss:  4.156544208526611 Discriminator loss:  2.803851657517953e-06\n",
      "Iterations:  243400 Epoch:  81 Generator loss:  3.8774890899658203 Discriminator loss:  5.7523346185917035e-05\n",
      "saving the output\n",
      "Iterations:  243600 Epoch:  81 Generator loss:  4.177333831787109 Discriminator loss:  3.23026848325636e-12\n",
      "Iterations:  243800 Epoch:  81 Generator loss:  4.079327583312988 Discriminator loss:  1.1060035109977662e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82/200 [5:56:12<8:27:57, 258.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  244000 Epoch:  82 Generator loss:  3.585178852081299 Discriminator loss:  0.19768765568733215\n",
      "saving the output\n",
      "Iterations:  244200 Epoch:  82 Generator loss:  4.197810649871826 Discriminator loss:  8.746778856760784e-10\n",
      "Iterations:  244400 Epoch:  82 Generator loss:  4.373038291931152 Discriminator loss:  0.00031237228540703654\n",
      "saving the output\n",
      "Iterations:  244600 Epoch:  82 Generator loss:  4.14289665222168 Discriminator loss:  7.513962542449182e-12\n",
      "Iterations:  244800 Epoch:  82 Generator loss:  4.262781143188477 Discriminator loss:  1.3295961664994138e-08\n",
      "Iterations:  245000 Epoch:  82 Generator loss:  4.321540832519531 Discriminator loss:  0.0005060158437117934\n",
      "saving the output\n",
      "Iterations:  245200 Epoch:  82 Generator loss:  4.144795894622803 Discriminator loss:  2.6113451678799748e-11\n",
      "Iterations:  245400 Epoch:  82 Generator loss:  3.1792924404144287 Discriminator loss:  0.09183888137340546\n",
      "saving the output\n",
      "Iterations:  245600 Epoch:  82 Generator loss:  4.190983772277832 Discriminator loss:  1.3352047972148284e-05\n",
      "Iterations:  245800 Epoch:  82 Generator loss:  3.5608277320861816 Discriminator loss:  5.344876896629103e-08\n",
      "Iterations:  246000 Epoch:  82 Generator loss:  3.554300308227539 Discriminator loss:  0.0026279070880264044\n",
      "saving the output\n",
      "Iterations:  246200 Epoch:  82 Generator loss:  3.600679874420166 Discriminator loss:  4.598447844728071e-08\n",
      "Iterations:  246400 Epoch:  82 Generator loss:  3.7904224395751953 Discriminator loss:  0.0008911481127142906\n",
      "saving the output\n",
      "Iterations:  246600 Epoch:  82 Generator loss:  3.963979482650757 Discriminator loss:  8.670735405758023e-05\n",
      "Iterations:  246800 Epoch:  82 Generator loss:  4.064247131347656 Discriminator loss:  1.8746879504760727e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 83/200 [6:00:32<8:24:48, 258.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  247000 Epoch:  83 Generator loss:  3.615274429321289 Discriminator loss:  1.3451706763589755e-05\n",
      "saving the output\n",
      "Iterations:  247200 Epoch:  83 Generator loss:  4.155722141265869 Discriminator loss:  0.0047683329321444035\n",
      "Iterations:  247400 Epoch:  83 Generator loss:  4.063272953033447 Discriminator loss:  1.2165118912221828e-09\n",
      "saving the output\n",
      "Iterations:  247600 Epoch:  83 Generator loss:  3.4571313858032227 Discriminator loss:  0.021843867376446724\n",
      "Iterations:  247800 Epoch:  83 Generator loss:  3.7411420345306396 Discriminator loss:  1.619868754687559e-07\n",
      "Iterations:  248000 Epoch:  83 Generator loss:  3.9091596603393555 Discriminator loss:  6.115024042685491e-10\n",
      "saving the output\n",
      "Iterations:  248200 Epoch:  83 Generator loss:  4.702915191650391 Discriminator loss:  6.500197515663109e-13\n",
      "Iterations:  248400 Epoch:  83 Generator loss:  4.378406524658203 Discriminator loss:  0.006767439655959606\n",
      "saving the output\n",
      "Iterations:  248600 Epoch:  83 Generator loss:  3.920562267303467 Discriminator loss:  2.0551091495235596e-07\n",
      "Iterations:  248800 Epoch:  83 Generator loss:  3.7675886154174805 Discriminator loss:  2.0184512322884984e-05\n",
      "Iterations:  249000 Epoch:  83 Generator loss:  3.9201173782348633 Discriminator loss:  0.00044174306094646454\n",
      "saving the output\n",
      "Iterations:  249200 Epoch:  83 Generator loss:  3.739873170852661 Discriminator loss:  0.00025008359807543457\n",
      "Iterations:  249400 Epoch:  83 Generator loss:  3.7242558002471924 Discriminator loss:  1.9388601835146346e-09\n",
      "saving the output\n",
      "Iterations:  249600 Epoch:  83 Generator loss:  6.30735445022583 Discriminator loss:  3.2636026991777686e-14\n",
      "Iterations:  249800 Epoch:  83 Generator loss:  4.185024738311768 Discriminator loss:  3.0884532975505863e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 84/200 [6:04:48<8:18:41, 257.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  250000 Epoch:  84 Generator loss:  3.9193129539489746 Discriminator loss:  1.0866106237017448e-08\n",
      "saving the output\n",
      "Iterations:  250200 Epoch:  84 Generator loss:  3.8500003814697266 Discriminator loss:  1.9897685277214805e-08\n",
      "Iterations:  250400 Epoch:  84 Generator loss:  4.373183250427246 Discriminator loss:  5.039342340751318e-06\n",
      "saving the output\n",
      "Iterations:  250600 Epoch:  84 Generator loss:  4.153148174285889 Discriminator loss:  0.004323356319218874\n",
      "Iterations:  250800 Epoch:  84 Generator loss:  4.161957263946533 Discriminator loss:  3.171075150021352e-05\n",
      "Iterations:  251000 Epoch:  84 Generator loss:  5.178927421569824 Discriminator loss:  0.0006238672649487853\n",
      "saving the output\n",
      "Iterations:  251200 Epoch:  84 Generator loss:  3.7744498252868652 Discriminator loss:  3.606690199831064e-07\n",
      "Iterations:  251400 Epoch:  84 Generator loss:  3.502037286758423 Discriminator loss:  7.189050847955514e-07\n",
      "saving the output\n",
      "Iterations:  251600 Epoch:  84 Generator loss:  3.817448377609253 Discriminator loss:  3.2112186687527355e-08\n",
      "Iterations:  251800 Epoch:  84 Generator loss:  3.8774642944335938 Discriminator loss:  9.584776705651166e-08\n",
      "Iterations:  252000 Epoch:  84 Generator loss:  4.300168037414551 Discriminator loss:  4.1479967194391065e-07\n",
      "saving the output\n",
      "Iterations:  252200 Epoch:  84 Generator loss:  4.356040000915527 Discriminator loss:  2.761276221008302e-07\n",
      "Iterations:  252400 Epoch:  84 Generator loss:  3.8900985717773438 Discriminator loss:  4.865698510769789e-09\n",
      "saving the output\n",
      "Iterations:  252600 Epoch:  84 Generator loss:  3.941563129425049 Discriminator loss:  4.0143195434438894e-08\n",
      "Iterations:  252800 Epoch:  84 Generator loss:  5.439737796783447 Discriminator loss:  0.00018764979904517531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 85/200 [6:09:07<8:15:05, 258.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  253000 Epoch:  85 Generator loss:  4.129177093505859 Discriminator loss:  1.3052308567296222e-08\n",
      "saving the output\n",
      "Iterations:  253200 Epoch:  85 Generator loss:  4.20541524887085 Discriminator loss:  1.520826131695685e-08\n",
      "Iterations:  253400 Epoch:  85 Generator loss:  3.368082046508789 Discriminator loss:  0.0025120722129940987\n",
      "saving the output\n",
      "Iterations:  253600 Epoch:  85 Generator loss:  3.6940219402313232 Discriminator loss:  2.25669821235985e-15\n",
      "Iterations:  253800 Epoch:  85 Generator loss:  3.5857932567596436 Discriminator loss:  0.000727953331079334\n",
      "Iterations:  254000 Epoch:  85 Generator loss:  4.455808162689209 Discriminator loss:  5.599629267216688e-12\n",
      "saving the output\n",
      "Iterations:  254200 Epoch:  85 Generator loss:  4.080334663391113 Discriminator loss:  5.534717573141279e-08\n",
      "Iterations:  254400 Epoch:  85 Generator loss:  3.4599995613098145 Discriminator loss:  2.080672174997744e-06\n",
      "saving the output\n",
      "Iterations:  254600 Epoch:  85 Generator loss:  4.127343654632568 Discriminator loss:  0.0003856937983073294\n",
      "Iterations:  254800 Epoch:  85 Generator loss:  3.795093059539795 Discriminator loss:  0.059087447822093964\n",
      "Iterations:  255000 Epoch:  85 Generator loss:  3.5606398582458496 Discriminator loss:  6.723812111886218e-05\n",
      "saving the output\n",
      "Iterations:  255200 Epoch:  85 Generator loss:  4.2921142578125 Discriminator loss:  6.173340239001845e-07\n",
      "Iterations:  255400 Epoch:  85 Generator loss:  4.051012992858887 Discriminator loss:  8.914216920175022e-08\n",
      "saving the output\n",
      "Iterations:  255600 Epoch:  85 Generator loss:  3.729658365249634 Discriminator loss:  1.368474471519221e-07\n",
      "Iterations:  255800 Epoch:  85 Generator loss:  4.997218132019043 Discriminator loss:  0.011453897692263126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 86/200 [6:13:28<8:12:16, 259.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  256000 Epoch:  86 Generator loss:  4.010306358337402 Discriminator loss:  1.2640191926038824e-05\n",
      "saving the output\n",
      "Iterations:  256200 Epoch:  86 Generator loss:  4.559703826904297 Discriminator loss:  5.847925058333203e-05\n",
      "Iterations:  256400 Epoch:  86 Generator loss:  4.334352493286133 Discriminator loss:  4.929281516297124e-08\n",
      "saving the output\n",
      "Iterations:  256600 Epoch:  86 Generator loss:  4.499497413635254 Discriminator loss:  5.461390955902208e-14\n",
      "Iterations:  256800 Epoch:  86 Generator loss:  4.414342880249023 Discriminator loss:  1.8258500267265276e-09\n",
      "Iterations:  257000 Epoch:  86 Generator loss:  3.5983476638793945 Discriminator loss:  7.289810923793993e-07\n",
      "saving the output\n",
      "Iterations:  257200 Epoch:  86 Generator loss:  3.6186013221740723 Discriminator loss:  4.405647235916632e-10\n",
      "Iterations:  257400 Epoch:  86 Generator loss:  4.356537342071533 Discriminator loss:  1.8429786052820418e-07\n",
      "saving the output\n",
      "Iterations:  257600 Epoch:  86 Generator loss:  4.418021202087402 Discriminator loss:  9.002233958277372e-10\n",
      "Iterations:  257800 Epoch:  86 Generator loss:  3.99886155128479 Discriminator loss:  6.115462025668705e-10\n",
      "Iterations:  258000 Epoch:  86 Generator loss:  4.22136926651001 Discriminator loss:  0.00021314516197890043\n",
      "saving the output\n",
      "Iterations:  258200 Epoch:  86 Generator loss:  3.953474521636963 Discriminator loss:  0.0009930419037118554\n",
      "Iterations:  258400 Epoch:  86 Generator loss:  4.046665191650391 Discriminator loss:  0.0006493364344350994\n",
      "saving the output\n",
      "Iterations:  258600 Epoch:  86 Generator loss:  4.588400840759277 Discriminator loss:  5.111466805374221e-13\n",
      "Iterations:  258800 Epoch:  86 Generator loss:  4.861113548278809 Discriminator loss:  2.2802621607326962e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87/200 [6:17:46<8:07:34, 258.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  259000 Epoch:  87 Generator loss:  3.911205291748047 Discriminator loss:  1.619736705871233e-10\n",
      "saving the output\n",
      "Iterations:  259200 Epoch:  87 Generator loss:  4.910792350769043 Discriminator loss:  1.0236246907879831e-06\n",
      "Iterations:  259400 Epoch:  87 Generator loss:  3.961488723754883 Discriminator loss:  0.06593617796897888\n",
      "saving the output\n",
      "Iterations:  259600 Epoch:  87 Generator loss:  3.936105489730835 Discriminator loss:  0.0038496286142617464\n",
      "Iterations:  259800 Epoch:  87 Generator loss:  4.07776403427124 Discriminator loss:  1.1508244597280282e-06\n",
      "Iterations:  260000 Epoch:  87 Generator loss:  3.6191344261169434 Discriminator loss:  3.959938112529926e-06\n",
      "saving the output\n",
      "Iterations:  260200 Epoch:  87 Generator loss:  4.712289333343506 Discriminator loss:  0.05278958007693291\n",
      "Iterations:  260400 Epoch:  87 Generator loss:  4.522467613220215 Discriminator loss:  0.0001167230584542267\n",
      "saving the output\n",
      "Iterations:  260600 Epoch:  87 Generator loss:  3.8011951446533203 Discriminator loss:  1.93061009667872e-06\n",
      "Iterations:  260800 Epoch:  87 Generator loss:  4.060597896575928 Discriminator loss:  0.14383740723133087\n",
      "Iterations:  261000 Epoch:  87 Generator loss:  4.82600736618042 Discriminator loss:  9.12706266120722e-09\n",
      "saving the output\n",
      "Iterations:  261200 Epoch:  87 Generator loss:  4.61801290512085 Discriminator loss:  6.692550957865251e-09\n",
      "Iterations:  261400 Epoch:  87 Generator loss:  4.4932355880737305 Discriminator loss:  1.3404749310552688e-08\n",
      "saving the output\n",
      "Iterations:  261600 Epoch:  87 Generator loss:  3.6647791862487793 Discriminator loss:  1.5855021047173068e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 88/200 [6:22:06<8:04:04, 259.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  261800 Epoch:  88 Generator loss:  4.210063934326172 Discriminator loss:  6.1305463532335125e-06\n",
      "Iterations:  262000 Epoch:  88 Generator loss:  3.9577698707580566 Discriminator loss:  2.8143070096575684e-08\n",
      "saving the output\n",
      "Iterations:  262200 Epoch:  88 Generator loss:  5.557011127471924 Discriminator loss:  4.766809169609587e-11\n",
      "Iterations:  262400 Epoch:  88 Generator loss:  4.24724006652832 Discriminator loss:  4.3033463015262896e-08\n",
      "saving the output\n",
      "Iterations:  262600 Epoch:  88 Generator loss:  5.060225486755371 Discriminator loss:  1.7335792361090202e-13\n",
      "Iterations:  262800 Epoch:  88 Generator loss:  4.990143775939941 Discriminator loss:  3.1584800552764136e-08\n",
      "Iterations:  263000 Epoch:  88 Generator loss:  3.467041492462158 Discriminator loss:  5.81237351582331e-08\n",
      "saving the output\n",
      "Iterations:  263200 Epoch:  88 Generator loss:  3.6885287761688232 Discriminator loss:  4.99921526397884e-09\n",
      "Iterations:  263400 Epoch:  88 Generator loss:  3.4885594844818115 Discriminator loss:  1.8134409401682205e-05\n",
      "saving the output\n",
      "Iterations:  263600 Epoch:  88 Generator loss:  3.7989864349365234 Discriminator loss:  1.8673434354354868e-08\n",
      "Iterations:  263800 Epoch:  88 Generator loss:  3.9699039459228516 Discriminator loss:  0.0012843310832977295\n",
      "Iterations:  264000 Epoch:  88 Generator loss:  4.733420372009277 Discriminator loss:  0.039045874029397964\n",
      "saving the output\n",
      "Iterations:  264200 Epoch:  88 Generator loss:  3.660954713821411 Discriminator loss:  0.015764832496643066\n",
      "Iterations:  264400 Epoch:  88 Generator loss:  3.9554104804992676 Discriminator loss:  3.5472526178637054e-06\n",
      "saving the output\n",
      "Iterations:  264600 Epoch:  88 Generator loss:  4.143495559692383 Discriminator loss:  1.3441454882467951e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 89/200 [6:26:24<7:58:34, 258.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  264800 Epoch:  89 Generator loss:  5.252481460571289 Discriminator loss:  0.0016488219844177365\n",
      "Iterations:  265000 Epoch:  89 Generator loss:  4.675894737243652 Discriminator loss:  1.7900327053954612e-10\n",
      "saving the output\n",
      "Iterations:  265200 Epoch:  89 Generator loss:  3.8936948776245117 Discriminator loss:  0.014044316485524178\n",
      "Iterations:  265400 Epoch:  89 Generator loss:  4.101324081420898 Discriminator loss:  1.034064123217604e-08\n",
      "saving the output\n",
      "Iterations:  265600 Epoch:  89 Generator loss:  3.5071754455566406 Discriminator loss:  1.9538692868081853e-06\n",
      "Iterations:  265800 Epoch:  89 Generator loss:  4.098324775695801 Discriminator loss:  2.696536327562171e-10\n",
      "Iterations:  266000 Epoch:  89 Generator loss:  4.802772045135498 Discriminator loss:  6.303697830389865e-08\n",
      "saving the output\n",
      "Iterations:  266200 Epoch:  89 Generator loss:  3.4433679580688477 Discriminator loss:  0.0006192286382429302\n",
      "Iterations:  266400 Epoch:  89 Generator loss:  3.9473838806152344 Discriminator loss:  2.113765109126864e-12\n",
      "saving the output\n",
      "Iterations:  266600 Epoch:  89 Generator loss:  4.45564079284668 Discriminator loss:  0.015534675680100918\n",
      "Iterations:  266800 Epoch:  89 Generator loss:  3.625702142715454 Discriminator loss:  3.4852409847019317e-10\n",
      "Iterations:  267000 Epoch:  89 Generator loss:  4.61978816986084 Discriminator loss:  2.704730832192581e-06\n",
      "saving the output\n",
      "Iterations:  267200 Epoch:  89 Generator loss:  3.721895456314087 Discriminator loss:  6.694331773360318e-07\n",
      "Iterations:  267400 Epoch:  89 Generator loss:  4.576545715332031 Discriminator loss:  0.012563352473080158\n",
      "saving the output\n",
      "Iterations:  267600 Epoch:  89 Generator loss:  3.939399003982544 Discriminator loss:  1.1998496640686085e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [6:30:42<7:53:52, 258.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  267800 Epoch:  90 Generator loss:  3.968585729598999 Discriminator loss:  1.9911327361205045e-12\n",
      "Iterations:  268000 Epoch:  90 Generator loss:  3.920929193496704 Discriminator loss:  4.094647364227821e-12\n",
      "saving the output\n",
      "Iterations:  268200 Epoch:  90 Generator loss:  3.8298778533935547 Discriminator loss:  6.520665257747638e-11\n",
      "Iterations:  268400 Epoch:  90 Generator loss:  3.8493471145629883 Discriminator loss:  0.029949739575386047\n",
      "saving the output\n",
      "Iterations:  268600 Epoch:  90 Generator loss:  4.429105758666992 Discriminator loss:  7.056277536321431e-05\n",
      "Iterations:  268800 Epoch:  90 Generator loss:  4.178807735443115 Discriminator loss:  9.447336142553997e-12\n",
      "Iterations:  269000 Epoch:  90 Generator loss:  4.077078819274902 Discriminator loss:  5.695477011613548e-05\n",
      "saving the output\n",
      "Iterations:  269200 Epoch:  90 Generator loss:  3.759105682373047 Discriminator loss:  1.0890246215922161e-07\n",
      "Iterations:  269400 Epoch:  90 Generator loss:  3.8179445266723633 Discriminator loss:  1.4202698804359482e-13\n",
      "saving the output\n",
      "Iterations:  269600 Epoch:  90 Generator loss:  4.767077445983887 Discriminator loss:  0.010711194947361946\n",
      "Iterations:  269800 Epoch:  90 Generator loss:  4.453965187072754 Discriminator loss:  1.9073647763434565e-06\n",
      "Iterations:  270000 Epoch:  90 Generator loss:  3.6265194416046143 Discriminator loss:  7.268884161248934e-08\n",
      "saving the output\n",
      "Iterations:  270200 Epoch:  90 Generator loss:  3.6391398906707764 Discriminator loss:  0.02001158520579338\n",
      "Iterations:  270400 Epoch:  90 Generator loss:  4.224817276000977 Discriminator loss:  2.950061583906205e-10\n",
      "saving the output\n",
      "Iterations:  270600 Epoch:  90 Generator loss:  4.344162940979004 Discriminator loss:  2.4966926304159642e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [6:35:03<7:50:54, 259.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  270800 Epoch:  91 Generator loss:  4.22175931930542 Discriminator loss:  1.384099279633233e-09\n",
      "Iterations:  271000 Epoch:  91 Generator loss:  4.156639099121094 Discriminator loss:  0.0048462143167853355\n",
      "saving the output\n",
      "Iterations:  271200 Epoch:  91 Generator loss:  4.414677143096924 Discriminator loss:  1.1621724632995822e-12\n",
      "Iterations:  271400 Epoch:  91 Generator loss:  3.9337456226348877 Discriminator loss:  9.83521640865459e-13\n",
      "saving the output\n",
      "Iterations:  271600 Epoch:  91 Generator loss:  3.7721827030181885 Discriminator loss:  3.4201850212411955e-05\n",
      "Iterations:  271800 Epoch:  91 Generator loss:  3.632025718688965 Discriminator loss:  0.008534126915037632\n",
      "Iterations:  272000 Epoch:  91 Generator loss:  3.9238693714141846 Discriminator loss:  5.476871844933839e-09\n",
      "saving the output\n",
      "Iterations:  272200 Epoch:  91 Generator loss:  3.6245856285095215 Discriminator loss:  7.725911564193666e-05\n",
      "Iterations:  272400 Epoch:  91 Generator loss:  4.253595352172852 Discriminator loss:  5.7934806257931015e-11\n",
      "saving the output\n",
      "Iterations:  272600 Epoch:  91 Generator loss:  4.136336803436279 Discriminator loss:  1.1971804951826925e-06\n",
      "Iterations:  272800 Epoch:  91 Generator loss:  3.9239425659179688 Discriminator loss:  7.055468449834734e-05\n",
      "Iterations:  273000 Epoch:  91 Generator loss:  4.014606475830078 Discriminator loss:  5.929886789934891e-12\n",
      "saving the output\n",
      "Iterations:  273200 Epoch:  91 Generator loss:  3.8805527687072754 Discriminator loss:  1.6217047686950536e-06\n",
      "Iterations:  273400 Epoch:  91 Generator loss:  3.887887954711914 Discriminator loss:  0.0003303722769487649\n",
      "saving the output\n",
      "Iterations:  273600 Epoch:  91 Generator loss:  3.837047576904297 Discriminator loss:  2.4835069780237973e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 92/200 [6:39:21<7:46:08, 258.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  273800 Epoch:  92 Generator loss:  3.863567352294922 Discriminator loss:  3.064886018588897e-12\n",
      "Iterations:  274000 Epoch:  92 Generator loss:  3.929880380630493 Discriminator loss:  0.002154218964278698\n",
      "saving the output\n",
      "Iterations:  274200 Epoch:  92 Generator loss:  5.212375640869141 Discriminator loss:  6.325756030101104e-10\n",
      "Iterations:  274400 Epoch:  92 Generator loss:  3.9304492473602295 Discriminator loss:  5.651484684676689e-07\n",
      "saving the output\n",
      "Iterations:  274600 Epoch:  92 Generator loss:  3.960907459259033 Discriminator loss:  0.0029298607259988785\n",
      "Iterations:  274800 Epoch:  92 Generator loss:  3.513023614883423 Discriminator loss:  0.02289968729019165\n",
      "Iterations:  275000 Epoch:  92 Generator loss:  4.5207839012146 Discriminator loss:  4.768611720773475e-13\n",
      "saving the output\n",
      "Iterations:  275200 Epoch:  92 Generator loss:  4.3739705085754395 Discriminator loss:  6.082141457142143e-09\n",
      "Iterations:  275400 Epoch:  92 Generator loss:  4.291937828063965 Discriminator loss:  9.85087705851484e-12\n",
      "saving the output\n",
      "Iterations:  275600 Epoch:  92 Generator loss:  4.4154157638549805 Discriminator loss:  1.7901325766785797e-13\n",
      "Iterations:  275800 Epoch:  92 Generator loss:  3.7489051818847656 Discriminator loss:  5.881152231879128e-10\n",
      "Iterations:  276000 Epoch:  92 Generator loss:  3.938000440597534 Discriminator loss:  2.597396075998404e-07\n",
      "saving the output\n",
      "Iterations:  276200 Epoch:  92 Generator loss:  4.467093467712402 Discriminator loss:  0.22291244566440582\n",
      "Iterations:  276400 Epoch:  92 Generator loss:  3.436678647994995 Discriminator loss:  1.255894767382415e-05\n",
      "saving the output\n",
      "Iterations:  276600 Epoch:  92 Generator loss:  4.197044372558594 Discriminator loss:  2.584508399395419e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/200 [6:43:39<7:41:18, 258.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  276800 Epoch:  93 Generator loss:  4.483098030090332 Discriminator loss:  1.4995796271399797e-11\n",
      "Iterations:  277000 Epoch:  93 Generator loss:  3.5718140602111816 Discriminator loss:  0.0015174243599176407\n",
      "saving the output\n",
      "Iterations:  277200 Epoch:  93 Generator loss:  4.4135589599609375 Discriminator loss:  1.080676607229103e-11\n",
      "Iterations:  277400 Epoch:  93 Generator loss:  3.536961078643799 Discriminator loss:  4.2909502440124925e-07\n",
      "saving the output\n",
      "Iterations:  277600 Epoch:  93 Generator loss:  4.652837753295898 Discriminator loss:  2.920084085644703e-08\n",
      "Iterations:  277800 Epoch:  93 Generator loss:  3.769775390625 Discriminator loss:  2.6892339519690722e-05\n",
      "Iterations:  278000 Epoch:  93 Generator loss:  5.351755142211914 Discriminator loss:  9.201165220365515e-13\n",
      "saving the output\n",
      "Iterations:  278200 Epoch:  93 Generator loss:  4.574274063110352 Discriminator loss:  0.03273572027683258\n",
      "Iterations:  278400 Epoch:  93 Generator loss:  3.75386118888855 Discriminator loss:  1.4419168983814679e-11\n",
      "saving the output\n",
      "Iterations:  278600 Epoch:  93 Generator loss:  3.3058929443359375 Discriminator loss:  1.5028896086732857e-05\n",
      "Iterations:  278800 Epoch:  93 Generator loss:  4.215939521789551 Discriminator loss:  0.003262434620410204\n",
      "Iterations:  279000 Epoch:  93 Generator loss:  3.907166004180908 Discriminator loss:  0.0009774980135262012\n",
      "saving the output\n",
      "Iterations:  279200 Epoch:  93 Generator loss:  3.590878486633301 Discriminator loss:  1.5501340211443448e-09\n",
      "Iterations:  279400 Epoch:  93 Generator loss:  3.5661561489105225 Discriminator loss:  2.608167505968595e-06\n",
      "saving the output\n",
      "Iterations:  279600 Epoch:  93 Generator loss:  3.504413604736328 Discriminator loss:  0.000676401483360678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 94/200 [6:47:54<7:35:06, 257.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  279800 Epoch:  94 Generator loss:  3.7370777130126953 Discriminator loss:  5.426262994490116e-09\n",
      "Iterations:  280000 Epoch:  94 Generator loss:  4.1600799560546875 Discriminator loss:  2.096282369424326e-14\n",
      "saving the output\n",
      "Iterations:  280200 Epoch:  94 Generator loss:  3.529543399810791 Discriminator loss:  6.824062438681722e-05\n",
      "Iterations:  280400 Epoch:  94 Generator loss:  3.879666566848755 Discriminator loss:  1.1872588712329222e-15\n",
      "saving the output\n",
      "Iterations:  280600 Epoch:  94 Generator loss:  4.68855094909668 Discriminator loss:  2.5216948529305228e-08\n",
      "Iterations:  280800 Epoch:  94 Generator loss:  3.8378658294677734 Discriminator loss:  8.070985586527968e-07\n",
      "Iterations:  281000 Epoch:  94 Generator loss:  3.8519184589385986 Discriminator loss:  3.933984658033296e-07\n",
      "saving the output\n",
      "Iterations:  281200 Epoch:  94 Generator loss:  3.795063018798828 Discriminator loss:  0.0013287159381434321\n",
      "Iterations:  281400 Epoch:  94 Generator loss:  4.150938987731934 Discriminator loss:  8.393315908961085e-08\n",
      "saving the output\n",
      "Iterations:  281600 Epoch:  94 Generator loss:  4.073799133300781 Discriminator loss:  0.04831298440694809\n",
      "Iterations:  281800 Epoch:  94 Generator loss:  5.466303825378418 Discriminator loss:  3.6492702193413606e-09\n",
      "Iterations:  282000 Epoch:  94 Generator loss:  3.8458194732666016 Discriminator loss:  2.8422335162758827e-05\n",
      "saving the output\n",
      "Iterations:  282200 Epoch:  94 Generator loss:  4.08359956741333 Discriminator loss:  4.299876763980137e-06\n",
      "Iterations:  282400 Epoch:  94 Generator loss:  4.173201560974121 Discriminator loss:  1.520725234627207e-08\n",
      "saving the output\n",
      "Iterations:  282600 Epoch:  94 Generator loss:  4.576489448547363 Discriminator loss:  4.860340396817264e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95/200 [6:52:11<7:30:38, 257.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  282800 Epoch:  95 Generator loss:  4.257566452026367 Discriminator loss:  6.045615350558364e-07\n",
      "Iterations:  283000 Epoch:  95 Generator loss:  4.165163040161133 Discriminator loss:  1.9042467101826333e-05\n",
      "saving the output\n",
      "Iterations:  283200 Epoch:  95 Generator loss:  3.8077774047851562 Discriminator loss:  6.528406083816662e-05\n",
      "Iterations:  283400 Epoch:  95 Generator loss:  3.784583568572998 Discriminator loss:  0.28933185338974\n",
      "saving the output\n",
      "Iterations:  283600 Epoch:  95 Generator loss:  5.088561534881592 Discriminator loss:  0.027073251083493233\n",
      "Iterations:  283800 Epoch:  95 Generator loss:  4.623173236846924 Discriminator loss:  3.638028545083216e-07\n",
      "Iterations:  284000 Epoch:  95 Generator loss:  3.54557728767395 Discriminator loss:  5.868624612048734e-06\n",
      "saving the output\n",
      "Iterations:  284200 Epoch:  95 Generator loss:  3.840614080429077 Discriminator loss:  3.932730807676421e-10\n",
      "Iterations:  284400 Epoch:  95 Generator loss:  4.046718597412109 Discriminator loss:  2.402464076567412e-07\n",
      "saving the output\n",
      "Iterations:  284600 Epoch:  95 Generator loss:  3.780735492706299 Discriminator loss:  0.06555440276861191\n",
      "Iterations:  284800 Epoch:  95 Generator loss:  3.9959325790405273 Discriminator loss:  2.5523346999269114e-13\n",
      "Iterations:  285000 Epoch:  95 Generator loss:  4.845305919647217 Discriminator loss:  2.9073234486531874e-07\n",
      "saving the output\n",
      "Iterations:  285200 Epoch:  95 Generator loss:  3.9926881790161133 Discriminator loss:  4.599559360940475e-06\n",
      "Iterations:  285400 Epoch:  95 Generator loss:  4.397731781005859 Discriminator loss:  4.0490966699349706e-13\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 96/200 [6:56:29<7:26:21, 257.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  285600 Epoch:  96 Generator loss:  3.565061569213867 Discriminator loss:  0.036922335624694824\n",
      "Iterations:  285800 Epoch:  96 Generator loss:  3.8094229698181152 Discriminator loss:  0.007790948264300823\n",
      "Iterations:  286000 Epoch:  96 Generator loss:  3.863443613052368 Discriminator loss:  2.5950953386200126e-08\n",
      "saving the output\n",
      "Iterations:  286200 Epoch:  96 Generator loss:  4.3983659744262695 Discriminator loss:  0.013881010934710503\n",
      "Iterations:  286400 Epoch:  96 Generator loss:  4.159560203552246 Discriminator loss:  1.8286164804592886e-09\n",
      "saving the output\n",
      "Iterations:  286600 Epoch:  96 Generator loss:  4.081426620483398 Discriminator loss:  2.0077122826478444e-06\n",
      "Iterations:  286800 Epoch:  96 Generator loss:  3.728550434112549 Discriminator loss:  0.1135549247264862\n",
      "Iterations:  287000 Epoch:  96 Generator loss:  3.9739255905151367 Discriminator loss:  1.5184534185586074e-11\n",
      "saving the output\n",
      "Iterations:  287200 Epoch:  96 Generator loss:  4.224464416503906 Discriminator loss:  3.058159059321497e-09\n",
      "Iterations:  287400 Epoch:  96 Generator loss:  3.6110341548919678 Discriminator loss:  1.1240212233198932e-10\n",
      "saving the output\n",
      "Iterations:  287600 Epoch:  96 Generator loss:  3.6438851356506348 Discriminator loss:  0.013586037792265415\n",
      "Iterations:  287800 Epoch:  96 Generator loss:  4.270837306976318 Discriminator loss:  1.7009447184079818e-09\n",
      "Iterations:  288000 Epoch:  96 Generator loss:  4.382270812988281 Discriminator loss:  6.227468929864699e-06\n",
      "saving the output\n",
      "Iterations:  288200 Epoch:  96 Generator loss:  4.240509033203125 Discriminator loss:  8.200152796372651e-13\n",
      "Iterations:  288400 Epoch:  96 Generator loss:  3.3615002632141113 Discriminator loss:  1.4119483360275353e-09\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 97/200 [7:00:48<7:23:05, 258.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  288600 Epoch:  97 Generator loss:  4.337272644042969 Discriminator loss:  0.010098064318299294\n",
      "Iterations:  288800 Epoch:  97 Generator loss:  3.6162099838256836 Discriminator loss:  0.0001225132291438058\n",
      "Iterations:  289000 Epoch:  97 Generator loss:  3.75697922706604 Discriminator loss:  1.1214187907171436e-05\n",
      "saving the output\n",
      "Iterations:  289200 Epoch:  97 Generator loss:  4.2473320960998535 Discriminator loss:  3.7579008372971845e-13\n",
      "Iterations:  289400 Epoch:  97 Generator loss:  4.69993257522583 Discriminator loss:  2.262819445708608e-11\n",
      "saving the output\n",
      "Iterations:  289600 Epoch:  97 Generator loss:  3.2557315826416016 Discriminator loss:  0.07310867309570312\n",
      "Iterations:  289800 Epoch:  97 Generator loss:  3.4587929248809814 Discriminator loss:  2.858899073032717e-08\n",
      "Iterations:  290000 Epoch:  97 Generator loss:  4.034055233001709 Discriminator loss:  6.915356607350986e-07\n",
      "saving the output\n",
      "Iterations:  290200 Epoch:  97 Generator loss:  3.5437870025634766 Discriminator loss:  5.390065021919355e-13\n",
      "Iterations:  290400 Epoch:  97 Generator loss:  4.339261531829834 Discriminator loss:  3.9509363887191284e-06\n",
      "saving the output\n",
      "Iterations:  290600 Epoch:  97 Generator loss:  3.8534016609191895 Discriminator loss:  0.0005249233799986541\n",
      "Iterations:  290800 Epoch:  97 Generator loss:  3.797327756881714 Discriminator loss:  9.63485717875301e-07\n",
      "Iterations:  291000 Epoch:  97 Generator loss:  3.906932830810547 Discriminator loss:  6.083507586573944e-10\n",
      "saving the output\n",
      "Iterations:  291200 Epoch:  97 Generator loss:  4.156068325042725 Discriminator loss:  2.980233659855003e-08\n",
      "Iterations:  291400 Epoch:  97 Generator loss:  4.528197288513184 Discriminator loss:  8.129007449814152e-13\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 98/200 [7:05:06<7:18:20, 257.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  291600 Epoch:  98 Generator loss:  3.574162006378174 Discriminator loss:  0.14014127850532532\n",
      "Iterations:  291800 Epoch:  98 Generator loss:  3.72391414642334 Discriminator loss:  5.45332442397628e-13\n",
      "Iterations:  292000 Epoch:  98 Generator loss:  3.4269492626190186 Discriminator loss:  2.064995119344104e-10\n",
      "saving the output\n",
      "Iterations:  292200 Epoch:  98 Generator loss:  4.164304256439209 Discriminator loss:  2.2505133756567375e-08\n",
      "Iterations:  292400 Epoch:  98 Generator loss:  4.065239429473877 Discriminator loss:  0.009856599383056164\n",
      "saving the output\n",
      "Iterations:  292600 Epoch:  98 Generator loss:  3.7881174087524414 Discriminator loss:  0.00018677741172723472\n",
      "Iterations:  292800 Epoch:  98 Generator loss:  4.227988243103027 Discriminator loss:  4.518924839359839e-13\n",
      "Iterations:  293000 Epoch:  98 Generator loss:  3.759260416030884 Discriminator loss:  4.095249551028246e-06\n",
      "saving the output\n",
      "Iterations:  293200 Epoch:  98 Generator loss:  4.249073505401611 Discriminator loss:  2.3780215485658118e-07\n",
      "Iterations:  293400 Epoch:  98 Generator loss:  3.3382060527801514 Discriminator loss:  0.0010632858611643314\n",
      "saving the output\n",
      "Iterations:  293600 Epoch:  98 Generator loss:  3.7627060413360596 Discriminator loss:  5.477565956368835e-09\n",
      "Iterations:  293800 Epoch:  98 Generator loss:  4.887764930725098 Discriminator loss:  0.00020438659703359008\n",
      "Iterations:  294000 Epoch:  98 Generator loss:  3.9783670902252197 Discriminator loss:  0.0005739188636653125\n",
      "saving the output\n",
      "Iterations:  294200 Epoch:  98 Generator loss:  3.698399066925049 Discriminator loss:  1.8247386934788778e-09\n",
      "Iterations:  294400 Epoch:  98 Generator loss:  3.8096752166748047 Discriminator loss:  3.953536179324146e-06\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99/200 [7:09:23<7:13:34, 257.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  294600 Epoch:  99 Generator loss:  3.284919261932373 Discriminator loss:  0.0003164472582284361\n",
      "Iterations:  294800 Epoch:  99 Generator loss:  3.957261323928833 Discriminator loss:  5.345851241145283e-05\n",
      "Iterations:  295000 Epoch:  99 Generator loss:  3.4656670093536377 Discriminator loss:  9.038334383149049e-07\n",
      "saving the output\n",
      "Iterations:  295200 Epoch:  99 Generator loss:  4.156057357788086 Discriminator loss:  2.1956856905563926e-12\n",
      "Iterations:  295400 Epoch:  99 Generator loss:  3.757540702819824 Discriminator loss:  7.068626217687779e-08\n",
      "saving the output\n",
      "Iterations:  295600 Epoch:  99 Generator loss:  3.455345869064331 Discriminator loss:  2.1287279664689018e-13\n",
      "Iterations:  295800 Epoch:  99 Generator loss:  4.40924072265625 Discriminator loss:  9.858022531261668e-05\n",
      "Iterations:  296000 Epoch:  99 Generator loss:  3.771146774291992 Discriminator loss:  5.6520428337591966e-09\n",
      "saving the output\n",
      "Iterations:  296200 Epoch:  99 Generator loss:  3.866035223007202 Discriminator loss:  1.5018322301330045e-05\n",
      "Iterations:  296400 Epoch:  99 Generator loss:  3.9695942401885986 Discriminator loss:  5.856746429344639e-05\n",
      "saving the output\n",
      "Iterations:  296600 Epoch:  99 Generator loss:  3.501319408416748 Discriminator loss:  1.4339850167743862e-05\n",
      "Iterations:  296800 Epoch:  99 Generator loss:  3.316958427429199 Discriminator loss:  1.253331571859917e-08\n",
      "Iterations:  297000 Epoch:  99 Generator loss:  4.47953462600708 Discriminator loss:  0.0005249271634966135\n",
      "saving the output\n",
      "Iterations:  297200 Epoch:  99 Generator loss:  4.4734601974487305 Discriminator loss:  1.690592944214586e-05\n",
      "Iterations:  297400 Epoch:  99 Generator loss:  3.407987594604492 Discriminator loss:  2.432868839719049e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [7:13:41<7:09:28, 257.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  297600 Epoch:  100 Generator loss:  3.5188136100769043 Discriminator loss:  0.1532784402370453\n",
      "Iterations:  297800 Epoch:  100 Generator loss:  4.155228137969971 Discriminator loss:  2.3745177424658445e-15\n",
      "Iterations:  298000 Epoch:  100 Generator loss:  4.748618125915527 Discriminator loss:  8.428473563526495e-08\n",
      "saving the output\n",
      "Iterations:  298200 Epoch:  100 Generator loss:  3.4292964935302734 Discriminator loss:  0.0006236397312022746\n",
      "Iterations:  298400 Epoch:  100 Generator loss:  4.002562999725342 Discriminator loss:  1.6245307051576674e-05\n",
      "saving the output\n",
      "Iterations:  298600 Epoch:  100 Generator loss:  3.959885597229004 Discriminator loss:  8.928298484534025e-06\n",
      "Iterations:  298800 Epoch:  100 Generator loss:  4.310722351074219 Discriminator loss:  1.0323091373720672e-05\n",
      "Iterations:  299000 Epoch:  100 Generator loss:  3.875627040863037 Discriminator loss:  4.794766573468223e-05\n",
      "saving the output\n",
      "Iterations:  299200 Epoch:  100 Generator loss:  4.036661148071289 Discriminator loss:  0.39783042669296265\n",
      "Iterations:  299400 Epoch:  100 Generator loss:  3.455195903778076 Discriminator loss:  5.907927142292935e-13\n",
      "saving the output\n",
      "Iterations:  299600 Epoch:  100 Generator loss:  3.3981847763061523 Discriminator loss:  1.722479936461241e-08\n",
      "Iterations:  299800 Epoch:  100 Generator loss:  3.299764633178711 Discriminator loss:  1.1894468521234103e-08\n",
      "Iterations:  300000 Epoch:  100 Generator loss:  3.6964457035064697 Discriminator loss:  9.141618129149265e-09\n",
      "saving the output\n",
      "Iterations:  300200 Epoch:  100 Generator loss:  4.11704683303833 Discriminator loss:  1.396975221723551e-06\n",
      "Iterations:  300400 Epoch:  100 Generator loss:  4.330177307128906 Discriminator loss:  3.591247121903507e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [7:17:48<7:00:14, 254.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  300600 Epoch:  101 Generator loss:  3.8102493286132812 Discriminator loss:  2.063350601488878e-09\n",
      "Iterations:  300800 Epoch:  101 Generator loss:  3.803927421569824 Discriminator loss:  2.544713788665831e-05\n",
      "Iterations:  301000 Epoch:  101 Generator loss:  4.098682403564453 Discriminator loss:  4.979765071766451e-05\n",
      "saving the output\n",
      "Iterations:  301200 Epoch:  101 Generator loss:  4.659174919128418 Discriminator loss:  2.3112011859893755e-08\n",
      "Iterations:  301400 Epoch:  101 Generator loss:  4.377310752868652 Discriminator loss:  2.719997838074306e-10\n",
      "saving the output\n",
      "Iterations:  301600 Epoch:  101 Generator loss:  3.266896963119507 Discriminator loss:  0.044401757419109344\n",
      "Iterations:  301800 Epoch:  101 Generator loss:  3.728212594985962 Discriminator loss:  7.187968975586045e-08\n",
      "Iterations:  302000 Epoch:  101 Generator loss:  3.4983251094818115 Discriminator loss:  3.2565455887478834e-10\n",
      "saving the output\n",
      "Iterations:  302200 Epoch:  101 Generator loss:  3.6361083984375 Discriminator loss:  0.030371809378266335\n",
      "Iterations:  302400 Epoch:  101 Generator loss:  3.7389628887176514 Discriminator loss:  3.770973222572138e-08\n",
      "saving the output\n",
      "Iterations:  302600 Epoch:  101 Generator loss:  4.291172504425049 Discriminator loss:  4.02027609425204e-07\n",
      "Iterations:  302800 Epoch:  101 Generator loss:  3.363999843597412 Discriminator loss:  4.279736822354607e-05\n",
      "Iterations:  303000 Epoch:  101 Generator loss:  4.950177192687988 Discriminator loss:  4.6130898309192786e-14\n",
      "saving the output\n",
      "Iterations:  303200 Epoch:  101 Generator loss:  3.4501256942749023 Discriminator loss:  0.019783347845077515\n",
      "Iterations:  303400 Epoch:  101 Generator loss:  3.905977725982666 Discriminator loss:  1.9596548099798383e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102/200 [7:22:05<6:57:11, 255.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  303600 Epoch:  102 Generator loss:  3.581083297729492 Discriminator loss:  0.00013175119238439947\n",
      "Iterations:  303800 Epoch:  102 Generator loss:  3.8987245559692383 Discriminator loss:  1.491573868861451e-07\n",
      "Iterations:  304000 Epoch:  102 Generator loss:  3.7562952041625977 Discriminator loss:  8.952263306127861e-05\n",
      "saving the output\n",
      "Iterations:  304200 Epoch:  102 Generator loss:  3.7720534801483154 Discriminator loss:  3.010825275850948e-05\n",
      "Iterations:  304400 Epoch:  102 Generator loss:  3.490889549255371 Discriminator loss:  1.5392965790894664e-09\n",
      "saving the output\n",
      "Iterations:  304600 Epoch:  102 Generator loss:  3.6090283393859863 Discriminator loss:  4.421732171522308e-07\n",
      "Iterations:  304800 Epoch:  102 Generator loss:  4.128505229949951 Discriminator loss:  1.304477532937387e-11\n",
      "Iterations:  305000 Epoch:  102 Generator loss:  3.571378231048584 Discriminator loss:  1.0426999708101903e-08\n",
      "saving the output\n",
      "Iterations:  305200 Epoch:  102 Generator loss:  4.087348937988281 Discriminator loss:  2.7001231472922882e-08\n",
      "Iterations:  305400 Epoch:  102 Generator loss:  3.7218689918518066 Discriminator loss:  0.0002519045665394515\n",
      "saving the output\n",
      "Iterations:  305600 Epoch:  102 Generator loss:  4.341239929199219 Discriminator loss:  0.00145517208147794\n",
      "Iterations:  305800 Epoch:  102 Generator loss:  3.872100353240967 Discriminator loss:  8.027685460820777e-11\n",
      "Iterations:  306000 Epoch:  102 Generator loss:  4.099212169647217 Discriminator loss:  6.561376267200103e-06\n",
      "saving the output\n",
      "Iterations:  306200 Epoch:  102 Generator loss:  4.392515659332275 Discriminator loss:  1.0364316826647069e-12\n",
      "Iterations:  306400 Epoch:  102 Generator loss:  3.5426478385925293 Discriminator loss:  2.918275640695356e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103/200 [7:26:18<6:51:23, 254.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the output\n",
      "Iterations:  306600 Epoch:  103 Generator loss:  4.631598472595215 Discriminator loss:  3.456462309259223e-06\n",
      "Iterations:  306800 Epoch:  103 Generator loss:  5.031154632568359 Discriminator loss:  8.594023711339105e-06\n",
      "Iterations:  307000 Epoch:  103 Generator loss:  3.8003079891204834 Discriminator loss:  4.939197140174656e-08\n",
      "saving the output\n",
      "Iterations:  307200 Epoch:  103 Generator loss:  3.9982380867004395 Discriminator loss:  0.0014983325963839889\n",
      "Iterations:  307400 Epoch:  103 Generator loss:  3.5876152515411377 Discriminator loss:  2.4451971558647756e-09\n",
      "saving the output\n",
      "Iterations:  307600 Epoch:  103 Generator loss:  4.134079933166504 Discriminator loss:  1.31725610117428e-05\n",
      "Iterations:  307800 Epoch:  103 Generator loss:  3.7237391471862793 Discriminator loss:  8.106212021630199e-07\n",
      "Iterations:  308000 Epoch:  103 Generator loss:  3.8212790489196777 Discriminator loss:  5.27509801031556e-05\n",
      "saving the output\n",
      "Iterations:  308200 Epoch:  103 Generator loss:  4.277539253234863 Discriminator loss:  7.514170221375321e-14\n",
      "Iterations:  308400 Epoch:  103 Generator loss:  4.011822700500488 Discriminator loss:  3.97360339077224e-11\n",
      "saving the output\n",
      "Iterations:  308600 Epoch:  103 Generator loss:  3.99570369720459 Discriminator loss:  0.00027110258815810084\n",
      "Iterations:  308800 Epoch:  103 Generator loss:  3.613673210144043 Discriminator loss:  1.4002005777058457e-08\n",
      "Iterations:  309000 Epoch:  103 Generator loss:  4.067877769470215 Discriminator loss:  3.1915220688460977e-07\n",
      "saving the output\n",
      "Iterations:  309200 Epoch:  103 Generator loss:  3.6908767223358154 Discriminator loss:  4.1033840279640355e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 104/200 [7:30:36<6:49:04, 255.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  309400 Epoch:  104 Generator loss:  3.797325849533081 Discriminator loss:  0.003589907195419073\n",
      "saving the output\n",
      "Iterations:  309600 Epoch:  104 Generator loss:  3.303797960281372 Discriminator loss:  0.0037742252461612225\n",
      "Iterations:  309800 Epoch:  104 Generator loss:  3.640660047531128 Discriminator loss:  8.899119166017044e-06\n",
      "Iterations:  310000 Epoch:  104 Generator loss:  4.295146942138672 Discriminator loss:  6.408479161831154e-14\n",
      "saving the output\n",
      "Iterations:  310200 Epoch:  104 Generator loss:  3.7324421405792236 Discriminator loss:  1.2032977912690423e-11\n",
      "Iterations:  310400 Epoch:  104 Generator loss:  4.110234260559082 Discriminator loss:  1.863436294158305e-09\n",
      "saving the output\n",
      "Iterations:  310600 Epoch:  104 Generator loss:  3.524829626083374 Discriminator loss:  0.0021127054933458567\n",
      "Iterations:  310800 Epoch:  104 Generator loss:  3.5711071491241455 Discriminator loss:  4.027617269645317e-14\n",
      "Iterations:  311000 Epoch:  104 Generator loss:  3.709286689758301 Discriminator loss:  0.0069373794831335545\n",
      "saving the output\n",
      "Iterations:  311200 Epoch:  104 Generator loss:  3.3785877227783203 Discriminator loss:  1.0947810835659766e-07\n",
      "Iterations:  311400 Epoch:  104 Generator loss:  4.007706642150879 Discriminator loss:  0.011212179437279701\n",
      "saving the output\n",
      "Iterations:  311600 Epoch:  104 Generator loss:  3.5975239276885986 Discriminator loss:  0.00012488682114053518\n",
      "Iterations:  311800 Epoch:  104 Generator loss:  3.466981887817383 Discriminator loss:  2.3264137838374666e-10\n",
      "Iterations:  312000 Epoch:  104 Generator loss:  4.366804122924805 Discriminator loss:  2.067364057722898e-08\n",
      "saving the output\n",
      "Iterations:  312200 Epoch:  104 Generator loss:  3.621480941772461 Discriminator loss:  2.1953419491183013e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [7:34:51<6:44:19, 255.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  312400 Epoch:  105 Generator loss:  3.6049087047576904 Discriminator loss:  2.013253777022328e-07\n",
      "saving the output\n",
      "Iterations:  312600 Epoch:  105 Generator loss:  3.874114513397217 Discriminator loss:  0.0006842653383500874\n",
      "Iterations:  312800 Epoch:  105 Generator loss:  4.15262508392334 Discriminator loss:  0.0028685631696134806\n",
      "Iterations:  313000 Epoch:  105 Generator loss:  4.603063106536865 Discriminator loss:  2.2110204021385388e-13\n",
      "saving the output\n",
      "Iterations:  313200 Epoch:  105 Generator loss:  3.5610547065734863 Discriminator loss:  7.916907634353265e-05\n",
      "Iterations:  313400 Epoch:  105 Generator loss:  3.5633835792541504 Discriminator loss:  2.584773574199062e-05\n",
      "saving the output\n",
      "Iterations:  313600 Epoch:  105 Generator loss:  4.972008228302002 Discriminator loss:  1.9328210906777166e-12\n",
      "Iterations:  313800 Epoch:  105 Generator loss:  3.5045204162597656 Discriminator loss:  3.1993505622551766e-09\n",
      "Iterations:  314000 Epoch:  105 Generator loss:  4.285341262817383 Discriminator loss:  8.36228809930617e-06\n",
      "saving the output\n",
      "Iterations:  314200 Epoch:  105 Generator loss:  4.069580554962158 Discriminator loss:  4.379135631893405e-08\n",
      "Iterations:  314400 Epoch:  105 Generator loss:  3.7353909015655518 Discriminator loss:  5.369801783672301e-06\n",
      "saving the output\n",
      "Iterations:  314600 Epoch:  105 Generator loss:  3.323680877685547 Discriminator loss:  0.0032657161355018616\n",
      "Iterations:  314800 Epoch:  105 Generator loss:  3.840381383895874 Discriminator loss:  1.6491524590378503e-08\n",
      "Iterations:  315000 Epoch:  105 Generator loss:  3.587489604949951 Discriminator loss:  0.027669748291373253\n",
      "saving the output\n",
      "Iterations:  315200 Epoch:  105 Generator loss:  4.528354644775391 Discriminator loss:  0.019785111770033836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [7:39:09<6:41:37, 256.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  315400 Epoch:  106 Generator loss:  4.016247272491455 Discriminator loss:  2.2144949980429374e-06\n",
      "saving the output\n",
      "Iterations:  315600 Epoch:  106 Generator loss:  4.356298446655273 Discriminator loss:  0.00010102861415361986\n",
      "Iterations:  315800 Epoch:  106 Generator loss:  3.506300210952759 Discriminator loss:  1.0731588361012623e-11\n",
      "Iterations:  316000 Epoch:  106 Generator loss:  3.6288628578186035 Discriminator loss:  1.501838596595917e-06\n",
      "saving the output\n",
      "Iterations:  316200 Epoch:  106 Generator loss:  3.5791244506835938 Discriminator loss:  9.583445148564351e-13\n",
      "Iterations:  316400 Epoch:  106 Generator loss:  3.760324478149414 Discriminator loss:  8.227432271709287e-14\n",
      "saving the output\n",
      "Iterations:  316600 Epoch:  106 Generator loss:  4.630471706390381 Discriminator loss:  2.6708767142391565e-11\n",
      "Iterations:  316800 Epoch:  106 Generator loss:  3.651766300201416 Discriminator loss:  1.2312263431013548e-09\n",
      "Iterations:  317000 Epoch:  106 Generator loss:  4.391651153564453 Discriminator loss:  0.03555762767791748\n",
      "saving the output\n",
      "Iterations:  317200 Epoch:  106 Generator loss:  3.114246368408203 Discriminator loss:  1.2736479959585267e-07\n",
      "Iterations:  317400 Epoch:  106 Generator loss:  3.5744404792785645 Discriminator loss:  9.73210489974008e-09\n",
      "saving the output\n",
      "Iterations:  317600 Epoch:  106 Generator loss:  4.243480682373047 Discriminator loss:  0.00019878211605828255\n",
      "Iterations:  317800 Epoch:  106 Generator loss:  3.675302028656006 Discriminator loss:  1.910451574715921e-09\n",
      "Iterations:  318000 Epoch:  106 Generator loss:  3.896026372909546 Discriminator loss:  1.3319814229362237e-07\n",
      "saving the output\n",
      "Iterations:  318200 Epoch:  106 Generator loss:  3.5351314544677734 Discriminator loss:  1.2284684988012051e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [7:43:26<6:37:26, 256.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  318400 Epoch:  107 Generator loss:  3.698173999786377 Discriminator loss:  7.115733637874655e-07\n",
      "saving the output\n",
      "Iterations:  318600 Epoch:  107 Generator loss:  3.953281879425049 Discriminator loss:  1.4417156704582546e-11\n",
      "Iterations:  318800 Epoch:  107 Generator loss:  3.226855754852295 Discriminator loss:  4.064174774498497e-08\n",
      "Iterations:  319000 Epoch:  107 Generator loss:  4.225255012512207 Discriminator loss:  3.993066911789356e-06\n",
      "saving the output\n",
      "Iterations:  319200 Epoch:  107 Generator loss:  3.700084924697876 Discriminator loss:  1.100923554986366e-06\n",
      "Iterations:  319400 Epoch:  107 Generator loss:  3.8670737743377686 Discriminator loss:  6.6270631577936e-06\n",
      "saving the output\n",
      "Iterations:  319600 Epoch:  107 Generator loss:  3.4949839115142822 Discriminator loss:  5.192648533380861e-09\n",
      "Iterations:  319800 Epoch:  107 Generator loss:  3.2108399868011475 Discriminator loss:  2.4130838482960826e-07\n",
      "Iterations:  320000 Epoch:  107 Generator loss:  3.7855801582336426 Discriminator loss:  3.942312254423541e-09\n",
      "saving the output\n",
      "Iterations:  320200 Epoch:  107 Generator loss:  3.5744872093200684 Discriminator loss:  8.028442977092709e-08\n",
      "Iterations:  320400 Epoch:  107 Generator loss:  3.8707022666931152 Discriminator loss:  8.028408160498657e-08\n",
      "saving the output\n",
      "Iterations:  320600 Epoch:  107 Generator loss:  5.17073917388916 Discriminator loss:  7.72325508668209e-13\n",
      "Iterations:  320800 Epoch:  107 Generator loss:  3.7492403984069824 Discriminator loss:  1.4907658396623447e-07\n",
      "Iterations:  321000 Epoch:  107 Generator loss:  4.328085899353027 Discriminator loss:  0.033965252339839935\n",
      "saving the output\n",
      "Iterations:  321200 Epoch:  107 Generator loss:  3.5187792778015137 Discriminator loss:  6.454926870791411e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 108/200 [7:47:43<6:33:26, 256.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  321400 Epoch:  108 Generator loss:  3.3924803733825684 Discriminator loss:  3.540033821636257e-09\n",
      "saving the output\n",
      "Iterations:  321600 Epoch:  108 Generator loss:  3.4219532012939453 Discriminator loss:  3.1367757280520436e-09\n",
      "Iterations:  321800 Epoch:  108 Generator loss:  4.3333587646484375 Discriminator loss:  0.00017657165881246328\n",
      "Iterations:  322000 Epoch:  108 Generator loss:  3.53314471244812 Discriminator loss:  0.00042056923848576844\n",
      "saving the output\n",
      "Iterations:  322200 Epoch:  108 Generator loss:  3.7709121704101562 Discriminator loss:  0.0001408512471243739\n",
      "Iterations:  322400 Epoch:  108 Generator loss:  3.2699129581451416 Discriminator loss:  1.1969586921622977e-06\n",
      "saving the output\n",
      "Iterations:  322600 Epoch:  108 Generator loss:  3.8375306129455566 Discriminator loss:  2.8670432584476657e-05\n",
      "Iterations:  322800 Epoch:  108 Generator loss:  3.6616873741149902 Discriminator loss:  7.4438903538975865e-06\n",
      "Iterations:  323000 Epoch:  108 Generator loss:  3.416731834411621 Discriminator loss:  2.373321450477306e-08\n",
      "saving the output\n",
      "Iterations:  323200 Epoch:  108 Generator loss:  4.645566940307617 Discriminator loss:  5.377918910198787e-07\n",
      "Iterations:  323400 Epoch:  108 Generator loss:  3.6634740829467773 Discriminator loss:  3.960550556134437e-14\n",
      "saving the output\n",
      "Iterations:  323600 Epoch:  108 Generator loss:  3.5809764862060547 Discriminator loss:  5.6425477623633924e-08\n",
      "Iterations:  323800 Epoch:  108 Generator loss:  3.9392383098602295 Discriminator loss:  3.488688851693844e-11\n",
      "Iterations:  324000 Epoch:  108 Generator loss:  3.8005599975585938 Discriminator loss:  4.002240501358757e-14\n",
      "saving the output\n",
      "Iterations:  324200 Epoch:  108 Generator loss:  3.4673054218292236 Discriminator loss:  0.0008048526360653341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [7:52:02<6:30:07, 257.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  324400 Epoch:  109 Generator loss:  3.5820131301879883 Discriminator loss:  6.141263053649482e-10\n",
      "saving the output\n",
      "Iterations:  324600 Epoch:  109 Generator loss:  4.073511600494385 Discriminator loss:  2.009277008554848e-14\n",
      "Iterations:  324800 Epoch:  109 Generator loss:  4.1541900634765625 Discriminator loss:  1.2164232954248178e-09\n",
      "Iterations:  325000 Epoch:  109 Generator loss:  3.6354122161865234 Discriminator loss:  1.815566808005542e-09\n",
      "saving the output\n",
      "Iterations:  325200 Epoch:  109 Generator loss:  3.6518800258636475 Discriminator loss:  5.6507165169250584e-08\n",
      "Iterations:  325400 Epoch:  109 Generator loss:  3.6187357902526855 Discriminator loss:  2.4466404457967883e-09\n",
      "saving the output\n",
      "Iterations:  325600 Epoch:  109 Generator loss:  3.520498752593994 Discriminator loss:  2.6404609401731172e-11\n",
      "Iterations:  325800 Epoch:  109 Generator loss:  3.679986000061035 Discriminator loss:  8.075173356055822e-15\n",
      "Iterations:  326000 Epoch:  109 Generator loss:  3.5328474044799805 Discriminator loss:  0.0036009550094604492\n",
      "saving the output\n",
      "Iterations:  326200 Epoch:  109 Generator loss:  3.517148017883301 Discriminator loss:  2.6866733282560062e-09\n",
      "Iterations:  326400 Epoch:  109 Generator loss:  3.5599687099456787 Discriminator loss:  6.145404540802701e-08\n",
      "saving the output\n",
      "Iterations:  326600 Epoch:  109 Generator loss:  4.115602493286133 Discriminator loss:  0.0006412051734514534\n",
      "Iterations:  326800 Epoch:  109 Generator loss:  3.9550461769104004 Discriminator loss:  5.833456113990554e-12\n",
      "Iterations:  327000 Epoch:  109 Generator loss:  4.577429294586182 Discriminator loss:  2.5737688889859722e-12\n",
      "saving the output\n",
      "Iterations:  327200 Epoch:  109 Generator loss:  3.7598228454589844 Discriminator loss:  6.264573215730707e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [7:56:19<6:26:04, 257.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  327400 Epoch:  110 Generator loss:  3.3855557441711426 Discriminator loss:  2.0480461077054812e-11\n",
      "saving the output\n",
      "Iterations:  327600 Epoch:  110 Generator loss:  3.4557693004608154 Discriminator loss:  0.0006205444224178791\n",
      "Iterations:  327800 Epoch:  110 Generator loss:  4.0853471755981445 Discriminator loss:  0.005465139169245958\n",
      "Iterations:  328000 Epoch:  110 Generator loss:  3.3059029579162598 Discriminator loss:  3.530126191364502e-10\n",
      "saving the output\n",
      "Iterations:  328200 Epoch:  110 Generator loss:  3.1604878902435303 Discriminator loss:  0.23253822326660156\n",
      "Iterations:  328400 Epoch:  110 Generator loss:  3.4501559734344482 Discriminator loss:  1.4912841794778586e-11\n",
      "saving the output\n",
      "Iterations:  328600 Epoch:  110 Generator loss:  3.6085379123687744 Discriminator loss:  2.6907356343031097e-08\n",
      "Iterations:  328800 Epoch:  110 Generator loss:  3.3974266052246094 Discriminator loss:  1.521719354968809e-06\n",
      "Iterations:  329000 Epoch:  110 Generator loss:  3.508265495300293 Discriminator loss:  0.011790496297180653\n",
      "saving the output\n",
      "Iterations:  329200 Epoch:  110 Generator loss:  3.4455833435058594 Discriminator loss:  8.42371797316055e-11\n",
      "Iterations:  329400 Epoch:  110 Generator loss:  3.042940616607666 Discriminator loss:  1.151850170799662e-07\n",
      "saving the output\n",
      "Iterations:  329600 Epoch:  110 Generator loss:  3.654460906982422 Discriminator loss:  6.014052269165404e-05\n",
      "Iterations:  329800 Epoch:  110 Generator loss:  3.8026061058044434 Discriminator loss:  4.622508242846379e-08\n",
      "Iterations:  330000 Epoch:  110 Generator loss:  3.549966335296631 Discriminator loss:  8.068536061500708e-09\n",
      "saving the output\n",
      "Iterations:  330200 Epoch:  110 Generator loss:  4.528258800506592 Discriminator loss:  3.3451584613430896e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 111/200 [8:00:35<6:20:59, 256.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  330400 Epoch:  111 Generator loss:  3.51871657371521 Discriminator loss:  0.049741897732019424\n",
      "saving the output\n",
      "Iterations:  330600 Epoch:  111 Generator loss:  3.576531410217285 Discriminator loss:  3.0970088573667454e-06\n",
      "Iterations:  330800 Epoch:  111 Generator loss:  4.033297538757324 Discriminator loss:  3.706957068061456e-05\n",
      "Iterations:  331000 Epoch:  111 Generator loss:  3.434889316558838 Discriminator loss:  1.7132155694099538e-09\n",
      "saving the output\n",
      "Iterations:  331200 Epoch:  111 Generator loss:  4.219814300537109 Discriminator loss:  6.454675371969643e-08\n",
      "Iterations:  331400 Epoch:  111 Generator loss:  3.7403440475463867 Discriminator loss:  1.6745350876590237e-05\n",
      "saving the output\n",
      "Iterations:  331600 Epoch:  111 Generator loss:  4.345995903015137 Discriminator loss:  0.0010552145540714264\n",
      "Iterations:  331800 Epoch:  111 Generator loss:  3.252945899963379 Discriminator loss:  0.005495010409504175\n",
      "Iterations:  332000 Epoch:  111 Generator loss:  3.2190747261047363 Discriminator loss:  4.2079722817334186e-08\n",
      "saving the output\n",
      "Iterations:  332200 Epoch:  111 Generator loss:  3.70491361618042 Discriminator loss:  8.219438150935954e-12\n",
      "Iterations:  332400 Epoch:  111 Generator loss:  3.773193836212158 Discriminator loss:  0.00023520996910519898\n",
      "saving the output\n",
      "Iterations:  332600 Epoch:  111 Generator loss:  3.108318328857422 Discriminator loss:  1.020834133370896e-12\n",
      "Iterations:  332800 Epoch:  111 Generator loss:  4.390329360961914 Discriminator loss:  4.546984655462438e-06\n",
      "Iterations:  333000 Epoch:  111 Generator loss:  3.6625468730926514 Discriminator loss:  0.0010058454936370254\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 112/200 [8:04:50<6:15:57, 256.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  333200 Epoch:  112 Generator loss:  3.594998359680176 Discriminator loss:  4.882533721946303e-13\n",
      "Iterations:  333400 Epoch:  112 Generator loss:  3.3176450729370117 Discriminator loss:  8.98400176083669e-05\n",
      "saving the output\n",
      "Iterations:  333600 Epoch:  112 Generator loss:  3.512263774871826 Discriminator loss:  0.004519700538367033\n",
      "Iterations:  333800 Epoch:  112 Generator loss:  3.31601619720459 Discriminator loss:  6.091758208981446e-10\n",
      "Iterations:  334000 Epoch:  112 Generator loss:  4.3787841796875 Discriminator loss:  0.00010381000174675137\n",
      "saving the output\n",
      "Iterations:  334200 Epoch:  112 Generator loss:  3.833134174346924 Discriminator loss:  6.084745485246401e-10\n",
      "Iterations:  334400 Epoch:  112 Generator loss:  3.8530735969543457 Discriminator loss:  2.3062819015651215e-12\n",
      "saving the output\n",
      "Iterations:  334600 Epoch:  112 Generator loss:  3.6248865127563477 Discriminator loss:  1.7879229119444062e-07\n",
      "Iterations:  334800 Epoch:  112 Generator loss:  3.8721346855163574 Discriminator loss:  7.906819199376969e-09\n",
      "Iterations:  335000 Epoch:  112 Generator loss:  4.037292003631592 Discriminator loss:  1.9967585558333667e-06\n",
      "saving the output\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "iters = 0\n",
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()\n",
    " \n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "\n",
    "img_counter = 0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    for X, y in trainloader:\n",
    "\n",
    "    \n",
    "        X = X.to(ModelArgs.device)\n",
    "        y = y.to(ModelArgs.device)\n",
    "        if(img_counter > 50):\n",
    "            img_counter = 0\n",
    "            \n",
    "        \n",
    "        #############################\n",
    "        # Discriminator Training\n",
    "        #############################\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            #Enabling the discriminators trainable ability \n",
    "            for params in discriminatorX.parameters():\n",
    "                params.requires_grad = True            \n",
    "                \n",
    "            current_batch_size = X.shape[0]  #Getting the current batch size\n",
    "            \n",
    "            real_data = torch.ones((current_batch_size,), device=ModelArgs.device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            y_pred = discriminatorX(X)\n",
    "            # print(y_pred)\n",
    "            # print(y_pred.shape)\n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss_real = loss_fn(y_pred, real_data)\n",
    "\n",
    "            # 3. Optimizer zero grad\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "        \n",
    "            # loss_real.backward()\n",
    "\n",
    "\n",
    "            #Train the discriminator (with fake data)\n",
    "\n",
    "            # noise = torch.randn((batch_size, latent_vector_size, 1, 1), device=device)\n",
    "            fake_data = torch.zeros(( current_batch_size,), device=ModelArgs.device)\n",
    "            mask_generated_by_generatorY = generatorY(y)\n",
    "\n",
    "            #1. Forward pass\n",
    "            y_pred = discriminatorX(mask_generated_by_generatorY.detach())\n",
    "\n",
    "\n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss_fake = loss_fn(y_pred, fake_data)\n",
    "\n",
    "\n",
    "            #Accumulating total discriminator loss\n",
    "            discriminatorX_combined_loss = (loss_real + loss_fake) \n",
    "            # loss_d.append(discriminator_combined_loss.item())\n",
    "\n",
    "            \n",
    "            \n",
    "            #Enabling the discriminators trainable ability \n",
    "            for params in discriminatorY.parameters():\n",
    "                params.requires_grad = True            \n",
    "                \n",
    "            current_batch_size = X.shape[0]  #Getting the current batch size\n",
    "            \n",
    "            real_data = torch.ones((current_batch_size,), device=ModelArgs.device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            y_pred = discriminatorY(y)\n",
    "            # print(y_pred.shape)\n",
    "            \n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss_real = loss_fn(y_pred, real_data)\n",
    "\n",
    "\n",
    "            #Train the discriminator (with fake data)\n",
    "\n",
    "            # noise = torch.randn((batch_size, latent_vector_size, 1, 1), device=device)\n",
    "            fake_data = torch.zeros(( current_batch_size,), device=ModelArgs.device)\n",
    "            mask_generated_by_generatorX = generatorX(X)\n",
    "\n",
    "            #1. Forward pass\n",
    "            y_pred = discriminatorY(mask_generated_by_generatorX.detach())\n",
    "\n",
    "\n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss_fake = loss_fn(y_pred, fake_data)\n",
    "            \n",
    "            \n",
    "            discriminatorY_combined_loss = (loss_real + loss_fake) \n",
    "            \n",
    "            discriminator_combined_loss = (discriminatorX_combined_loss + discriminatorY_combined_loss) * 0.5\n",
    "            \n",
    "            \n",
    "            # 4. Loss backward\n",
    "            d_scaler.scale(discriminator_combined_loss).backward()\n",
    "            \n",
    "            # 5. Optimizer step\n",
    "            d_scaler.step(optimizerD)\n",
    "            d_scaler.update()\n",
    "            \n",
    "\n",
    "        ###########################\n",
    "        # Generator Training\n",
    "        ##########################\n",
    "        with torch.cuda.amp.autocast():\n",
    "            #Disabling the discriminators trainable ability \n",
    "            for params in discriminatorX.parameters():\n",
    "                params.requires_grad = False\n",
    "            \n",
    "            #Disabling the discriminators trainable ability \n",
    "            for params in discriminatorY.parameters():\n",
    "                params.requires_grad = False\n",
    "                \n",
    "            # mask_generated_by_generator = unet(X)\n",
    "            labels = torch.ones((current_batch_size,), device=ModelArgs.device)\n",
    "\n",
    "            #1. Forward pass\n",
    "            y_pred = discriminatorX(mask_generated_by_generatorY)\n",
    "            # y_pred = torch.argmax(probs, dim=1).type(torch.float32)\n",
    "\n",
    "\n",
    "            #2. Calculate and accumulate loss\n",
    "            loss_geny = loss_fn(y_pred,labels) \n",
    "            \n",
    "    \n",
    "            # mask_generated_by_generator = unet(X)\n",
    "            labels = torch.ones((current_batch_size,), device=ModelArgs.device)\n",
    "\n",
    "            #1. Forward pass\n",
    "            y_pred = discriminatorY(mask_generated_by_generatorX)\n",
    "            # y_pred = torch.argmax(probs, dim=1).type(torch.float32)\n",
    "\n",
    "\n",
    "            #2. Calculate and accumulate loss\n",
    "            loss_genx = loss_fn(y_pred,labels) \n",
    "            # print(loss_geny)\n",
    "            # print(loss_genx)\n",
    "            # print(nn.functional.l1_loss(mask_generated_by_generatorY, X))\n",
    "            # print(nn.functional.l1_loss(mask_generated_by_generatorX, y))\n",
    "            identity_genx = nn.functional.l1_loss(mask_generated_by_generatorX, y)\n",
    "            identity_geny = nn.functional.l1_loss(mask_generated_by_generatorY, X)\n",
    "            combined_generator_loss = (loss_geny + loss_genx + identity_genx + identity_geny) +  ModelArgs.lambda_gen * (nn.functional.l1_loss(mask_generated_by_generatorY, X) + nn.functional.l1_loss(mask_generated_by_generatorX, y))\n",
    "\n",
    "            # 3. Optimizer zero grad\n",
    "            optimizerG.zero_grad()\n",
    "\n",
    "            # 4. Loss backward\n",
    "            g_scaler.scale(combined_generator_loss).backward()\n",
    "\n",
    "            # 5. Optimizer step\n",
    "            g_scaler.step(optimizerG)\n",
    "            g_scaler.update()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if iters % 200 == 0:\n",
    "            print(\"Iterations: \", iters, \"Epoch: \", epoch, \"Generator loss: \", combined_generator_loss.item(), \"Discriminator loss: \", discriminator_combined_loss.item())\n",
    "\n",
    "    \n",
    "        if iters % 500 == 0:\n",
    "            \n",
    "            print('saving the output')\n",
    "            torchvision.utils.save_image(X* 0.5 + 0.5,'{}/realB_images_iters_{}.png'.format(save_images, iters))\n",
    "            torchvision.utils.save_image(y* 0.5 + 0.5,'{}/realA_images_iters_{}.png'.format(save_images, iters))\n",
    "            # fakeA = generatorX(X)\n",
    "            # fakeB = generatorY(y)\n",
    "            torchvision.utils.save_image(mask_generated_by_generatorX* 0.5 + 0.5,'{}/fake_imageA_iters_{}.png'.format(save_images, iters))\n",
    "            torchvision.utils.save_image(mask_generated_by_generatorY* 0.5 + 0.5,'{}/fake_imageB_iters_{}.png'.format(save_images, iters))\n",
    "\n",
    "\n",
    "            img_grid_fakeA = torchvision.utils.make_grid(mask_generated_by_generatorX, normalize=True)\n",
    "            img_grid_fakeB = torchvision.utils.make_grid(mask_generated_by_generatorY, normalize=True)\n",
    "            # img_grid_map = torchvision.utils.make_grid(X, normalize=True)\n",
    "                \n",
    "            writer_fake.add_image(\n",
    "                        \"Cityscapes2lables FakeA Images\", img_grid_fakeA, global_step=iters\n",
    "                    )\n",
    "            writer_real.add_image(\n",
    "                        \"Cityscapes2lables FakeB Images\", img_grid_fakeB, global_step=iters\n",
    "                    )\n",
    "            \n",
    "            # writer_real.add_image(\n",
    "            #             \"Map2Aerial Aerial Images\", img_grid_map, global_step=iters\n",
    "            #         )\n",
    "                    \n",
    "\n",
    "            # Check pointing for every epoch\n",
    "            # torch.save(generator.state_dict(), 'weights/CelebA/generator_steps_%d.pth' % (iters))\n",
    "            # torch.save(discriminator.state_dict(), 'weights/CelebA/discriminator_steps_%d.pth' % (iters))\n",
    "\n",
    "\n",
    "        iters += 1\n",
    "        \n",
    "    scheduler.step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
